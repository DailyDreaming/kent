# This file describes how we made the browser database on the mouse
# genome, June 2003 build. - Mm4
#
#	Things to watch out for mm4 build:
#	the usual location of /cluster/store2 has changed to /cluster/store5
#	Thus, the usual NFS server machine was kkstore is now eieio
#	Therefore, for I/O intensive operations, work on eieio
#	Due to the global replace of mm3 with mm4, some comment
#	references may not be correct.

# NOTE: The README_PREBUILD file for this assembly mentions several
# differences from the previous release (build 30):
# 1. seq_contig.md - new first line is a comment containing column name
#       Also, last two columns (group label and weight, have been swapped)
#       Also, some lines have id with CONTIG: prepended, and upper-case
#               feature type (CONTIG)
# 2. contig.idmap - has an additional column "contig label"
# This required changing the jkStuff ncbi* utilities (7/1/03 KRR)
#
# NOTE: Y chrom was left out of original release at NCBI, and so was
# added in later, and database reloads were performed to include Y. 7/8/03 KRR

# DOWNLOAD THE MOUSE SEQUENCE FROM NCBI (DONE 2003-06-17 - Hiram)
    ssh eieio
    mkdir -p /cluster/store5/mm.2003.06/ncbi
    cd /cluster/store5/mm.2003.06/ncbi
    mkdir chrfasta contigfasta
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_31
      prompt
      bin
      mget *
      quit
    gunzip *.agp.gz

# Check chromosome files
    cd chrfasta
    cp /dev/null faSize.out
    foreach f (*.fa)
        echo $f >> faSize.out
        /cluster/bin/i386/faSize $f >> faSize.out
    end
   /cluster/bin/i386/faSize *.fa >> faSize.out
   gzip *.fa


# GET MISSING FILES FROM NCBI (DONE 2003-07-01 - Kate)
    # These were left out of the original release,
    # and were provided on 6/30/03.
    cd /cluster/store5/mm.2003.06/ncbi
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_31
      prompt
      bin
      mget contig_overlaps.agp.gz  ctg_coords.gz seq_contig.md.gz README_PREBUILD
      quit    
      gunzip contig_overlaps.agp.gz ctg_coords.gz seq_contig.md.gz

# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (DONE 2003-06-18 - hc)

    # This version of the mouse sequence data is in 
    # /cluster/store5/mm.2003.06/mm4/assembly
    # This will split the mouse sequence into approx. 5 Mbase supercontigs 
    # between non-bridged clone contigs and drop the resulting dir structure 
    # in /cluster/store5/mm.2003.06/mm4.
    # The resulting dir structure will include 1 dir for each chromosome, 
    # each of which has a set of subdirectories, one subdir per supercontig. 

    ssh eieio
    mkdir /cluster/store5/mm.2003.06/mm4
    ln -s /cluster/store5/mm.2003.06/mm4 /cluster/data/mm4
    cd /cluster/store5/mm.2003.06/mm4
    # splitFaIntoContigs doesn't do right with agp lines arriving in a 
    # different order than fasta chrom sequences.  so split up the agp 
    # into one per chrom.
    foreach c ( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Y Un )
      mkdir $c
      if (! -e /cluster/store5/mm.2003.06/ncbi/chrfasta/chr$c.fa.gz) then
        continue
      endif
      perl -we "while(<>){if (/^chr$c\t/) {print;}}" \
        ../ncbi/allrefcontig.chr.agp \
        > $c/chr$c.agp
      gunzip -c /cluster/store5/mm.2003.06/ncbi/chrfasta/chr$c.fa.gz \
        | perl -wpe 's/^>lcl\|(chr\w+)\.fa.*/>$1/' \
        | splitFaIntoContigs $c/chr$c.agp \
          stdin /cluster/store5/mm.2003.06/mm4 -nSize=5000000
    end
    # NOTE: no chrUn (only random)


# CREATE CHROM-LEVEL AGP AND FASTA FOR _RANDOMS (2003-07-02 Kate)
    ssh eieio
    cd /cluster/store5/mm.2003.06/ncbi

    # reorder random contigs in allrefcontig agp file to match seq_contig.md
    # this is required by the ncbiToRandomAgps scripts
    ../mm4/jkStuff/ncbiFixAgp allrefcontig.chr.agp > \
                        allrefcontig.chr.ordered.agp
    ../mm4/jkStuff/ncbiToRandomAgps seq_contig.md allrefcontig.chr.ordered.agp \
                        contig.idmap ../mm4
        # creating ../mm4/1/chr1_random.agp...
        # ... creating ../mm4/Un/chrUn_random.agp...

    cd /cluster/store5/mm.2003.06/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.ctg.agp) then
        echo building $c/chr${c}_random.fa
        gunzip -c ../ncbi/contigfasta/chr$c.fa.gz \
          | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
          > ./tmp.fa
        agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
          $c/chr${c}_random.fa ./tmp.fa
        rm tmp.fa
      endif
    end
        # building 1/chr1_random.fa
        # Writing 8573794 bases to 1/chr1_random.fa ...
        # building 19/chr19_random.fa
        # Writing 2953240 bases to 19/chr19_random.fa
        # building Un/chrUn_random.fa
        # Program error: trying to allocate 1444837753 bytes in needLargeMem
        # agpToFa: memalloc.c:82: needLargeMem: Assertion `0' failed.
        # 20 minutes or so

    # Rebuild chrUn
    # With 50000-long gaps in between, chrUn is just 
    # too damn big to fit in memory on any of our machines!!  So use a 
    # gap size of 1000 (OK with Jim and Terry) just for chrUn.  
    cd /cluster/store5/mm.2003.06/ncbi
    ../mm4/jkStuff/ncbiToRandomAgps -gapLen 1000 -chrom Un \
      seq_contig.md allrefcontig.chr.ordered.agp contig.idmap ../mm4
    cd /cluster/store5/mm.2003.06/mm4
    set c=Un
    echo building $c/chr${c}_random.fa
    gunzip -c ../ncbi/contigfasta/chr$c.fa.gz \
      | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
      > ./tmp.fa
    agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
      $c/chr${c}_random.fa ./tmp.fa
    rm tmp.fa
        # Writing 85430752 bases to Un/chrUn_random.fa

    # Clean these up to avoid confusion later... they're easily rebuilt.
    rm ?{,?}/*.ctg.agp


# BREAK UP _RANDOMS INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (2003-07-02 Kate)
    ssh eieio
    cd /cluster/store5/mm.2003.06/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.agp) then
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end


# MAKE LIFTALL.LFT (DONE 2003-07-04 kate)

    # remove spurious files for chrUn (should only be chrUn_random)
    cd /cluster/data/mm4
    rm Un/lift/o*
    cat ?{,?}/lift/{ordered,random}.lft > liftAll.lft


# CREATING DATABASE (DONE - 2003-06-18 - Hiram)

o - Create the database.
    ssh hgwdev
    echo 'create database mm4' | hgsql ''
    # if you need to delete this database:  !!! WILL DELETE EVERYTHING !!!
    #	echo 'drop database mm4' | hgsql ce1
        alias mm4 "mysql -u hguser -phguserstuff -A mm4"
o - Use df to make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    # [hiram@hgwdev /] df -h /var/lib/mysql
    # Filesystem            Size  Used Avail Use% Mounted on
    # /dev/sda1             472G  378G   69G  85% /var/lib/mysql


# CREATING GRP TABLE FOR TRACK GROUPING (DONE - 2003-06-18 - Hiram)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from mm3.grp" \
      | hgsql mm4


# STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE - 2003-06-18 - Hiram)
# (RANDOMS ADDED, except chrUn 2003-07-01 - Kate)
# (chrUn random added  2003-07-02 - Kate)

    # Create (unmasked) nib files 
    ssh eieio
    cd /cluster/data/mm4
    mkdir -p unmaskedNib
    foreach f (?{,?}/chr?{,?}{,_random}.fa)
      echo $f:t:r
      faToNib $f unmaskedNib/$f:t:r.nib
    end
    # Create symbolic links from /gbdb/mm4/nib to real nib files
    ssh hgwdev
    mkdir -p /gbdb/mm4/nib
    foreach f (/cluster/store5/mm.2003.06/mm4/unmaskedNib/chr*.nib)
      ln -s $f /gbdb/mm4/nib
    end

    # Load /gbdb nib paths into database and save size info.
    ssh hgwdev
    hgsql mm4  < ~/src/hg/lib/chromInfo.sql
    cd /cluster/data/mm4
    hgNibSeq -preMadeNib mm4 /gbdb/mm4/nib ?{,?}/chr?{,?}{,_random}.fa
    # 2988739106 total bases
    # NOTE: mm3 was 2708220133, an increase of 280 Mb (~10%)
    echo "select chrom,size from chromInfo" | hgsql -N mm4 > chrom.sizes
    # check the resulting file chrom.sizes

Store o+o info in database.
     cd /cluster/data/mm4
     # remove so as not to confuse hgGoldGap -- they are easily regenerated
     rm */chr*.ctg.agp
     # to undo/redo: 
     #     jkStuff/dropSplitTable.csh gap
     #     jkStuff/dropSplitTable.csh gold
     hgGoldGapGl mm4 /cluster/store5/mm.2003.06 mm4 -noGl

# Make and load GC percent table
     ssh hgwdev
     mkdir -p /cluster/data/mm4/bed/gcPercent
     cd /cluster/data/mm4/bed/gcPercent
     hgsql mm4  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent mm4 ../../unmaskedNib


# ADD MAP CONTIGS TRACK (2003-07-03 Kate)
    ssh hgwdev
    mkdir -p ~/mm4/bed/ctgPos
    cd ~/mm4/bed/ctgPos
    # hgCtgPos uses the lift files... but mouse lift files are for the 
    # 5MB contigs from splitFaIntoContigs, not for the real NT_ contigs 
    # from the assembly.  (In the future, we should go with the NT's!)  
    # So... just for this release, go straight from the seq_contig.md 
    # to the table def'n: contig, size, chrom, chromStart, chromEnd 
    perl -we \
     'while (<>) { \
        if (/^\d+\s+(\w+)\s+(\d+)\s+(\d+)\s+\S+\s+(NT_\d+)\s+.*ref_strain/) { \
          $chr=$1; $start=$2; $start -= 1; $end=$3; $ctg=$4; \
          print "$ctg\t" . ($end-$start) . "\tchr$chr\t$start\t$end\n"; \
        } \
      }' /cluster/store5/mm.2003.06/ncbi/seq_contig.md \
    > ctgPos.tab
    hgsql mm4 < ~/kent/src/hg/lib/ctgPos.sql
    echo "load data local infile 'ctgPos.tab' into table ctgPos" | hgsql mm4
    # Note: the info is there in seq_contig.md to also do the _random's, 
    # but we'd have to do some more work: duplicate the gaps of 50000 between 
    # contigs for all _random's except chrUn_random (1000 between).  


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR MM4 (DONE by Hiram)
    # Enter mm4 into hgcentraltest.dbDb so test browser knows about it:
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, defaultPos, \
         active, orderKey, genome, scientificName) \
      VALUES(
        "mm4", "June 2003", "/gbdb/mm4/nib", "Mouse", "USP18", \
         1, 30, "Mouse", "Mus musculus");' \
      | hgsql -h genome-testdb hgcentraltest
    #	If you need to delete that entry:
    	echo 'delete from dbDb where name="mm4";' \
    		 hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add mm4 in all the right places and do
    make update
    make alpha
    cvs commit makefile


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR MM4 (mm4 SERVER REQUESTED 2003-06-18)
    ssh hgwdev
    echo 'insert into blatServers values("mm4", "blat9", "17778", "1"); \
          insert into blatServers values("mm4", "blat9", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


# REPEAT MASKING (DONE 2003-07-04 kate)
   # Split contigs, run RepeatMasker, lift results
   # Notes: 
   # * If there is a new version of RepeatMasker, build it and ask the admins 
   #   to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
   # * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
   #   RepeatMasker runs manageable on the cluster ==> results need lifting.
   # * For the NCBI assembly we repeat mask on the sensitive mode setting
   #  (RepeatMasker -m -s -ali)

      #- Split contigs into 500kb chunks:
        ssh eieio
        cd ~/mm4
        foreach d ( */chr?{,?}{,_random}_?{,?} )
          cd $d
          set contig = $d:t
          faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -maxN=500000
          cd ../..
        end

        #- Make the run directory and job list:

        cd ~/mm4
    cat << '_EOF_' > jkStuff/RMMouse
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/$USER/$2
/bin/cp $2 /tmp/$USER/$2/
cd /tmp/$USER/$2
/cluster/bluearc/RepeatMasker030619/RepeatMasker -ali -s -m $2   
popd
/bin/cp /tmp/$USER/$2/$2.out ./
if (-e /tmp/$USER/$2/$2.align) /bin/cp /tmp/$USER/$2/$2.align ./
# /bin/cp /tmp/$2*.masked ../masked/
/bin/rm -r /tmp/$USER
'_EOF_'
        chmod +x jkStuff/RMMouse

        mkdir -p RMRun
        rm -f RMRun/RMJobs
        touch RMRun/RMJobs
        foreach d ( ?{,?}/chr*_?{,?} )
          foreach f ( $d/chr*_?{,?}_?{,?}.fa )
            set f = $f:t
            echo /cluster/store5/mm.2003.06/mm4/jkStuff/RMMouse \
                 /cluster/store5/mm.2003.06/mm4/$d $f \
               '{'check out line+ /cluster/store5/mm.2003.06/mm4/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
        end

        #- Do the run
        ssh kk
        cd ~/mm4/RMRun
        para create RMJobs
        para try, para check, para check, para push, para check,...
        # total elapsed time ~16 hours
        # longest job ~5 hours

        #- Lift up the split-contig .out's to contig-level .out's
	ssh eieio
        cd ~/mm4
        foreach d ( ?{,?}/chr*_?{,?} )
          cd $d
          set contig = $d:t
          liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
          cd ../..
        end

        #- Lift up the contig-level .out's to chr-level
        cd ~/mm4
        ./jkStuff/liftOut5.sh

        #- Load the .out files into the database with:
        ssh hgwdev
        cd ~/mm4
        # to redo:
        #    ./jkStuff/dropSplitTable.csh rmsk  
        # make sure there's no chrUn -- rm Un/chrUn.fa.out
        hgLoadOut mm4 ?/*.fa.out ??/*.fa.out


# VERIFY REPEATMASKER RESULTS (DONE 2003-7-04 kate)

    # Run featureBits on mm4 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits mm4 rmsk
        # 1209759437 bases of 2804814251 (43.132%) in intersection

    featureBits mm3 rmsk
        # 1080265553 bases of 2505900260 (43.109%) in intersection


# SIMPLE REPEAT TRACK (DONE 200-07-06 kate)
    # Instructions below are for run on fileserver.
    # TRF can be run on fileserver
    # in parallel with RepeatMasker on cluster, since it
    # doesn't require masked input sequence.
    ssh eieio
    mkdir ~/mm4/bed/simpleRepeat
    cd ~/mm4/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    touch jobs.csh
    # create job list of 5MB chunks
    foreach f \
       (/cluster/store5/mm.2003.06/mm4/?{,?}/chr?{,?}_[0-9]*/chr?{,?}_?{,?}.fa \
       /cluster/store5/mm.2003.06/mm4/?{,?}/chr*_random_?{,?}/chr*_random_?{,?}.fa)
      set fout = $f:t:r.bed
      echo "/cluster/bin/i386/trfBig -trf=/cluster/home/kent/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    wc -l jobs.csh
        #   598 jobs.csh

    tcsh jobs.csh >&! jobs.log &
    tail -f jobs.log
    #OR tcsh jobs.csh |& tee jobs.log

    ls -1 trf | wc -l
        #    598
        #    602 after adding Y chrom

    # When job is done lift output files
    liftUp simpleRepeat.bed ~/mm4/liftAll.lft warn trf/*.bed

    # Load into the database
    ssh hgwdev
    cd ~/mm4/bed/simpleRepeat
    hgLoadBed mm4 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
        # Loaded 1219874 elements


# PROCESS SIMPLE REPEATS INTO MASK (DONE 2003-07-06 kate)

    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd ~/mm4/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

    # Lift up filtered trf output to chrom coords
    cd ~/mm4
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
        $c/lift/ordered.lst > $c/lift/oTrf.lst
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
        liftAll.lft warn `cat $c/lift/oTrf.lst`
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # NOTE: ignore warning about non-existent Un/Lift/ordered.lift
    # since there is no chrUn
    

# MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 2003-07-08 kate)
    ssh eieio
    cd ~/mm4
    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh jkStuff/makeFaMasked.sh >&! maskFa.out &
    tail -100f maskFa.out

    #- Make hard-masked .fa.masked files as well:
    tcsh jkStuff/makeHardMasked.sh

    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh jkStuff/makeNib.sh
    # ignore complaints about missing chrUn

    # Redo symbolic links from /gbdb/mm4/nib to 
    #   mixed (RM and TRF) soft-masked nib files
    ssh hgwdev
    rm -fr /gbdb/mm4/nib/*
    foreach f (/cluster/store5/mm.2003.06/mm4/mixedNib/chr*.nib)
      ln -s $f /gbdb/mm4/nib
    end

    # Copy data to /cluster/bluearc for cluster runs
    ssh eieio

    # masked contigs
    rm -fr /cluster/bluearc/mm4/trfFa
    mkdir -p /cluster/bluearc/mm4/trfFa
    # cp -p ~/mm4/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /cluster/bluearc/mm4/trfFa
    cp ~/mm4/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /cluster/bluearc/mm4/trfFa

    # masked chrom nibs
    cd ~/mm4
    rm -fr /cluster/bluearc/mm4/mixedNib
    mkdir -p /cluster/bluearc/mm4/mixedNib
    cp -p mixedNib/chr*.nib /cluster/bluearc/mm4/mixedNib

    # lift file, for mrna processing
    cp -p liftAll.lft /cluster/bluearc/mm4

    # also copy to iservers
    ssh kkr1u00
    cd ~/mm4
    cp -p liftAll.lft /iscratch/i/mm4
    mkdir -p /iscratch/i/mm4/mixedNib
    cp -p mixedNib/chr*.nib /cluster/bluearc/mm4/mixedNib
    /cluster/bin/scripts/iSync


# AUTO UPDATE GENBANK MRNA RUN  (IN PROGRESS - 2003-07-07 - kate)

    ssh eieio
    cd /cluster/store5/genbank
    set db = mm4
    # set nibGlob = '/cluster/bluearc/mm4/mixedNib/chr*.nib'
    # set liftFile = /cluster/bluearc/$db/liftAll.lft
    # make sure 'ssh localhost' works before running this:
    # NOTE: initially just align RefSeq, for speed
    # nice bin/gbAlignStep -verbose=1 -initial -iserver=localhost \
        # -clusterdir=/cluster/bluearc/genbank/work \
        # -srcDb=refseq -type=mrna $db "$nibGlob" $liftFile &
    set nibGlob = '/iscratch/i/mm4/mixedNib/chr*.nib'
    set liftFile = /iscratch/i/$db/liftAll.lft
     nice bin/gbAlignStep -verbose=1 -initial \
         -clusterdir=/iscratch/i/genbank/work \
         -omit-iserver=kkr5u00 -omit-iserver=kkr6u00 \
         -srcDb=refseq -type=mrna $db "$nibGlob" $liftFile &

    # To watch the progress of your cluster job, go to machine kk and
    # cd /cluster/store5/genbank/work/initial.mm4/align
    # where the batch file is.  You can now do normal parasol checking
    # operations.  Beware of "para check" it can take quite a bit of time
    # if your batch job is very large.  'parasol list batches' or
    # 'parasol list users' may be quicker to take a look at status.

    #  After that is finished successfully, load the mRNAs:
    #  The drop and load is faster if tables have been loaded before.
    ssh hgwdev
    cd /cluster/store5/genbank
    ./bin/i386/gbLoadRna -drop mm4
    nice ./bin/gbDbLoadStep -verbose=1 -initialLoad mm4


