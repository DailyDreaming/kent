# This file describes how we made the browser database on the mouse
# genome, October 2003 build. - Mm4
#
#
#	NOTE:  There is a new chrMT sequence in the build 32
#	>gi|34538597|ref|NC_005089.1| Mus musculus mitochondrion
#
#   Will have to beware of this NC_ contig in the processing since
#	all previous builds had only NT_ contigs
#
# DOWNLOAD THE MOUSE SEQUENCE FROM NCBI (DONE 2003-10-16 - Hiram)
    ssh kksilo
    mkdir -p /cluster/store6/mm4/ncbi
    ln -s /cluster/store6/mm4 /cluster/data
    cd /cluster/data/mm4/ncbi
    mkdir chrfasta contigfasta
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_32
      prompt
      bin
      mget *
      quit
    gunzip *.agp.gz

# Check chromosome files  (DONE 2003-10-19 - Hiram)
    cd chrfasta
    foreach f (*.fa.gz)
        echo $f:r >> faSize.out
	gunzip $f
        /cluster/bin/i386/faSize $f:r >> faSize.out
	echo $f:r done
    end
   /cluster/bin/i386/faSize *.fa >> faSize.out
   grep "^>" *.fa > ../chrfasta.all.fa.headers
   gzip *.fa



# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (DONE 2003-10-16 - Hc)
    ssh kksilo
    cd /cluster/data/mm4
    gunzip ncbi/allrefcontig.chr.agp.gz
    # splitFaIntoContigs doesn't do right with agp lines arriving in a 
    # different order than fasta chrom sequences.  so split up the agp 
    # into one per chrom.
    foreach c ( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Y MT )
      mkdir $c
      perl -we "while(<>){if (/^chr$c\t/) {print;}}" \
        ./ncbi/allrefcontig.chr.agp \
        > $c/chr$c.agp
      gunzip -c ./ncbi/chrfasta/chr$c.fa.gz \
        | perl -wpe 's/^>lcl\|(chr\w+)\.fa.*/>$1/' \
        | splitFaIntoContigs $c/chr$c.agp \
          stdin /cluster/data/mm4 -nSize=5000000
    end
    gzip ncbi/chrfasta/chr*.fa

# CREATE CHROM-LEVEL AGP AND FASTA FOR _RANDOMS (DONE 2003-10-17 Hiram)
    ssh kksilo
    cd /cluster/data/mm4/ncbi

    gunzip seq_contig.md.gz

    mkdir ../Un
    # reorder random contigs in allrefcontig agp file to match seq_contig.md
    # this is required by the ncbiToRandomAgps scripts
    ../jkStuff/ncbiFixAgp allrefcontig.chr.agp > \
                        allrefcontig.chr.ordered.agp
    ../jkStuff/ncbiToRandomAgps seq_contig.md allrefcontig.chr.ordered.agp \
                        contig.idmap ..
        # creating ../mm4/1/chr1_random.agp...
        # ... creating ../mm4/Un/chrUn_random.agp...
    # had to fixup ncbiToRandomAgps to match the lines better, and to
    #	do the MT/NC_ mitochondrion thing

    ssh kksilo
    cd /cluster/data/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.ctg.agp) then
        echo building $c/chr${c}_random.fa
        gunzip -c ./ncbi/contigfasta/chr$c.fa.gz \
          | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
          > ./tmp.fa
        agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
          $c/chr${c}_random.fa ./tmp.fa
        rm tmp.fa
      endif
    end
        # building 1/chr1_random.fa
	# ... etc ...

#	Program error: trying to allocate 1446087545 bytes in needLargeMem
#	agpToFa: memalloc.c:82: needLargeMem: Assertion `0' failed.
#	Abort
#	The above breaks the chrUn build, try this on kolossus:
    ssh kolossus
    cd kent.x86_64/src/hg/agpToFa
    make

    cd /cluster/data/mm4
    foreach c (Un)
      if (-e $c/chr${c}_random.ctg.agp) then
        echo building $c/chr${c}_random.fa
        gunzip -c ./ncbi/contigfasta/chr$c.fa.gz \
          | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
          > ./tmp.fa
        $HOME/bin/x86_64/agpToFa -simpleMulti \
		$c/chr${c}_random.ctg.agp chr${c}_random \
          $c/chr${c}_random.fa ./tmp.fa
        rm tmp.fa
      endif
    end
#	That worked on kolossus after adding:
#if defined(MACHTYPE_x86_64)
static size_t maxAlloc = 8LL*1024LL*1024LL*1024LL;
#else
static size_t maxAlloc = 128*4*1024*1024;
#endif
#	To src/lib/memalloc.c

    # Clean these up to avoid confusion later... they're easily rebuilt.
    rm ?{,?}/*.ctg.agp

# BREAK UP _RANDOMS INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (2003-07-02 Kate)
    ssh kksilo
    cd /cluster/data/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.agp) then
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end
    #  This has a lot of output.  It is difficult to see if anything
    #	goes wrong.  It fails on the chrUn:
Processing agpFile Un/chrUn_random.agp and fasta file Un/chrUn_random.fa, with nonbridged split boundaries of 5000000 bases, bridged split boundaries of 0 bases
Out of memory - request size 1073741824 bytes

mv: can't stat source Un_random/lift/oOut.lst
mv: can't stat source Un_random/lift/ordered.lft
mv: can't stat source Un_random/lift/ordered.lst
rmdir: `Un_random/lift': No such file or directory
rm: cannot lstat `Un_random/chrUn_random.agp': No such file or directory
rm: cannot lstat `Un_random/chrUn_random.fa': No such file or directory
mv: No match.
rmdir: `Un_random': No such file or directory

    #	This might not be a good idea.  I started this on kolossus and
    #	it has been running for over an hour, consuming CPU time but
    #	seemingly not getting anywhere.
    #	try it on kolossus
    ssh kolossus
    cd kent.x86_64/src/hg/splitFaIntoContigs
    make

    cd /cluster/data/mm4
    foreach c (Un)
      if (-e $c/chr${c}_random.agp) then
        $HOME/bin/x86_64/splitFaIntoContigs $c/chr${c}_random.agp \
	$c/chr${c}_random.fa . -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end


XXXX  -----   all below is old data for reference only  XXXXXXXXXX
XXXX	The sections below will be deleted as they are performed above

# NOTE: The README_PREBUILD file for this assembly mentions several
# differences from the previous release (build 30):
# 1. seq_contig.md - new first line is a comment containing column name
#       Also, last two columns (group label and weight, have been swapped)
#       Also, some lines have id with CONTIG: prepended, and upper-case
#               feature type (CONTIG)
# 2. contig.idmap - has an additional column "contig label"
# This required changing the jkStuff ncbi* utilities (7/1/03 KRR)
#
# NOTE: Y chrom was left out of original release at NCBI, and so was
# added in later, and database reloads were performed to include Y. 7/8/03 KRR


XXXXXX


# BREAK UP _RANDOMS INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (2003-07-02 Kate)
    ssh eieio
    cd /cluster/store5/mm.2003.06/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.agp) then
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end


# MAKE LIFTALL.LFT (DONE 2003-07-04 kate)

    # remove spurious files for chrUn (should only be chrUn_random)
    cd /cluster/data/mm4
    rm Un/lift/o*
    cat ?{,?}/lift/{ordered,random}.lft > liftAll.lft


# CREATING DATABASE (DONE - 2003-06-18 - Hiram)

o - Create the database.
    ssh hgwdev
    echo 'create database mm4' | hgsql ''
    # if you need to delete this database:  !!! WILL DELETE EVERYTHING !!!
    #	echo 'drop database mm4' | hgsql ce1
        alias mm4 "mysql -u hguser -phguserstuff -A mm4"
o - Use df to make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    # [hiram@hgwdev /] df -h /var/lib/mysql
    # Filesystem            Size  Used Avail Use% Mounted on
    # /dev/sda1             472G  378G   69G  85% /var/lib/mysql


# CREATING GRP TABLE FOR TRACK GROUPING (DONE - 2003-06-18 - Hiram)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from mm3.grp" \
      | hgsql mm4


# STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE - 2003-06-18 - Hiram)
# (RANDOMS ADDED, except chrUn 2003-07-01 - Kate)
# (chrUn random added  2003-07-02 - Kate)

    # Create (unmasked) nib files 
    ssh eieio
    cd /cluster/data/mm4
    mkdir -p unmaskedNib
    foreach f (?{,?}/chr?{,?}{,_random}.fa)
      echo $f:t:r
      faToNib $f unmaskedNib/$f:t:r.nib
    end
    # Create symbolic links from /gbdb/mm4/nib to real nib files
    ssh hgwdev
    mkdir -p /gbdb/mm4/nib
    foreach f (/cluster/store5/mm.2003.06/mm4/unmaskedNib/chr*.nib)
      ln -s $f /gbdb/mm4/nib
    end

    # Load /gbdb nib paths into database and save size info.
    ssh hgwdev
    hgsql mm4  < ~/src/hg/lib/chromInfo.sql
    cd /cluster/data/mm4
    hgNibSeq -preMadeNib mm4 /gbdb/mm4/nib ?{,?}/chr?{,?}{,_random}.fa
    # 2988739106 total bases
    # NOTE: mm3 was 2708220133, an increase of 280 Mb (~10%)
    echo "select chrom,size from chromInfo" | hgsql -N mm4 > chrom.sizes
    # check the resulting file chrom.sizes

    # Store o+o info in database.  # (REDO with fully gapped random chrom AGP's  2003-07-14 kate)
     cd /cluster/data/mm4
     # remove so as not to confuse hgGoldGap -- they are easily regenerated
     rm */chr*.ctg.agp
     # to undo/redo: 
     #     jkStuff/dropSplitTable.csh gap
     #     jkStuff/dropSplitTable.csh gold
     /cluster/bin/i386/hgGoldGapGl mm4 /cluster/store5/mm.2003.06 mm4 -noGl
     featureBits mm4 gold
        # 2819804865 bases of 2819804865 (100.000%) in intersection
     featureBits mm3 gold
       # 2505900260 bases of 2505900260 (100.000%) in intersection

     featureBits mm4 gap
        # 168934241 bases of 2819804865 (5.991%) in intersection
     featureBits mm3 gap
        # 202319873 bases of 2505900260 (8.074%) in intersection


# Make and load GC percent table
     ssh hgwdev
     mkdir -p /cluster/data/mm4/bed/gcPercent
     cd /cluster/data/mm4/bed/gcPercent
     hgsql mm4  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent mm4 ../../unmaskedNib


# ADD MAP CONTIGS TRACK (2003-07-03 Kate)
    ssh hgwdev
    mkdir -p ~/mm4/bed/ctgPos
    cd ~/mm4/bed/ctgPos
    # hgCtgPos uses the lift files... but mouse lift files are for the 
    # 5MB contigs from splitFaIntoContigs, not for the real NT_ contigs 
    # from the assembly.  (In the future, we should go with the NT's!)  
    # So... just for this release, go straight from the seq_contig.md 
    # to the table def'n: contig, size, chrom, chromStart, chromEnd 
    perl -we \
     'while (<>) { \
        if (/^\d+\s+(\w+)\s+(\d+)\s+(\d+)\s+\S+\s+(NT_\d+)\s+.*ref_strain/) { \
          $chr=$1; $start=$2; $start -= 1; $end=$3; $ctg=$4; \
          print "$ctg\t" . ($end-$start) . "\tchr$chr\t$start\t$end\n"; \
        } \
      }' /cluster/store5/mm.2003.06/ncbi/seq_contig.md \
    > ctgPos.tab
    hgsql mm4 < ~/kent/src/hg/lib/ctgPos.sql
    echo "load data local infile 'ctgPos.tab' into table ctgPos" | hgsql mm4
    # Note: the info is there in seq_contig.md to also do the _random's, 
    # but we'd have to do some more work: duplicate the gaps of 50000 between 
    # contigs for all _random's except chrUn_random (1000 between).  


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR MM4 (DONE by Hiram)
    # Enter mm4 into hgcentraltest.dbDb so test browser knows about it:
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, defaultPos, \
         active, orderKey, genome, scientificName) \
      VALUES(
        "mm4", "June 2003", "/gbdb/mm4/nib", "Mouse", "USP18", \
         1, 30, "Mouse", "Mus musculus");' \
      | hgsql -h genome-testdb hgcentraltest
    #	If you need to delete that entry:
    	echo 'delete from dbDb where name="mm4";' \
    		 hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add mm4 in all the right places and do
    make update
    make alpha
    cvs commit makefile


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR MM4 (DONE 2003-07-13 kate)
    ssh hgwdev
    echo 'INSERT INTO blatServers (db, host, port, isTrans) \
                VALUES ("mm4", "blat10", "17778", "1"); \
          INSERT INTO blatServers (db, host, port, isTrans) \
                VALUES ("mm4", "blat", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


# REPEAT MASKING (DONE 2003-07-04 kate)
   # Split contigs, run RepeatMasker, lift results
   # Notes: 
   # * If there is a new version of RepeatMasker, build it and ask the admins 
   #   to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
   # * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
   #   RepeatMasker runs manageable on the cluster ==> results need lifting.
   # * For the NCBI assembly we repeat mask on the sensitive mode setting
   #  (RepeatMasker -m -s -ali)

      #- Split contigs into 500kb chunks:
        ssh eieio
        cd ~/mm4
        foreach d ( */chr?{,?}{,_random}_?{,?} )
          cd $d
          set contig = $d:t
          faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -maxN=500000
          cd ../..
        end

        #- Make the run directory and job list:

        cd ~/mm4
    cat << '_EOF_' > jkStuff/RMMouse
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/$USER/$2
/bin/cp $2 /tmp/$USER/$2/
cd /tmp/$USER/$2
/cluster/bluearc/RepeatMasker030619/RepeatMasker -ali -s -m $2   
popd
/bin/cp /tmp/$USER/$2/$2.out ./
if (-e /tmp/$USER/$2/$2.align) /bin/cp /tmp/$USER/$2/$2.align ./
# /bin/cp /tmp/$2*.masked ../masked/
/bin/rm -r /tmp/$USER
'_EOF_'
        chmod +x jkStuff/RMMouse

        mkdir -p RMRun
        rm -f RMRun/RMJobs
        touch RMRun/RMJobs
        foreach d ( ?{,?}/chr*_?{,?} )
          foreach f ( $d/chr*_?{,?}_?{,?}.fa )
            set f = $f:t
            echo /cluster/store5/mm.2003.06/mm4/jkStuff/RMMouse \
                 /cluster/store5/mm.2003.06/mm4/$d $f \
               '{'check out line+ /cluster/store5/mm.2003.06/mm4/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
        end

        #- Do the run
        ssh kk
        cd ~/mm4/RMRun
        para create RMJobs
        para try, para check, para check, para push, para check,...
        # total elapsed time ~16 hours
        # longest job ~5 hours

        #- Lift up the split-contig .out's to contig-level .out's
	ssh eieio
        cd ~/mm4
        foreach d ( ?{,?}/chr*_?{,?} )
          cd $d
          set contig = $d:t
          liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
          cd ../..
        end

        #- Lift up the contig-level .out's to chr-level
        cd ~/mm4
        ./jkStuff/liftOut5.sh

        #- Load the .out files into the database with:
        ssh hgwdev
        cd ~/mm4
        # to redo:
        #    ./jkStuff/dropSplitTable.csh rmsk  
        # make sure there's no chrUn -- rm Un/chrUn.fa.out
        hgLoadOut mm4 ?/*.fa.out ??/*.fa.out



# VERIFY REPEATMASKER RESULTS (DONE 2003-7-04 kate)

    # Run featureBits on mm4 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits mm4 rmsk
        # 1218703233 bases of 2819804865 (43.219%) in intersection

    featureBits mm3 rmsk
        # 1080265553 bases of 2505900260 (43.109%) in intersection


# SIMPLE REPEAT TRACK (DONE 200-07-06 kate)
    # Instructions below are for run on fileserver.
    # TRF can be run on fileserver
    # in parallel with RepeatMasker on cluster, since it
    # doesn't require masked input sequence.
    ssh eieio
    mkdir ~/mm4/bed/simpleRepeat
    cd ~/mm4/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    touch jobs.csh
    # create job list of 5MB chunks
    foreach f \
       (/cluster/store5/mm.2003.06/mm4/?{,?}/chr?{,?}_[0-9]*/chr?{,?}_?{,?}.fa \
       /cluster/store5/mm.2003.06/mm4/?{,?}/chr*_random_?{,?}/chr*_random_?{,?}.fa)
      set fout = $f:t:r.bed
      echo "/cluster/bin/i386/trfBig -trf=/cluster/home/kent/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    wc -l jobs.csh
        #   598 jobs.csh

    tcsh jobs.csh >&! jobs.log &
    tail -f jobs.log
    #OR tcsh jobs.csh |& tee jobs.log

    ls -1 trf | wc -l
        #    598
        #    602 after adding Y chrom

    # When job is done lift output files
    liftUp simpleRepeat.bed ~/mm4/liftAll.lft warn trf/*.bed

    # Load into the database
    ssh hgwdev
    cd ~/mm4/bed/simpleRepeat
    hgLoadBed mm4 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
        # Loaded 1219874 elements


# PROCESS SIMPLE REPEATS INTO MASK (DONE 2003-07-06 kate)

    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd ~/mm4/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

    # Lift up filtered trf output to chrom coords
    cd ~/mm4
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
        $c/lift/ordered.lst > $c/lift/oTrf.lst
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
        liftAll.lft warn `cat $c/lift/oTrf.lst`
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # NOTE: ignore warning about non-existent Un/Lift/ordered.lift
    # since there is no chrUn
    

# MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 2003-07-08 kate)
    ssh eieio
    cd ~/mm4
    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh jkStuff/makeFaMasked.sh >&! maskFa.out &
    tail -100f maskFa.out

    #- Make hard-masked .fa.masked files as well:
    tcsh jkStuff/makeHardMasked.sh

    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh jkStuff/makeNib.sh
    # ignore complaints about missing chrUn

    # Redo symbolic links from /gbdb/mm4/nib to 
    #   mixed (RM and TRF) soft-masked nib files
    ssh hgwdev
    rm -fr /gbdb/mm4/nib/*
    foreach f (/cluster/store5/mm.2003.06/mm4/mixedNib/chr*.nib)
      ln -s $f /gbdb/mm4/nib
    end

    # Copy data to /cluster/bluearc for cluster runs
    ssh eieio

    # masked contigs
    rm -fr /cluster/bluearc/mm4/trfFa
    mkdir -p /cluster/bluearc/mm4/trfFa
    # cp -p ~/mm4/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /cluster/bluearc/mm4/trfFa
    cp ~/mm4/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /cluster/bluearc/mm4/trfFa

    # masked chrom nibs
    cd ~/mm4
    rm -fr /cluster/bluearc/mm4/mixedNib
    mkdir -p /cluster/bluearc/mm4/mixedNib
    cp -p mixedNib/chr*.nib /cluster/bluearc/mm4/mixedNib

    # lift file, for mrna processing
    cp -p liftAll.lft /cluster/bluearc/mm4

    # also copy to iservers
    ssh kkr1u00
    cd ~/mm4
    cp -p liftAll.lft /iscratch/i/mm4
    mkdir -p /iscratch/i/mm4/mixedNib
    cp -p /cluster/bluearc/mm4/mixedNib/chr*.nib /iscratch/i/mixedNib
    mkdir -p /iscratch/i/mm4/trfFa
    cp ?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /cluster/bluearc/mm4/trfFa
    /cluster/bin/scripts/iSync


# AUTO UPDATE GENBANK MRNA RUN  (IN PROGRESS - 2003-07-07 - kate)

    ssh eieio
    cd /cluster/data/genbank
    set db = mm4
    # set nibGlob = '/cluster/bluearc/mm4/mixedNib/chr*.nib'
    # set liftFile = /cluster/bluearc/$db/liftAll.lft
    # make sure 'ssh localhost' works before running this:
    # Add mm4 entries for lift file and nib dir to 
    # /cluster/data/genbank/etc/genbank.conf
    # NOTE: initially just align RefSeq, for speed
    # nice bin/gbAlignStep -verbose=1 -initial -iserver=localhost \
    # set nibGlob = '/cluster/bluearc/mm4/mixedNib/chr*.nib'
    # set liftFile = /cluster/bluearc/mm4/liftAll.lft
    #set nibGlob = '/iscratch/i/mm4/mixedNib/chr*.nib'
    #set liftFile = /iscratch/i/$db/liftAll.lft
     nice bin/gbAlignStep -verbose=1 -initial \
         -clusterRootDir=/cluster/bluearc/genbank \
         -iserver=no \
         -srcDb=refseq -type=mrna $db &
    # -omit-iserver=kkr5u00 -omit-iserver=kkr6u00 \

    # To watch the progress of your cluster job, go to machine kk and
    # cd /cluster/store5/genbank/work/initial.mm4/align
    # where the batch file is.  You can now do normal parasol checking
    # operations.  Beware of "para check" it can take quite a bit of time
    # if your batch job is very large.  'parasol list batches' or
    # 'parasol list users' may be quicker to take a look at status.

    #  After that is finished successfully, load the mRNAs:
    #  The drop and load is faster if tables have been loaded before.
    ssh hgwdev
    cd /cluster/data/genbank
    ./bin/i386/gbLoadRna -drop mm4
    nice ./bin/gbDbLoadStep -verbose=1 -initialLoad mm4
    # check log file /cluster/data/genbank/var/build/logs/*mm4*
    # check for para problems in /cluster/bluearc/genbank/work/initial.mm4/align

    # refseq protein ids included version, which caused searches to fail.
    # clean our refseq sequences and reload:
      drop table refFlat,refGene,refLink,refSeqAli,refSeqStatus;
      delete from gbSeq where acc like 'NM_%' or acc like 'NP_%';
      delete from gbStatus where acc like 'NM_%' or acc like 'NP_%';
      delete from mrna where acc like 'NM_%';
      delete from gbLoaded where srcDb='RefSeq';
     nice ./bin/gbDbLoadStep -verbose=1 mm4
    # opps, need to clean out imageClone table too.  going to just rerun
    # gbDbLoadStep, which should clean things up.

    # Align Genbank mrna's
    # Note: next time, probably want to do this in same
    # jobs with refseq (leave out the srcDb arg)
    ssh eieio
    # clean out previous work area
    rm -fr /cluster/bluearc/genbank/work/initial.mm4
    cd /cluster/data/genbank
    nice bin/gbAlignStep -verbose=1 -initial \
         -clusterRootDir=/cluster/bluearc/genbank \
         -iserver=no \
         -srcDb=genbank -type=mrna mm4 &
    # load into database
    ssh hgwdev
    cd /cluster/data/genbank
    nice ./bin/gbDbLoadStep -verbose=1 mm4
    # after checking load, clean out build area
    rm -fr /cluster/bluearc/genbank/work/initial.mm4

    # Align everything else that still needs it (EST's)
    ssh eieio
    cd /cluster/data/genbank
    nice bin/gbAlignStep -verbose=1 -initial \
         -clusterRootDir=/cluster/bluearc/genbank \
         -iserver=no mm4 &
    # load into database
    ssh hgwdev
    cd /cluster/data/genbank
    # drop database and load all at once, for efficiency
    nice ./bin/gbDbLoadStep -drop -initalLoad -verbose=1 mm4
    # after checking load, clean out build area
    rm -fr /cluster/bluearc/genbank/work/initial.mm4

    #NOTE: jobs overdosed the bluearc
    # Recovered by moving mm4 nibs to /scratch, and restarting
    # with directions from markd:
    
    cd /cluster/bluearc/genbank/work/initial.mm4/align/
    rm -rf batch* err pararesults
    sed -e 's|/cluster/bluearc/mm4/mixedNib/|/scratch/hg/mm4/nib/|' align.jobs
    >align.edit.jobs
    para recover align.edit.jobs align.missing.jobs
    para create align.missing.jobs
    para try
    para check
    para push
    etc.


# MAKE DOWNLOADABLE SEQUENCE FILES (IN PROGRESS 2003-07-08 kate)
    ssh eieio
    cd /cluster/data/mm4

    # Build the .zip files
    jkStuff/zipAll.sh >&! zipAll.log &
    tail -f zipAll.log
    mkdir zip
    mv *.zip zip
    cd zip
    # Look at zipAll.log to make sure all file lists look reasonable.
    # Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test
     # 46 chromAgp.zip.test
     # 45 chromFaMasked.zip.test
     # 45 chromFa.zip.test
     # 45 chromOut.zip.test
     # 45 chromTrf.zip.test
     # 604 contigAgp.zip.test
     # 604 contigFaMasked.zip.test
     # 604 contigFa.zip.test
     # 604 contigOut.zip.test
     # 604 contigTrf.zip.test
     # 3246 total

    # Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd ~/mm4/zip
    # edit copy program for mouse
    # TODO: make this generic
    ../jkStuff/cpToWeb.sh
    cd /usr/local/apache/htdocs/goldenPath/mmJun2003
    # Take a look at bigZips/* and chromosomes/*, update their README.txt's

    # Make the upstream sequence files.
    # NOTE: must be redone due to bad gap track
    cd bigZips
    featureBits mm4 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits mm4 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits mm4 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa
    # mrna zips -- how ?


# PRODUCING GENSCAN PREDICTIONS (IN PROGRESS 2003-07-09 - kate)
    
    ssh eieio
    mkdir -p ~/mm4/bed/genscan
    cd ~/mm4/bed/genscan
    # NOTE: next time, make a "run" subdir for para job
    # Make 3 subdirectories for genscan to put their output files in
    mkdir -p gtf pep subopt
       
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    # NOTE: running on rack 9
    ssh kkr9u01
    cd ~/mm4/bed/genscan
    ls -1S /cluster/store5/mm.2003.06/mm4/?{,?}/chr*_*/chr*_*.fa.masked \
      > genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    # Note: I changed this to 1800000 in this build because some jobs were
    # taking so long I thought they had crashed.
#LOOP
/cluster/home/kent/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=1800000
#ENDLOOP
    echo "" > dummy.list
    gensub2 genome.list dummy.list gsub jobList
    para create jobList
    para try
    para check
    para push
    # Issue either one of the following two commands to check the
    # status of the cluster and your jobs, until they are done.
    parasol status
    para check
    # If there were out-of-memory problems (run "para problems"), then
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.
    # chr7_15

    # Convert these to chromosome level files as so:
    ssh eieio
    cd ~/mm4/bed/genscan
    liftUp genscan.gtf ../../liftAll.lft warn gtf/chr*.gtf
    liftUp genscanSubopt.bed ../../liftAll.lft warn subopt/chr*.bed > \
      /dev/null
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/mm4/bed/genscan
    ldHgGene mm4 genscan genscan.gtf
        # Read 50447 transcripts in 357519 lines in 1 files
          # 50447 groups 43 seqs 1 sources 1 feature types
        # 50447 gene predictions
    hgPepPred mm4 generic genscanPep genscan.pep
    hgLoadBed mm4 genscanSubopt genscanSubopt.bed > /dev/null


# PREPARE CLUSTER FOR BLASTZ RUN (IN PROGRESS 2003-07-10 kate)

    # This needs to be done after trf-masking and nib generation.
    
    # NOTE: generated lineage-specific .out files
    # using "old" script, for use vs. human 
    # Will need species-specific version for mouse 
    # 2003-07-09 kate
    ssh eieio
    # Extract lineage-specific repeats using Arian Smit's script:
    mkdir -p ~/mm4/bed/linSpecRep
    cd ~/mm4/bed/linSpecRep
    # foreach f (~/mm4/*/chr*.out)
        # ln -sf $f .
    # end
    # don't step on existing .out's
    foreach f (~/mm4/*/chr*.out)
        cp $f .
    end

    /cluster/bin/scripts/rodentSpecificRepeats.pl *.out 
    /cluster/bin/scripts/perl-rename 's/(\.fa|\.nib)//' *.out.*spec
    /cluster/bin/scripts/perl-rename 's/\.(rod|prim)spec/.spec/' *.out.*spec
    rm *.out
    cd ~/mm4/bed
    rm -rf /cluster/bluearc/mm4/linSpecRep
    #  This dir already exists from above
    cp -Rp linSpecRep /cluster/bluearc/mm4
    # RepeatMasker .out:
    cd ~/mm4
    rm -rf /cluster/bluearc/mm4/rmsk
    mkdir -p /cluster/bluearc/mm4/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /cluster/bluearc/mm4/rmsk


# LOAD CPGISSLANDS (DONE 2003-07-13 kate)
     ssh eieio
     mkdir -p /cluster/data/mm4/bed/cpgIsland
     cd /cluster/data/mm4/bed/cpgIsland
     # cpglh requires hard-masked (N) .fa's.  
     # There may be warnings about "bad character" for IUPAC ambiguous 
     # characters like R, S, etc.  Ignore the warnings.  
     foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
       set fout=$f:t:r:r.cpg
       /cluster/bin/cpglh $f > $fout
       echo Done with $fout
     end
     ln -s /cluster/data/mm3 /cluster/data/lastMm
     cp /cluster/data/lastMm/bed/cpgIsland/filter.awk .
     awk -f filter.awk chr*.cpg > cpgIsland.bed

     # Load into db
     ssh hgwdev
     cd /cluster/data/mm4/bed/cpgIsland
     /cluster/bin/i386/hgLoadBed mm4 cpgIsland -tab -noBin \
       -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed
