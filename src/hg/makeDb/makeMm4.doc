# This file describes how we made the browser database on the mouse
# genome, June 2003 build. - Mm4
#
#	Things to watch out for mm4 build:
#	the usual location of /cluster/store2 has changed to /cluster/store5
#	Thus, the usual NFS server machine was kkstore is now eieio
#	Therefore, for I/O intensive operations, work on eieio
#	Due to the global replace of mm3 with mm4, some comment
#	references may not be correct.

DOWNLOAD THE MOUSE SEQUENCE FROM NCBI (DONE 2003-06-17 - Hiram)
    ssh eieio
    mkdir -p /cluster/store5/mm.2003.06/ncbi
    cd /cluster/store5/mm.2003.06/ncbi
    mkdir chrfasta contigfasta
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_30
      prompt
      bin
      mget *
      quit
    gunzip *.agp.gz

GET UPDATED MOUSE ASSEMBLY FILES FROM NCBI (Maybe later if updates)
    # Deanna regenerated allrefcontig.chr.agp for us with _random's.  
    # While downloading that, I noticed some other new files.  I saved 
    # the original copies of those to *.orig.  
    cd /cluster/store5/mm.2003.06/ncbi
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_30
      prompt
      bin
      mget allrefcontig.chr.agp.gz contig.idmap ctg_coords seq_contig.md
      quit    

BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (Working 2003-06-17)

    # This version of the mouse sequence data is in 
    # /cluster/store5/mm.2003.06/mm4/assembly
    # This will split the mouse sequence into approx. 5 Mbase supercontigs 
    # between non-bridged clone contigs and drop the resulting dir structure 
    # in /cluster/store5/mm.2003.06/mm4.
    # The resulting dir structure will include 1 dir for each chromosome, 
    # each of which has a set of subdirectories, one subdir per supercontig. 

    ssh eieio
    mkdir /cluster/store5/mm.2003.06/mm4
    cd /cluster/store5/mm.2003.06/mm4
    # splitFaIntoContigs doesn't do right with agp lines arriving in a 
    # different order than fasta chrom sequences.  so split up the agp 
    # into one per chrom.
    foreach c ( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Y Un )
      mkdir $c
      perl -we "while(<>){if (/^chr$c\t/) {print;}}" \
        ../ncbi/allrefcontig.chr.agp \
        > $c/chr$c.agp
      gunzip -c /cluster/store5/mm.2003.06/ncbi/chrfasta/chr$c.fa.gz \
        | perl -wpe 's/^>lcl\|(chr\w+)\.fa.*/>$1/' \
        | splitFaIntoContigs $c/chr$c.agp \
          stdin /cluster/store5/mm.2003.06/mm4 -nSize=5000000
    end

CREATE CHROM-LEVEL AGP AND FASTA FOR _RANDOMS (TBD)
    ssh eieio
    cd /cluster/store5/mm.2003.06/ncbi
    ../mm4/jkStuff/ncbiToRandomAgps seq_contig.md allrefcontig.chr.agp \
      contig.idmap ../mm4
    cd /cluster/store5/mm.2003.06/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.ctg.agp) then
        echo building $c/chr${c}_random.fa
        gunzip -c ../ncbi/contigfasta/chr$c.fa.gz \
          | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
          > ./tmp.fa
        agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
          $c/chr${c}_random.fa ./tmp.fa
        rm tmp.fa
      endif
    end
    # At 37402 sequences with 50000-long gaps in between, chrUn is just 
    # too damn big to fit in memory on any of our machines!!  So use a 
    # gap size of 1000 (OK with Jim and Terry) just for chrUn.  
    cd /cluster/store5/mm.2003.06/ncbi
    ../mm4/jkStuff/ncbiToRandomAgps -gapLen 1000 -chrom Un \
      seq_contig.md allrefcontig.chr.agp contig.idmap ../mm4
    cd /cluster/store5/mm.2003.06/mm4
    set c=Un
    echo building $c/chr${c}_random.fa
    gunzip -c ../ncbi/contigfasta/chr$c.fa.gz \
      | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
      > ./tmp.fa
    agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
      $c/chr${c}_random.fa ./tmp.fa
    rm tmp.fa
    # Clean these up to avoid confusion later... they're easily rebuilt.
    rm ?{,?}/*.ctg.agp

BREAK UP _RANDOMS INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (TBD)
    ssh eieio
    cd /cluster/store5/mm.2003.06/mm4
    foreach c (?{,?})
      if (-e $c/chr${c}_random.agp) then
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end

CREATING DATABASE (TBD)

o - Create the database.
     - ssh hgwdev
     - Enter mysql via:
           mysql -u hgcat -pbigsecret
     - At mysql prompt type:
        create database mm4;
        quit
     - make a semi-permanent read-only alias:
        alias mm4 "mysql -u hguser -phguserstuff -A mm4"
o - Use df to ake sure there is at least 5 gig free on hgwdev:/var/lib/mysql


CREATING GRP TABLE FOR TRACK GROUPING (TBD)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from mm2.grp" \
      | hgsql mm4


STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (TBD)

    # Create (unmasked) nib files 
    ssh eieio
    cd ~/mm
    mkdir -p nib
    foreach f (?{,?}/chr*.fa)
      echo $f:t:r
      faToNib $f nib/$f:t:r.nib
    end
    # Create symbolic links from /gbdb/mm4/nib to real nib files
    ssh hgwdev
    mkdir -p /gbdb/mm4/nib
    foreach f (/cluster/store5/mm.2003.06/mm4/nib/chr*.nib)
      ln -s $f /gbdb/mm4/nib
    end

    # Load /gbdb nib paths into database and save size info.
    ssh hgwdev
    hgsql mm4  < ~/src/hg/lib/chromInfo.sql
    cd ~/mm
    hgNibSeq -preMadeNib mm4 /gbdb/mm4/nib ?/chr*.fa ??/chr*.fa 
    echo "select chrom,size from chromInfo" | hgsql -N mm4 > chrom.sizes

Store o+o info in database.
     cd /cluster/store5/mm.2003.06/mm4
     hgGoldGapGl mm4 /cluster/store5/mm.2003.06 mm4 -noGl

Make and load GC percent table
     ssh hgwdev
     mkdir -p /cluster/store5/mm.2003.06/mm4/bed/gcPercent
     cd /cluster/store5/mm.2003.06/mm4/bed/gcPercent
     hgsql mm4  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent mm4 ../../nib


ADD MAP CONTIGS TRACK (TBD)
    ssh hgwdev
    mkdir -p ~/mm4/bed/ctgPos
    cd ~/mm4/bed/ctgPos
    # hgCtgPos uses the lift files... but mouse lift files are for the 
    # 5MB contigs from splitFaIntoContigs, not for the real NT_ contigs 
    # from the assembly.  (In the future, we should go with the NT's!)  
    # So... just for this release, go straight from the seq_contig.md 
    # to the table def'n: contig, size, chrom, chromStart, chromEnd 
    perl -we \
     'while (<>) { \
        if (/^\d+\s+(\w+)\s+(\d+)\s+(\d+)\s+\S+\s+(NT_\d+)\s+.*ref_strain/) { \
          $chr=$1; $start=$2; $start -= 1; $end=$3; $ctg=$4; \
          print "$ctg\t" . ($end-$start) . "\tchr$chr\t$start\t$end\n"; \
        } \
      }' /cluster/store5/mm.2003.06/ncbi/seq_contig.md \
    > ctgPos.tab
    hgsql mm4 < ~/kent/src/hg/lib/ctgPos.sql
    echo "load data local infile 'ctgPos.tab' into table ctgPos" | hgsql mm4
    # Note: the info is there in seq_contig.md to also do the _random's, 
    # but we'd have to do some more work: duplicate the gaps of 50000 between 
    # contigs for all _random's except chrUn_random (1000 between).  

MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR MM4 (TBD)
    # Enter mm4 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb values("mm4", "Mouse Feb. 2003", "/gbdb/mm4/nib", "Mouse", "USP18", 1, 30, "Mouse");' \
      | hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add mm4 in all the right places and do
    make update
    make alpha
    cvs commit makefile


MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR MM4 (TBD)
    ssh hgwdev
    echo 'insert into blatServers values("mm4", "blat9", "17778", "1"); \
          insert into blatServers values("mm4", "blat9", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


REPEAT MASKING (TBD)
   Split contigs, run RepeatMasker, lift results
   Notes: 
   * If there is a new version of RepeatMasker, build it and ask the admins 
     to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
   * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
     RepeatMasker runs manageable on the cluster ==> results need lifting.
   * For the NCBI assembly we repeat mask on the sensitive mode setting
     (RepeatMasker -m -s)

        #- Split contigs into 500kb chunks:
        cd ~/mm4
        foreach d ( */chr*_?{,?} )
          cd $d
          set contig = $d:t
          faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -maxN=500000
          cd ../..
        end

        #- Make the run directory and job list:
        cd ~/mm4
        mkdir RMRun
        rm -f RMRun/RMJobs
        touch RMRun/RMJobs
        foreach d ( ?{,?}/chr*_?{,?} )
          foreach f ( $d/chr*_*_*.fa )
            set f = $f:t
            echo /cluster/bin/scripts/RMMouse \
                 /cluster/store5/mm.2003.06/mm4/$d $f \
               '{'check out line+ /cluster/store5/mm.2003.06/mm4/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
        end

        #- Do the run
        ssh kk
        cd ~/mm4/RMRun
        para create RMJobs
        para try, para check, para check, para push, para check,...

        #- Lift up the split-contig .out's to contig-level .out's
	ssh eieio
        cd ~/mm4
        foreach d ( ?{,?}/chr*_?{,?} )
          cd $d
          set contig = $d:t
          liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
          cd ../..
        end

        #- Lift up the contig-level .out's to chr-level
        cd ~/mm4
        ./jkStuff/liftOut5.sh

        #- Load the .out files into the database with:
        ssh hgwdev
        cd ~/mm4
        hgLoadOut mm4 ?/*.fa.out ??/*.fa.out

VERIFY REPEATMASKER RESULTS (IN PROGRESS)

    # Run featureBits on mm4 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits mm4 rmsk
    # --> 1079906607 bases of 2708220133 (39.875%) in intersection
    # --> (orig run, July libs:) 1001999794 bases of 2577261074 (38.878%) in intersection
    featureBits mm2 rmsk
    # --> 1037964664 bases of 2726995854 (38.063%) in intersection


MAKE LIFTALL.LFT (TBD)

    cd ~/mm4
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft

SIMPLE REPEAT TRACK (TBD)
    # TRF runs pretty quickly now... it takes a few hours total runtime.
    # Also, it ignores masking of input sequence, so this can be run in 
    # parallel with RepeatMasker!
    # So instead of binrsyncing and para-running, just do this on kkstore:
    ssh kkstore
    mkdir ~/mm4/bed/simpleRepeat
    cd ~/mm4/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    touch jobs.csh
    foreach f (/cluster/store5/mm.2003.06/mm4/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa)
      set fout = $f:t:r.bed
      echo "/cluster/home/kent/bin/i386/trfBig -trf=/cluster/home/kent/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    tcsh jobs.csh |& tee jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    # When job is done do:
    liftUp simpleRepeat.bed ~/mm4/jkStuff/liftAll.lft warn trf/*.bed

    # Load this into the database as so
    ssh hgwdev
    cd ~/mm4/bed/simpleRepeat
    hgLoadBed mm4 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql


PROCESS SIMPLE REPEATS INTO MASK (TBD)

    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kkstore
    cd ~/mm4/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd ~/mm4
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
        $c/lift/ordered.lst > $c/lift/oTrf.lst
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
        jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end


MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (TBD)
    ssh kkstore
    cd ~/mm4
    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh jkStuff/makeFaMasked.sh
    #- Make hard-masked .fa.masked files as well:
    tcsh jkStuff/makeHardMasked.sh
    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh jkStuff/makeNib.sh
    # Copy the masked contig fa to /scratch:
    rm -f /scratch/hg/mm4/trfFa
    mkdir -p /scratch/hg/mm4/trfFa
    cp -p ~/mm4/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /scratch/hg/mm4/trfFa


MAKE DOWNLOADABLE SEQUENCE FILES (TBD)
    ssh kkstore
    cd ~/mm4
    #- Build the .zip files
    jkStuff/zipAll.sh |& tee zipAll.log
    mkdir zip
    mv *.zip zip
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd ~/mm4/zip
    ../jkStuff/cpToWeb.sh
    cd /usr/local/apache/htdocs/goldenPath/mmFeb2003
    #- Take a look at bigZips/* and chromosomes/*, update their README.txt's

    # Then make the upstream sequence files.
    cd bigZips
    featureBits mm4 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits mm4 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits mm4 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa


PREPARE CLUSTER FOR BLASTZ RUN (TBD)
    # This needs to be done after trf-masking and nib generation.
    ssh kkstore
    # Extract lineage-specific repeats using Arian Smit's script:
    mkdir -p ~/mm4/bed/linSpecRep
    cd ~/mm4/bed/linSpecRep
    foreach f (~/mm4/*/*.out)
        ln -sf $f .
    end
    /cluster/bin/scripts/rodentSpecificRepeats.pl *.out
    /cluster/bin/scripts/perl-rename 's/(\.fa|\.nib)//' *.out.*spec
    /cluster/bin/scripts/perl-rename 's/\.(rod|prim)spec/.spec/' *.out.*spec
    rm *.out
    cd ..
    rm -rf /scratch/hg/mm4/linSpecRep
    mkdir -p /scratch/hg/mm4
    cp -Rp linSpecRep /scratch/hg/mm4
    # RepeatMasker .out:
    cd ~/mm4
    rm -rf /scratch/hg/mm4/rmsk
    mkdir -p /scratch/hg/mm4/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /scratch/hg/mm4/rmsk
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /scratch/hg/mm4/chromTrfMixedNib
    mkdir -p /scratch/hg/mm4/chromTrfMixedNib
    cp -p mixedNib/chr*.nib /scratch/hg/mm4/chromTrfMixedNib
    # Ask cluster-admin@cse.ucsc.edu to binrsync /scratch/hg to clusters

    # Jim's comments Feb 12 '03 about the order in which to run blastz:
    # In general we should do
    # 1) hg/mm
    # 2) mm/rn
    # 3) rn/hg
    # 4) hg/hg
    # 5) mm/mm
    # 6) rn/rn
    # There is now an 'axtSwap' program that might let us
    # get out of having to run the inverse of 1,2 & 3,  though
    # 2 in particular is so fast perhaps it's just as well to
    # do the inverse explicitly.


MAKING AND STORING mRNA AND EST ALIGNMENTS (TBD)

    # Load up the local disks of the cluster with refSeq.fa, mrna.fa and est.fa
    # from /cluster/store5/mrna.133  into /scratch/hg/mrna.133
    # Make sure that /scratch/hg/mm4/trfFa is loaded with chr*_*.fa and pushed 
    # to the cluster nodes.
    ssh kk
    cd ~/mm/bed
    foreach i (refSeq mrna est)
      mkdir $i
      cd $i
      ls -1S /mnt/scratch/hg/mm4/trfFa/*.fa > genome.lst
      ls -1 /mnt/scratch/hg/mrna.133/Mus_musculus/$i.fa > mrna.lst
      cp -p ~/lastMm/bed/$i/gsub .
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      cd ..
    end 

    # In each dir: para try, para check, para push, para check....
      
    # Process refSeq mRNA and EST alignments into near best in genome.
    ssh kkstore
    cd ~/mm/bed

      cd refSeq
      pslSort dirs raw.psl /cluster/store5/tmp psl
      pslReps -minCover=0.2 -sizeMatters -minAli=0.98 -nearTop=0.002 raw.psl contig.psl /dev/null
      liftUp -nohead all_refSeq.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /cluster/store5/tmp all_refSeq.psl
      pslCat -dir chrom > refSeqAli.psl
      cd ..

      cd mrna
      pslSort dirs raw.psl /cluster/store5/tmp psl
      pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl contig.psl /dev/null
      liftUp -nohead all_mrna.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /cluster/store5/tmp all_mrna.psl
      cd ..

      cd est
      pslSort dirs raw.psl /cluster/store5/tmp psl
      pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl contig.psl /dev/null
      liftUp -nohead all_est.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /cluster/store5/tmp all_est.psl
      cd ..

    # Load refSeq alignments into database
      ssh hgwdev
      cd ~/mm/bed/refSeq
      hgLoadPsl mm4 -tNameIx refSeqAli.psl

    # Load mRNA alignments into database.
      ssh hgwdev
      cd ~/mm/bed/mrna/chrom
      foreach i (*.psl)
          mv $i $i:r_mrna.psl
      end
      hgLoadPsl mm4 *.psl
      cd ..
      hgLoadPsl mm4 all_mrna.psl -nobin

    # Load EST alignments into database.
      ssh hgwdev
      cd ~/mm/bed/est/chrom
      foreach i (*.psl)
            mv $i $i:r_est.psl
      end
      hgLoadPsl mm4 *.psl
      cd ..
      hgLoadPsl mm4 all_est.psl -nobin

    # Create subset of ESTs with introns and load into database.
      - ssh kkstore
      cd ~/mm
      tcsh jkStuff/makeIntronEst.sh
      - ssh hgwdev
      cd ~/mm/bed/est/intronEst
      hgLoadPsl mm4 *.psl


ADD REFSEQ/MRNA/EST ALIGNMENTS TO _RANDOMS (TBD)
    # Note: in future builds, we should get the _randoms in the beginning,
    # so this should not be necessary!  
    ssh kk
    cd ~/mm/bed
    # refSeq, mrna done -- est too large for pslSort when run on unmasked, 
    # so rerun est on masked.
    foreach i (refSeq mrna est)
      mkdir ${i}_random
      cd ${i}_random
      ls -1S /mnt/scratch/hg/mm4/contigs/chr*_random_*.fa > genome.lst
      ls -1 /mnt/scratch/hg/mrna.133/Mus_musculus/$i.fa > mrna.lst
      cp -p ~/lastMm/bed/$i/gsub .
      #-- Edit the gsub so it doesn't say -mask=lower!!! 
      # _randoms are all lower right now -- I'm running this before masking.
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      cd ..
    end 
    # para try,check,push,check... in each ${i}_random directory.

    # Now run the "Process..." and "Load..." steps above, but for *_random


CREATE REFSEQ GENES TRACK (TBD)
    # Load the refSeq mRNA
    ssh hgwdev
    mkdir -p /gbdb/mm4/mrna.133
    ln -s /cluster/store5/mrna.133/refSeq/org/Mus_musculus/refSeq.fa \
      /gbdb/mm4/mrna.133
    hgLoadRna new mm4
    hgLoadRna add -type=refSeq mm4 /gbdb/mm4/mrna.133/refSeq.fa \
      /cluster/store5/mrna.133/refSeq/org/Mus_musculus/refSeq.ra

    # Produce refGene, refPep, refMrna, and refLink tables as so:
    # Get the proteins:
    ssh kkstore
    cd ~/mm/bed/refSeq
    wget ftp://ftp.ncbi.nih.gov/refseq/M_musculus/mRNA_Prot/mouse.faa.gz
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/loc2ref
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/mim2loc
    gunzip mouse.faa.gz
    ssh hgwdev
    cd ~/mm/bed/refSeq
    hgRefSeqMrna mm4 \
      /gbdb/mm4/mrna.133/refSeq.fa \
      /cluster/store5/mrna.133/refSeq/org/Mus_musculus/refSeq.ra \
      all_refSeq.psl loc2ref mouse.faa mim2loc
    # Don't worry about the "No gene name" errors

    # Add RefSeq status info
    hgRefSeqStatus -mouse mm4 loc2ref


REFFLAT (TBD)
    # create precomputed join of refFlat and refGene:
    echo 'CREATE TABLE refFlat (KEY geneName (geneName), KEY name (name), KEY chrom (chrom)) SELECT refLink.name as geneName, refGene.* FROM refLink,refGene WHERE refLink.mrnaAcc = refGene.name' | hgsql mm4


LOAD MRNA DATA (TBD)
    ssh hgwdev
    ln -s /cluster/store5/mrna.133/org/Mus_musculus/mrna.fa /gbdb/mm4/mrna.133
    ln -s /cluster/store5/mrna.133/org/Mus_musculus/est.fa /gbdb/mm4/mrna.133
    hgLoadRna add -type=mRNA mm4 /gbdb/mm4/mrna.133/mrna.fa \
      /cluster/store5/mrna.133/org/Mus_musculus/mrna.ra
    hgLoadRna add -type=EST mm4 /gbdb/mm4/mrna.133/est.fa \
      /cluster/store5/mrna.133/org/Mus_musculus/est.ra


LOADING MOUSE MM4 HUMAN BLASTZ ALIGNMENTS FROM PENN STATE: (TBD)

    # Translate Penn State .lav files into sorted axt:
    ssh kkstore
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH"
    set seq1_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set seq2_dir="/cluster/store4/gs.14/build31/mixedNib/"
    set tbl="blastzHuman"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
    ssh hgwdev
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH"
    set tbl="blastzHuman"
    cd $base/pslChrom
    hgLoadPsl mm4 chr*_${tbl}.psl

MAKING THE BLASTZBESTHUMAN TRACK FROM PENN STATE MM4 AXT FILES (TBD)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH"
    set seq1_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set seq2_dir="/cluster/store4/gs.14/build31/mixedNib/"
    set tbl="blastzBestHuman"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH"
     set tbl="blastzBestHuman"
     cd $base/pslBest
     hgLoadPsl mm4 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm4/axtBestHg13
     cd /gbdb/mm4/axtBestHg13
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/mm4/axtBestHg13/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('hg13','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql mm4 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql mm4 < axtInfoInserts.sql

MAKING THE HUMAN AXTTIGHT FROM AXTBEST (TBD)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/mm4/bed/blastz.hg13.2003-03-06-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightHuman.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/mm4/bed/blastz.hg13.2003-03-06-ASH/pslTight
    hgLoadPsl mm4 chr*_blastzTightHuman.psl

CREATING HUMAN/MOUSE CHAINS AND NET BASED ON BLASTZ ALIGNMENTS MM4 vs HG12
    # Do small cluster run on kkr1u00
    # Make sure that ~/oo points to the latest human and ~/mm to the 
    # latest mouse.
    # The little cluster run will probably take about 1 hours.
    ssh kkr1u00
    cd /cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH
    mkdir axtChain
    cd axtChain
    mkdir run1
    cd run1
    ls -1S ../../axtChrom/*.axt.gz > input.lst
    echo '#LOOP' > gsub
    echo 'doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}' >> gsub
    echo '#ENDLOOP' >> gsub
    gensub2 input.lst single gsub spec
    para create spec
    echo '#!/bin/csh' > doChain
    echo 'gunzip -c $1 | axtChain stdin  ~/mm/mixedNib ~/oo/mixedNib $2 > $3' >> doChain
    chmod a+x doChain
    para shove

    # Do some sorting on the little cluster job on the file server
    # This will take about 20 minutes.  This also ends up assigning
    # a unique id to each member of the chain.
    ssh kkstore
    cd /cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # Load the chains into the database as so.  This will take about
    # 45 minutes.
    ssh hgwdev
    cd /cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH/axtChain
    cd chain
    foreach i (*.chain)
	set c = $i:r
	hgLoadChain mm4 ${c}_humanChain $i
	echo done $c
    end

    # Create the nets.  You can do this while the database is loading
    # This is fastest done on the file server.  All told it takes about
    # 40 minutes.
    ssh kkstore
    cd /cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH/axtChain
    # First do a crude filter that eliminates many chains so the
    # real chainer has less work to do.
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      chainPreNet $i ~/mm/chrom.sizes ~/oo/chrom.sizes ../preNet/$i
    end
    cd ..
    # Run the main netter, putting the results in n1.
    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      chainNet $i -minSpace=1 ~/mm/chrom.sizes ~/oo/chrom.sizes ../n1/$n /dev/null
    end
    cd ..
    # Classify parts of net as syntenic, nonsyntenic etc.
    cat n1/*.net | netSyntenic stdin hNoClass.net

    # The final step of net creation needs the database.
    # Best to wait for the database load to finish if it
    # hasn't already.
    ssh hgwdev
    cd /cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH/axtChain
    netClass hNoClass.net mm4 hg13 mouse.net -tNewR=$HOME/mm/bed/linSpecRep -qNewR=$HOME/oo/bed/linSpecRep
    rm -r n1 hNoClass.net

    # Load the net into the database as so:
    netFilter -minGap=10 mouse.net |  hgLoadNet mm4 humanNet stdin

    # Move back to the file server to create axt files corresponding
    # to the net.
    ssh kkstore
    cd /cluster/store5/mm.2003.06/mm4/bed/blastz.hg13.2003-03-06-ASH/axtChain
    mkdir ../axtNet
    netSplit mouse.net mouseNet
    cd mouseNet
    foreach i (*.net)
        set c = $i:r
	netToAxt $i ../chain/$c.chain ~/mm/mixedNib ~/oo/mixedNib ../../axtNet/$c.axt
	echo done ../axt/$c.axt
    end
    cd ..
    rm -r mouseNet

    # At this point there is a blastz..../axtNet directory that should
    # be used in place of the axtBest for making the human/mouse
    # conservation track and for loading up the downloads page.


LOADING MOUSE MM4 RAT BLASTZ ALIGNMENTS FROM PENN STATE: (TBD)

    # Translate Penn State .lav files into sorted axt:
    ssh kkstore
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.rn2.2003-03-07-ASH"
    set seq1_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set seq2_dir="/cluster/store4/rn2/mixedNib/"
    set tbl="blastzRat"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r:r
       axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
    ssh hgwdev
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.rn2.2003-03-07-ASH"
    set tbl="blastzRat"
    cd $base/pslChrom
    hgLoadPsl mm4 chr*_${tbl}.psl

MAKING THE BLASTZBESTRAT TRACK FROM PENN STATE MM4 AXT FILES (TBD)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.rn2.2003-03-07-ASH"
    set seq1_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set seq2_dir="/cluster/store4/rn2/mixedNib/"
    set tbl="blastzBestRat"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.rn2.2003-03-07-ASH"
     set tbl="blastzBestRat"
     cd $base/pslBest
     hgLoadPsl mm4 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm4/axtBestRn2
     cd /gbdb/mm4/axtBestRn2
     rm -f *
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/mm4/axtBestRn2/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('rn2','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql mm4 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql mm4 < axtInfoInserts.sql

MAKING THE RAT AXTTIGHT FROM AXTBEST (TBD)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/mm4/bed/blastz.rn2.2003-03-07-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightRat.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/mm4/bed/blastz.rn2.2003-03-07-ASH/pslTight
    hgLoadPsl mm4 chr*_blastzTightRat.psl


LOADING MOUSE MM4 SELF BLASTZ ALIGNMENTS FROM PENN STATE: (TBD)

    # Translate Penn State .lav files into sorted axt:
    ssh kkstore
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.mm4.2003-03-06-ASH"
    set seq1_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set seq2_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set tbl="blastzMouse"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
# Did not load tables for this one -- they're very big, and low demand.
TODO    ssh hgwdev
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.mm4.2003-03-06-ASH"
    set tbl="blastzMouse"
    cd $base/pslChrom
    hgLoadPsl mm4 chr*_${tbl}.psl

MAKING THE BLASTZBESTMOUSE TRACK FROM PENN STATE MM4 AXT FILES (TBD)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.mm4.2003-03-06-ASH"
    set seq1_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set seq2_dir="/cluster/store5/mm.2003.06/mm4/mixedNib/"
    set tbl="blastzBestMouse"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    # If a chromosome has so many alignments that axtBest runs out of mem,
    # run axtBest in 2 passes to reduce size of the input to final axtBest:
    foreach chrdir (lav/chr{1,2,3,4,6,7,X})
      set chr=$chrdir:t
      echo two-pass axtBesting $chr
      foreach d ($chrdir/*.lav)
        set smallout=$d.axt
        lavToAxt $d $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $smallout
      end
      foreach a ($chrdir/*.axt)
        axtBest $a $chr $a:r.axtBest
      end
      cat `ls -1 $chrdir/*.axtBest | sort -g` \
        > $chrdir/$chr.axtBestPieces
      axtBest $chrdir/$chr.axtBestPieces $chr axtBest/$chr.axt
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    rm lav/chr*/*.axt*

    # Load tables
     ssh hgwdev
     set base="/cluster/store5/mm.2003.06/mm4/bed/blastz.mm4.2003-03-06-ASH"
     set tbl="blastzBestMouse"
     cd $base/pslBest
     hgLoadPsl mm4 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm4/axtBestMM4
     cd /gbdb/mm4/axtBestMM4
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/mm4/axtBestMM4/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('mm4','Best Mouse Mouse','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql mm4 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql mm4 < axtInfoInserts.sql

MAKING THE MOUSE SELF AXTTIGHT FROM AXTBEST (TBD)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/mm4/bed/blastz.mm4.2003-03-06-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMouse.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/mm4/bed/blastz.mm4.2003-03-06-ASH/pslTight
    hgLoadPsl mm4 chr*_blastzTightMouse.psl


PRODUCING GENSCAN PREDICTIONS (TODO - REDO)
    
    ssh kkstore
    mkdir -p ~/mm4/bed/genscan
    cd ~/mm4/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir -p gtf pep subopt
       
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    cd ~/mm4/bed/genscan
    ls -1S /cluster/store5/mm.2003.06/mm4/?{,?}/chr*_*/chr*_*.fa.masked \
      > genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    # Note: I changed this to 1800000 in this build because some jobs were 
    # taking so long I thought they had crashed.
#LOOP
/cluster/home/kent/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=1800000
#ENDLOOP
    echo "" > dummy.list
    gensub2 genome.list dummy.list gsub jobList
    para create jobList
    para try
    para check
    para push
    # Issue either one of the following two commands to check the
    # status of the cluster and your jobs, until they are done.
    parasol status
    para check
    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.  
    # chr8_24

    # Convert these to chromosome level files as so:     
    ssh kkstore
    cd ~/mm4/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/chr*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/chr*.bed > \
      /dev/null
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/mm4/bed/genscan
    ldHgGene mm4 genscan genscan.gtf
    hgPepPred mm4 generic genscanPep genscan.pep
    hgLoadBed mm4 genscanSubopt genscanSubopt.bed > /dev/null


TWINSCAN GENE PREDICTIONS (TBD)
    mkdir -p ~/mm4/bed/twinscan
    cd ~/mm4/bed/twinscan

    mkdir -p ~/mm4/bed/twinscan/gtf
    mkdir -p ~/mm4/bed/twinscan/ptx
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X)
      cd ~/mm4/bed/twinscan/gtf
      wget http://genes.cs.wustl.edu/mouse/5-01-03/gtf/chr$c.gtf
      cd ~/mm4/bed/twinscan/ptx
      wget http://genes.cs.wustl.edu/mouse/5-01-03/ptx/chr$c.ptx
    end

    cd ~/mm4/bed/twinscan/gtf
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X)
      f=chr$c
      cat chr$c.gtf | sed "s/^[0-9]*	//"  | sed "s/^/$f	/" > foo
      mv foo chr$c.gtf
    end
    ldHgGene mm4 twinscan chr*.gtf -exon=CDS

    cd ~/mm4/bed/twinscan/ptx
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X)
      perl -wpe 's/^\>.*\s+source_id\s*\=\s*(\S+).*$/\>$1/;' < \
        chr$c.ptx | sed  "s/^>chr.*/&.a/" > chr$c-fixed.fa
    end
    hgPepPred mm4 generic twinscanPep chr*-fixed.fa

NCBI GENE MODELS (TODO)

    mkdir -p ~/mm4/bed/ncbiGenes
    cd ~/mm4/bed/ncbiGenes
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/maps/chr_genes.gtf.gz
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/protein/protein.fa.gz
    gunzip chr_genes.gtf.gz
    gunzip protein.fa.gz
    - Process the .gtf and .fa together to join IDs
    ../../jkStuff/mungeNCBIids chr_genes.gtf protein.fa |& uniq
    ldHgGene mm4 ncbiGenes chr_genes-fixed.gtf
    hgPepPred mm4 generic ncbiPep protein-fixed.fa

NCBI GENOMESCAN MODELS (TODO)

    mkdir -p ~/mm4/bed/genomeScan
    cd ~/mm4/bed/genomeScan
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/maps/chr_GenomeScan.gtf.gz
    # Remove the ".1" at the end of transcript_id's:
    gunzip -c chr_GenomeScan.gtf.gz | \
      perl -wpe 's/transcript_id "([^\"]+)\.1"/transcript_id "$1"/' > \
      chr_GenomeScan-fixed.gtf
    ldHgGene mm4 genomeScan chr_GenomeScan-fixed.gtf
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/protein/GS_prot.fsa.gz
    hgPepPred mm4 generic genomeScanPep GS_prot.fsa


GET FRESH MRNA SEQUENCE FROM GENBANK

This will create a genbank.133 directory containing compressed
GenBank flat files and a mrna.133 containing unpacked sequence
info and auxiliary info in a relatively easy to parse (.ra)
format.

  o - Point your browser to ftp://ftp.ncbi.nih.gov/genbank and
      look at the README.genbank.  Figure out the current release number
      (which is 133).
  o - Consider deleting one of the older genbank releases.  It''s
      good to at least keep one previous release though.
  o - Where there is space make a new genbank directory.  Create a
      symbolic link to it:
          mkdir /cluster/store5/genbank.133
          ln -s /cluster/store5/genbank.133 ~/genbank
      cd ~/genbank
  o - ftp ftp.ncbi.nih.gov  (do anonymous log-in).  Then do the
      following commands inside ftp:
           cd genbank
           prompt
           mget gbpri* gbrod* gbv* gbsts* gbest* gbmam* gbinv* gbbct* gbhtc* gbpat* gbphg* gbpln*
      This will take at least 2 hours.
  o - Make the refSeq subdir and download files:
       mkdir -p /cluster/store5/mrna.133/refSeq
       cd /cluster/store5/mrna.133/refSeq

  o - ftp ftp.ncbi.nih.gov  (do anonymous log-in).  Then do the
      following commands inside ftp:
           cd refseq/cumulative
           prompt
           mget *.gz
  o - Unpack this into species-specific fa files and get extra info with:
      cd /cluster/store5/mrna.133/refSeq
      gunzip -c rscu.gbff.Z  | \
        gbToFaRa -byOrganism=org ../anyRna.fil refSeq.fa refSeq.ra refSeq.ta stdin

  o - ssh kkstore
      cd /cluster/store5/mrna.133

# Make the RNAs
        gunzip -c /cluster/store5/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa -byOrganism=org anyRna.fil mrna.fa mrna.ra mrna.ta stdin

# Make the ESTs
        gunzip -c /cluster/store5/genbank.133/gbest*.gz | \
        gbToFaRa anyRna.fil est.fa est.ra est.ta stdin -byOrganism=org

# Make the nonhuman RNAs
        gunzip -c /cluster/store5/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa humanXenoRna.fil humanXenoRna.fa humanXenoRna.ra humanXenoRna.ta stdin

# Make the nonMouse RNAs
        gunzip -c /cluster/store5/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa mouseXenoRna.fil mouseXenoRna.fa mouseXenoRna.ra mouseXenoRna.ta stdin

# Make the nonRat RNAs
        gunzip -c /cluster/store5/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa ratXenoRna.fil ratXenoRna.fa ratXenoRna.ra ratXenoRna.ta stdin

# Make the nonhuman ESTs
        gunzip -c /cluster/store5/genbank.133/gbest*.gz | \
        gbToFaRa humanXenoRna.fil humanXenoEst.fa humanXenoEst.ra humanXenoEst.ta stdin


PRODUCING CROSS_SPECIES mRNA ALIGMENTS (TBD)

    # Here you align non-mouse mRNAs against the masked genome on the
    # cluster you set up during the previous step.
    # Make sure that gbpri, gbmam, gbrod, and gbvert are downloaded from 
    # Genbank into /cluster/store5/genbank.133 and unpacked by organism into 
    # /cluster/store5/mrna.133/org. 

    # Set up cluster run more or less as so:
      ssh kk
      cd ~/mm4/bed
      mkdir xenoMrna
      cd xenoMrna
      ls -1S /scratch/hg/mm4/trfFa/* > genome.lst
      cp -R /cluster/store5/mrna.133/org /mnt/scratch/hg/mrna.133
    # The below ls command fails when you have too many files so skip it and 
    # instead run the find command after it.
    #      ls -1S /mnt/scratch/hg/mrna.133/org/*/mrna.fa > allMrna.lst
      find /mnt/scratch/hg/mrna.133/org -name mrna.fa -ls \
        | awk '{print $7,$11}' | grep -v /Mus_musculus/ \
        | sort -gr | awk '{print $2}' \
        >  allMrna.lst
    # Put the first line of allMrna.lst into 1.org, the second line into 
    # 2.org, and so forth:
      foreach n (1 2 3 4 5 6)
        head -$n allMrna.lst | tail -1 > $n.org
      end
    # After the 6th line just leave the rest in 7.org.
      tail +7 allMrna.lst > 7.org
    # Then
      ls -1 *.org > mrna.lst
      cp ~/lastMm/bed/xenoMrna/gsub .
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      para try
      para check
    # If all looks well do
      para push

    # Sort xeno mRNA alignments as so:
       ssh kkstore
       cd ~/mm4/bed/xenoMrna
       pslSort dirs raw.psl /cluster/store5/temp psl
       pslReps raw.psl cooked.psl /dev/null -minAli=0.25
       liftUp chrom.psl ../../jkStuff/liftAll.lft warn cooked.psl
       pslSortAcc nohead chrom /cluster/store5/temp chrom.psl
       pslCat -dir chrom > xenoMrna.psl
       rm -r chrom raw.psl cooked.psl chrom.psl

    # Load into database as so:
       ssh hgwdev
       cd ~/mm4/bed/xenoMrna
       hgLoadPsl mm4 xenoMrna.psl -tNameIx

    # Make the xenoRna file
       # Make a /gbdb symlink for the .fa (not .ra)
       cd /gbdb/mm4/mrna.133
       ln -s /cluster/store5/mrna.133/mouseXenoRna.fa mouseXenoRna.fa
       hgLoadRna add -type=xenoRna mm4 /gbdb/mm4/mrna.133/mouseXenoRna.fa \
         /cluster/store5/mrna.133/mouseXenoRna.ra

PRODUCING ESTORIENTINFO TABLE (TBD)

This table is needed for proper orientation of ESTs in the
browser.  Many will appear on the wrong strand without it.
This involves a cluster run.  First load the EST psl files
as so:
     ssh kkstore
     cd ~/mm4/bed/est
     pslSortAcc nohead contig /cluster/store5/temp contig.psl
     mkdir /mnt/scratch/hg/mm4/est
     cp -r contig /mnt/scratch/hg/mm4/est

Wait for these to finish.
     cd ..
     mkdir estOrientInfo
     cd estOrientInfo
     mkdir ei
     ls -1S /mnt/scratch/hg/mm4/est/contig/* > psl.lst
     cp ~/lastMm/bed/estOrientInfo/gsub .
Update gsub to refer to mouse contig sequence currently on
/scratch, and mouse ESTs on /scratch.
     gensub2 psl.lst single gsub spec
     para create spec
Then run the  job on the cluster
     ssh kk
     cd ~/mm4/bed/estOrientInfo
     para try
     sleep 60
     para check
If things look good
     para push

Wait for this to finish then
     liftUp estOrientInfo.bed ../../jkStuff/liftAll.lft warn ei/*.tab
Load them into database as so:
     ssh hgwdev
     cd ~/mm4/bed/estOrientInfo
     hgLoadBed mm4 estOrientInfo estOrientInfo.bed \
       -sqlTable=/cluster/home/kent/src/hg/lib/estOrientInfo.sql

PRODUCING MRNAORIENTINFO TABLE (TBD)
    ssh kkstore
    cd ~/mm4/bed/mrna
    pslSortAcc nohead contig /cluster/store5/temp contig.psl
    mkdir /mnt/scratch/hg/mm4/mrna
    cp -r contig /mnt/scratch/hg/mm4/mrna
    mkdir -p ~/mm4/bed/mrnaOrientInfo/oi
    cd ~/mm4/bed/mrnaOrientInfo
    ls -1S /mnt/scratch/hg/mm4/mrna/contig/* > psl.lst
    cp ~/lastMm/bed/mrnaOrientInfo/gsub .
    echo placeholder > single
    gensub2 psl.lst single gsub spec

    ssh kk
    cd ~/mm4/bed/mrnaOrientInfo
    para create spec
    para try, para check, para push, para check,...
    liftUp mrnaOrientInfo.bed ../../jkStuff/liftAll.lft warn oi/*.tab

    ssh hgwdev
    cd ~/mm4/bed/mrnaOrientInfo
    hgLoadBed mm4 mrnaOrientInfo mrnaOrientInfo.bed \
       -sqlTable=/cluster/home/kent/src/hg/lib/mrnaOrientInfo.sql


CREATE RNACLUSTER TABLE (TBD)
    # Make sure that refSeqAli, estOrientInfo and mrnaOrientInfo tables are 
    # made already (see above).
    ssh hgwdev
    mkdir -p ~/mm4/bed/rnaCluster/chrom
    cd ~/mm4/bed/rnaCluster
    foreach i (~/mm4/?{,?})
      foreach f ($i/chr*.fa)
        set c = $f:t:r
        clusterRna mm4 /dev/null chrom/$c.bed -chrom=$c
        echo done $c
      end
    end
    hgLoadBed mm4 rnaCluster chrom/*.bed


PRODUCING TETRAODON FISH ALIGNMENTS (TODO)

o - Download sequence from ... and put it on the cluster local disk
    at
       /scratch/hg/fish
o - Do fish/mouse alignments.
       ssh kk
       cd ~/mm/bed
       mkdir blatFish
       cd blatFish
       mkdir psl
       ls -1S /scratch/hg/fish/* > fish.lst
       ls -1S /scratch/hg/mm4/trfFa/* > mouse.lst
       cp ~/lastMm/blatFish/gsub .
       gensub2 mouse.lst fish.lst gsub spec
       para create spec
       para try
     Make sure jobs are going ok with para check.  Then
       para push
     wait about 2 hours and do another
       para push
     do para checks and if necessary para pushes until done
     or use para shove.
o - Sort alignments as so 
       pslCat -dir psl | liftUp -type=.psl stdout ~/mm/jkStuff/liftAll.lft warn stdin | pslSortAcc nohead chrom /cluster/store5/tmp stdin
o - Copy to hgwdev:/scratch.  Rename to correspond with tables as so and 
    load into database:
       ssh hgwdev
       cd ~/mm/bed/blatFish/chrom
       foreach i (*.psl)
           set r = $i:r
           mv $i ${r}_blatFish.psl
       end
       hgLoadPsl mm4 *.psl
       #*** Make /gbdb/mm4/fish_seq15jun2001 links
       hgLoadRna addSeq mm4 /gbdb/mm4/fish_seq15jun2001/*.fa

# PRODUCING SQUIRT ALIGNMENTS  
    ssh kkstore
    mkdir -p ~/mm4/bed/blatCi1
    cd ~/mm4/bed/blatCi1
    ls -1S /iscratch/i/squirt/ci1/queryFa/*.fa > squirt.lst
    ls -1S /scratch/hg/mm4/trfFa/* > mouse.lst

    rm -rf psl
    foreach ctg (`cat mouse.lst`)
      mkdir -p psl/$ctg:t:r
    end
    # get gsub2D from someplace
    gensub2 mouse.lst squirt.lst gsub2D spec

    ssh kk
    cd ~/mm4/bed/blatCi1
    para create spec
    ....
    # When cluster run is done, sort alignments:
    ssh eieio
    cd ~/mm4/bed/blatCi1
    rm -rf /tmp/$LOGNAME
    mkdir /tmp/$LOGNAME
    pslSort dirs raw.psl /tmp/$LOGNAME psl/*
    pslReps raw.psl cooked.psl /dev/null -minAli=0.05
    liftUp -nohead lifted.psl ../../jkStuff/liftAll.lft warn cooked.psl
    pslSortAcc nohead chrom /tmp/$LOGNAME lifted.psl

    # Rename to correspond with tables as so and load into database:
    ssh hgwdev
    cd ~/mm4/bed/blatCi1/chrom
    rm -f chr*_blatCi1.psl
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        mv $i ${r}_blatCi1.psl
    end
    hgLoadPsl mm4 *.psl

    # Make squirt /gbdb/ symlink 
    mkdir /gbdb/mm4/squirtSeq
    cd /gbdb/mm4/squirtSeq
    ln -s /cluster/store5/squirt/ci1/ciona.rm.fasta

PRODUCING FUGU FISH ALIGNMENTS (TBD)

    # sequence was previously downloaded to /cluster/store3/fuguSeq/ from
    #   ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_mask.fasta.Z
    #   ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_prot.fasta.Z
    # Load it up on /mnt/scratch:
    ssh kkstore
    mkdir -p /mnt/scratch/hg/fugu
# Next time, use /cluster/store3/fuguSeq/split2.5Mb !!!
    cp -p /cluster/store3/fuguSeq/split/*.fa /mnt/scratch/hg/fugu/

    ssh kk
    mkdir ~/mm/bed/blatFugu
    cd ~/mm/bed/blatFugu
    ls -1S /mnt/scratch/hg/fugu/* > fugu.lst
    ls -1S /scratch/hg/mm4/trfFa/* > mouse.lst
    # Create dir structure for run
    mkdir psl
    foreach ctg (`ls -1 /scratch/hg/mm4/trfFa/`)
      mkdir psl/$ctg:t:r
    end
    cp ~/lastMm/bed/blatFugu/gsub .
    gensub2 mouse.lst fugu.lst gsub spec
    para create spec
    para try
    # Make sure jobs are going ok with para check.  Then
    para push
    # wait about 2 hours and do another
    para push
    # do para checks and if necessary para pushes until done or use para shove.
    ssh kkstore
    cd ~/mm/bed/blatFugu
    pslCat -dir psl/* \
      | liftUp -type=.psl stdout ~/mm4/jkStuff/liftAll.lft warn stdin \
      | pslSortAcc nohead chrom /cluster/store5/tmp stdin
    # load into database:
    ssh hgwdev
    cd ~/mm4/bed/blatFugu/chrom
    foreach i (*.psl)
      set r = $i:r
      mv $i ${r}_blatFugu.psl
    end
    hgLoadPsl mm4 *.psl
    mkdir -p /gbdb/mm4/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta /gbdb/mm4/fuguSeq/
    hgLoadRna addSeq mm4 /gbdb/mm4/fuguSeq/fugu_v3_mask.fasta


LOAD SOFTBERRY GENES (TBD)
     cd /cluster/store5/mm.2003.06/mm4/bed
     mkdir softberry
     cd softberry
     wget ftp://www.softberry.com/pub/SC_MOU_FEB03/Softb_mouse_gff_f03.tar.gz
     gunzip -c Softb_mouse_gff_f03.tar.gz | tar xvf -
     ldHgGene mm4 softberryGene chr*.gff
     hgPepPred mm4 softberry *.protein
     hgSoftberryHom mm4 *.protein

LOAD GENEID GENES (TBD)
    mkdir -p ~/mm4/bed/geneid/download
    cd ~/mm4/bed/geneid/download
    set webroot = \
      http://genome.imim.es/genepredictions/M.musculus/mmFeb2003/geneid_v1.1
    foreach f (~/mm4/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget $webroot/$chr.gtf
      wget $webroot/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene mm4 geneid download/*.gtf -exon=CDS
    hgPepPred mm4 generic geneidPep download/*-fixed.prot

SGP GENE PREDICTIONS (4/17/03 KRR)
    mkdir -p ~/mm4/bed/sgp/download
    cd ~/mm4/bed/sgp/download
    #foreach f (~/mm4/?{,?}/chr?{,?}{,_random}.fa)
    # Doesn't have chr_random entries KRR
    foreach f (~/mm4/?{,?}/chr?{,?}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/M.musculus/mmFeb2003/SGP/humangp20021114/$chr.gtf
      wget http://genome.imim.es/genepredictions/M.musculus/mmFeb2003/SGP/humangp20021114/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene mm4 sgpGene download/*.gtf -exon=CDS
    hgPepPred mm4 generic sgpPep download/*-fixed.prot


TIGR GENE INDEX (TODO)
    mkdir -p ~/mm4/bed/tigr
    cd ~/mm4/bed/tigr
    wget ftp://ftp.tigr.org/private/NHGI_mgi_jiashu/TGI_track_MouseGenome_Nov2002.tgz
    gunzip -c TGI*.tgz | tar xvf -
    foreach f (*cattle*)
      set f1 = `echo $f | sed -e 's/cattle/cow/g'`
      mv $f $f1
    end
    foreach o (mouse cow human pig rat)
      setenv O $o
      foreach f (chr*_$o*s)
        tail +2 $f | perl -wpe 's /THC/TC/; s/(TH?C\d+)/$ENV{O}_$1/;' > $f.gff
      end
    end
    ldHgGene -exon=TC mm4 tigrGeneIndex *.gff


LOAD STS MAP (TODO)
     - login to hgwdev
      cd ~/mm/bed
      mm4 < ~/src/hg/lib/stsMap.sql
      mkdir stsMap
      cd stsMap
      bedSort /projects/cc/hg/mapplots/data/tracks/build28/stsMap.bed stsMap.bed
      - Enter database with "mm4" command.
      - At mysql> prompt type in:
          load data local infile 'stsMap.bed' into table stsMap;
      - At mysql> prompt type

LOAD MGI IDs (TODO)
      - The Locuslink ID to MGI IDs converstion data file,
        LL2MGI.txt, from Jackson Lab should be found under
        ~/mm/bed/refSeq
      - login to hgwdev
      
      cd ~/mm/bed/refSeq
      mm4 < ~/src/hg/lib/mgiID.sql
      - Enter database with "mm4" command.
      - At mysql> prompt type in:
          load data local infile 'LL2MGI.txt' into table MGIid;
      - At mysql> prompt type
          quit

LOAD CHROMOSOME BANDS (TODO)
      - login to hgwdev
      cd /cluster/store5/mm.2003.06/mm4/bed
      mkdir cytoBands
      cp /projects/cc/hg/mapplots/data/tracks/build28/cytobands.bed cytoBands
      mm4 < ~/src/hg/lib/cytoBand.sql
      Enter database with "mm4" command.
      - At mysql> prompt type in:
          load data local infile 'cytobands.bed' into table cytoBand;
      - At mysql> prompt type
          quit

LOAD MOUSEREF TRACK (TODO)
    First copy in data from kkstore to ~/mm/bed/mouseRef.  
    Then substitute 'genome' for the appropriate chromosome 
    in each of the alignment files.  Finally do:
       hgRefAlign webb mm4 mouseRef *.alignments

LOAD AVID MOUSE TRACK (TODO)
      ssh cc98
      cd ~/mm/bed
      mkdir avidMouse
      cd avidMouse
      wget http://pipeline.lbl.gov/tableCS-LBNL.txt
      hgAvidShortBed *.txt avidRepeat.bed avidUnique.bed
      hgLoadBed avidRepeat avidRepeat.bed
      hgLoadBed avidUnique avidUnique.bed

LOAD SNPS (TODO)
      - ssh hgwdev
      - cd ~/mm/bed
      - mkdir snp
      - cd snp
      - Download SNPs from ftp://ftp.ncbi.nlm.nih.gov/pub/sherry/mouse.b27.out.gz
      - Unpack.
        createBed < mouse.b27.out > snpNih.bed
        hgLoadBed mm4 snpNih snpNih.bed

LOAD CPGISSLANDS (TBD)
     ssh kkstore
     mkdir -p ~/mm4/bed/cpgIsland
     cd ~/mm4/bed/cpgIsland
     # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
     # copy the tar file to the current directory
     tar xvf cpg_dist.tar 
     cd cpg_dist
     gcc readseq.c cpg_lh.c -o cpglh.exe
     cd ..
     # cpglh.exe requires hard-masked (N) .fa's.  
     # There may be warnings about "bad character" for IUPAC ambiguous 
     # characters like R, S, etc.  Ignore the warnings.  
     foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
       set fout=$f:t:r:r.cpg
       ./cpg_dist/cpglh.exe $f > $fout
       echo Done with $fout
     end
     cp ~/lastMm/bed/cpgIsland/filter.awk .
     awk -f filter.awk chr*.cpg > cpgIsland.bed
     # Load into db
     ssh hgwdev
     cd ~/mm4/bed/cpgIsland
     hgLoadBed mm4 cpgIsland -tab -noBin \
       -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed

LOAD ENSEMBL GENES (TBD)
     cd ~/mm4/bed
     mkdir ensembl
     cd ensembl

        Get the ensembl gene data from http://www.ensembl.org/
        Go to the Martview link
        Choose Mus musculus as the organism
        Follow this sequence through the pages:
        Page 1) Choose the Ensembl Genes choice. Hit next.
        Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.        
        Page 3) Choose the "Structures" box. 
        Page 4) Choose GTF as the ouput, choose gzip compression and then hit Export.gunzip the file and name to mm4EnsGene.gtf.gz. Unzip it.

# Ensembl handles random chromosomes differently than us, so we
# strip this data.  Fortunately it just loses a couple of genes.
     grep -v ^6_DR51 ensembl.gtf | grep -v _NT_ > unrandom.gtf

# Add "chr" to front of each line in the gene data gtf file to make 
# it compatible with ldHgGene 
     ~matt/bin/addchr.pl unrandom.gtf ensGene.gtf
     ~matt/bin/fixEns.pl ensGene.gtf ensFixed.gtf 
     ldHgGene mm4 ensGene ensGene.gtf

o - Load Ensembl peptides:
        Get the ensembl protein data from http://www.ensembl.org/
        Go to the Martview link
        Choose Mus musculus as the organism
        Follow this sequence through the pages:
        Page 1) Choose the Ensembl Genes choice. Hit next.
        Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
        Page 3) Choose the "Sequences" box. 
        Page 4) Choose Transcripts/Proteins and Gene sequence Only as the ouput, choose text/fasta and gzip compression and then hit export. Name to mm4EnsGene.pep.gz

     If needed, substitute ENST for ENSP in ensPep with the program called subs
     edit subs.in to read: ENSP|ENST
     subs -e mm4EnsGene.pep > /dev/null

     ~matt/bin/fixPep.pl mm4EnsGene.pep ensembl.pep
     hgPepPred mm4 generic ensPep ensembl.pep


LOAD ENSEMBL ESTS (TBD)
     cd ~/mm4/bed
     mkdir ensemblEst
     cd ensemblEst

        Get the ensembl EST data from http://www.ensembl.org/
        Go to the Martview link
        Choose Mus musculus as the organism
        Follow this sequence through the pages:
        Page 1) Choose the Ensembl ESTs choice. Hit next.
        Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.        
        Page 3) Choose the "Structures" box. 
        Page 4) Choose GTF as the ouput, choose gzip compression and then hit Export.gunzip the file and name to mm4EnsEst.gtf.gz. Unzip it.

# Ensembl handles random chromosomes differently than us, so we
# strip this data.  Fortunately it just loses a couple of genes.
     grep -v ^6_DR51 mm4EnsEst.gtf | grep -v _NT_ > unrandom.gtf

# Add "chr" to front of each line in the gene data gtf file to make 
# it compatible with ldHgGene 
     ~matt/bin/addchr.pl unrandom.gtf ensEst.gtf
     ~matt/bin/fixEns.pl ensEst.gtf ensFixed.gtf 
     ldHgGene mm4 ensEst ensEst.gtf

o - Load Ensembl peptides:
        Get the ensembl protein data from http://www.ensembl.org/
        Go to the Martview link
        Choose Mus musculus as the organism
        Follow this sequence through the pages:
        Page 1) Choose the Ensembl ESTs choice. Hit next.
        Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
        Page 3) Choose the "Sequences" box. 
        Page 4) Choose Transcripts/Proteins and Gene sequence Only as the ouput, choose text/fasta and gzip compression and then hit export. Name to mm4EnsEst.pep.gz

     If needed, substitute ENST for ENSP in ensPep with the program called subs
     edit subs.in to read: ENSP|ENST
     subs -e mm4EnsEst.pep > /dev/null

     ~matt/bin/fixPep.pl mm4EnsEst.pep ensembl.pep
     hgPepPred mm4 generic ensEstPep ensembl.pep

LOAD RNAGENES (TODO)
      - login to hgwdev
      - cd ~kent/src/hg/lib
      - mm4 < rnaGene.sql
      - cd /cluster/store5/mm.2003.06/mm4/bed
      - mkdir rnaGene
      - cd rnaGene
      - download data from ftp.genetics.wustl.edu/pub/eddy/pickup/ncrna-oo27.gff.gz
      - gunzip *.gz
      - liftUp chrom.gff ../../jkStuff/liftAll.lft carry ncrna-oo27.gff
      - hgRnaGenes mm4 chrom.gff

LOAD EXOFISH (TODO)
     - login to hgwdev
     - cd /cluster/store5/mm.2003.06/mm4/bed
     - mkdir exoFish
     - cd exoFish
     - mm4 < ~kent/src/hg/lib/exoFish.sql
     - Put email attatchment from Olivier Jaillon (ojaaillon@genoscope.cns.fr)
       into /cluster/store5/mm.2003.06/mm4/bed/exoFish/all_maping_ecore
     - awk -f filter.awk all_maping_ecore > exoFish.bed
     - hgLoadBed mm4 exoFish exoFish.bed

LOAD MOUSE SYNTENY (TODO)
     - login to hgwdev.
     - cd ~/kent/src/hg/lib
     - mm4 < mouseSyn.sql
     - mkdir ~/mm/bed/mouseSyn
     - cd ~/mm/bed/mouseSyn
     # Put Deanna Church's (church@ncbi.nlm.nih.gov) email attatchment as
     # mouseSyn.txt
     - awk -f format.awk *.txt > mouseSyn.bed
     - delete first line of mouseSyn.bed
     - Enter database with "mm4" command.
     - At mysql> prompt type in:
          load data local infile 'mouseSyn.bed' into table mouseSyn


LOAD GENIE (TODO)
     mkdir -p ~/mm4/bed/genieAlt
     cd ~/mm4/bed/genieAlt
     wget http://www.neomorphic.com/mgap/mgscv3/gtf/mgscv3.genie.gtf.tgz
     gunzip -c mgscv3.genie.gtf.tgz | tar xvf -
     ldHgGene mm4 genieAlt mgscv3.genie.gtf/chr*.gtf
     wget http://www.neomorphic.com/mgap/mgscv3/fa/mgscv3.aa.tgz
     gunzip -c mgscv3.aa.tgz | tar xvf -
     hgPepPred mm4 genie geniePep chr*.aa.fa

LOAD GENIE CLONE BOUNDS (TODO)
     mkdir -p ~/mm4/bed/genieBounds
     cd ~/mm4/bed/genieBounds
     wget http://www.neomorphic.com/mgap/mgscv3/cb.bed/mgscv3_cb.bed.tgz
     gunzip -c mgscv3_cb.bed.tgz | tar xvf -
     - Trim the track definition from each file (these are actually custom 
       track files):
     foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Un)
       tail +2 chr${c}_cb.bed > chr${c}_cb-fixed.bed
     end
     hgLoadBed mm4 genieBounds *-fixed.bed

LOAD JACKSON LABS QTL (TODO)
    ssh hgwdev
    mkdir ~/mm4/bed/jaxQTL2
    # Save the email attachment from Sridhar Ramachandran at Jackson Labs
    # (bed 8+, jaxQTL2 format).
    # Strip the column headers and load into the database.  
    tail +2 QTLBedFormat.txt > jaxQTL2.bed
    hgLoadBed -noBin -tab -sqlTable=$HOME/kent/src/hg/lib/jaxQTL2.sql \
      mm4 jaxQTL2 jaxQTL2.bed


MAKING MOUSE AND RAT SYNTENY
#
syntenicBest.pl -db=mm4 -table=blastzBestHuman
smooth.pl
joinsmallgaps.pl
fillgap.pl -db=mm4 -table=blastzBestHuman
synteny2bed.pl
hgLoadBed mm4 syntenyHuman ucsc100k.bed

syntenicBest.pl -db=mm4 -table=blastzBestRat
smooth.pl
joinsmallgaps.pl
fillgap.pl -db=mm4 -table=blastzBestRat
synteny2bed.pl
hgLoadBed mm4 syntenyRat ucsc100k.bed



CREATING THE mm4Rn2L SAMPLE TRACK (a.k.a WIGGLE TRACK)
------------------------------------------------------
o - refer to the script at src/hg/sampleTracks/makeMM4Rn2.doc

# create MGC Genes track (markd 13 may 2003)
# this will be automated in the incremental genbank update
/cluster/store5/genbank/bin/i386/mgcDbLoad mm4 /cluster/store5/genbank/data/download/mgc/2003.05.06/mgcFullStatus.tab.gz 

