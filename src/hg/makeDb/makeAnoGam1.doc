#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# Anopheles gambiae -- complete chromosomes from Ensembl, apparently from 
# May 2004:
# ftp://ftp.ensembl.org/pub/current_mosquito/data/fasta/dna
# (NCBI still has just scaffolds from 2002 here...?!
#  ftp://ftp.ncbi.nih/gov/genbank/genomes/Anopheles_gambiae/Assembly_scaffolds)
#

# DOWNLOAD SEQUENCE (DONE 6/7/04 angie)
    ssh kksilo
    mkdir /cluster/store7/anoGam1
    cd /cluster/data
    ln -s /cluster/store7/anoGam1 anoGam1
    cd /cluster/data/anoGam1
    mkdir downloads
    cd downloads
    foreach c (2L 2R 3L 3R X UNKN)
      wget ftp://ftp.ensembl.org/pub/current_mosquito/data/fasta/dna/Anopheles_gambiae.MOZ2a.may.dna.chromosome.$c.fa.gz
      wget ftp://ftp.ensembl.org/pub/current_mosquito/data/fasta/dna/Anopheles_gambiae.MOZ2a.may.dna_rm.chromosome.$c.fa.gz
    end
    gunzip *.fa.gz
    # sanity check -- make sure the 2 versions are the same modulo masking:
    foreach f (*.dna.*)
      set g = `echo $f | sed -e 's/\.dna\./\.dna_rm\./'`
      faCmp $f $g
    end
    # Is their masking actually different? 
    foreach f (*.dna.*)
      set g = `echo $f | sed -e 's/\.dna\./\.dna_rm\./'`
      faCmp -softMask $f $g
    end
    # Nope!  ?  Well, OK, clean up then.
    rm Ano*.dna_rm.*

    # Put in our usual chrom dir structure.
    foreach c (2L 2R 3L 3R X)
      mkdir ../$c
      sed -e 's/^>.*$/>'chr$c/ A*.dna.chromosome.$c.fa > ../$c/chr$c.fa
    end
    mkdir ../U
    sed -e 's/^>.*$/>'chrU/ A*.dna.chromosome.UNKN.fa > ../U/chrU.fa
    cd ..
    foreach c (?{,?})
      diff $c/chr$c.fa downloads/A*.dna.*.$c*.fa
    end

    # download mitochondrion sequence
    mkdir M
    cd M
    # go to http://www.ncbi.nih.gov/ and search Genome for 
    # "anopheles gambiae mitochondrion complete".  That shows the gi number:
    # 5834911
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=5834911&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Anopheles gambiae mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".
    cd ..
    # tidy up downloads
    nice gzip downloads/* &


# GET ASSEMBLY INFO FROM ENSEMBL (DONE 6/7/04 angie)
    # Since there's no AGP, extract what we can from Ensembl... looks like 
    # they give offsets of both their "chunks" and of the real scaffolds.
    ssh kksilo
    cd /cluster/data/anoGam1/bed/ensChunks
    wget ftp://ftp.ensembl.org/pub/current_mosquito/data/mysql/anopheles_gambiae_core_22_2b/assembly.txt.table.gz
    wget ftp://ftp.ensembl.org/pub/current_mosquito/data/mysql/anopheles_gambiae_core_22_2b/anopheles_gambiae_core_22_2b.sql.gz
    wget ftp://ftp.ensembl.org/pub/current_mosquito/data/mysql/anopheles_gambiae_core_22_2b/seq_region.txt.table.gz
    gunzip *.gz
    ssh hgwdev
    cd /cluster/data/anoGam1/bed/ensChunks
    hgsql -e "create database ensAnoGam"
    hgsql ensAnoGam < anopheles_gambiae_core_22_2b.sql
    hgsql ensAnoGam \
      -e 'load data local infile "assembly.txt.table" into table assembly'
    hgsql ensAnoGam \
      -e 'load data local infile "seq_region.txt.table" into table seq_region'
    hgsql ensAnoGam -e 'create table assembly1 \
      select assembly.asm_seq_region_id,seq_region.name, \
      assembly.asm_start,assembly.asm_end,assembly.cmp_start,\
      assembly.cmp_end,assembly.ori from assembly,seq_region  \
      where assembly.cmp_seq_region_id = seq_region.seq_region_id'
    hgsql ensAnoGam -e 'create table assembly2 \
      select seq_region.name as chrom, \
      assembly1.asm_start as chromStart, assembly1.asm_end as chromEnd, \
      assembly1.name, \
      assembly1.cmp_start as fragStart, assembly1.cmp_end as fragEnd, \
      assembly1.ori from assembly1,seq_region  \
      where assembly1.asm_seq_region_id = seq_region.seq_region_id'
    hgsql ensAnoGam -e 'update assembly2 set chrom = "U" where chrom = "UNKN"'
    hgsql ensAnoGam -e 'update assembly2 set chrom = concat("chr", chrom)'
    hgsql ensAnoGam -N -e 'select * from assembly2 order by chrom,chromStart' \
    | perl -we '$i = 0; \
         while (<>) { \
           chomp;  @w = split;  $w[6] =~ s/1$//;  $w[6] =~ s/^$/+/;  ++$i; \
           print "$w[0]\t$w[1]\t$w[2]\t$i\tW\t$w[3]\t$w[4]\t$w[5]\t$w[6]\n"; \
         }' \
      > ensAll.agp
    # Get just the scaffold entries, and put gap records in there...
    ssh kksilo
    cd /cluster/data/anoGam1
    awk '$6 !~ /_[0-9]+$/ {print;}' ensAll.agp \
    | perl -we '$i = 0; $prevChr = ""; \
       while (<>) { \
         @w = split;  ++$i; \
         if ($w[0] eq $prevChr && defined $prevEnd) { \
           $gapEnd = $w[1] - 1;  $size = $w[1] - $prevEnd; \
           print "$w[0]\t$prevEnd\t$gapEnd\t$i\tN\t$size\tclone\tno\n"; $i++; \
         } \
         $prevEnd = $w[2] + 1;  $prevChr = $w[0];  \
         print; \
       }' \
    > ensScaffold.agp
    cd ../..
    foreach c (?{,?})
      grep "^chr$c" bed/ensChunks/ensScaffold.agp > $c/chr$c.agp
    end
    # clean up 0-length inappropriate chrM.agp:
    rm M/chrM.agp
    # checkAgpAndFa prints out way too much info -- keep the end/stderr only:
    foreach agp (?{,?}/chr*.agp)
      if (-e $agp) then
        set fa = $agp:r.fa
        echo checking consistency of $agp and $fa
        checkAgpAndFa $agp $fa | tail -1
      endif
    end
    # clean up ensAnoGam database
    ssh hgwdev
    hgsql -e "drop database ensAnoGam"


# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT CHUNKS OF N'S (DONE 6/7/04 angie)
    # Since we didn't get real AGP with gap info, we don't have enough info 
    # to help us break into ~5MB chunks at proper gap boundaries.  So just 
    # use runs of N's as gaps.
    ssh kksilo
    cd /cluster/data/anoGam1
    foreach c (?{,?})
      faSplit gap -minGapSize=100 -lift=$c/chr$c.lft \
        $c/chr$c.fa 5000000 $c/chr${c}_
    end
    # put chunks into usual "contig" dir structure
    foreach ctg (?{,?}/chr?{,?}_?{,?}.fa)
      mkdir $ctg:r
      mv $ctg $ctg:r/
    end


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 6/7/04 angie)
    # This used to hold scripts -- better to keep them inline here so 
    # they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/anoGam1/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/anoGam1/bed


# CREATING DATABASE (DONE 6/7/04 angie)
    # Create the database.
    ssh hgwdev
    # Make sure there is at least 5 gig free for the database
    df -h /var/lib/mysql
    hgsql -e 'create database anoGam1'


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 6/7/04 angie)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg16.grp" \
      | hgsql anoGam1


# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS (DONE 6/7/04 angie)
    # Make nib/, unmasked until RepeatMasker and TRF steps are done.
    # Do this now so we can load up RepeatMasker and run featureBits; 
    # can also load up other tables that don't depend on masking.  
    ssh kksilo
    cd /cluster/data/anoGam1
    mkdir nib
    foreach c (?{,?})
      foreach f ($c/chr${c}{,_random}.fa)
        if (-e $f) then
          echo "nibbing $f"
          /cluster/bin/i386/faToNib $f nib/$f:t:r.nib
        endif
      end
    end

    # Make symbolic links from /gbdb/anoGam1/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/anoGam1/nib
    foreach f (/cluster/data/anoGam1/nib/chr*.nib)
      ln -s $f /gbdb/anoGam1/nib
    end
    # Load /gbdb/anoGam1/nib paths into database and save size info.
    cd /cluster/data/anoGam1
    hgsql anoGam1  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib anoGam1 /gbdb/anoGam1/nib */chr*.fa
    echo "select chrom,size from chromInfo" | hgsql -N anoGam1 > chrom.sizes
    # take a look at chrom.sizes, should be 18 lines
    wc chrom.sizes


# REPEATMASKER (DONE 6/8/04 angie)
    #- Split sequence into 500kb chunks, at gaps if possible:
    ssh kksilo
    cd /cluster/data/anoGam1
    foreach c (?{,?})
      foreach d ($c/chr${c}*_?{,?})
        cd $d
        echo "splitting $d"
        set contig = $d:t
        faSplit gap $contig.fa 500000 ${contig}_ -lift=$contig.lft \
          -minGapSize=100
        cd ../..
      end
    end

    #- Make the run directory and job list:
    cd /cluster/data/anoGam1
    cat << '_EOF_' > jkStuff/RMAnopheles
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/anoGam1/$2
/bin/cp $2 /tmp/anoGam1/$2/
cd /tmp/anoGam1/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s -spec anopheles $2
popd
/bin/cp /tmp/anoGam1/$2/$2.out ./
if (-e /tmp/anoGam1/$2/$2.align) /bin/cp /tmp/anoGam1/$2/$2.align ./
if (-e /tmp/anoGam1/$2/$2.tbl) /bin/cp /tmp/anoGam1/$2/$2.tbl ./
if (-e /tmp/anoGam1/$2/$2.cat) /bin/cp /tmp/anoGam1/$2/$2.cat ./
/bin/rm -fr /tmp/anoGam1/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/anoGam1/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/anoGam1
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMAnopheles
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach c (?{,?})
      foreach d ($c/chr${c}*_?{,?})
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/data/anoGam1/jkStuff/RMAnopheles \
                 /cluster/data/anoGam1/$d $f \
               '{'check out line+ /cluster/data/anoGam1/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
      end
    end

    #- Do the run
    ssh kk9
    cd /cluster/data/anoGam1/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
#Completed: 747 of 747 jobs
#Average job time:                1597s      26.61m     0.44h    0.02d
#Longest job:                     2788s      46.47m     0.77h    0.03d
#Submission to last job:         20691s     344.85m     5.75h    0.24d

    #- Lift up the 500KB chunk .out's to 5MB ("pseudo-contig") level
    ssh kksilo
    cd /cluster/data/anoGam1
    foreach d (*/chr*_?{,?})
      set contig = $d:t
      echo $contig
      liftUp $d/$contig.fa.out $d/$contig.lft warn $d/${contig}_*.fa.out \
        > /dev/null
    end

    #- Lift pseudo-contigs to chromosome level
    foreach c (?{,?})
      echo lifting $c
      cd $c
      liftUp chr$c.fa.out chr$c.lft warn \
        `awk '{print $2 "/" $2 ".fa.out";}' chr$c.lft` \
        > /dev/null
      cd ..
    end

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/anoGam1
    hgLoadOut anoGam1 */chr*.fa.out


# VERIFY REPEATMASKER RESULTS (DONE 6/9/04 angie)
    # Eyeball some repeat annotations in the browser, compare to lib seqs.
    # Run featureBits on anoGam1 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits anoGam1 rmsk
#21785530 bases of 278268413 (7.829%) in intersection

    # compare to dm1:
    featureBits dm1 rmsk
#15452875 bases of 126527731 (12.213%) in intersection


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE 6/7/04 angie)
    # Warning: genome and organism fields must correspond
    # with defaultDb values
    hgsql -h genome-testdb hgcentraltest \
      -e 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome, scientificName, \
                htmlPath, hgNearOk) values \
        ("anoGam1", "Apr. 2004", "/gbdb/anoGam1/nib", "A. gambiae", \
               "chr2L:827700-845800", 1, 59, "A. gambiae", \
                "Anopheles gambiae", "/gbdb/anoGam1/html/description.html", \
                0);'
    hgsql -h genome-testdb hgcentraltest \
      -e 'INSERT INTO defaultDb (genome, name) values ("A. gambiae", "anoGam1");'

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P

    # Edit that makefile to add anoGam1 in all the right places and do
    make update

    mkdir /gbdb/anoGam1/html
    # go public on genome-test
    cvs commit makefile
    make alpha

    # Add trackDb directories
    mkdir anopheles
    mkdir anopheles/anoGam1
    cvs add anopheles
    cvs add anopheles/anoGam1
    cvs commit anopheles/anoGam1


# GOLD AND GAP TRACKS (DONE 6/7/04 angie)
    ssh hgwdev
    cd /cluster/data/anoGam1
    cp /dev/null chrom.lst
    foreach f (?{,?}/chr*.agp chrM)
      echo $f:t:r >> chrom.lst
    end
    hgGoldGapGl -noGl -chromLst=chrom.lst anoGam1 /cluster/data/anoGam1 .
    # featureBits fails if there's no chrM_gap, so make one:
    # echo "create table chrM_gap like chr1_gap" | hgsql anoGam1
    # oops, that won't work until v4.1, so do this for the time being:
    hgsql anoGam1 -e 'create table chrM_gap select * from chr2L_gap where 0=1'


# MAKE LIFTALL.LFT (DONE 6/8/04 angie)
    ssh kksilo
    cd /cluster/data/anoGam1
    cat ?{,?}/chr*.lft > jkStuff/liftAll.lft


# SIMPLE REPEATS (TRF) (DONE 6/8/04 angie)
    ssh kksilo
    mkdir /cluster/data/anoGam1/bed/simpleRepeat
    cd /cluster/data/anoGam1/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach d (/cluster/data/anoGam1/?{,?}/chr*_?{,?})
      set ctg = $d:t
      foreach f ($d/${ctg}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
      end
    end
    tcsh jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    liftUp simpleRepeat.bed ../../jkStuff/liftAll.lft warn \
      trf/*.bed > /dev/null

    # Load this into the database as so
    ssh hgwdev
    hgLoadBed anoGam1 simpleRepeat \
      /cluster/data/anoGam1/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
    featureBits anoGam1 simpleRepeat
#5668988 bases of 278268413 (2.037%) in intersection


# FILTER SIMPLE REPEATS (TRF) INTO MASK (DONE 6/8/04 angie)
    # make a filtered version of the trf output: 
    # keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/anoGam1/bed/simpleRepeat
    mkdir trfMask
    foreach f (trf/*.bed)
      echo -n "filtering $f... "
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords:
    mkdir trfMaskChrom
    foreach f (../../?{,?}/chr*.fa)
      set c = $f:t:r
      echo $c
      liftUp trfMaskChrom/$c.bed ../../jkStuff/liftAll.lft warn \
        trfMask/${c}_[0-9]*.bed > /dev/null
    end


# MASK FA USING REPEATMASKER AND FILTERED TRF FILES (DONE 6/8/04 angie)
    ssh kksilo
    cd /cluster/data/anoGam1
    # Soft-mask (lower-case) the contig and chr .fa's, 
    # then make hard-masked versions from the soft-masked.  
    set trfCtg=bed/simpleRepeat/trfMask
    set trfChr=bed/simpleRepeat/trfMaskChrom
    foreach f (*/chr*.fa)
      echo "repeat- and trf-masking $f"
      maskOutFa -soft $f $f.out $f
      set chr = $f:t:r
      maskOutFa -softAdd $f $trfChr/$chr.bed $f
      echo "hard-masking $f"
      maskOutFa $f hard $f.masked
    end
    foreach c (?{,?})
      echo "repeat- and trf-masking contigs of chr$c, chr${c}_random"
      foreach d ($c/chr*_?{,?})
        set ctg=$d:t
        set f=$d/$ctg.fa
        maskOutFa -soft $f $f.out $f
        maskOutFa -softAdd $f $trfCtg/$ctg.bed $f
        maskOutFa $f hard $f.masked
      end
    end
    #- Rebuild the nib files, using the soft masking in the fa:
    foreach f (*/chr*.fa)
      faToNib -softMask $f nib/$f:t:r.nib
    end
    # Make one big 2bit file as well, and make a link to it in 
    # /gbdb/anoGam1/nib because hgBlat looks there:
    faToTwoBit */chr*.fa anoGam1.2bit
    ssh hgwdev
    ln -s /cluster/data/anoGam1/anoGam1.2bit /gbdb/anoGam1/nib/


# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 6/17/04 angie)
    ssh kksilo
    cd /cluster/data/anoGam1
    #- Build the .zip files -- no genbank for now.
    cat << '_EOF_' > jkStuff/zipAll.csh
rm -rf zip
mkdir zip
zip -j zip/chromAgp.zip [0-9A-Z]*/chr*.agp
zip -j zip/chromOut.zip */chr*.fa.out
zip -j zip/chromFa.zip */chr*.fa
zip -j zip/chromFaMasked.zip */chr*.fa.masked
cd bed/simpleRepeat
zip ../../zip/chromTrf.zip trfMaskChrom/chr*.bed
cd ../..
'_EOF_'
    # << this line makes emacs coloring happy
    csh ./jkStuff/zipAll.csh |& tee zipAll.log
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd /cluster/data/anoGam1/zip
    set gp = /usr/local/apache/htdocs/goldenPath/anoGam1
    mkdir -p $gp/bigZips
    cp -p *.zip $gp/bigZips
    mkdir -p $gp/chromosomes
    foreach f ( ../*/chr*.fa )
      nice zip -j $gp/chromosomes/$f:t.zip $f
    end
    cd $gp/bigZips
    nice md5sum *.zip > md5sum.txt
    cd $gp/chromosomes
    nice md5sum *.zip > md5sum.txt
    # Take a look at bigZips/* and chromosomes/*, update their README.txt's


# PUT MASKED SEQUENCE OUT FOR CLUSTER RUNS (DONE 6/8/04 angie)
    ssh kkr1u00
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /iscratch/i/anoGam1/nib
    mkdir -p /iscratch/i/anoGam1/nib
    cp -p /cluster/data/anoGam1/nib/chr*.nib /iscratch/i/anoGam1/nib
    iSync
    # bluearc too (rack 9 can't see iscratch):
    ssh kksilo
    rm -rf /cluster/bluearc/anoGam1/nib
    mkdir -p /cluster/bluearc/anoGam1/nib
    cp -p /cluster/data/anoGam1/nib/chr*.nib /cluster/bluearc/anoGam1/nib


# LOAD ENSEMBL GENES (DONE 6/9/04 angie)
    mkdir /cluster/data/anoGam1/bed/ensembl
    cd /cluster/data/anoGam1/bed/ensembl
    # Get the ensembl gene data from 
    # http://www.ensembl.org/Anopheles_gambiae/martview
    # Follow this sequence through the pages:
    # Page 1) Make sure that the Anopheles_gambiae choice is selected. Hit next.
    # Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
    # Page 3) Choose the "Structures" box. 
    # Page 4) Choose GTF as the ouput.  choose gzip compression.  hit export.
    # Save as ensembl.gff.gz
    # Add "chr" to front of each line in the gene data gtf file to make 
    # it compatible with our software.
    gunzip -c ensembl.gff.gz \
    | perl -wpe 's/^UNKN/U/; s/^([2-3][LR]?|X|U)/chr$1/ \
                 || die "Line $. doesnt start with anopheles chrom:\n$_"' \
    > ensGene.gtf
    ssh hgwdev
    ldHgGene -gtf -genePredExt anoGam1 ensGene \
      /cluster/data/anoGam1/bed/ensembl/ensGene.gtf

    # ensGtp associates geneId/transcriptId/proteinId for hgPepPred and 
    # hgKnownToSuper.  Use ensMart to create it as above, except:
    # Page 3) Choose the "Features" box. In "Ensembl Attributes", check 
    # Ensembl Gene ID, Ensembl Transcript ID, Ensembl Peptide ID.  
    # Choose Text, tab-separated as the output format.  Result name ensGtp.
    # Save file as ensGtp.txt.gz
    gunzip ensGtp.txt.gz
    hgsql anoGam1 < ~/kent/src/hg/lib/ensGtp.sql
    hgsql anoGam1 -e 'load data local infile "ensGtp.txt" into table ensGtp'

    # Load Ensembl peptides:
    # Get them from ensembl as above in the gene section except for
    # Page 3) Choose the "Sequences" box. 
    # Page 4) Transcripts/Proteins.  Peptide.  Format = FASTA.
    # Save file as ensemblPep.fa.gz
    gunzip -c ensemblPep.fa.gz \
    | perl -wpe 's/^(>ENSANGT\d+\.\d+).*/$1/' \
    > ensPep.fa
    hgPepPred anoGam1 generic ensPep ensPep.fa


# PRODUCING GENSCAN PREDICTIONS (DONE 6/9/04 angie)
    # Run on small cluster -- genscan needs big mem.
    ssh hgwdev
    mkdir /cluster/data/anoGam1/bed/genscan
    cd /cluster/data/anoGam1/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Run on small cluster (more mem than big cluster).
    ssh kki
    cd /cluster/data/anoGam1/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    cp /dev/null genome.list
    foreach f ( `ls -1S /cluster/data/anoGam1/*/chr*_*/chr*_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    wc -l genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 68 of 68 jobs
#Average job time:                 133s       2.21m     0.04h    0.00d
#Longest job:                      167s       2.78m     0.05h    0.00d
#Submission to last job:           720s      12.00m     0.20h    0.01d

    # Convert these to chromosome level files as so:
    ssh kksilo
    cd /cluster/data/anoGam1/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/anoGam1/bed/genscan
    ldHgGene -gtf -genePredExt anoGam1 genscan genscan.gtf
    hgPepPred anoGam1 generic genscanPep genscan.pep
    hgLoadBed anoGam1 genscanSubopt genscanSubopt.bed


# SWAP BLASTZ MELANOGASTER-ANOPHELES TO ANOPHELES-MEL (DONE 6/10/04 angie)
    ssh kolossus
    mkdir /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10
    set aliDir = /cluster/data/dm1/bed/blastz.anoGam1.2004-06-10
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSplitByTarget stdin unsorted
    # Sort the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    du -sh $aliDir/axtChrom unsorted axtChrom
#157M    /cluster/data/dm1/bed/blastz.anoGam1.2004-06-10/axtChrom
#157M    unsorted
#157M    axtChrom
    rm -r unsorted


# CHAIN MELANOGASTER BLASTZ (DONE 6/10/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    # Make our own linear gap file with reduced gap penalties:
    cat << '_EOF_' > ../../chickenHumanTuned.gap
tablesize	11
smallSize	111
position	1	2	3	11	111	2111	12111	32111	72111	152111	252111
qGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
tGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
bothGap	625	660	700	750	900	1400	4000	8000	16000	32000	57000
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=../../chickenHumanTuned.gap \
         -verbose=0 $1 \
  /iscratch/i/anoGam1/nib \
  /cluster/bluearc/drosophila/dm1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 7 of 7 jobs
#Average job time:                  10s       0.17m     0.00h    0.00d
#Longest job:                       13s       0.22m     0.00h    0.00d
#Submission to last job:            13s       0.22m     0.00h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    du -sh chain run1/chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain anoGam1 ${c}_chainDm1 $i
    end


# NET MELANOGASTER BLASTZ (DONE 6/10/04 angie)
    ssh kksilo
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain
    netClass -noAr noClass.net anoGam1 dm1 melanogaster.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain
    rm noClass.net
    netFilter -syn melanogaster.net > melanogasterSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain
    netFilter -minGap=10 melanogaster.net |  hgLoadNet anoGam1 netDm1 stdin
    netFilter -minGap=10 melanogasterSyn.net | hgLoadNet anoGam1 netSyntenyDm1 stdin


# MAKE VSDM1 DOWNLOADABLES (DONE 6/9/04 angie)
    ssh kksilo
    cd /cluster/data/anoGam1/bed/blastz.dm1.swap.2004-06-10/axtChain
    cp all.chain melanogaster.chain
    zip /cluster/data/anoGam1/zip/melanogaster.chain.zip melanogaster.chain
    rm melanogaster.chain
    zip /cluster/data/anoGam1/zip/melanogaster.net.zip melanogaster.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/anoGam1/vsDm1
    cd /usr/local/apache/htdocs/goldenPath/anoGam1/vsDm1
    mv /cluster/data/anoGam1/zip/melanogaster*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


