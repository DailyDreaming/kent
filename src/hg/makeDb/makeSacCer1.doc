#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This describes how to make the sacCer1 browser database.
#
# The genomic sequence was downloaded Nov. 17, 2003, and is dated
# 10/1/2003 on the Stanford FTP site.  The previous version of the
# genomic sequence is dated Nov. 2002.  I don't see version numbers.

# Create the directory structure and download sequence from the SGD
# site at Stanford.
    mkdir /cluster/store6/sacCer1
    ln -s /cluster/store6/sacCer1 /cluster/data/sacCer1
    cd /cluster/data/sacCer1
    mkdir 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 M bed download
    cd download
    mkdir chromosomes
    cd chromosomes
    foreach i (01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 mt)
	wget ftp://genome-ftp.stanford.edu/pub/yeast/data_download/sequence/genomic_sequence/chromosomes/fasta/chr$i.fsa
    end
    foreach i (1 2 3 4 5 6 7 8 9)
	echo ">chr$i" > chr$i.fa
	grep -v '^>' chr0$i.fsa >> chr$i.fa
    end
    foreach i (chr1?.fsa)
	echo ">$i:r" > $i:r.fa
	grep -v '^>' $i >> $i:r.fa
    end
    echo ">chrM" > chrM.fa
    grep -v '^>' chrmt.fsa > chrM.fa
    foreach i (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 M)
	mv chr$i.fa ../../$i
    end
    gzip -4 *.fsa

# Download other info from the FTP site.
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/chromosomal_feature
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/gene_registry
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/literature_curation
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/oracle_schema
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/protein_info
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/sequence_similarity
    wget -nH --cut-dirs=3 -r ftp://genome-ftp.stanford.edu/pub/yeast/data_download/systematic_results
    wget -nH --cut-dirs=5 -r -l 2 ftp://genome-ftp.stanford.edu/pub/yeast/data_download/sequence/genomic_sequence/orf_protein

    # Check that the genome is in sync with the annotations
    cd /cluster/data/sacCer1
    checkSgdSync download
    # This showed 5 of 5788 with no ATG.  I sent these to Mike Cherry.

# CREATING DATABASE, MAKE AND LOAD NIBS (DONE 2003-11-24 - Jim)
# NOTE FOR YEAST WE DO NOT REPEAT MASK SEQUENCE.
    ssh hgwdev
    echo 'create database sacCer1' | hgsql ''
    cd /cluster/data/sacCer1
    hgNibSeq sacCer1 /cluster/data/sacCer1/nib */*.fa
    faSize -detailed */*.fa > chrom.sizes
    mkdir -p /gbdb/sacCer1/nib
    ln -s /cluster/data/sacCer1/nib/*.nib /gbdb/sacCer1/nib
    # Create a read-only alias in your .cshrc or .profile
    alias sacCer1 mysql -u hguser -phguserstuff -A sacCer1
    # Use df to ake sure there is at least 5 gig of free mySql table space
    df -h /var/lib/mysql

# CREATING GRP TABLE FOR TRACK GROUPING (DONE 2003-11-21 - Jim)
    ssh hgwdev
    #  the following command copies all the data from the table
    #	grp in the database hg16 to our new database sacCer1
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg16.grp" \
      | hgsql sacCer1

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR YEAST (DONE 2003-11-24 Jim)
    # Warning: must genome and organism fields must correspond
    # with defaultDb values
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome, scientificName, \
                htmlPath, hgNearOk) values \
        ("sacCer1", "Oct. 2003", "/gbdb/sacCer1/nib", "Yeast", \
               "chr2:827700-845800", 1, 65, "Yeast", \
                "Saccharomyces cerevisiae", "/gbdb/sacCer1/html/description.html", \
                0);' \
      | hgsql -h genome-testdb hgcentraltest
    echo 'INSERT INTO defaultDb (genome, name) values ("Yeast", "sacCer1");' \
      | hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P

    # Edit that makefile to add sacCer1 in all the right places and do
    make update

    # go public on genome-test
    #make alpha
    cvs commit makefile

    # Add trackDb directories
    mkdir sacCer
    mkdir sacCer/sacCer1
    cvs add sacCer
    cvs add sacCer/sacCer1
    cvs commit sacCer

# MAKE GCPERCENT (DONE 2003-11-24 - Jim)
     ssh hgwdev
     mkdir /cluster/data/sacCer1/bed/gcPercent
     cd /cluster/data/sacCer1/bed/gcPercent
     # create and load gcPercent table
     hgsql sacCer1  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent sacCer1 ../../nib

# RUN TANDEM REPEAT MASKER (DONE 2003-11-24 - Jim)
    # Do tandem repeat masking - this takes about 2 minutes.
    ssh hgwdev
    mkdir -p /cluster/data/sacCer1/bed/simpleRepeat
    cd /cluster/data/sacCer1
    foreach i (? ??)
	trfBig $i/chr$i.fa /dev/null \
	-bedAt=/cluster/data/sacCer1/bed/simpleRepeat/chr$i.bed
    end
    # Load into the database
    cd /cluster/data/sacCer1/bed/simpleRepeat
    hgLoadBed sacCer1 simpleRepeat *.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
    # Loaded 1316 elements of size 16
    featureBits sacCer1 simpleRepeat
    # 82600648 bases of 2627444668 (3.144%) in intersection

# MAKE DESCRIPTION/SAMPLE POSITION HTML PAGE (done)
    ssh hgwdev
    # Write ~/kent/src/hg/makeDb/trackDb/sacCer/sacCer1/description.html 
    # with a description of the assembly and some sample position queries.  
    chmod a+r ~/kent/src/hg/makeDb/trackDb/sacCer/sacCer1/description.html
    # Check it in 
    mkdir -p /gbdb/sacCer1/html
    ln -s /cluster/data/sacCer1/html/description.html /gbdb/sacCer1/html/
    # Create line in trackDb/makefile that copies description.html into
    #     /cluster/data/sacCer1/html/description.html  
    # Note, you definitely want to make the symbolic link in /gbdb/sacCer/html
    # before doing this.

# MAKE HGCENTRALTEST BLATSERVERS ENTRY (DONE 2003-11-24 Jim)
# AND SET UP BLAT SERVERS
    ssh blat10
    cd /scratch
    mkdir sacCer1Nib
    scp 'hgwdev:/cluster/data/sacCer1/nib/*.nib' sacCer1Nib
    # Ask admins to set up blat servers and ask which ports they assign.
    ssh hgwdev
    echo 'insert into blatServers values("sacCer1", "blat10", "17788", "0"); \
          insert into blatServers values("sacCer1", "blat10", "17789", "1");' \
      | hgsql -h genome-testdb hgcentraltest

# CREATING SGD-BASED KNOWN GENES AND OTHER FEATURES (DONE 2003-12-02 Jim)
# Note initially the s_cerevisiae.gff3 file ended up being out of
# sync with the genome. Mike Cherry (cherry@genome.stanford.edu)
# regenerated it.  The format may end up changing in the future though.
    ssh hgwdev
    cd /cluster/data/sacCer1/bed
    mkdir sgdGene
    hgSgdGff3 ../download/chromosomal_feature/s_cerevisiae.gff3 sgdGene
    cd sgdGene
    ldHgGene sacCer1 sgdGene codingGenes.gff
    hgLoadBed sacCer1 sgdOther otherFeatures.bed \
        -tab -sqlTable=$HOME/kent/src/hg/lib/sgdOther.sql
    zcat ../../download/orf_protein/*.fasta.gz \
        | hgSgdPep -restrict=genePred.tab stdin sgdPep.fa symbol.txt
    hgPepPred sacCer1 generic sgdPep sgdPep.fa
    echo 'create table sgdToName ( \
          name varchar(10) not null, \
	  value varchar(10) not null, \
	  PRIMARY KEY(name), \
	  INDEX (value));' | hgsql sacCer1
    echo 'load data local infile "symbol.txt" \
          into table sgdToName;' | hgsql sacCer1
    hgsql sacCer1 < $HOME/kent/src/hg/lib/sgdDescription.sql
    echo 'load data local infile "descriptions.txt" \
          into table sgdDescription;' | hgsql sacCer1
    hgsql sacCer1 < $HOME/kent/src/hg/lib/sgdOtherDescription.sql
    echo 'load data local infile "notes.txt" \
          into table sgdOtherDescription;' | hgsql sacCer1

# ADDING SWISSPROT ACCESSION TO KNOWN GENES (DONE 2003-11-25 Jim)
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/sgdGene
    awk '$2 == "SwissProt" {printf("%s\t%s\n", $3, $1);}' \
        ../../download/chromosomal_feature/external_id.tab \
	> sgdToSwissProt.txt
    echo 'create table sgdToSwissProt ( \
          name varchar(10) not null, \
	  value varchar(10) not null, \
	  PRIMARY KEY(name), \
	  INDEX (value));' | hgsql sacCer1
    echo 'load data local infile "sgdToSwissProt.txt" \
          into table sgdToSwissProt;' | hgsql sacCer1
    hgProtIdToGenePred sacCer1 sgdGene sgdToSwissProt name value

# CREATE SGD-BASED CLONE TRACK (DONE 2003-11-25 Jim)
    ssh hgwdev
    cd /cluster/data/sacCer1/bed
    mkdir sgdClone
    cd sgdClone
    awk -F '\t' '{printf("chr%s\t%d\t%d\t%s\t%s\n", $3, $4-1, $5, $2, $1);}' \
    	../../download/chromosomal_feature/clone.tab > sgdClone.bed
    hgLoadBed sacCer1 sgdClone  sgdClone.bed -tab \
        -sqlTable=$HOME/kent/src/hg/lib/sgdClone.sql

# AUTO UPDATE GENBANK MRNA RUN  (In Progress 2003-11-24 Jim)

    # Put the nib's on /cluster/bluearc:
    ssh eieio
    mkdir -p /cluster/bluearc/sacCer/sacCer1/nib
    cp -pR /cluster/data/sacCer1/nib/*.nib /cluster/bluearc/sacCer/sacCer1/nib

    # Instructions for setting up incremental genbank updates are here:
    # http://www.soe.ucsc.edu/~markd/genbank-update/doc/initial-load.html

    # Added
static char *sacCerNames[] = {"Saccharomyces cerevisiae", NULL};
    and
{"dm", dmNames, NULL},
    to appropriate parts of src/hg/makeDb/genbank/src/lib/gbGenome.c
    # Then make and make install
    cd src/hg/make/makeDb/genbank
    make PREFIX=/cluster/store5/genbank install

    # Edit /cluster/data/genbank/etc/genbank.conf and add:
# sacCer1
sacCer1.genome = /cluster/bluearc/sacCer/sacCer1/nib/chr*.nib
sacCer1.lift = no
sacCer1.genbank.mrna.xeno.load = no
sacCer1.genbank.est.xeno.load = no
sacCer1.downloadDir = sacCer1

    # Do the alignments
    ssh eieio
    cd /cluster/data/genbank
    nice bin/gbAlignStep -iserver=no \
      -clusterRootDir=/cluster/bluearc/genbank \
      -verbose=1 -initial sacCer1

    # Load the results from the above
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad sacCer1

# DOING MULTIPLE ALIGNMENT WITH OTHER YEAST
# Grab sequence from all six yeast and massage
# it so that fasta records all start with sacXXX
# in the directory /cluster/data/sacCer1/bed/otherYeast/align
       ssh kkr1u00
       cd /cluster/data/sacCer1/bed/otherYeast/align

       # Create directory full of size info
       mkdir sizes
       foreach i (sac*)
           faSize $i -detailed > sizes/$i
       end

       # Create some working directories
       mkdir lav axtAll axtBest mafIn mafRawOut mafOut

       # Create little shell script to do blastz alignments
       cat > bz << end
#!/bin/csh -ef
blastz \$1 \$2 > \$3
end
       chmod a+x bz

       # Create job spec to do all blastz alignments
       ls -1 ../../../*/chr*.fa > sacCer.lst
       ls -1 sac??? > other.lst
       cat > gsub << end
#LOOP
bz \$(path1) \$(path2) {check out line+ lav/\$(root1).\$(root2)}
#ENDLOOP
end
       gensub2 sacCer.lst other.lst gsub spec

       # Do parasol blastz run
       para create spec
       para try
       # Do some para checks and if all is well
       para push
#Completed: 102 of 102 jobs
#CPU time in finished jobs:      43279s     721.31m    12.02h    0.50d  0.001 y
#IO & Wait Time:                   540s       9.00m     0.15h    0.01d  0.000 y
#Average job time:                 430s       7.16m     0.12h    0.00d
#Longest job:                     1458s      24.30m     0.41h    0.02d
#Submission to last job:          3994s      66.57m     1.11h    0.05d

       # Convert from lav to axt
       cd lav
       foreach i (sacPar sacMik sacKud sacBay sacCas sacKlu)
           foreach j (*.$i)
	       lavToAxt $j ../../../../nib ../$i ../axtAll/$j -fa
	   end
	   echo done $i
       end
       cd ..

       # Run axtBest
       cd axtAll
       foreach i (sacPar sacMik sacKud sacBay sacCas sacKlu)
           foreach j (*.$i)
	       axtBest $j $j:r ../axtBest/$j
	   end
	   echo done $i
       end
       cd ..

       # Convert to maf
       cd axtBest
       foreach i (sacPar sacMik sacKud sacBay sacCas sacKlu)
           foreach j (*.$i)
	       axtToMaf $j ../../../../chrom.sizes ../sizes/$i ../mafIn/$j -tPrefix=sacCer1.
	   end
	   echo done $i
       end
       cd ..


       # Run multiz
       cd mafIn
       set mz = /cluster/bin/penn/tba.9.13/multiz
       foreach i (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 M)
          set c = chr$i
	  $mz $c.sacPar $c.sacMik - > ../mafRawOut/$c.maf
	  echo done $c.sacMik
	  foreach s (sacKud sacBay sacCas sacKlu)
	      $mz $c.$s ../mafRawOut/$c.maf - > ../mafRawOut/tmp
	      mv ../mafRawOut/tmp ../mafRawOut/$c.maf
	      echo done $c.$s
	  end
       end
       cd ..

       #Load into database
       ssh hgwdev
       cd /cluster/data/sacCer1/bed/otherYeast/align
       ln -s /cluster/store6/sacCer1/bed/otherYeast/align/mafOut /gbdb/sacCer1/multizYeast
       hgLoadMaf sacCer1 multizYeast

       # Clean up
       cd mafRawOut
       foreach i (*.maf)
           mafFilter -minScore=100 $i > ../mafOut/$i
       rm -r axtAll axtBest lav err mafRawOut multizYeast.tab


# ADDING LOCALIZATION AND ABUNDANCE INFO FROM SGD AND 
# http://yeastgfp.ucsf.edu  				(DONE 2003-11-24 - Jim)
	ssh hgwdev
	cd /cluster/data/sacCer1/bed
	mkdir sgdLocalization
	cd sgdLocalization
	hgSgdGfp sacCer1 ../../download/systematic_results/localization/OS*.tab .

# UPDATE GO DATABASE
    ssh hgwdev
    cd /cluster/store1/geneOntology
    mkdir 20031202
    cd 20031202
    wget ftp://ftp.geneontology.org/pub/go/godatabase/archive/latest/go_200311-termdb-data.gz
    wget ftp://ftp.geneontology.org/pub/go/gene-associations/gene_association.goa_sptr.gz
    hgsql mysql <<end
    drop database go;
    create database go;
    end
    zcat go_*data.gz | hgsql go
    zcat gene_association.goa_sptr.gz | hgGoAssociation go goaPart stdin -taxon=9606,10090,10116,6239,7227,4932

######## MAKING FAMILY BROWSER TABLES #######

# GETTING STARTED WITH FAMILY BROWSER (DONE 2003-11-29 Jim)
    # Making tables to cluster splice varients
    ssh hgwdev
    hgClusterGenes sacCer1 sgdGene sgdIsoforms sgdCanonical

    # Make self mapping table for expression. 
    echo 'create table sgdToSgd ( \
          name varchar(10) not null, \
	  value varchar(10) not null, \
	  PRIMARY KEY(name), \
	  UNIQUE (value));' | hgsql sacCer1
    echo 'select name from sgdGene;' | hgsql -N sacCer1 \
         | awk '{printf("%s\t%s\n", $1, $1);}' > sgdToSgd.tab
    echo 'load data local infile "sgdToSgd.tab" into table sgdToSgd' \
         | hgsql sacCer1

    # Make expression similarity table. 
    cd ~/src/hg/near/hgExpDistance
    hgExpDistance sacCer1 hgFixed.yeastChoCellCycle hgFixed.yeastChoCellCycleExps choExpDistance 


#DOING SELF-PROTEIN ALIGNMENTS AND LOADING (DONE 2003-12-8 Jim)
    # Extract peptides from genome database into fasta file
    # and create a blast database out of them. 
    mkdir -p /cluster/data/sacCer1/bed/blastp
    cd /cluster/data/sacCer1/bed/blastp
    pepPredToFa sacCer1 sgdPep sgdPep.faa
    formatdb -i sgdPep.faa -t sgdPep -n sgdPep
    cd ..

    # Copy over database to /scratch
    ssh kk
    mkdir -p /scratch/sacCer1/blastp
    cp /cluster/data/sacCer1/bed/blastp/sgdPep.p* /scratch/sacCer1/blastp
    sudo /cluster/install/utilities/updateLocal

    # Split up fasta file into bite sized chunks for cluster
    cd /cluster/data/sacCer1/bed/blastp
    mkdir split
    faSplit sequence sgdPep.faa 6000 split/kg

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/sacCer1/bed/blastp/self
    cd /cluster/data/sacCer1/bed/blastp/self
    mkdir run
    cd run
    mkdir out

    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /scratch/blast/data
/scratch/blast/blastall -p blastp -d /scratch/sacCer1/blastp/sgdPep -i \$1 -o \$2 -e 0.01 -m 8 -b 1000
end
    chmod a+x blastSome

    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

    # Create parasol batch
    echo ../../split/*.fa | wordLine stdin > split.lst
    gensub2 split.lst single gsub spec
    para create spec
    para try

    # Wait a couple of minutes, and do a para check,  if all is good
    # then do a
    para push
    # This should finish in 1 minute if the cluster is free.
#Completed: 5743 of 5743 jobs
#CPU time in finished jobs:       3570s      59.50m     0.99h    0.04d  0.000 y
#IO & Wait Time:                 14973s     249.55m     4.16h    0.17d  0.000 y
#Average job time:                   3s       0.05m     0.00h    0.00d
#Longest job:                       12s       0.20m     0.00h    0.00d
#Submission to last job:            55s       0.92m     0.02h    0.00d

    # Load into database.  This takes a minute 
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/blastp/self/run/out
    hgLoadBlastTab sacCer1 sgdBlastTab *.tab
#Scanning through 5743 files
#Loading database with 52725 rows


#DOING C.ELEGANS-PROTEIN ALIGNMENTS AND LOADING (DONE 2003-12-8 Jim)
    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/sacCer1/bed/blastp/ce1
    cd /cluster/data/sacCer1/bed/blastp/ce1
    mkdir run
    cd run
    mkdir out

    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/scratch/blast/blastall -p blastp -d /iscratch/i/ce1/blastp/wormPep -i \$1 -o \$2 -e 0.01 -m 8 -b 1
end
    chmod a+x blastSome

    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

    # Create parasol batch
    echo ../../split/*.fa | wordLine stdin > split.lst
    gensub2 split.lst single gsub spec
    para create spec
    para try

    # Wait a couple of minutes, and do a para check,  if all is good
    # then do a
    para push
Completed: 5743 of 5743 jobs
#CPU time in finished jobs:       9397s     156.62m     2.61h    0.11d  0.000 y
#IO & Wait Time:                 21849s     364.15m     6.07h    0.25d  0.001 y
#Average job time:                   5s       0.09m     0.00h    0.00d
#Longest job:                       26s       0.43m     0.01h    0.00d
#Submission to last job:            75s       1.25m     0.02h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/blastp/ce1/run/out
    hgLoadBlastTab sacCer1 ceBlastTab -maxPer=1 *.tab

#DOING MOUSE-PROTEIN ALIGNMENTS AND LOADING (DONE 2003-12-8 Jim)
    # Make mouse ortholog column using blastp on mouse known genes.
    # First make mouse protein database and copy it to iscratch/i
    # if it doesn't exist already
    cd /cluster/data/mm4/bed
    mkdir blastp
    cd blastp
    pepPredToFa mm4 knownGenePep known.faa
    formatdb -i known.faa -t known -n known
    ssh kkr1u00
    if (-e /iscratch/i/mm4/blastp) then
       rm -r /iscratch/i/mm4/blastp
    endif
    mkdir -p /iscratch/i/mm4/blastp
    cp /cluster/data/mm4/bed/blastp/known.p?? /iscratch/i/mm4/blastp
    iSync

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/sacCer1/bed/blastp/mm4
    cd /cluster/data/sacCer1/bed/blastp/mm4
    mkdir run
    cd run
    mkdir out

    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/scratch/blast/blastall -p blastp -d /iscratch/i/mm4/blastp/known -i \$1 -o \$2 -e 0.001 -m 8 -b 1
end
chmod a+x blastSome

    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

    # Create parasol batch
    echo ../../split/*.fa | wordLine stdin > split.lst
    gensub2 split.lst single gsub spec
    para create spec
    para try

    # Wait a couple of minutes, and do a para check,  if all is good
    # then do a
    para push
#Completed: 5743 of 5743 jobs
#CPU time in finished jobs:      13913s     231.88m     3.86h    0.16d  0.000 y
#IO & Wait Time:                 27267s     454.45m     7.57h    0.32d  0.001 y
#Average job time:                   7s       0.12m     0.00h    0.00d
#Longest job:                       40s       0.67m     0.01h    0.00d
#Submission to last job:            80s       1.33m     0.02h    0.00d


    # Load into database.  
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/blastp/mm4/run/out
    hgLoadBlastTab sacCer1 mmBlastTab -maxPer=1 *.tab

#DOING ZEBRAFISH-PROTEIN ALIGNMENTS AND LOADING (DONE 2003-12-8 Jim)
    # Make Danio rerio (zebrafish) ortholog column using blastp on Ensembl.
    # First make protein database and copy it to iscratch/i
    # if it doesn't exist already
    cd /cluster/data/dr1/bed
    mkdir blastp
    cd blastp
    wget ftp://ftp.ensembl.org/pub/current_zebrafish/data/fasta/pep/Danio_rerio.ZFISH2.pep.fa.gz 
    zcat Dan*.pep.fa.gz > ensembl.faa
    echo "Translation:" > subs.in
    subs -e ensembl.faa > /dev/null
    formatdb -i ensembl.faa -t ensembl -n ensembl
    ssh kkr1u00
    if (-e /iscratch/i/dr1/blastp) then
       rm -r /iscratch/i/dr1/blastp
    endif
    mkdir -p /iscratch/i/dr1/blastp
    cp /cluster/data/dr1/bed/blastp/ensembl.p?? /iscratch/i/dr1/blastp
    iSync

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/sacCer1/bed/blastp/dr1
    cd /cluster/data/sacCer1/bed/blastp/dr1
    mkdir run
    cd run
    mkdir out

    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/scratch/blast/blastall -p blastp -d /iscratch/i/dr1/blastp/ensembl -i \$1 -o \$2 -e 0.005 -m 8 -b 1
end
    chmod a+x blastSome

    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

    # Create parasol batch
    echo ../../split/*.fa | wordLine stdin > split.lst
    gensub2 split.lst single gsub spec
    para create spec
    para try

    # Wait a couple of minutes, and do a para check,  if all is good
    # then do a
    para push
#Completed: 5743 of 5743 jobs
#CPU time in finished jobs:      11135s     185.58m     3.09h    0.13d  0.000 y
#IO & Wait Time:                 23501s     391.69m     6.53h    0.27d  0.001 y
#Average job time:                   6s       0.10m     0.00h    0.00d
#Longest job:                       40s       0.67m     0.01h    0.00d
#Submission to last job:            71s       1.18m     0.02h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/blastp/dr1/run/out
    hgLoadBlastTab sacCer1 drBlastTab -maxPer=1 *.tab

#DOING FRUITFLY-PROTEIN ALIGNMENTS AND LOADING (DONE 2003-12-8 Jim)
    # Make Drosophila melanagaster ortholog column using blastp on FlyBase.
    # First make SwissProt protein database and copy it to iscratch/i
    # if it doesn't exist already
    cd /cluster/data/dm1/bed
    mkdir blastp
    cd blastp
    pepPredToFa dm1 bdgpGenePep bdgp.faa
    formatdb -i bdgp.faa -t bdgp -n bdgp
    ssh kkr1u00
    if (-e /iscratch/i/dm1/blastp) then
       rm -r /iscratch/i/dm1/blastp
    endif
    mkdir -p /iscratch/i/dm1/blastp
    cp /cluster/data/dm1/bed/blastp/bdgp.p?? /iscratch/i/dm1/blastp
    iSync


    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/sacCer1/bed/blastp/dm1
    cd /cluster/data/sacCer1/bed/blastp/dm1
    mkdir run
    cd run
    mkdir out

    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/scratch/blast/blastall -p blastp -d /iscratch/i/dm1/blastp/bdgp -i \$1 -o \$2 -e 0.01 -m 8 -b 1
end
chmod a+x blastSome

    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

    # Create parasol batch
    echo ../../split/*.fa | wordLine stdin > split.lst
    gensub2 split.lst single gsub spec
    para create spec
    para try

    # Wait a couple of minutes, and do a para check,  if all is good
    # then do a
    para push
#Completed: 5743 of 5743 jobs
#CPU time in finished jobs:       9749s     162.49m     2.71h    0.11d  0.000 y
#IO & Wait Time:                 22247s     370.78m     6.18h    0.26d  0.001 y
#Average job time:                   6s       0.09m     0.00h    0.00d
#Longest job:                       28s       0.47m     0.01h    0.00d
#Submission to last job:            64s       1.07m     0.02h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/blastp/dm1/run/out
    hgLoadBlastTab sacCer1 dmBlastTab -maxPer=1 *.tab

#DOING HUMAN-PROTEIN ALIGNMENTS AND LOADING (DONE 2003-12-8 Jim)
    # Make human ortholog column using blastp on human known genes.
    # First make human protein database and copy it to iscratch/i
    # if it doesn't exist already
    cd /cluster/data/hg16/bed
    mkdir blastp
    cd blastp
    pepPredToFa hg16 knownGenePep known.faa
    formatdb -i known.faa -t known -n known
    ssh kkr1u00
    if (-e /iscratch/i/hg16/blastp) then
       rm -r /iscratch/i/hg16/blastp
    endif
    mkdir -p /iscratch/i/hg16/blastp
    cp /cluster/data/hg16/bed/blastp/known.p?? /iscratch/i/hg16/blastp
    iSync

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/sacCer1/bed/blastp/hg16
    cd /cluster/data/sacCer1/bed/blastp/hg16
    mkdir run
    cd run
    mkdir out

    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/scratch/blast/blastall -p blastp -d /iscratch/i/hg16/blastp/known -i \$1 -o \$2 -e 0.001 -m 8 -b 1
end
chmod a+x blastSome

    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

    # Create parasol batch
    echo ../../split/*.fa | wordLine stdin > split.lst
    gensub2 split.lst single gsub spec
    para create spec
    para try

    # Wait a couple of minutes, and do a para check,  if all is good
    # then do a
    para push
#Completed: 5743 of 5743 jobs
#CPU time in finished jobs:      16096s     268.27m     4.47h    0.19d  0.001 y
#IO & Wait Time:                 29943s     499.05m     8.32h    0.35d  0.001 y
#Average job time:                   8s       0.13m     0.00h    0.00d
#Longest job:                       65s       1.08m     0.02h    0.00d
#Submission to last job:           100s       1.67m     0.03h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/sacCer1/bed/blastp/hg16/run/out
    hgLoadBlastTab sacCer1 hgBlastTab -maxPer=1 *.tab

