#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on the 
# Dog (Canis familiaris) July 2004 release.


# CREATE BUILD DIRECTORY (DONE 7/1/04 angie)
    ssh kksilo
    mkdir /cluster/store7/canFam1
    ln -s /cluster/store7/canFam1 /cluster/data/canFam1


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 7/1/04 angie)
    mkdir /cluster/data/canFam1/M
    cd /cluster/data/canFam1/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "canis familiaris mitochondrion genome".  That shows the gi number:
    # 17737322
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=17737322&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Canis familiaris mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 7/1/04 angie)
    # This used to hold scripts -- better to keep them inline in the .doc 
    # so they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/canFam1/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/canFam1/bed


# DOWNLOAD AGP, FASTA & QUAL (DONE 7/7/04 angie)
    ssh kksilo
    mkdir /cluster/data/canFam1/broad
    cd /cluster/data/canFam1/broad
    ftp ftp.broad.mit.edu
      # use username and password emailed by David Jaffe 7/3/04.
      prompt
      bin
      mget Dog1.0.agp Dog1.0.agp.chromosome.fasta.gz
      mget Dog1.0.agp.chromosome.qual.gz assembly.format supercontigs
      mget Dog1.0.masked.agp.chromosome.fasta.gz
      mget supercontigs.summary contigs.bases.gz
      bye
    # Loaded the above 7/5; Reloaded new versions on 7/6 of 
    # Dog1.0.agp Dog1.0.agp.chromosome.fasta.gz 
    # Dog1.0.agp.chromosome.qual.gz Dog1.0.masked.agp.chromosome.fasta.gz
    # And on 7/7 of Dog1.0.agp Dog1.0.agp.chromosome.fasta.gz 
    # Dog1.0.agp.chromosome.qual.gz


# UNPACK CHROM FASTA & AGP AND CROSS-CHECK (DONE 7/7/04 angie)
    # For some reason, the chromosome fasta has been split into 5000000-base
    # chunks.  Fix the headers so that there is one record per chromosome,
    # and make one .fa file per chromosome.  
    ssh kksilo
    cd /cluster/data/canFam1/broad
    cat > ../jkStuff/fixBroadChromHeaders.pl <<'_EOF_'
#!/usr/bin/perl -w
while (<>) {
  if (/^>(\w+)\.1-\d+/) {
    $chr = "chr$1";
    print ">$chr\n";
  } elsif (/^>\w+\.\d+000001-\d+/) {
    # Discard this extra header line. 
  } elsif (/^>/) {
    die "Cant parse line $.:\n$_";
  } else {
    print;
  }
}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x ../jkStuff/fixBroadChromHeaders.pl
    mkdir chroms
    zcat Dog1.0.agp.chromosome.fasta.gz \
    | ../jkStuff/fixBroadChromHeaders.pl \
    | faSplit byname stdin chroms/
    faSize chroms/chr*.fa
#2519779136 bases (159950770 N's 2359828366 real) in 40 sequences in 40 files
#Total size: mean 62994478.4 sd 23674450.6 min 26492144 (chr38) max 126913094 (chrX) median 61172541
#N count: mean 3998769.2 sd 2953878.1
    # Make our usual chrom dir structure and move chr*.fa into it.
    cp /dev/null ../chrom.lst
    foreach f (chroms/chr*.fa)
      set chr = $f:t:r
      set c = `echo $chr | sed -e 's/^chr//;'`
      echo $c >> ../chrom.lst
      mkdir ../$c
      mv $f ../$c
    end
    echo M >> ../chrom.lst

    # Split AGP file into per-chrom AGP files in usual chrom dir structure.
    cd /cluster/data/canFam1
    foreach c (`cat chrom.lst`)
      grep -w "^chr$c" broad/Dog1.0.agp > $c/chr$c.agp
    end
    rm M/chrM.agp
    wc -l ?{,?}/chr*.agp
# 119853 total
    wc -l broad/Dog1.0.agp
# 119853 broad/Dog1.0.agp

    # checkAgpAndFa prints out way too much info -- keep the end/stderr only:
    cd /cluster/data/canFam1
    foreach agp (?{,?}/chr*.agp)
      set fa = $agp:r.fa
      echo checking consistency of $agp and $fa
      checkAgpAndFa $agp $fa | tail -1
    end
    

# UNPACK CHROM QUAL SCORES (DONE 7/7/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1/broad
    # Reuse fixBroadChromHeaders.pl script created in previous step, 
    # compress to .qac for use in quality scores step later on.
    zcat Dog1.0.agp.chromosome.qual.gz \
    | ../jkStuff/fixBroadChromHeaders.pl \
    | qaToQac stdin fixedQuals.qac


# DOUBLE-CHECK BY BUILDING ALT CHROM FASTA FROM CONTIGS+AGP (DONE 7/7/04 angie)
    # This is a redundant check, very low chance of finding any problem 
    # since checkAgpAndFa passed.  It's also very slow.  So don't put this 
    # in the critical path to masked sequence -- run it in parallel.
    ssh kolossus
    cd /cluster/data/canFam1
    mkdir /cluster/bluearc/canFam1
    gunzip -c broad/contigs.bases.gz > /cluster/bluearc/canFam1/contigs.fa
    # The number of "real" bases here should be equal to the number of 
    # "real" bases in the chrom fasta -- and it is now on 7/7, whew.
    faSize /cluster/bluearc/canFam1/contigs.fa
#2359828366 bases (0 N's 2359828366 real) in 59927 sequences in 1 files
#Total size: mean 39378.4 sd 70249.8 min 352 (contig_41721) max 1356923 (contig_5971) median 8974
#N count: mean 0.0 sd 0.0
    foreach agp (?{,?}/chr*.agp)
      set fa = $agp:r.fa2
      echo building $fa from $agp
      awk '$5 == "W" {print $6;}' $agp > /tmp/contigs.lst
      faSomeRecords /cluster/bluearc/canFam1/contigs.fa  /tmp/contigs.lst \
        /tmp/contigs.fa
      agpToFa -simpleMultiMixed $agp $agp:t:r $fa /tmp/contigs.fa
    end
    faSize */chr*.fa2
#2519779136 bases (159950770 N's 2359828366 real) in 40 sequences in 40 files
#Total size: mean 62994478.4 sd 23674450.6 min 26492144 (chr38) max 126913094 (chrX) median 61172541
#N count: mean 3998769.2 sd 2953878.1
    foreach f (?{,?}/chr*.fa2)
      faCmp $f $f:r.fa
    end
    rm ?{,?}/chr*.fa2


# COMPARE CONTIG & CHROM NON-N BASE COUNTS (DONE 7/7/04 angie)
    # In the 7/6 assembly, faSize showed different "real" base counts
    # for contigs (2359828366) vs. chroms (2359035963): contigs have
    # 792403 more non-N bases than chroms.
    # Here's how I determined that the difference was explained by the 
    # omission of some contigs from the AGP.  
    # In the 7/7 assembly, all contigs are in the AGP so we're OK now.
    ssh kksilo
    cd /cluster/data/canFam1
    awk '$5 == "W" {print $6;}' broad/Dog1.0.agp | sort > /tmp/1
    uniq /tmp/1 > /tmp/2
    wc -l /tmp/[12]
#  59927 /tmp/1
#  59927 /tmp/2
# 119854 total
    zcat broad/contigs.bases.gz | g '^>' | sed -e 's/^>//' | sort > /tmp/3
    wc -l /tmp/3
#  59927 /tmp/3
    diff /tmp/1 /tmp/2
# (no difference ==> each contig appears only once)
    diff /tmp/1 /tmp/3 | egrep -v '^[0-9]+' | wc -l
#     0
    # Excellent!  0 contigs missing.  So we don't have to do this stuff,
    # but here it is in case we need it again in the future:
    set missers =  `diff /tmp/1 /tmp/3 | egrep -v '^[0-9]+' | sed -e 's/^> //'`
    zcat broad/contigs.bases.gz | faSize -detailed=on stdin > /tmp/4
    set total = 0
    foreach ctg ($missers)
      set size = `grep -w $ctg /tmp/4 | awk '{print $2;}'`
      echo "$ctg\t$size"
      set total = `expr $total + $size`
    end
    echo "total\t\t$total"
#total           0


# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT CONTIGS/GAPS (DONE 7/7/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    foreach agp (?{,?}/chr*.agp)
      set fa = $agp:r.fa
      echo splitting $agp and $fa
      cp -p $agp $agp.bak
      cp -p $fa $fa.bak
      splitFaIntoContigs $agp $fa . -nSize=5000000
    end
    # No _random's in this assembly, so no need to clean up after them.
    # Make a "pseudo-contig" for processing chrM too:
    mkdir M/chrM_1
    sed -e 's/chrM/chrM_1/' M/chrM.fa > M/chrM_1/chrM_1.fa
    mkdir M/lift
    echo "chrM_1/chrM_1.fa.out" > M/lift/oOut.lst
    echo "chrM_1" > M/lift/ordered.lst
    set msize = `faSize M/chrM.fa | awk '{print $1;}'`
    echo "0\tM/chrM_1\t$msize\tchrM\t$msize" > M/lift/ordered.lft
    foreach f ( ?{,?}/chr*.fa.bak )
      faCmp $f $f:r
    end


# MAKE LIFTALL.LFT (DONE 7/7/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft


# CREATING DATABASE (DONE 7/6/04 angie)
    ssh hgwdev
    echo 'create database canFam1' | hgsql ''
    # Use df to make sure there is at least 75G free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  409G  1.3T  25% /var/lib/mysql


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 7/6/04 angie)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg17.grp" \
      | hgsql canFam1


# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS (DONE 7/7/04 angie)
    # Make nib/, unmasked until RepeatMasker and TRF steps are done.
    # Do this now so we can load up RepeatMasker and run featureBits; 
    # can also load up other tables that don't depend on masking.  
    ssh kksilo
    cd /cluster/data/canFam1
    mkdir nib
    foreach f (?{,?}/chr*.fa)
      echo "nibbing $f"
      faToNib $f nib/$f:t:r.nib
    end

    # Make symbolic links from /gbdb/canFam1/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/canFam1/nib
    foreach f (/cluster/data/canFam1/nib/chr*.nib)
      ln -s $f /gbdb/canFam1/nib
    end
    # Load /gbdb/canFam1/nib paths into database and save size info.
    cd /cluster/data/canFam1
    hgsql canFam1  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib canFam1 /gbdb/canFam1/nib */chr*.fa
    echo "select chrom,size from chromInfo" | hgsql -N canFam1 > chrom.sizes
    # take a look at chrom.sizes, should be 41 lines
    wc chrom.sizes
#     41      82     603 chrom.sizes


# GOLD AND GAP TRACKS (DONE 7/7/04 angie)
    ssh hgwdev
    cd /cluster/data/canFam1
    hgGoldGapGl -noGl -chromLst=chrom.lst canFam1 /cluster/data/canFam1 .
    # featureBits fails if there's no chrM_gap, so make one:
    # echo "create table chrM_gap like chr1_gap" | hgsql canFam1
    # oops, that won't work until v4.1, so do this for the time being:
    hgsql canFam1 -e "create table chrM_gap select * from chr1_gap where 0=1"


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR CANFAM1 (DONE 7/7/04 angie)
    ssh hgwdev
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd $HOME/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add canFam1 in all the right places and do
    make update
    cvs commit makefile
    mkdir -p dog/canFam1
    cvs add dog dog/canFam1
    cvs ci -m "trackDb dir for dog genome(s)" dog/canFam1
    make alpha

    # Add dbDb and defaultDb entries:
    echo 'insert into dbDb (name, description, nibPath, organism,  \
          defaultPos, active, orderKey, genome, scientificName,  \
          htmlPath, hgNearOk)  \
          values("canFam1", "Jul. 2004", \
          "/gbdb/canFam1/nib", "Dog", "chr14:10666612-10673232", 1, \
          18, "Dog", "Canis familiaris", \
          "/gbdb/canFam1/html/description.html", 0);' \
    | hgsql -h genome-testdb hgcentraltest
    # If there's another dog assembly, this will be an update not insert:
    echo 'insert into defaultDb (genome, name) values("Dog", "canFam1");' \
    | hgsql -h genome-testdb hgcentraltest


# REPEAT MASKING (DONE 7/7/04 angie)
    #- Split contigs into 500kb chunks, at gaps if possible:
    ssh kksilo
    cd /cluster/data/canFam1
    foreach c (`cat chrom.lst`)
      foreach d ($c/chr${c}*_?{,?})
        cd $d
        echo "splitting $d"
        set contig = $d:t
        faSplit gap $contig.fa 500000 ${contig}_ -lift=$contig.lft \
          -minGapSize=100
        cd ../..
      end
    end

    #- Make the run directory and job list:
    cd /cluster/data/canFam1
    cat << '_EOF_' > jkStuff/RMDog
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/canFam1/$2
/bin/cp $2 /tmp/canFam1/$2/
cd /tmp/canFam1/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s -spec dog $2
popd
/bin/cp /tmp/canFam1/$2/$2.out ./
if (-e /tmp/canFam1/$2/$2.align) /bin/cp /tmp/canFam1/$2/$2.align ./
if (-e /tmp/canFam1/$2/$2.tbl) /bin/cp /tmp/canFam1/$2/$2.tbl ./
if (-e /tmp/canFam1/$2/$2.cat) /bin/cp /tmp/canFam1/$2/$2.cat ./
/bin/rm -fr /tmp/canFam1/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/canFam1/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/canFam1
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMDog
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach c (`cat chrom.lst`)
      foreach d ($c/chr${c}_?{,?})
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/data/canFam1/jkStuff/RMDog \
                 /cluster/data/canFam1/$d $f \
               '{'check out line+ /cluster/data/canFam1/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
      end
    end

    #- Do the run
    ssh kk
    cd /cluster/data/canFam1/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
#Completed: 6373 of 6373 jobs
#CPU time in finished jobs:   24949716s  415828.60m  6930.48h  288.77d  0.791 y
#IO & Wait Time:                220014s    3666.90m    61.12h    2.55d  0.007 y
#Average job time:                3949s      65.82m     1.10h    0.05d
#Longest job:                     6389s     106.48m     1.77h    0.07d
#Submission to last job:         31173s     519.55m     8.66h    0.36d

    #- Lift up the 500KB chunk .out's to 5MB ("pseudo-contig") level
    ssh kksilo
    cd /cluster/data/canFam1
    foreach d (*/chr*_?{,?})
      set contig = $d:t
      echo $contig
      liftUp $d/$contig.fa.out $d/$contig.lft warn $d/${contig}_*.fa.out \
        > /dev/null
    end

    #- Lift pseudo-contigs to chromosome level
    foreach c (`cat chrom.lst`)
      echo lifting $c
      cd $c
      liftUp chr$c.fa.out lift/ordered.lft warn `cat lift/oOut.lst` > /dev/null
      cd ..
    end

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/canFam1
    hgLoadOut canFam1 */chr*.fa.out


# VERIFY REPEATMASKER RESULTS (DONE 7/7/04 angie)
    # Eyeball some repeat annotations in the browser, compare to lib seqs.
    # Run featureBits on canFam1 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits canFam1 rmsk
#896773874 bases of 2359845093 (38.001%) in intersection
    # Good, 35-40% seems typical for mammals...


# COMPARE OUR REPEATMASKER .OUT'S TO BROAD'S (IN PROGRESS 7/9/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1/broad
    ftp ftp.broad.mit.edu
      # same username & password as for fasta etc.
      bin
      get dog1.0_repeatinfo.tar.gz
      bye
    mkdir /cluster/data/canFam1/bed/compareRmsk
    cd /cluster/data/canFam1/bed/compareRmsk
    tar xvzf ../../broad/dog1.0_repeatinfo.tar.gz
    rm dog1.0_repeatinfo/*.index
    # compare... files?  definitely coverage --- make a bed4.
    cp /dev/null broadRmskBed4.bed
    foreach f (dog1.0_repeatinfo/chr*.fa.out)
      tail +4 $f | awk '{print $5 "\t" $6-1 "\t" $7 "\t" $10;}' \
      >> broadRmskBed4.bed
    end
    wc -l ../../?{,?}/chr*.fa.out | tail -1
#4337285 total
    wc -l dog1.0_repeatinfo/chr*.fa.out | tail -1
#4059835 total
    ssh hgwdev
    cd /cluster/data/canFam1/bed/compareRmsk
    #Compare coverage with our RepeatMasker run:
#896773874 bases of 2359845093 (38.001%) in intersection
    featureBits canFam1 broadRmskBed4.bed
#883152916 bases of 2359845093 (37.424%) in intersection
    featureBits canFam1 broadRmskBed4.bed \!rmsk -bed=notInRmsk.bed
#7053647 bases of 2359845093 (0.299%) in intersection
    featureBits canFam1 \!broadRmskBed4.bed rmsk -bed=notInBroad.bed
#20674605 bases of 2359845093 (0.876%) in intersection
    featureBits canFam1 broadRmskBed4.bed \!rmsk \!simpleRepeat \
      -bed=notInRmskTRF.bed
#6906446 bases of 2359845093 (0.293%) in intersection

    # back on kksilo
    wc -l notInRmsk.bed 
# 256372 notInRmsk.bed
    awk '$3-$2 >= 40 {print;}' notInRmsk.bed > notInRmskOver40.bed
    # Take a look at some of those positions in the browser.


# SIMPLE REPEATS (TRF) (DONE 7/7/04 angie)
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/simpleRepeat
    cd /cluster/data/canFam1/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach d (/cluster/data/canFam1/*/chr*_?{,?})
      set ctg = $d:t
      foreach f ($d/${ctg}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
      end
    end
    csh -ef jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    endsInLf trf/*
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/canFam1/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load into the database:
    ssh hgwdev
    hgLoadBed canFam1 simpleRepeat \
      /cluster/data/canFam1/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
    featureBits canFam1 simpleRepeat
#36509895 bases of 2359845093 (1.547%) in intersection


# PROCESS SIMPLE REPEATS INTO MASK (DONE 7/7/04/ angie)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/canFam1/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/canFam1
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (`cat chrom.lst`)
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
    end
    # Here's the coverage for the filtered TRF:
    ssh hgwdev
    cat /cluster/data/canFam1/bed/simpleRepeat/trfMaskChrom/*.bed \
      > /tmp/filtTrf.bed
    featureBits canFam1 /tmp/filtTrf.bed
#23017541 bases of 2359845093 (0.975%) in intersection
    featureBits canFam1 /tmp/filtTrf.bed \!rmsk
#1275941 bases of 2359845093 (0.054%) in intersection


# MASK SEQUENCE WITH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 7/7/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    # Soft-mask (lower-case) the contig and chr .fa's, 
    # then make hard-masked versions from the soft-masked.  
    set trfCtg=bed/simpleRepeat/trfMask
    set trfChr=bed/simpleRepeat/trfMaskChrom
    foreach f (*/chr*.fa)
      echo "repeat- and trf-masking $f"
      maskOutFa -soft $f $f.out $f
      set chr = $f:t:r
      maskOutFa -softAdd $f $trfChr/$chr.bed $f
      echo "hard-masking $f"
      maskOutFa $f hard $f.masked
    end
    # Tons of warnings like this, mostly for L1M*:
#WARNING: negative rEnd: -189 chrX:117586389-117586475 L1M3e
    foreach c (`cat chrom.lst`)
      echo "repeat- and trf-masking contigs of chr$c"
      foreach d ($c/chr*_?{,?})
        set ctg=$d:t
        set f=$d/$ctg.fa
        maskOutFa -soft $f $f.out $f
        maskOutFa -softAdd $f $trfCtg/$ctg.bed $f
        maskOutFa $f hard $f.masked
      end
    end
    #- Rebuild the nib files, using the soft masking in the fa:
    foreach f (*/chr*.fa)
      faToNib -softMask $f nib/$f:t:r.nib
    end
    # Make one big 2bit file as well, and make a link to it in 
    # /gbdb/canFam1/nib because hgBlat looks there:
    faToTwoBit */chr*.fa canFam1.2bit
    ssh hgwdev
    ln -s /cluster/data/canFam1/canFam1.2bit /gbdb/canFam1/nib/


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR CANFAM1 (DONE 7/13/04 angie)
    ssh hgwdev
    echo 'insert into blatServers values("canFam1", "blat9", "17778", 1, 0); \
          insert into blatServers values("canFam1", "blat9", "17779", 0, 1);' \
      | hgsql -h genome-testdb hgcentraltest


# MAKE DESCRIPTION/SAMPLE POSITION HTML PAGE (DONE 7/6/04 angie)
    ssh hgwdev
    mkdir /gbdb/canFam1/html
    # Write ~/kent/src/hg/makeDb/trackDb/dog/canFam1/description.html 
    # with a description of the assembly and some sample position queries.  
    chmod a+r $HOME/kent/src/hg/makeDb/trackDb/dog/canFam1/description.html
    # Check it in and copy (ideally using "make alpha" in trackDb) to 
    # /gbdb/canFam1/html


# PUT MASKED SEQUENCE OUT FOR CLUSTER RUNS (DONE 7/7/04 angie)
    ssh kkr1u00
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /iscratch/i/canFam1/nib
    mkdir /iscratch/i/canFam1/nib
    cp -p /cluster/data/canFam1/nib/chr*.nib /iscratch/i/canFam1/nib
    # Pseudo-contig fa that have been repeat- and trf-masked:
    rm -rf /iscratch/i/canFam1/maskedContigs
    mkdir /iscratch/i/canFam1/maskedContigs
    foreach d (/cluster/data/canFam1/*/chr*_?{,?})
      cp $d/$d:t.fa /iscratch/i/canFam1/maskedContigs
    end
    cp -p /cluster/data/canFam1/canFam1.2bit /iscratch/i/canFam1/
    du -sh /iscratch/i/canFam1/*
#631M    /iscratch/i/canFam1/canFam1.2bit
#2.5G    /iscratch/i/canFam1/maskedContigs
#1.2G    /iscratch/i/canFam1/nib
    iSync
    # Put nibs and rmsk files in /scratch for big cluster blastz.
    mkdir /cluster/bluearc/scratch/hg/canFam1
    cp -pR /iscratch/i/canFam1/nib /cluster/bluearc/scratch/hg/canFam1
    ssh kksilo
    mkdir /cluster/bluearc/scratch/hg/canFam1/rmsk
    cp -p /cluster/data/canFam1/*/chr*.fa.out \
       /cluster/bluearc/scratch/hg/canFam1/rmsk
    # Ask cluster-admin for an rsync after the next step.  


# MAKE LINEAGE-SPECIFIC REPEATS VS. HUMAN, MOUSE (DONE 7/7/04 angie)
    ssh kksilo
    cd /cluster/bluearc/scratch/hg/canFam1/rmsk
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Human in extra column 1, Mouse in extra column 2
    foreach outfl ( *.out )
        echo "$outfl"
        /cluster/bluearc/RepeatMasker/DateRepsinRMoutput.pl \
          ${outfl} -query dog -comp human -comp mouse
    end
    # Now extract human (extra column 1), mouse (extra column).
    cd /cluster/bluearc/scratch/hg/canFam1
    mkdir linSpecRep.notInHuman
    mkdir linSpecRep.notInMouse
    foreach f (rmsk/*.out_hum_mus)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInHuman/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    wc -l rmsk/*.out
#4337285 total
    wc -l linSpecRep.notInHuman/*
#1333452 total
    wc -l linSpecRep.notInMouse/*
#1333452 total
    # The linSpecReps.notIn{Human,Mouse} files are the same.  I asked Arian 
    # if that's a bad thing last week (human vs. {dog,mouse} -> same).  
    # Haven't heard back yet, but hey, we're all mammals here...
    foreach f (linSpecRep.notInHuman/*)
      echo $f:t
      diff $f linSpecRep.notInMouse/$f:t | wc -l | g -vw 0
    end
    # Clean up.
    rm /cluster/bluearc/scratch/hg/canFam1/rmsk/*.out_hum_mus
    # Ask cluster-admin for an rsync.


# MAKE 10.OOC, 11.OOC FILES FOR BLAT (DONE 7/7/04 angie)
    # Use -repMatch=843 (based on size -- for human we use 1024, and 
    # dog size is 2359845093 / 2866216770 = ~82.3% of human judging by 
    # gapless genome size from featureBits)
    ssh kolossus
    mkdir /cluster/data/canFam1/bed/ooc
    cd /cluster/data/canFam1/bed/ooc
    ls -1 /cluster/data/canFam1/nib/chr*.nib > nib.lst
    blat nib.lst /dev/null /dev/null -tileSize=11 \
      -makeOoc=/cluster/bluearc/canFam1/11.ooc -repMatch=843
#Wrote 26268 overused 11-mers to /cluster/bluearc/canFam1/11.ooc
    blat nib.lst /dev/null /dev/null -tileSize=10 \
      -makeOoc=/cluster/bluearc/canFam1/10.ooc -repMatch=843
#Wrote 143003 overused 10-mers to /cluster/bluearc/canFam1/10.ooc
    ssh kkr1u00
    cp -p /cluster/bluearc/canFam1/*.ooc /iscratch/i/canFam1/
    iSync


# AUTO UPDATE GENBANK MRNA RUN  (DONE 7/8/04 angie)
    ssh hgwdev
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .
    # See if /cluster/data/genbank/etc/genbank.conf has had any un-checked-in
    # edits, check them in if necessary:
    diff /cluster/data/genbank/etc/genbank.conf etc/genbank.conf

    # Edit etc/genbank.conf and add these lines:
# canFam1 (dog)
canFam1.genome = /iscratch/i/canFam1/nib/chr*.nib
canFam1.lift = /cluster/data/canFam1/jkStuff/liftAll.lft
canFam1.refseq.mrna.native.load = no
canFam1.genbank.mrna.xeno.load = yes
canFam1.genbank.est.xeno.load = no
canFam1.downloadDir = canFam1

    cvs ci etc/genbank.conf
    # Since dog is a new species for us, edit src/lib/gbGenome.c.  
    # Pick some other browser species, & monkey-see monkey-do.  
    cvs diff src/lib/gbGenome.c
    make
    cvs ci src/lib/gbGenome.c

    # Edit src/align/gbBlat to add /iscratch/i/canFam1/11.ooc
    cvs diff src/align/gbBlat
    make
    cvs ci src/align/gbBlat
    # Install to /cluster/data/genbank:
    make install-server

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -clusterRootDir=/cluster/store7/genbank \
      -srcDb=genbank -type=mrna -verbose=1 -initial canFam1 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad canFam1
    featureBits canFam1 mrna
#1850373 bases of 2359845093 (0.078%) in intersection
    featureBits canFam1 xenoMrna
#62236255 bases of 2359845093 (2.637%) in intersection
    # Clean up:
    rm -r work/initial.canFam1

    ssh eieio
    # -initial for ESTs (now with /cluster/store7 and iservers):
    nice bin/gbAlignStep -clusterRootDir=/cluster/store7/genbank \
      -srcDb=genbank -type=est -verbose=1 -initial canFam1 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 canFam1 &
    featureBits canFam1 intronEst
#4090352 bases of 2359845093 (0.173%) in intersection
    featureBits canFam1 est
#10958036 bases of 2359845093 (0.464%) in intersection
    # Clean up:
    rm -r work/initial.canFam1


# COMPARE COUNTS OF ALIGNED VS NON-ALIGNED MRNAS (DONE 7/8/04 angie)
    ssh hgwdev
    mkdir /cluster/data/canFam1/bed/mrnaCheck
    cd /cluster/data/canFam1/bed/mrnaCheck
    # Get accs of all mRNAs and ESTs in our genbank build.  
    # Note: if/when there's a RefSeq for dog, filter NM_* accessions 
    # out of the mRNA list!
    hgsql -N canFam1 -e 'select acc from mrna where type = "mRNA" and \
                         organism = 2497 or organism = 2654' \
    | sort > accs.mrna
    hgsql -N canFam1 -e 'select acc from mrna where type = "EST" and \
                         organism = 2497 or organism = 2654' \
    | sort > accs.est
    # Get accs of mRNAs and ESTs that were aligned:
    hgsql -N canFam1 -e "select distinct(qName) from  all_mrna" \
    | sort > alignedAccs.mrna
    hgsql -N canFam1 -e "select distinct(qName) from  all_est" \
    | sort > alignedAccs.est
    # Get accs of mRNAs and ESTs that were not aligned:
    diff accs.mrna alignedAccs.mrna | egrep -v '^[0-9]' | sed -e 's/^< //' \
    > notAlignedAccs.mrna
    diff accs.est alignedAccs.est | egrep -v '^[0-9]' | sed -e 's/^< //' \
    > notAlignedAccs.est
    # Look at counts, compute percentages.
    wc -l *
#  37387 accs.est
#   1188 accs.mrna
#  34781 alignedAccs.est
#   1133 alignedAccs.mrna
#   2606 notAlignedAccs.est
#     55 notAlignedAccs.mrna
    expr 37387 - 34781
#2606  (93.0% aligned, 7.0% not aligned) 
    expr 1188 - 1133
#55    (95.4% aligned, 4.6% not aligned)
    # Add descriptions to mRNAs not aligned.  
    cp /dev/null notAlignedDesc.mrna
    foreach acc (`cat notAlignedAccs.mrna`)
      hgsql -N canFam1 \
        -e 'select mrna.acc,description.name from mrna,description \
            where mrna.acc = "'$acc'" and mrna.description = description.id' \
      >> notAlignedDesc.mrna
    end


# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 7/7/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    #- Build the .zip files
    cat << '_EOF_' > jkStuff/zipAll.csh
rm -rf zip
mkdir zip
zip -j zip/chromAgp.zip [0-9A-Z]*/chr*.agp
zip -j zip/chromOut.zip */chr*.fa.out
zip -j zip/chromFa.zip */chr*.fa
zip -j zip/chromFaMasked.zip */chr*.fa.masked
cd bed/simpleRepeat
zip ../../zip/chromTrf.zip trfMaskChrom/chr*.bed
cd ../..
cd /cluster/data/genbank
./bin/i386/gbGetSeqs -db=canFam1 -native GenBank mrna \
        /cluster/data/canFam1/zip/mrna.fa
cd /cluster/data/canFam1/zip
zip -j mrna.zip mrna.fa
'_EOF_'
    # << this line makes emacs coloring happy
    csh ./jkStuff/zipAll.csh |& tee zipAll.log
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd /cluster/data/canFam1/zip
    set gp = /usr/local/apache/htdocs/goldenPath/canFam1
    mkdir -p $gp/bigZips
    cp -p *.zip $gp/bigZips
    mkdir -p $gp/chromosomes
    foreach f ( ../*/chr*.fa )
      zip -j $gp/chromosomes/$f:t.zip $f
    end

    cd $gp/bigZips
    md5sum *.zip > md5sum.txt
    cd $gp/chromosomes
    md5sum *.zip > md5sum.txt
    # Take a look at bigZips/* and chromosomes/*, update their README.txt's
    # Can't make refGene upstream sequence files - no refSeq for dog.
    # Maybe ensGene when we get that.


# SWAP BLASTZ HUMAN-DOG TO DOG-HUMAN (HG17) (DONE 7/9/04 angie)
    ssh kolossus
    mkdir /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08
    set aliDir = /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSplitByTarget stdin unsorted
    # Sort the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    du -sh $aliDir/axtChrom unsorted axtChrom
    rm -r unsorted


# CHAIN HUMAN BLASTZ (DONE 7/10/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in line+ $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 \
  /iscratch/i/canFam1/nib \
  /iscratch/i/gs.18/build35/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # Wow, chr1 dwarfs the others...
#Completed: 41 of 41 jobs
#Average job time:                 293s       4.88m     0.08h    0.00d
#Longest job:                     4419s      73.65m     1.23h    0.05d
#Submission to last job:          4419s      73.65m     1.23h    0.05d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=4000 /tmp/score.$f:t:r
      echo ""
    end

    # Lots of chaff with scores in the 3000's.  Many very-high-scoring 
    # chains.  So filter the chain down somewhat...
    mv all.chain all.chain.unfiltered
    chainFilter -minScore=5000 all.chain.unfiltered > all.chain
    rm chain/*
    chainSplit chain all.chain
    gzip all.chain.unfiltered

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain canFam1 ${c}_chainHg17 $i
    end


# NET HUMAN BLASTZ (DONE 7/10/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain
    netClass noClass.net canFam1 hg17 human.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet canFam1 netHg17 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet canFam1 netSyntenyHg17 stdin
    # Add entries for chaing16, netHg17, syntenyHg17 to dog/canFam1 trackDb


# MAKE VSHG17 DOWNLOADABLES (TODO 7/9/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-07-08/axtChain
    cp all.chain human.chain
    zip /cluster/data/canFam1/zip/human.chain.zip human.chain
    rm human.chain
    zip /cluster/data/canFam1/zip/human.net.zip human.net
    zip /cluster/data/canFam1/zip/humanSyn.net.zip humanSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/canFam1/vsHg17
    cd /usr/local/apache/htdocs/goldenPath/canFam1/vsHg17
    mv /cluster/data/canFam1/zip/human*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# BLASTZ SELF (TODO 7/9/04 angie)
    ssh kk
    mkdir -p /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    # OK, the 500k x whole chrom 03-02 run was taking FOREVER (18hrs, ~63%)
    # and multiple folks are asking me to dig up pileups for Arian.  So, 
    # just do a vanilla run as a baseline; return to the experiments later.
    cat << '_EOF_' > DEF
# dog vs. dog
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET
# Dog
SEQ1_DIR=/iscratch/i/canFam1/nib
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Dog
SEQ2_DIR=/iscratch/i/canFam1/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/data/canFam1/bed/blastz.canFam1.2004-03-03

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # Save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.canFam1-canFam1

    # source the DEF file
    bash
    . ./DEF
    mkdir -p $BASE/run
    ~angie/hummus/make-joblist $DEF > $BASE/run/j
    sh $BASE/xdir.sh
    cd $BASE/run
    # now edit j to prefix path to executable name
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    # make sure the j2 edits are OK, then use it:
    mv j2 j
    para create j
    para try, check, push, check, ...
#Completed: 22801 of 22801 jobs
#Average job time:                 257s       4.29m     0.07h    0.00d
#Longest job:                     1238s      20.63m     0.34h    0.01d
#Submission to last job:          6939s     115.65m     1.93h    0.08d

    # --- normalize (PennSpeak for lift)
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    # run bash shell if not running it already
    source DEF
    mkdir -p $BASE/run.1
    mkdir -p $BASE/lav
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1
    wc -l jobList
    head jobList
    # make sure the job list is OK
    para create jobList
    para push
#Completed: 151 of 151 jobs
#Average job time:                  24s       0.41m     0.01h    0.00d
#Longest job:                      127s       2.12m     0.04h    0.00d
#Submission to last job:           246s       4.10m     0.07h    0.00d

    # convert lav files to axt
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    mkdir axtChrom
    # a new run directory
    mkdir run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh
cd $1
cat `ls -1 *.lav | sort -g` \
| lavToAxt -dropSelf stdin /iscratch/i/canFam1/nib /iscratch/i/canFam1/nib \
    stdout \
| axtSort stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x do.csh
    cat << '_EOF_' > gsub
#LOOP
./do.csh {check in exists $(path1)} {check out line+ /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChrom/$(root1).axt}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    \ls -1Sd ../lav/chr* > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
    head jobList
    para create jobList
    para try, check, push, check,...


# CHAIN SELF BLASTZ (TODO 7/9/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtFilter -notQ=chrUn $1 \
| axtChain stdin /iscratch/i/canFam1/nib /iscratch/i/canFam1/nib $2 \
  > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...

    # now on the cluster server, sort chains
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # trim to minScore=20000 to cut some of the fluff
    mkdir chainFilt
    foreach f (chain/*.chain)
      chainFilter -minScore=20000 $f > chainFilt/$f:t
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain/chainFilt
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain canFam1 ${c}_chainSelf $i
    end


# NET SELF BLASTZ (TODO 7/9/04 angie)
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    netClass -noAr noClass.net canFam1 canFam1 self.net

    # Make a 'syntenic' subset:
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    rm noClass.net
    netFilter -syn self.net > selfSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    netFilter -minGap=10 self.net |  hgLoadNet canFam1 netSelf stdin
    netFilter -minGap=10 selfSyn.net | hgLoadNet canFam1 netSyntenySelf stdin
    # Add entries for chainSelf, netSelf, netSyntenySelf to 
    # dog/canFam1 trackDb


# MAKE VSSELF DOWNLOADABLES (TODO 7/9/04 angie)
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    cp all.chain self.chain
    zip /cluster/data/canFam1/zip/self.chain.zip self.chain
    rm self.chain
    zip /cluster/data/canFam1/zip/self.net.zip self.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/canFam1/vsSelf
    cd /usr/local/apache/htdocs/goldenPath/canFam1/vsSelf
    mv /cluster/data/canFam1/zip/self*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# PRODUCING GENSCAN PREDICTIONS (DONE 7/9/04 angie)
    ssh hgwdev
    mkdir /cluster/data/canFam1/bed/genscan
    cd /cluster/data/canFam1/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Run on small cluster (more mem than big cluster).
    ssh kki
    cd /cluster/data/canFam1/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/data/canFam1/*/chr*_*/chr*_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    wc -l genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 495 of 497 jobs
#Crashed: 2 jobs
#Average job time:                 803s      13.39m     0.22h    0.01d
#Longest job:                    28087s     468.12m     7.80h    0.33d
#Submission to last job:         34710s     578.50m     9.64h    0.40d
    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    ssh kkr7u00
    cd /cluster/data/canFam1/bed/genscan
    /cluster/bin/x86_64/gsBig /cluster/data/canFam1/5/chr5_17/chr5_17.fa.masked gtf/chr5_17.fa.gtf -trans=pep/chr5_17.fa.pep -subopt=subopt/chr5_17.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/x86_64/gsBig /cluster/data/canFam1/1/chr1_21/chr1_21.fa.masked gtf/chr1_21.fa.gtf -trans=pep/chr1_21.fa.pep -subopt=subopt/chr1_21.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    ls -1 gtf | wc -l
#    497
    endsInLf gtf/*

    # Convert these to chromosome level files as so:
    ssh kksilo
    cd /cluster/data/canFam1/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/genscan
    ldHgGene -gtf -genePredExt canFam1 genscan genscan.gtf
    hgPepPred canFam1 generic genscanPep genscan.pep
    hgLoadBed canFam1 genscanSubopt genscanSubopt.bed


# PRODUCING FUGU BLAT ALIGNMENTS (TODO 7/9/04)
    ssh kk
    mkdir /cluster/data/canFam1/bed/blatFr1
    cd /cluster/data/canFam1/bed/blatFr1
    # Note: might need to do a better job of partitioning here...
    ls -1S /iscratch/i/fugu/trfFa/*.fa > fugu.lst
    ls -1S /iscratch/i/canFam1/nib/*.nib > dog.lst
    cat << '_EOF_' > gsub
#LOOP
blat -mask=lower -q=dnax -t=dnax {check in exists $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    mkdir psl
    gensub2 dog.lst fugu.lst gsub spec
    para create spec
    para try, check, push, check, ...
    # for future reference, the fugu trfFa on bluearc seem better partitioned...

    # Sort alignments:
    ssh kksilo
    cd /cluster/data/canFam1/bed/blatFr1
    pslCat -dir psl | pslSortAcc nohead chrom /cluster/store2/temp stdin

    # load seq & psl into database:
    ssh hgwdev
    mkdir /gbdb/canFam1/fuguSeq
    ln -s /cluster/data/fr1/fugu_v3.masked.fa /gbdb/canFam1/fuguSeq/
    cd /cluster/data/canFam1/bed/blatFr1
    hgLoadSeq canFam1 /gbdb/canFam1/fuguSeq/fugu_v3.masked.fa
    cd /cluster/data/canFam1/bed/blatFr1/chrom
    cat *.psl | hgLoadPsl -fastLoad -table=blatFr1 canFam1 stdin


# LOAD CPGISSLANDS (TODO 3/23/04 angie)
    ssh hgwdev
    mkdir -p /cluster/data/canFam1/bed/cpgIsland
    cd /cluster/data/canFam1/bed/cpgIsland
    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    mv cpglh.exe /cluster/data/canFam1/bed/cpgIsland/
    
    ssh kksilo
    cd /cluster/data/canFam1/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpglh.exe $f > $fout
    end
    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIsland
    hgLoadBed canFam1 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed


# BUILD BLAST DATABASES
    cd /cluster/data/canFam1
    mkdir blastDb
     for i in `cat chrom.lst`; do for j in `echo $i/chr$i_*/chr*_*_*.fa`; do ln -s `pwd`/$j blastDb/`basename $j .fa`;
      done; done 
      cd blastDb
      for i in *; do formatdb -p F -i $i; done
# END BLAST


# GC 5 BASE WIGGLE TRACK (DONE 7/7/04 angie)
    # put unmasked nibs in /iscratch for small cluster run.
    ssk kkr1u00
    mkdir /iscratch/i/canFam1/
    cp -pR /cluster/data/canFam1/nib /iscratch/i/canFam1/
    iSync
    ssh kki
    mkdir /cluster/data/canFam1/bed/gc5Base
    cd /cluster/data/canFam1/bed/gc5Base
    mkdir wigData dataLimits
    cat > doGc5Base.csh <<'_EOF_'
#!/bin/csh -fe
set c = $1
set chr = "chr$c"
/cluster/bin/x86_64/hgGcPercent \
  -chr=${chr} -doGaps -file=stdout -win=5 canFam1 ../../nib \
| awk '$4 == "GC" && ($3-$2) >= 5 {printf "%d\t%.1f\n", $2+1, $5/10.0;}' \
| /cluster/bin/x86_64/wigAsciiToBinary \
    -dataSpan=5 -chrom=${chr} -wibFile=wigData/gc5Base_${c} \
    -name=${c} stdin > dataLimits/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doGc5Base.csh
    cp /dev/null spec
    foreach c (`cat ../../chrom.lst`)
      echo "./doGc5Base.csh $c" >> spec
    end
    para create spec
    para try, check, push, check, ...
    # ran on kolossus (csh spec >& tee spec.log) because small cluster was 
    # solidly hogged, oh well.
    # data is complete, load track on hgwdev
    ssh hgwdev
    cd /cluster/data/canFam1/bed/gc5Base
    # create symlinks for .wib files, then load track
    mkdir -p /gbdb/canFam1/wib/gc5Base
    ln -s `pwd`/wigData/*.wib /gbdb/canFam1/wib/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/canFam1/wib/gc5Base \
      canFam1 gc5Base wigData/*.wig


# CREATING QUALITY SCORE TRACK (DONE 7/7/04 angie)
    ssh kolossus
    mkdir /cluster/data/canFam1/bed/qual
    cd /cluster/data/canFam1/bed/qual
    mkdir wigData dataLimits
    foreach agp (../../?{,?}/chr*.agp)
      set chr = $agp:t:r
      set abbrev = `echo $chr | sed -e 's/^chr//;  s/_random/r/;'`
      echo $chr to $abbrev wiggle
      qacToWig ../../broad/fixedQuals.qac -name=$chr stdout \
      | wigAsciiToBinary -dataSpan=1 -chrom=$chr \
          -wibFile=wigData/qual_$abbrev -name=$abbrev stdin \
          > dataLimits/$chr
    end
    # Verify size of .wib file = chrom length
    foreach f (wigData/*.wib)
      set abbrev = $f:t:r
      set chr = `echo $abbrev | sed -e 's/^qual_/chr/;  s/r$/_random/;'`
      set wibLen = `ls -l $f | awk '{print $5;}'`
      set chromLen = `grep -w $chr ../../chrom.sizes | awk '{print $2;}'`
      if ($wibLen != $chromLen) then
        echo "ERROR: $chr size is $chromLen but wib size is $wibLen"
      else
        echo $chr OK.
      endif
    end

    # /gbdb & load:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/qual
    mkdir -p /gbdb/canFam1/wib/qual
    ln -s `pwd`/wigData/*.wib /gbdb/canFam1/wib/qual
    hgLoadWiggle -pathPrefix=/gbdb/canFam1/wib/qual \
      canFam1 quality wigData/*.wig

    # To speed up display for whole chrom views, need to make zoomed
    # data views.  Zoom to 1K points per pixel.
    ssh kolossus
    cd /cluster/data/canFam1/bed/qual
    mkdir -p wigData1K
    mkdir -p dataLimits1K
    foreach c (`cat ../../chrom.lst`)
      if (-f ../../${c}/chr${c}.agp) then
        echo "chr${c} quality 1K zoom"
        qacToWig ../../broad/fixedQuals.qac -name=chr${c} stdout \
        | wigZoom stdin \
        | wigAsciiToBinary -dataSpan=1024 \
                -chrom=chr${c} -wibFile=wigData1K/qc1K_${c} \
                -name=${c} stdin > dataLimits1K/chr${c}
      endif
    end
    ssh hgwdev
    cd /cluster/data/canFam1/bed/qual/wigData1K
    # create symlinks for .wib files
    ln -s `pwd`/*.wib /gbdb/canFam1/wib/qual
    # load in addition to existing data
    hgLoadWiggle -oldTable -pathPrefix=/gbdb/canFam1/wib/qual \
      canFam1 quality *.wig


# MAKE UNIGENE ALIGNMENTS (TODO 7/10/04 angie)
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/unigene
    cd /cluster/data/canFam1/bed/unigene
    # Download dog Unigene and run Chuck's preproc scripts:
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Cfa.info
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Cfa.seq.uniq.gz
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Cfa.data.gz
    gunzip *.gz
    # Chuck's script expects human (Hs) -- use Cfa for dog:
    sed -e 's/Hs/Cfa/g' /projects/cc/hg/sugnet/uniGene/countSeqsInCluster.pl \
    > ./countSeqsInCluster.pl
    chmod a+x ./countSeqsInCluster.pl
    ./countSeqsInCluster.pl Cfa.data counts.tab
    /projects/cc/hg/sugnet/uniGene/parseUnigene.pl Cfa.seq.uniq \
      Cfa.seq.uniq.simpleHeader.fa leftoverData.tab
    # Put on iscratch for cluster run
    ssh kkr1u00
    mkdir /iscratch/i/canFam1/unigene
    cp -p /cluster/data/canFam1/bed/unigene/Cfa.seq.uniq.simpleHeader.fa \
      /iscratch/i/canFam1/unigene/
    iSync
    # align on big cluster
    ssh kk
    cd /cluster/data/canFam1/bed/unigene
    ls -1S /iscratch/i/canFam1/maskedContigs/*.fa > allctg.lst
    ls -1S /iscratch/i/canFam1/unigene/*.fa > uniGene.lst
    cat << '_EOF_' > template.sub
#LOOP
/cluster/bin/i386/blat -mask=lower -minIdentity=95 -ooc=/iscratch/i/canFam1/11.ooc {check in line+ $(path1)} {check in line+ $(path2)}  {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 allctg.lst uniGene.lst template.sub jobList
    para create jobList
    mkdir psl
    para try, check, push, check
    # postprocess
    ssh kksilo
    pslSort dirs raw.psl tmp psl >& pslSort.log
    liftUp -type=.psl stdout ../../jkStuff/liftAll.lft warn raw.psl \
    | pslReps -minCover=0.2 -minAli=0.965 -nearTop=0.002 \
      stdin uniGene.lifted.pslReps.psl /dev/null
    rm raw.psl
    gzip Cfa.seq.uniq Cfa.data 
    # load into db
    ssh hgwdev
    cd /cluster/data/canFam1/bed/unigene
    mkdir /gbdb/canFam1/unigene
    ln -s /cluster/data/canFam1/bed/unigene/Cfa.seq.uniq.simpleHeader.fa \
      /gbdb/canFam1/unigene/
    hgLoadSeq canFam1 /gbdb/canFam1/unigene/Cfa.seq.uniq.simpleHeader.fa
    hgLoadPsl -fastLoad -table=uniGene_cf canFam1 uniGene.lifted.pslReps.psl


# RUN GENE-CHECK ON MRNA W/CDS, ENSEMBL (TODO 9/1/04 angie)
    # Note: /cluster/bin/scripts/runGeneCheck should make this easier 
    # in the future, but this also shows how MarkD ran gene-check on 
    # mRNAs with annotated CDS:

    # get mrna data from hgwbeta, which is most current:
    ssh hgwbeta
    mkdir /cluster/store7/markd/canFam1
    cd /cluster/store7/markd/canFam1
    mkdir data
    hgsql -N -e 'select * from all_mrna' canFam1 |cut -f 2-30 \
      > data/all_mrna.psl
    hgsql -N -e 'select mrna.acc,cds.name from mrna,cds,all_mrna where all_mrna.qName=mrna.acc and mrna.cds = cds.id' canFam1 \
      > data/cds.tab
    nice mrnaToGene -cdsFile=data/cds.tab data/all_mrna.psl data/all_mrna.gp \
      >& data/all_mrna.log

    # get ensGene data from hgwdev:
    ssh hgwdev
    cd /cluster/store7/markd/canFam1
    hgsql -N -e 'select * from ensGene ' canFam1 >data/ensGene.gp

    # run gene-check and gene-extract
    ssh kksilo
    cd /cluster/store7/markd/canFam1
    mkdir results
    ~markd/bin/gene-check -incl-ok -nib-dir /cluster/data/canFam1/nib \
      -details-out results/all_mrna.details data/all_mrna.gp \
      results/all_mrna.chk >& all_mrna.log
    ~markd/bin/gene-check -incl-ok -nib-dir /cluster/data/canFam1/nib \
      -details-out results/ensGene.details data/ensGene.gp \
      results/ensGene.chk >& ensGene.log
    ~markd/bin/gene-extract -nib-dir  /cluster/data/canFam1/nib \
      -all-cds-fa results/all_mrna.cds.fa  data/all_mrna.gp >& all_mrna.log
    ~markd/bin/gene-extract -nib-dir  /cluster/data/canFam1/nib \
      -all-cds-fa results/ensGene.cds.fa  data/ensGene.gp >&ensGene.log
    # Files in results/
    #     *.chk - output of the gene-check program, rdb format
    #     *.details - details of problems detected 
    #     *.cds.fa - fasta of CDS taken from genome
    # Columns in *.chk file are
    #     acc - name field from genePred
    #     chr  - genome location from genePred
    #     chrStart
    #     chrEnd
    #     strand
    #     stat - overall status based on other data: ok or err
    #     frame - is the frame annotation sane (mult of 3): ok, bad, or noCDS
    #             if noCDS, other CDS checks are not done.
    #     start - Is there a valid start codon: ok or no
    #     stop - Is there a valid stop codon: ok or no
    #     orfStop - Number of in-frame stop codons
    #     smallGap - Number of small gaps, too small to be introns
    #     unknownSplice - Number of introns with unknown splicing patterns 
    #          (considers the three most common splicing patterns as valid)
    #     causes - list of symbolic names summarizing the failures 


# TWINSCAN FROM BRENT LAB (TODO 8/1/04 angie)
    ssh hgwdev
    mkdir /cluster/data/canFam1/bed/twinscan
    cd /cluster/data/canFam1/bed/twinscan
    wget http://www.cs.wustl.edu/????
    tar xvzf ????
    ldHgGene -gtf -frame -id -geneName canFam1 twinscan chr*.gtf
    runGeneCheck .
    wget http://www.cs.wustl.edu/????
    tar xvzf ????
    perl -wpe 's/^>(\S+)/>$1.a/' chr*.prot.fa > twinscanPep.fa
    hgPepPred canFam1 generic twinscanPep twinscanPep.fa



# ANDY LAW CPGISSLANDS (TODO 7/16/04 angie)
    # See notes in makeGalGal2.doc.
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/cpgIslandGgfAndy
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    # Use masked sequence since this is a mammal...
    cp /dev/null cpgIslandGgfAndyMasked.bed
    foreach f (../../*/chr*.fa.masked)
      set chr = $f:t:r:r
      echo preproc masked $chr
      /cluster/home/angie/bin/$MACHTYPE/preProcGgfAndy $f > $chr.masked.preproc
      echo running modified on $chr masked
      /cluster/home/angie/ggf-andy-cpg-island.pl $chr.masked.preproc \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyMasked.bed
    end
    # load into database:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyMasked/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > cpgIslandGgfAndyMasked.sql
    hgLoadBed canFam1 cpgIslandGgfAndyMasked -tab -noBin \
      -sqlTable=cpgIslandGgfAndyMasked.sql cpgIslandGgfAndyMasked.bed
    featureBits canFam1 cpgIslandExt
    featureBits canFam1 cpgIslandGgfAndyMasked
    wc -l ../cpgIsland/cpgIsland.bed *bed
    # 6/28/04 -- masking simpleRepeats, and even repeats other than Alu's,
    # might not be the right thing to do (?).  Give it a try with less-masked 
    # sequence.
    ssh kksilo
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    cp /dev/null cpgIslandGgfAndyOnlyRM.bed
    foreach f (../../*/chr*.fa)
      set chr = $f:t:r
      echo preproc, ggf-andy $chr onlyRM
      maskOutFa $f $f.out stdout \
      | /cluster/home/angie/bin/$MACHTYPE/preProcGgfAndy stdin \
      | /cluster/home/angie/ggf-andy-cpg-island.pl \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyOnlyRM.bed
    end
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyOnlyRM/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > /tmp/c.sql
    hgLoadBed canFam1 cpgIslandGgfAndyOnlyRM -tab -noBin -sqlTable=/tmp/c.sql \
      cpgIslandGgfAndyOnlyRM.bed
    featureBits canFam1 cpgIslandGgfAndyOnlyRM.bed
    # OK, just for fun let's run ggf-andy script with TJ parameters!
    ssh kksilo
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    foreach f (../../*/chr*.fa)
      set chr = $f:t:r
      echo running modified w/TJ on $chr
      /cluster/home/angie/ggf-andy-cpg-island.pl \
         -min-length 500 -percent-gc 55 -obs-over-exp 0.65 \
         $chr.preproc \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyTJ.bed
    end
    # load into database:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    # this one is a cpgIslandExt but with a different table name:
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyTJ/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > cpgIslandGgfAndyTJ.sql
    hgLoadBed canFam1 cpgIslandGgfAndyTJ -tab -noBin \
      -sqlTable=cpgIslandGgfAndyTJ.sql cpgIslandGgfAndyTJ.bed
    featureBits canFam1 cpgIslandGgfAndyTJ
    wc -l cpgIslandGgfAndyTJ.bed


# RELOAD ENSEMBL GENES (TODO 9/1/04 angie)
    # previous set was sent out to dog group -- pull in the released 
    # version from Ensembl's main site.  Looks like 75 transcripts have 
    # been yanked, will ask Steve Searle and Ewan.  
    mkdir /cluster/data/canFam1/bed/ensembl
    cd /cluster/data/canFam1/bed/ensembl
    # Get the ensembl gene data from 
    # http://www.ensembl.org/Canis_familiaris/martview
    # Follow this sequence through the pages:
    # Page 1) Make sure that the Canis_familiaris choice is selected. Hit next.
    # Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
    # Page 3) Choose the "Structures" box. 
    # Page 4) Choose GTF as the ouput.  choose gzip compression.  hit export.
    # Save as ensembl.gff.gz
    # Add "chr" to front of each line in the gene data gtf file to make 
    # it compatible with our software.
    gunzip -c ensembl.gff.gz \
    | perl -wpe 's/^([1-9][0-9]?|[XYM]|Un)/chr$1/ \
                 || die "Line $. doesnt start with dog chrom:\n$_"' \
    > ensGene.gtf
    ssh hgwdev
    ldHgGene -gtf -genePredExt canFam1 ensGene \
      /cluster/data/canFam1/bed/ensembl/ensGene.gtf

    # ensGtp associates geneId/transcriptId/proteinId for hgPepPred and 
    # hgKnownToSuper.  Use ensMart to create it as above, except:
    # Page 3) Choose the "Features" box. In "Ensembl Attributes", check 
    # Ensembl Gene ID, Ensembl Transcript ID, Ensembl Peptide ID.  
    # Choose Text, tab-separated as the output format.  Result name ensGtp.
    # Save file as ensGtp.txt.gz
    gunzip ensGtp.txt.gz
    hgsql canFam1 < ~/kent/src/hg/lib/ensGtp.sql
    hgsql canFam1 -e 'load data local infile "ensGtp.txt" into table ensGtp'

    # Load Ensembl peptides:
    # Get them from ensembl as above in the gene section except for
    # Page 3) Choose the "Sequences" box. 
    # Page 4) Transcripts/Proteins.  Peptide.  Format = FASTA.
    # Save file as ensemblPep.fa.gz
    gunzip -c ensemblPep.fa.gz \
    | perl -wpe 's/^(>ENSCANT\d+\.\d+).*/$1/' \
    > ensPep.fa
    hgPepPred canFam1 generic ensPep ensPep.fa


