#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on the 
# Dog (Canis familiaris) July 2004 release.


# CREATE BUILD DIRECTORY (DONE 7/1/04 angie)
    ssh kksilo
    mkdir /cluster/store7/canFam1
    ln -s /cluster/store7/canFam1 /cluster/data/canFam1


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 7/1/04 angie)
    mkdir /cluster/data/canFam1/M
    cd /cluster/data/canFam1/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "canis familiaris mitochondrion genome".  That shows the gi number:
    # 17737322
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=17737322&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Canis familiaris mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# DOWNLOAD WHOLE GENOME SHOTGUN CONTIGS & QUAL (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    # Fetch FASTA -- still don't know if it'll be chromosome or contig
    wget ftp://????
    # Take a look at what we got... if many separate contig files, glom 
    # together on bluearc so we can build chrom agp on kolossus
    faSize *.fa
    # Get qual scores too
    cd /cluster/data/canFam1
    wget ftp://????
    

# DOWNLOAD AGP, BUILD AND CHECK CHROM-LEVEL SEQUENCE (TODO 7/6/04 angie)
    # If they give us chrom fasta, don't build, just check.
    ssh kolossus
    cd /cluster/data/canFam1
    wget ftp://????
    tar xvzf ????
    cd ????
    cp /dev/null ../chrom.lst
    foreach f (*.agp)
      set chr = `echo $f:r | sed -e 's/^chr//'`
      set base = `echo $chr | sed -e 's/_random$//'`
      mkdir -p ../$base
      cp -p $f ../$base
      if ("$chr" == "$base") echo $chr >> ../chrom.lst
    end
    # OK, tack chrM on there too:
    echo M >> ../chrom.lst
    cd /cluster/data/canFam1
    foreach c (`cat chrom.lst`)
      foreach agp ($c/chr$c{,_random}.agp)
        if (-e $agp) then
          set fa = $agp:r.fa
          echo building $fa from $agp
          agpToFa -simpleMultiMixed $agp $agp:t:r $fa \
            ???? # file with all contigs glommed together
        endif
      end
    end
    # checkAgpAndFa prints out way too much info -- keep the end/stderr only:
    foreach c (`cat chrom.lst`)
      foreach agp ($c/chr$c{,_random}.agp)
        if (-e $agp) then
          set fa = $agp:r.fa
          echo checking consistency of $agp and $fa
          ~/bin/$MACHTYPE/checkAgpAndFa $agp $fa | tail -1
        endif
      end
    end
    faSize */chr*.fa
    # excluding chrM.fa:  note the same #real as for WGS contigs:


# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT CONTIGS/GAPS (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    foreach c (`cat chrom.lst`)
      foreach agp ($c/chr$c{,_random}.agp)
        if (-e $agp) then
          set fa = $agp:r.fa
          echo splitting $agp and $fa
          cp -p $agp $agp.bak
          cp -p $fa $fa.bak
          splitFaIntoContigs $agp $fa . -nSize=5000000
        endif
      end
    end
    # splitFaIntoContigs makes new dirs for _randoms.  Move their contents 
    # back into the main chrom dirs and get rid of the _random dirs.
    foreach d (*_random)
      set base = `echo $d | sed -e 's/_random$//'`
      mv $d/lift/oOut.lst $base/lift/rOut.lst
      mv $d/lift/ordered.lft $base/lift/random.lft
      mv $d/lift/ordered.lst $base/lift/random.lst
      rmdir $d/lift
      mv $d/* $base
      rmdir $d
    end
    # Make a "pseudo-contig" for processing chrM too:
    mkdir M/chrM_1
    sed -e 's/chrM/chrM_1/' M/chrM.fa > M/chrM_1/chrM_1.fa
    mkdir M/lift
    echo "chrM_1/chrM_1.fa.out" > M/lift/oOut.lst
    echo "chrM_1" > M/lift/ordered.lst
    echo "0	M/chrM_1	16775	chrM	16775" > M/lift/ordered.lft


# MAKE JKSTUFF AND BED DIRECTORIES (TODO 7/6/04 angie)
    # This used to hold scripts -- better to keep them inline here so 
    # they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/canFam1/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/canFam1/bed


# CREATING DATABASE (TODO 7/6/04 angie)
    ssh hgwdev
    echo 'create database canFam1' | hgsql ''
    # Use df to make sure there is at least 75G free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql


# CREATING GRP TABLE FOR TRACK GROUPING (TODO 7/6/04 angie)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg17.grp" \
      | hgsql canFam1


# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS (TODO 7/6/04 angie)
    # Make nib/, unmasked until RepeatMasker and TRF steps are done.
    # Do this now so we can load up RepeatMasker and run featureBits; 
    # can also load up other tables that don't depend on masking.  
    ssh kksilo
    cd /cluster/data/canFam1
    mkdir nib
    foreach c (`cat chrom.lst`)
      foreach f ($c/chr${c}{,_random}.fa)
        if (-e $f) then
          echo "nibbing $f"
          /cluster/bin/i386/faToNib $f nib/$f:t:r.nib
        endif
      end
    end

    # Make symbolic links from /gbdb/canFam1/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/canFam1/nib
    foreach f (/cluster/data/canFam1/nib/chr*.nib)
      ln -s $f /gbdb/canFam1/nib
    end
    # Load /gbdb/canFam1/nib paths into database and save size info.
    cd /cluster/data/canFam1
    hgsql canFam1  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib canFam1 /gbdb/canFam1/nib */chr*.fa
    echo "select chrom,size from chromInfo" | hgsql -N canFam1 > chrom.sizes
    # take a look at chrom.sizes, should be 54 lines
    wc chrom.sizes


# GOLD AND GAP TRACKS (TODO 7/6/04 angie)
    ssh hgwdev
    cd /cluster/data/canFam1
    hgGoldGapGl -noGl -chromLst=chrom.lst canFam1 /cluster/data/canFam1 .
    # featureBits fails if there's no chrM_gap, so make one:
    # echo "create table chrM_gap like chr1_gap" | hgsql canFam1
    # oops, that won't work until v4.1, so do this for the time being:
    echo "create table chrM_gap select * from chr1_gap where 0=1" \
    | hgsql canFam1


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR CANFAM1 (TODO 7/6/04 angie)
    ssh hgwdev
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd $HOME/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add canFam1 in all the right places and do
    make update
    make alpha
    cvs commit makefile

    # Add dbDb and defaultDb entries:
    echo 'insert into dbDb (name, description, nibPath, organism,  \
          defaultPos, active, orderKey, genome, scientificName,  \
          htmlPath, hgNearOk)  \
          values("canFam1", "Jul. 2004", \
          "/gbdb/canFam1/nib", "Dog", "chr13:13120186-13124117", 1, \
          18, "Dog", "Canis familiaris", \
          "/gbdb/canFam1/html/description.html", 0);' \
    | hgsql -h genome-testdb hgcentraltest
    echo 'update defaultDb set name = "canFam1" where genome = "Dog"' \
        | hgsql -h genome-testdb hgcentraltest


# REPEAT MASKING (TODO 7/6/04 angie)
    #- Split contigs into 500kb chunks, at gaps if possible:
    ssh kksilo
    cd /cluster/data/canFam1
    foreach c (`cat chrom.lst`)
      foreach d ($c/chr${c}*_?{,?})
        cd $d
        echo "splitting $d"
        set contig = $d:t
        ~/bin/i386/faSplit gap $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -minGapSize=100
        cd ../..
      end
    end

    #- Make the run directory and job list:
    cd /cluster/data/canFam1
    cat << '_EOF_' > jkStuff/RMDog
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/canFam1/$2
/bin/cp $2 /tmp/canFam1/$2/
cd /tmp/canFam1/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s -spec dog $2
popd
/bin/cp /tmp/canFam1/$2/$2.out ./
if (-e /tmp/canFam1/$2/$2.align) /bin/cp /tmp/canFam1/$2/$2.align ./
if (-e /tmp/canFam1/$2/$2.tbl) /bin/cp /tmp/canFam1/$2/$2.tbl ./
if (-e /tmp/canFam1/$2/$2.cat) /bin/cp /tmp/canFam1/$2/$2.cat ./
/bin/rm -fr /tmp/canFam1/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/canFam1/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/canFam1
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMDog
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach c (`cat chrom.lst`)
      foreach d ($c/chr${c}{,_random}_?{,?})
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/data/canFam1/jkStuff/RMDog \
                 /cluster/data/canFam1/$d $f \
               '{'check out line+ /cluster/data/canFam1/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
      end
    end

    #- Do the run
    ssh kk
    cd /cluster/data/canFam1/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...

    #- Lift up the 500KB chunk .out's to 5MB ("pseudo-contig") level
    ssh kksilo
    cd /cluster/data/canFam1
    foreach d (*/chr*_?{,?})
      set contig = $d:t
      echo $contig
      liftUp $d/$contig.fa.out $d/$contig.lft warn $d/${contig}_*.fa.out \
        > /dev/null
    end

    #- Lift pseudo-contigs to chromosome level
    foreach c (`cat chrom.lst`)
      echo lifting $c
      cd $c
      if (-e lift/ordered.lft && ! -z lift/ordered.lft) then
        liftUp chr$c.fa.out lift/ordered.lft warn `cat lift/oOut.lst` \
        > /dev/null
      endif
      if (-e lift/random.lft && ! -z lift/random.lft) then
        liftUp chr${c}_random.fa.out lift/random.lft warn `cat lift/rOut.lst` \
        > /dev/null
      endif
      cd ..
    end

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/canFam1
    hgLoadOut canFam1 */chr*.fa.out


# VERIFY REPEATMASKER RESULTS (TODO 7/6/04 angie)
    # Eyeball some repeat annotations in the browser, compare to lib seqs.
    # Run featureBits on canFam1 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits canFam1 rmsk


# MAKE 10.OOC, 11.OOC FILES FOR BLAT (TODO 7/6/04 angie)
    # Use -repMatch=??? (based on size -- for human we use 1024, and 
    # dog size is ~??% of human)
    ssh kkr1u00
    mkdir /cluster/data/canFam1/bed/ooc
    cd /cluster/data/canFam1/bed/ooc
    ls -1 /cluster/data/canFam1/nib/chr*.nib > nib.lst
    mkdir /cluster/bluearc/canFam1
    blat nib.lst /dev/null /dev/null -tileSize=11 \
      -makeOoc=/cluster/bluearc/canFam1/11.ooc -repMatch=???
    blat nib.lst /dev/null /dev/null -tileSize=10 \
      -makeOoc=/cluster/bluearc/canFam1/10.ooc -repMatch=???
    mkdir /iscratch/i/canFam1
    cp -p /cluster/bluearc/canFam1/*.ooc /iscratch/i/canFam1/
    iSync


# MAKE LIFTALL.LFT (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft


# SIMPLE REPEATS (TRF) (TODO 7/6/04 angie)
    # TRF runs pretty quickly now... it takes a few hours total runtime, 
    # so instead of binrsyncing and para-running, just do this on the
    # local fileserver
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/simpleRepeat
    cd /cluster/data/canFam1/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach d (/cluster/data/canFam1/*/chr*_?{,?})
      set ctg = $d:t
      foreach f ($d/${ctg}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
      end
    end
    csh -ef jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    endsInLf trf/*
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/canFam1/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load into the database:
    ssh hgwdev
    hgLoadBed canFam1 simpleRepeat \
      /cluster/data/canFam1/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
    featureBits canFam1 simpleRepeat


# PROCESS SIMPLE REPEATS INTO MASK (TODO 7/6/04/ angie)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/canFam1/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/canFam1
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (`cat chrom.lst`)
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # Here's the coverage for the filtered TRF:
    ssh hgwdev
    cat /cluster/data/canFam1/bed/simpleRepeat/trfMaskChrom/*.bed \
      > /tmp/filtTrf.bed
    featureBits canFam1 /tmp/filtTrf.bed


# MASK SEQUENCE WITH REPEATMASKER AND SIMPLE REPEAT/TRF (TODO 7/6/04 angie)
    # Note: just to keep things consistent, redid chr1 and chr2 7/6 with 
    # the ProcessRepeats-only rerun results (only masking changes were 
    # 5bp in chr1 and 3bp in chr2)
    ssh kksilo
    cd /cluster/data/canFam1
    # Soft-mask (lower-case) the contig and chr .fa's, 
    # then make hard-masked versions from the soft-masked.  
    set trfCtg=bed/simpleRepeat/trfMask
    set trfChr=bed/simpleRepeat/trfMaskChrom
    foreach f (*/chr*.fa)
      echo "repeat- and trf-masking $f"
      maskOutFa -soft $f $f.out $f
      set chr = $f:t:r
      maskOutFa -softAdd $f $trfChr/$chr.bed $f
      echo "hard-masking $f"
      maskOutFa $f hard $f.masked
    end
    foreach c (`cat chrom.lst`)
      echo "repeat- and trf-masking contigs of chr$c, chr${c}_random"
      foreach d ($c/chr*_?{,?})
        set ctg=$d:t
        set f=$d/$ctg.fa
        maskOutFa -soft $f $f.out $f
        maskOutFa -softAdd $f $trfCtg/$ctg.bed $f
        maskOutFa $f hard $f.masked
      end
    end
    #- Rebuild the nib files, using the soft masking in the fa:
    mkdir nib
    foreach f (*/chr*.fa)
      faToNib -softMask $f nib/$f:t:r.nib
    end
    # Make one big 2bit file as well, and make a link to it in 
    # /gbdb/canFam1/nib because hgBlat looks there:
    faToTwoBit */chr*.fa canFam1.2bit
    ln -s /cluster/data/canFam1/canFam1.2bit /gbdb/canFam1/nib/


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR CANFAM1 (TODO 7/6/04 angie)
    ssh hgwdev
    echo 'insert into blatServers values("canFam1", "blat1", "17778", "1"); \
          insert into blatServers values("canFam1", "blat1", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


# MAKE DESCRIPTION/SAMPLE POSITION HTML PAGE (TODO 7/6/04 angie)
    ssh hgwdev
    mkdir /gbdb/canFam1/html
    # Write ~/kent/src/hg/makeDb/trackDb/dog/canFam1/description.html 
    # with a description of the assembly and some sample position queries.  
    chmod a+r $HOME/kent/src/hg/makeDb/trackDb/dog/canFam1/description.html
    # Check it in and copy (ideally using "make alpha" in trackDb) to 
    # /gbdb/canFam1/html


# PUT MASKED SEQUENCE OUT FOR CLUSTER RUNS (TODO 7/6/04 angie)
    ssh kkr1u00
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /iscratch/i/canFam1/nib
    mkdir /iscratch/i/canFam1/nib
    cp -p /cluster/data/canFam1/nib/chr*.nib /iscratch/i/canFam1/nib
    # Pseudo-contig fa that have been repeat- and trf-masked:
    rm -rf /iscratch/i/canFam1/trfFa
    mkdir /iscratch/i/canFam1/trfFa
    foreach d (/cluster/data/canFam1/*/chr*_?{,?})
      cp $d/$d:t.fa /iscratch/i/canFam1/trfFa
    end
    cp -p /cluster/data/canFam1/canFam1.2bit /iscratch/i/canFam1/
    iSync
    # Put nibs and rmsk files in /scratch for big cluster blastz.
    mkdir /cluster/bluearc/scratch/hg/canFam1
    cp -pR /iscratch/i/canFam1/nib /cluster/bluearc/scratch/hg/canFam1
    ssh kksilo
    mkdir /cluster/bluearc/scratch/hg/canFam1/rmsk
    cp -p /cluster/data/canFam1/*/chr*.fa.out \
       /cluster/bluearc/scratch/hg/canFam1/rmsk
    # Ask cluster-admin for an rsync after the next step.  


# MAKE LINEAGE-SPECIFIC REPEATS VS. HUMAN, MOUSE (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/bluearc/scratch/hg/canFam1/rmsk
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Human in extra column 1, Mouse in extra column 2
    foreach outfl ( *.out )
        echo "$outfl"
        /cluster/bluearc/RepeatMasker/DateRepsinRMoutput.pl \
          ${outfl} -query dog -comp human -comp mouse
    end
    # Now extract human (extra column 1), ignore mouse.
    cd /cluster/bluearc/scratch/hg/canFam1
    mkdir linSpecRep.notInHuman
    mkdir linSpecRep.notInMouse
    foreach f (rmsk/*.out_hum_mus)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInHuman/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    # Clean up.
    rm /cluster/bluearc/scratch/hg/canFam1/rmsk/*.out_hum_mus
    # Ask cluster-admin for an rsync.


# AUTO UPDATE GENBANK MRNA RUN  (TODO 7/6/04 angie)
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .
    # See if /cluster/data/genbank/etc/genbank.conf has had any un-checked-in
    # edits, check them in if necessary:
    diff /cluster/data/genbank/etc/genbank.conf etc/genbank.conf

    # Edit etc/genbank.conf and add these lines:
# canFam1 (dog)
canFam1.genome = /iscratch/i/canFam1/nib/chr*.nib
canFam1.lift = /cluster/data/canFam1/jkStuff/liftAll.lft
canFam1.refseq.mrna.native.load = no
canFam1.genbank.mrna.xeno.load = yes
canFam1.genbank.est.xeno.load = no
canFam1.downloadDir = canFam1

    cvs ci etc/genbank.conf
    # Edit src/align/gbBlat to add /iscratch/i/canFam1/11.ooc
    cvs diff src/align/gbBlat
    make
    cvs ci src/align/gbBlat
    # Install to /cluster/data/genbank:
    make install-server

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -clusterRootDir=/cluster/bluearc/genbank \
      -iserver=kkr1u00 -iserver=kkr2u00 -iserver=kkr3u00 -iserver=kkr4u00 \
      -iserver=kkr5u00 -iserver=kkr6u00 -iserver=kkr7u00 -iserver=kkr8u00 \
      -srcDb=genbank -type=mrna -verbose=1 -initial canFam1
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad canFam1
    # Clean up:
    rm -r /cluster/bluearc/genbank/work/initial.canFam1

    ssh eieio
    # -initial for ESTs (now with /cluster/store7 and iservers):
    nice bin/gbAlignStep -clusterRootDir=/cluster/store7/genbank \
      -iserver=kkr1u00 -iserver=kkr2u00 -iserver=kkr3u00 -iserver=kkr4u00 \
      -iserver=kkr5u00 -iserver=kkr6u00 -iserver=kkr7u00 -iserver=kkr8u00 \
      -srcDb=genbank -type=est -verbose=1 -initial canFam1
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 canFam1
    # Clean up:
    rm -r /cluster/store7/genbank/work/initial.canFam1


# MAKE DOWNLOADABLE SEQUENCE FILES (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1
    #- Build the .zip files
    cat << '_EOF_' > jkStuff/zipAll.csh
rm -rf zip
mkdir zip
zip -j zip/chromAgp.zip [0-9A-Z]*/chr*.agp
zip -j zip/chromOut.zip */chr*.fa.out
zip -j zip/chromFa.zip */chr*.fa
zip -j zip/chromFaMasked.zip */chr*.fa.masked
cd bed/simpleRepeat
zip ../../zip/chromTrf.zip trfMaskChrom/chr*.bed
cd ../..
cd /cluster/data/genbank
./bin/i386/gbGetSeqs -db=canFam1 -native GenBank mrna \
        /cluster/data/canFam1/zip/mrna.fa
cd /cluster/data/canFam1/zip
zip -j mrna.zip mrna.fa
'_EOF_'
    # << this line makes emacs coloring happy
    csh ./jkStuff/zipAll.csh |& tee zipAll.log
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd /cluster/data/canFam1/zip
    set gp = /usr/local/apache/htdocs/goldenPath/canFam1
    mkdir -p $gp/bigZips
    cp -p *.zip $gp/bigZips
    mkdir -p $gp/chromosomes
    foreach f ( ../*/chr*.fa )
      zip -j $gp/chromosomes/$f:t.zip $f
    end

    cd $gp/bigZips
    md5sum *.zip > md5sum.txt
    cd $gp/chromosomes
    md5sum *.zip > md5sum.txt
    # Take a look at bigZips/* and chromosomes/*, update their README.txt's
    # Can't make refGene upstream sequence files - no refSeq for dog.
    # Maybe ensGene when we get that.


# SWAP BLASTZ HUMAN-DOG TO DOG-HUMAN (HG17) (TODO 7/6/04 angie)
    ssh kolossus
    mkdir /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25
    set aliDir = /cluster/data/hg17/bed/blastz.canFam1.2004-02-25
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSplitByTarget stdin unsorted
    # Sort the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    du -sh $aliDir/axtChrom unsorted axtChrom
#1.4G    /cluster/data/hg17/bed/blastz.canFam1.2004-02-25/axtChrom
#1.4G    unsorted
#1.4G    axtChrom
    rm -r unsorted


# RESCORE HUMAN BLASTZ (TODO 7/6/04 angie)
    # Webb noticed low scores in latest runs with repeats abridged --
    # PSU's restore_rpts program rescored alignments with default matrix 
    # instead of BLASTZ_Q matrix.  Rescore them here so the chainer sees 
    # the higher scores:
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25
    mkdir axtChrom.rescore
    foreach f (axtChrom/chr*.axt)
      axtRescore -scoreScheme=/cluster/data/blastz/HoxD55.q \
        $f axtChrom.rescore/$f:t
    end
    mv axtChrom axtChrom.orig
    mv axtChrom.rescore axtChrom


# CHAIN HUMAN BLASTZ (TODO 7/6/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 \
  /iscratch/i/canFam1/nib \
  /iscratch/i/gs.18/build35/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 50 of 50 jobs
#Average job time:                  69s       1.15m     0.02h    0.00d
#Longest job:                      218s       3.63m     0.06h    0.00d
#Submission to last job:           232s       3.87m     0.06h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain canFam1 ${c}_chainHg17 $i
    end


# NET HUMAN BLASTZ (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain
    netClass noClass.net canFam1 hg17 human.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet canFam1 netHg17 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet canFam1 netSyntenyHg17 stdin
    # Add entries for chaing16, netHg17, syntenyHg17 to dog/canFam1 trackDb


# MAKE VSHG17 DOWNLOADABLES (TODO 7/6/04 angie)
    ssh kksilo
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25
    # Webb asked for axtChrom/chr22.axt... since axtChrom is rel. small 
    # this time, just put it all out there.
    zip /cluster/data/canFam1/zip/HGaxtChrom.zip axtChrom/chr*.axt
    cd /cluster/data/canFam1/bed/blastz.hg17.swap.2004-02-25/axtChain
    cp all.chain human.chain
    zip /cluster/data/canFam1/zip/human.chain.zip human.chain
    rm human.chain
    zip /cluster/data/canFam1/zip/human.net.zip human.net
    zip /cluster/data/canFam1/zip/humanSyn.net.zip humanSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/canFam1/vsHg17
    cd /usr/local/apache/htdocs/goldenPath/canFam1/vsHg17
    mv /cluster/data/canFam1/zip/HGaxtChrom.zip axtChrom.zip
    mv /cluster/data/canFam1/zip/human*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# BLASTZ SELF (TODO 7/6/04 angie)
    ssh kk
    mkdir -p /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    # OK, the 500k x whole chrom 03-02 run was taking FOREVER (18hrs, ~63%)
    # and multiple folks are asking me to dig up pileups for Arian.  So, 
    # just do a vanilla run as a baseline; return to the experiments later.
    cat << '_EOF_' > DEF
# dog vs. dog
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET
# Dog
SEQ1_DIR=/iscratch/i/canFam1/nib
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Dog
SEQ2_DIR=/iscratch/i/canFam1/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/data/canFam1/bed/blastz.canFam1.2004-03-03

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # Save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.canFam1-canFam1

    # source the DEF file
    bash
    . ./DEF
    mkdir -p $BASE/run
    ~angie/hummus/make-joblist $DEF > $BASE/run/j
    sh $BASE/xdir.sh
    cd $BASE/run
    # now edit j to prefix path to executable name
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    # make sure the j2 edits are OK, then use it:
    mv j2 j
    para create j
    para try, check, push, check, ...
#Completed: 22801 of 22801 jobs
#Average job time:                 257s       4.29m     0.07h    0.00d
#Longest job:                     1238s      20.63m     0.34h    0.01d
#Submission to last job:          6939s     115.65m     1.93h    0.08d

    # --- normalize (PennSpeak for lift)
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    # run bash shell if not running it already
    source DEF
    mkdir -p $BASE/run.1
    mkdir -p $BASE/lav
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1
    wc -l jobList
    head jobList
    # make sure the job list is OK
    para create jobList
    para push
#Completed: 151 of 151 jobs
#Average job time:                  24s       0.41m     0.01h    0.00d
#Longest job:                      127s       2.12m     0.04h    0.00d
#Submission to last job:           246s       4.10m     0.07h    0.00d

    # convert lav files to axt
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    mkdir axtChrom
    # a new run directory
    mkdir run.2
    cd run.2
# lavToAxt has a new -dropSelf option that *will* replace axtDropOverlap,
# once /cluster/bin/i386/lavToAxt is rebuilt...  Meanwhile it's built 
# for x86_64.
    cat << '_EOF_' > do.csh
#!/bin/csh
cd $1
cat `ls -1 *.lav | sort -g` \
| lavToAxt -dropSelf stdin /iscratch/i/canFam1/nib /iscratch/i/canFam1/nib \
    stdout \
| axtSort stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x do.csh
    cat << '_EOF_' > gsub
#LOOP
./do.csh {check in exists $(path1)} {check out line+ /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChrom/$(root1).axt}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    \ls -1Sd ../lav/chr* > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
    head jobList
    para create jobList
    para try, check, push, check,...
#Completed: 53 of 54 jobs
#Crashed: 1 jobs
#Average job time:                  30s       0.51m     0.01h    0.00d
#Longest job:                      541s       9.02m     0.15h    0.01d
#Submission to last job:           576s       9.60m     0.16h    0.01d
    # The crash was not a memory problem -- it was that chr8_random's lav 
    # contained only 1 alignment, to itself (dropped), so its .axt is empty.  


# CHAIN SELF BLASTZ (TODO 7/6/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtFilter -notQ=chrUn $1 \
| axtChain stdin /iscratch/i/canFam1/nib /iscratch/i/canFam1/nib $2 \
  > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # oops -- empty chr8_random strikes again:
#Completed: 53 of 54 jobs
#Crashed: 1 jobs
#Average job time:                  53s       0.89m     0.01h    0.00d
#Longest job:                      514s       8.57m     0.14h    0.01d
#Submission to last job:           514s       8.57m     0.14h    0.01d

    # now on the cluster server, sort chains
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # trim to minScore=20000 to cut some of the fluff
    mkdir chainFilt
    foreach f (chain/*.chain)
      chainFilter -minScore=20000 $f > chainFilt/$f:t
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain/chainFilt
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain canFam1 ${c}_chainSelf $i
    end


# NET SELF BLASTZ (TODO 7/6/04 angie)
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    netClass -noAr noClass.net canFam1 canFam1 self.net

    # Make a 'syntenic' subset:
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    rm noClass.net
    netFilter -syn self.net > selfSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    netFilter -minGap=10 self.net |  hgLoadNet canFam1 netSelf stdin
    netFilter -minGap=10 selfSyn.net | hgLoadNet canFam1 netSyntenySelf stdin
    # Add entries for chainSelf, netSelf, netSyntenySelf to 
    # dog/canFam1 trackDb


# MAKE VSSELF DOWNLOADABLES (TODO 7/6/04 angie)
    ssh kolossus
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03
    # Webb asked for axtChrom/chr22.axt... since axtChrom is rel. small 
    # this time, just put it all out there.
    zip /cluster/data/canFam1/zip/CCaxtChrom.zip axtChrom/chr*.axt
    cd /cluster/data/canFam1/bed/blastz.canFam1.2004-03-03/axtChain
    cp all.chain self.chain
    zip /cluster/data/canFam1/zip/self.chain.zip self.chain
    rm self.chain
    zip /cluster/data/canFam1/zip/self.net.zip self.net
    zip /cluster/data/canFam1/zip/selfSyn.net.zip selfSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/canFam1/vsSelf
    cd /usr/local/apache/htdocs/goldenPath/canFam1/vsSelf
    mv /cluster/data/canFam1/zip/CCaxtChrom.zip axtChrom.zip
    mv /cluster/data/canFam1/zip/self*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# PRODUCING GENSCAN PREDICTIONS (TODO 7/6/04 angie)
    ssh hgwdev
    mkdir /cluster/data/canFam1/bed/genscan
    cd /cluster/data/canFam1/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Run on small cluster (more mem than big cluster).
    ssh kki
    cd /cluster/data/canFam1/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/data/canFam1/*/chr*_*/chr*_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    wc -l genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try, check, push, check, ...
    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".

    # Convert these to chromosome level files as so:
    ssh kksilo
    cd /cluster/data/canFam1/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/genscan
    ldHgGene canFam1 genscan genscan.gtf
    hgPepPred canFam1 generic genscanPep genscan.pep
    hgLoadBed canFam1 genscanSubopt genscanSubopt.bed


# PRODUCING FUGU BLAT ALIGNMENTS (TODO 7/6/04)
    ssh kk
    mkdir /cluster/data/canFam1/bed/blatFr1
    cd /cluster/data/canFam1/bed/blatFr1
    ls -1S /iscratch/i/fugu/trfFa/*.fa > fugu.lst
    ls -1S /iscratch/i/canFam1/nib/*.nib > dog.lst
    cat << '_EOF_' > gsub
#LOOP
blat -mask=lower -q=dnax -t=dnax {check in exists $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    mkdir psl
    gensub2 dog.lst fugu.lst gsub spec
    para create spec
    para try, check, push, check, ...
    # for future reference, the trfFa on bluearc seem better partitioned...
#Completed: 31212 of 31212 jobs
#Average job time:                 187s       3.11m     0.05h    0.00d
#Longest job:                    31706s     528.43m     8.81h    0.37d
#Submission to last job:         31706s     528.43m     8.81h    0.37d

    # Sort alignments:
    ssh kksilo
    cd /cluster/data/canFam1/bed/blatFr1
    pslCat -dir psl | pslSortAcc nohead chrom /cluster/store2/temp stdin

    # load seq & psl into database:
    ssh hgwdev
    mkdir /gbdb/canFam1/fuguSeq
    ln -s /cluster/data/fr1/fugu_v3.masked.fa /gbdb/canFam1/fuguSeq/
    cd /cluster/data/canFam1/bed/blatFr1
    hgLoadSeq canFam1 /gbdb/canFam1/fuguSeq/fugu_v3.masked.fa
    cd /cluster/data/canFam1/bed/blatFr1/chrom
    cat *.psl | hgLoadPsl -fastLoad -table=blatFr1 canFam1 stdin


# LOAD CPGISSLANDS (TODO 3/23/04 angie)
    ssh hgwdev
    mkdir -p /cluster/data/canFam1/bed/cpgIsland
    cd /cluster/data/canFam1/bed/cpgIsland
    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    mv cpglh.exe /cluster/data/canFam1/bed/cpgIsland/
    
    ssh kksilo
    cd /cluster/data/canFam1/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpglh.exe $f > $fout
    end
    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIsland
    hgLoadBed canFam1 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed


# BUILD BLAST DATABASES
    cd /cluster/data/canFam1
    mkdir blastDb
     for i in `cat chrom.lst`; do for j in `echo $i/chr$i_*/chr*_*_*.fa`; do ln -s `pwd`/$j blastDb/`basename $j .fa`;
      done; done 
      cd blastDb
      for i in *; do formatdb -p F -i $i; done
# END BLAST


# GC 5 BASE WIGGLE TRACK (TODO 7/6/04 angie)
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/gc5Base
    cd /cluster/data/canFam1/bed/gc5Base
    mkdir wigData5 dataLimits5
    foreach n (../../nib/*.nib)
      set c=`basename ${n} | sed -e "s/.nib//"`
      set C=`echo $c | sed -e "s/chr//"`
      echo "working on ${c} - ${C} ... "
      hgGcPercent -chr=${c} -doGaps -file=stdout -win=5 canFam1 ../../nib \
      | grep -w GC \
      | awk '{ \
               bases = $3 - $2 \
               perCent = $5/10.0 \
               printf "%d\t%.1f\n", $2+1, perCent \
             }' \
      | wigAsciiToBinary \
        -dataSpan=5 -chrom=${c} -wibFile=wigData5/gc5Base_${C} \
        -name=${C} stdin > dataLimits5/${c}
    end
    # data is complete, load track on hgwdev
    ssh hgwdev
    cd /cluster/data/canFam1/bed/gc5Base
    # create symlinks for .wib files, then load track
    mkdir /gbdb/canFam1/wib
    ln -s `pwd`/wigData5/*.wib /gbdb/canFam1/wib
    hgLoadWiggle canFam1 gc5Base wigData5/*.wig


# CREATING QUALITY SCORE TRACK (TODO 7/6/04 angie)
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/qual
    cd /cluster/data/canFam1/bed/qual
    cat ../../agp_040224/chr*.agp > assembly.agp
    tar xvzf ../../dog_040105.contigs.qual.tar.gz
    cat dog*.qual | qaToQac stdin stdout \
    | chimpChromQuals assembly.agp stdin chrom.qac
    rm dog*.qual
    mkdir wigData dataLimits
    foreach c (`cat ../../chrom.lst`)
      foreach agp (../../$c/chr$c.agp ../../$c/chr${c}_random.agp)
        if (-e $agp) then
          set chr = $agp:t:r
          set abbrev = `echo $chr | sed -e 's/^chr//;  s/_random/r/;'`
          echo $chr to $abbrev wiggle
          qacToWig chrom.qac -name=$chr stdout \
          | wigAsciiToBinary -dataSpan=1 -chrom=$chr \
              -wibFile=wigData/qual_$abbrev -name=$abbrev stdin \
              > dataLimits/$chr
        endif
      end
    end
    # Verify size of .wib file = chrom length
    foreach f (wigData/*.wib)
      set abbrev = $f:t:r
      set chr = `echo $abbrev | sed -e 's/^qual_/chr/;  s/r$/_random/;'`
      set wibLen = `ls -l $f | awk '{print $5;}'`
      set chromLen = `grep -w $chr ../../chrom.sizes | awk '{print $2;}'`
      if ($wibLen != $chromLen) then
        echo "ERROR: $chr size is $chromLen but wib size is $wibLen"
      else
        echo $chr OK.
      endif
    end

    # /gbdb & load:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/qual
    mkdir -p /gbdb/canFam1/wib
    ln -s `pwd`/wigData/*.wib /gbdb/canFam1/wib
    hgLoadWiggle canFam1 quality wigData/*.wig

    # To speed up display for whole chrom views, need to make zoomed
    # data views.  Zoom to 1K points per pixel.
    ssh kksilo
    cd /cluster/data/canFam1/bed/qual/wigData1K
    mkdir -p wigData1K
    mkdir -p dataLimits1K
    foreach c (`cat ../../chrom.lst`)
      if (-f ../../${c}/chr${c}.agp) then
        echo "chr${c} quality 1K zoom"
        qacToWig chrom.qac -name=chr${c} stdout \
        | wigZoom stdin \
        | wigAsciiToBinary -dataSpan=1024 \
                -chrom=chr${c} -wibFile=wigData1K/qc1K_${c} \
                -name=${c} stdin > dataLimits1K/chr${c}
      endif
      if (-f ../../${c}/chr${c}_random.agp) then
        echo "chr${c}_random quality 1K zoom"
        qacToWig chrom.qac -name=chr${c}_random stdout \
        | wigZoom stdin \
        | wigAsciiToBinary -dataSpan=1024 \
                -chrom=chr${c}_random -wibFile=wigData1K/qc1K_${c}r \
                -name=${c}_random stdin > dataLimits1K/chr${c}r
      endif
    end

    ssh hgwdev
    cd /cluster/data/canFam1/bed/qual/wigData1K
    # create symlinks for .wib files
    ln -s `pwd`/*.wib /gbdb/canFam1/wib
    # load in addition to existing data
    hgLoadWiggle -oldTable canFam1 quality *.wig


# MAKE UNIGENE ALIGNMENTS (TODO 7/10/04 angie)
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/unigene
    cd /cluster/data/canFam1/bed/unigene
    # Download dog Unigene and run Chuck's preproc scripts:
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Cfa.info
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Cfa.seq.uniq.gz
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Cfa.data.gz
    gunzip *.gz
    # Chuck's script expects human (Hs) -- use Cfa for dog:
    sed -e 's/Hs/Cfa/g' /projects/cc/hg/sugnet/uniGene/countSeqsInCluster.pl \
    > ./countSeqsInCluster.pl
    chmod a+x ./countSeqsInCluster.pl
    ./countSeqsInCluster.pl Cfa.data counts.tab
    /projects/cc/hg/sugnet/uniGene/parseUnigene.pl Cfa.seq.uniq \
      Cfa.seq.uniq.simpleHeader.fa leftoverData.tab
    # Put on iscratch for cluster run
    ssh kkr1u00
    mkdir /iscratch/i/canFam1/unigene
    cp -p /cluster/data/canFam1/bed/unigene/Cfa.seq.uniq.simpleHeader.fa \
      /iscratch/i/canFam1/unigene/
    iSync
    # align on big cluster
    ssh kk
    cd /cluster/data/canFam1/bed/unigene
    ls -1S /iscratch/i/canFam1/trfFa/*.fa > allctg.lst
    ls -1S /iscratch/i/canFam1/unigene/*.fa > uniGene.lst
# seems to be a bug in latest blat: -mask=lower => 0 alignments!  
# for now, use Jim's next-to-latest blat.27:
    cat << '_EOF_' > template.sub
#LOOP
/cluster/home/kent/bin/i386/blat.27 -mask=lower -minIdentity=95 -ooc=/iscratch/i/canFam1/11.ooc {check in line+ $(path1)} {check in line+ $(path2)}  {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 allctg.lst uniGene.lst template.sub jobList
    para create jobList
    mkdir psl
    para try, check, push, check
#Completed: 259 of 259 jobs
#Average job time:                  13s       0.22m     0.00h    0.00d
#Longest job:                       21s       0.35m     0.01h    0.00d
#Submission to last job:            22s       0.37m     0.01h    0.00d
    # postprocess
    ssh kksilo
    pslSort dirs raw.psl tmp psl >& pslSort.log
    liftUp -type=.psl stdout ../../jkStuff/liftAll.lft warn raw.psl \
    | pslReps -minCover=0.2 -minAli=0.965 -nearTop=0.002 \
      stdin uniGene.lifted.pslReps.psl /dev/null
    rm raw.psl
    gzip Cfa.seq.uniq Cfa.data 
    # load into db
    ssh hgwdev
    cd /cluster/data/canFam1/bed/unigene
    mkdir /gbdb/canFam1/unigene
    ln -s /cluster/data/canFam1/bed/unigene/Cfa.seq.uniq.simpleHeader.fa \
      /gbdb/canFam1/unigene/
    hgLoadSeq canFam1 /gbdb/canFam1/unigene/Cfa.seq.uniq.simpleHeader.fa
    hgLoadPsl -fastLoad -table=uniGene_cf canFam1 uniGene.lifted.pslReps.psl


# RUN GENE-CHECK ON MRNA W/CDS, ENSEMBL (TODO 3/29/04 markd)
    # Note: /cluster/bin/scripts/runGeneCheck should make this easier 
    # in the future, but this also shows how MarkD ran gene-check on 
    # mRNAs with annotated CDS:

    # get mrna data from hgwbeta, which is most current:
    ssh hgwbeta
    mkdir /cluster/store7/markd/canFam1
    cd /cluster/store7/markd/canFam1
    mkdir data
    hgsql -N -e 'select * from all_mrna' canFam1 |cut -f 2-30 \
      > data/all_mrna.psl
    hgsql -N -e 'select mrna.acc,cds.name from mrna,cds,all_mrna where all_mrna.qName=mrna.acc and mrna.cds = cds.id' canFam1 \
      > data/cds.tab
    nice mrnaToGene -cdsFile=data/cds.tab data/all_mrna.psl data/all_mrna.gp \
      >& data/all_mrna.log

    # get ensGene data from hgwdev:
    ssh hgwdev
    cd /cluster/store7/markd/canFam1
    hgsql -N -e 'select * from ensGene ' canFam1 >data/ensGene.gp

    # run gene-check and gene-extract
    ssh kksilo
    cd /cluster/store7/markd/canFam1
    mkdir results
    ~markd/bin/gene-check -incl-ok -nib-dir /cluster/data/canFam1/nib \
      -details-out results/all_mrna.details data/all_mrna.gp \
      results/all_mrna.chk >& all_mrna.log
    ~markd/bin/gene-check -incl-ok -nib-dir /cluster/data/canFam1/nib \
      -details-out results/ensGene.details data/ensGene.gp \
      results/ensGene.chk >& ensGene.log
    ~markd/bin/gene-extract -nib-dir  /cluster/data/canFam1/nib \
      -all-cds-fa results/all_mrna.cds.fa  data/all_mrna.gp >& all_mrna.log
    ~markd/bin/gene-extract -nib-dir  /cluster/data/canFam1/nib \
      -all-cds-fa results/ensGene.cds.fa  data/ensGene.gp >&ensGene.log
    # Files in results/
    #     *.chk - output of the gene-check program, rdb format
    #     *.details - details of problems detected 
    #     *.cds.fa - fasta of CDS taken from genome
    # Columns in *.chk file are
    #     acc - name field from genePred
    #     chr  - genome location from genePred
    #     chrStart
    #     chrEnd
    #     strand
    #     stat - overall status based on other data: ok or err
    #     frame - is the frame annotation sane (mult of 3): ok, bad, or noCDS
    #             if noCDS, other CDS checks are not done.
    #     start - Is there a valid start codon: ok or no
    #     stop - Is there a valid stop codon: ok or no
    #     orfStop - Number of in-frame stop codons
    #     smallGap - Number of small gaps, too small to be introns
    #     unknownSplice - Number of introns with unknown splicing patterns 
    #          (considers the three most common splicing patterns as valid)
    #     causes - list of symbolic names summarizing the failures 


# TWINSCAN FROM BRENT LAB (TODO 8/1/04)
    ssh hgwdev
    mkdir /cluster/data/canFam1/bed/twinscan
    cd /cluster/data/canFam1/bed/twinscan
    wget http://www.cs.wustl.edu/~pflicek/dog/dog.043004.ts.tar.gz
    tar xvzf dog.043004.ts.tar.gz
    ldHgGene -gtf -frame -id -geneName canFam1 twinscan chr*.gtf
    runGeneCheck .
    wget http://www.cs.wustl.edu/~pflicek/dog/dog.043004.ts.ptx.tar.gz
    tar xvzf dog.043004.ts.ptx.tar.gz
    perl -wpe 's/^>(\S+)/>$1.a/' chr*.prot.fa > twinscanPep.fa
    hgPepPred canFam1 generic twinscanPep twinscanPep.fa



# ANDY LAW CPGISSLANDS (TODO 7/16/04 angie)
    # See notes in makeGalGal2.doc.
    ssh kksilo
    mkdir /cluster/data/canFam1/bed/cpgIslandGgfAndy
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    # Use masked sequence since this is a mammal...
    cp /dev/null cpgIslandGgfAndyMasked.bed
    foreach f (../../*/chr*.fa.masked)
      set chr = $f:t:r:r
      echo preproc masked $chr
      /cluster/home/angie/bin/$MACHTYPE/preProcGgfAndy $f > $chr.masked.preproc
      echo running modified on $chr masked
      /cluster/home/angie/ggf-andy-cpg-island.pl $chr.masked.preproc \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyMasked.bed
    end
    # load into database:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyMasked/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > cpgIslandGgfAndyMasked.sql
    hgLoadBed canFam1 cpgIslandGgfAndyMasked -tab -noBin \
      -sqlTable=cpgIslandGgfAndyMasked.sql cpgIslandGgfAndyMasked.bed
    featureBits canFam1 cpgIslandExt
    featureBits canFam1 cpgIslandGgfAndyMasked
    wc -l ../cpgIsland/cpgIsland.bed *bed
    # 6/28/04 -- masking simpleRepeats, and even repeats other than Alu's,
    # might not be the right thing to do (?).  Give it a try with less-masked 
    # sequence.
    ssh kksilo
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    cp /dev/null cpgIslandGgfAndyOnlyRM.bed
    foreach f (../../*/chr*.fa)
      set chr = $f:t:r
      echo preproc, ggf-andy $chr onlyRM
      maskOutFa $f $f.out stdout \
      | /cluster/home/angie/bin/$MACHTYPE/preProcGgfAndy stdin \
      | /cluster/home/angie/ggf-andy-cpg-island.pl \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyOnlyRM.bed
    end
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyOnlyRM/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > /tmp/c.sql
    hgLoadBed canFam1 cpgIslandGgfAndyOnlyRM -tab -noBin -sqlTable=/tmp/c.sql \
      cpgIslandGgfAndyOnlyRM.bed
    featureBits canFam1 cpgIslandGgfAndyOnlyRM.bed
    # OK, just for fun let's run ggf-andy script with TJ parameters!
    ssh kksilo
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    foreach f (../../*/chr*.fa)
      set chr = $f:t:r
      echo running modified w/TJ on $chr
      /cluster/home/angie/ggf-andy-cpg-island.pl \
         -min-length 500 -percent-gc 55 -obs-over-exp 0.65 \
         $chr.preproc \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyTJ.bed
    end
    # load into database:
    ssh hgwdev
    cd /cluster/data/canFam1/bed/cpgIslandGgfAndy
    # this one is a cpgIslandExt but with a different table name:
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyTJ/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > cpgIslandGgfAndyTJ.sql
    hgLoadBed canFam1 cpgIslandGgfAndyTJ -tab -noBin \
      -sqlTable=cpgIslandGgfAndyTJ.sql cpgIslandGgfAndyTJ.bed
    featureBits canFam1 cpgIslandGgfAndyTJ
    wc -l cpgIslandGgfAndyTJ.bed


# RELOAD ENSEMBL GENES (TODO 9/1/04 angie)
    # previous set was sent out to dog group -- pull in the released 
    # version from Ensembl's main site.  Looks like 75 transcripts have 
    # been yanked, will ask Steve Searle and Ewan.  
    mkdir /cluster/data/canFam1/bed/ensembl
    cd /cluster/data/canFam1/bed/ensembl
    # Get the ensembl gene data from 
    # http://www.ensembl.org/Canis_familiaris/martview
    # Follow this sequence through the pages:
    # Page 1) Make sure that the Canis_familiaris choice is selected. Hit next.
    # Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
    # Page 3) Choose the "Structures" box. 
    # Page 4) Choose GTF as the ouput.  choose gzip compression.  hit export.
    # Save as ensembl.gff.gz
    # Add "chr" to front of each line in the gene data gtf file to make 
    # it compatible with our software.
    gunzip -c ensembl.gff.gz \
    | perl -wpe 's/^([0-9]+|[XY]|Un(_random)?)/chr$1/ \
                 || die "Line $. doesnt start with dog chrom:\n$_"' \
    > ensGene.gtf
    ssh hgwdev
    ldHgGene -gtf -genePredExt canFam1 ensGene \
      /cluster/data/canFam1/bed/ensembl/ensGene.gtf

    # ensGtp associates geneId/transcriptId/proteinId for hgPepPred and 
    # hgKnownToSuper.  Use ensMart to create it as above, except:
    # Page 3) Choose the "Features" box. In "Ensembl Attributes", check 
    # Ensembl Gene ID, Ensembl Transcript ID, Ensembl Peptide ID.  
    # Choose Text, tab-separated as the output format.  Result name ensGtp.
    # Save file as ensGtp.txt.gz
    gunzip ensGtp.txt.gz
    hgsql canFam1 < ~/kent/src/hg/lib/ensGtp.sql
    hgsql canFam1 -e 'load data local infile "ensGtp.txt" into table ensGtp'

    # Load Ensembl peptides:
    # Get them from ensembl as above in the gene section except for
    # Page 3) Choose the "Sequences" box. 
    # Page 4) Transcripts/Proteins.  Peptide.  Format = FASTA.
    # Save file as ensemblPep.fa.gz
    gunzip -c ensemblPep.fa.gz \
    | perl -wpe 's/^(>ENSCANT\d+\.\d+).*/$1/' \
    > ensPep.fa
    hgPepPred canFam1 generic ensPep ensPep.fa


