# This file describes how we made the browser database on the Rattus 
# Norvegicus genome, June 2003 update.
#
#	Things got a bit confused because the first Rat for June
#	got started about June 22.  Processing proceeded on that for
#	that week, then it was annnounced that portions of Chr 7 and Chr X
#	were being moved around and a new Rat was released June 29.
#	Also, had some difficulty with RepeatMasker.
#	And, there were cluster difficulties to work around.
#	What happens is that some things may not be exactly where they
#	are claimed to be.  Although I believe everything has been
#	corrected.

DOWNLOAD SEQUENCE (DONE Rnor3.1 - 2003-06-29 - Hiram)

    ssh kkstore
    mkdir /cluster/store3/rn3
    cd /cluster/store3/rn3
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/README
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/conditions_for_use
    #  Three extra files that were not in Rn2:
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bac.clones
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bacfile.gz
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bactigs.bacs
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bactigs.contigs

    # Get BCM's chrom assemblies -- we will assemble our own chr*.fa from 
    # contig fa + agp, and cross-check against this.  
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 X Un)
      mkdir $c
      wget -O $c/chr$c.fa.bcm.gz \
       ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/chromosome/chr$c.fa.gz
      wget -O $c/chr${c}_random.fa.bcm.gz \
 ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/chromosome/chr$c.random.fa.gz
    end

    # Get BCM's contig fa + agp.  We will split into our own conveniently-sized
    # pseudo-contigs, and assemble chrom fa.  
    # These two files are not available in this rat June 2003
    #  But they don't seem to be used anywhere else here anyway
    # wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/bacfile2-1.gz
    # wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/record.dat.gz
    #  Perhaps the extra three files bac.clones, bactigs.bacs and
    #  bactigs.contigs can be used ?
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 X Un)
      wget -O $c/chr$c.agp \
       ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.agp
      wget -O $c/chr$c.contig.fa.gz \
   ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.contig.fa.gz
      wget -O $c/chr${c}_random.agp \
   ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.random.agp
      wget -O $c/chr${c}_random.contig.fa.gz \
   ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.random.contig.fa.gz
    end

BUILD AND CHECK CHROM-LEVEL SEQUENCE (DONE - 2003-06-29 - Hiram)

    # Make chrom fa:
    ssh kkstore
    # The contig sequences are delivered with various upper and lower
    # case.  We need them all in upper case to begin with.  The first
    # line of the file is not a problem, it is already all upper case.
    # According to Kim Worley: <kworley@swan.hgsc.bcm.tmc.edu>
    # "The lowercase letters are regions where Phrap assigns a quality score
    #	of less than 20.  These can safely be ignored."
    foreach c (?{,?})
	set f = $c/chr$c.contig.fa.gz
	set g = $f:r
	echo "${f}"
	zcat ${f} | tr '[a-z]' '[A-Z]' > ${g}
    end
    foreach c (?{,?})
	set f = $c/chr${c}_random.contig.fa.gz
	set g = $f:r
	if (-e ${f}) then
	    echo "${f}"
	    zcat ${f} | tr '[a-z]' '[A-Z]' > ${g}
	endif
    end

    foreach c (?{,?})
      echo "Processing ${c}"
      $HOME/bin/i386/agpToFa -simpleMultiMixed $c/chr$c.agp chr$c \
	$c/chr$c.fa $c/chr$c.contig.fa
      if (-e $c/chr${c}_random.agp) then
        $HOME/bin/i386/agpToFa -simpleMultiMixed $c/chr${c}_random.agp \
	chr${c}_random $c/chr${c}_random.fa $c/chr${c}_random.contig.fa
      endif
      echo "${c} - DONE"
    end
    # Check that the size of each chromosome .fa file is equal to the 
    # last coord of the .agp:
    foreach f ( ?{,?}/*.agp )
      set agpLen = `tail -1 $f | awk '{print $3;}'`
      set g = $f:r
      set faLen = `faSize $g.fa | awk '{print $1;}'`
      if ($agpLen == $faLen) then
        echo "   OK: $f length = $g length = $faLen"
      else
        echo "ERROR:  $f length = $agpLen, but $g length = $faLen"
      endif
    end
    # Check that our assembled chrom fa jive with the BCM chrom fa
    #	You will want a long window size in your terminal to run this
    #	It outputs quite a few lines
    foreach c ( ?{,?} )
      set ucscLen = `faSize $c/chr$c.fa | awk '{print $1;}'`
      set bcmLen  = `gunzip -c $c/chr$c.fa.bcm.gz | faSize stdin \
                       | awk '{print $1;}'`
      if ($ucscLen == $bcmLen) then
        echo "   OK: chr$c.fa length = chr$c.fa.bcm length = $bcmLen"
      else
        echo -n "ERROR:  chr$c.fa length = $ucscLen, but chr$c.fa.bcm length"
	echo " = $bcmLen"
        echo -n "ERROR:  chr$c.fa length = $ucscLen, but chr$c.fa.bcm length"
	echo " = $bcmLen"
      endif
      if (-e $c/chr${c}_random.fa) then
        set ucscLen = `faSize $c/chr${c}_random.fa | awk '{print $1;}'`
        set bcmLen  = `gunzip -c $c/chr${c}_random.fa.bcm.gz | faSize stdin \
                        | awk '{print $1;}'`
        if ($ucscLen == $bcmLen) then
          echo -n "   OK: chr${c}_random.fa length = chr${c}_random.fa.bcm"
	  echo " length = $bcmLen"
        else
          echo -n "ERROR:  chr${c}_random.fa length = $ucscLen, but"
	  echo " chr${c}_random.fa.bcm length = $bcmLen"
        endif
      endif
    end

BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON_BRIDGED CONTIGS
					(DONE - 2003-06-29 - Hiram)

    # This will split the rat sequence into approx. 5 Mbase
    # supercontigs between non-bridged clone contigs and drop the
    # resulting dir structure in /cluster/store3/rn3.  The resulting
    # dir structure will include 1 dir for each chromosome, each of
    # which has a set of subdirectories, one subdir per supercontig.
    ssh kkstore
    cd /cluster/store3/rn3
    foreach c (?{,?})
      echo "Working ${c}"
      cp -p $c/chr$c.agp $c/chr$c.agp.bak
      cp -p $c/chr$c.fa $c/chr$c.fa.bak
      splitFaIntoContigs $c/chr$c.agp $c/chr$c.fa . -nSize=5000000
      if (-e $c/chr${c}_random.fa) then
        cp -p $c/chr${c}_random.agp $c/chr${c}_random.agp.bak
        cp -p $c/chr${c}_random.fa $c/chr${c}_random.fa.bak
        rm -fr ${c}_random
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        rm -fr $c/chr${c}_random_1
        rm -fr $c/chr${c}_random_2
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
      echo "DONE ${c}"
    end
    # Make sure the reconstructed .fa jives with the original:
    #	four lines output for each chrom, long window required to be
    #	able to catch all the output.  Look for non-zero numbers.  The
    #	wc -l should always output zero
    foreach f ( */*.fa.bak )
      echo -n $f:r " "
      diff $f $f:r | wc -l
    end
    # The .agp goes through a slight format change, but make sure it 
    # at least ends up with the same number of lines:
    foreach f ( ?{,?}/*.agp.bak )
      set l1 = `wc -l $f | awk '{print $1}'`
      set l2 = `wc -l $f:r | awk '{print $1}'`
      if ($l1 == $l2) then
        echo "   OK: $f and $f:r have the same #lines"
      else
        echo "ERROR:  $f has $l1 lines, but $f:r has $l2"
      endif
    end
    # Save some space - NO - the *.contig.fa.gz files already existing
    # here are the original downloads.  These non-zipped versions are
    # the translated to upper case versions.
#	foreach c (?{,?})
#	echo $c
#	gzip $c/chr*.contig.fa
#	end
    # Do need to at least move these out of the way because later
    # wild card expansions are looking for things like *.fa and we
    # don't want these in those expansions.
	foreach c (?{,?})
	echo "$c/chr${c}.contig.fa -> $c/chr${c}.contig.fa.UC"
	mv $c/chr${c}_random.contig.fa $c/chr${c}_random.contig.fa.UC
	mv $c/chr${c}.contig.fa $c/chr${c}.contig.fa.UC
	end
    # This rm may be a good thing to do.  But later, after repeat
    # masking is done and thus the soft masked results can be compared
    # with the *.bak originals.
#	rm */*.bak

COPY OVER JKSTUFF SCRIPTS DIRECTORY (DONE - 2003-06-29 - Hiram)
	# Some of these scripts are being edited after they were
	#	copied to here.  Some cases of binaries in
	#	~kent/bin/i386 need to be changed either to
	#	/cluster/bin/i386 or ~hiram/bin/i386 depending upon what
	#	was being fixed as all this proceeded.
	#	The "real" place should be /cluster/bin/i386 but before
	#	we go that route, we need to have our build processes
	#	working properly to keep that bin up to date.

    ssh kkstore
    ln -s /cluster/store3/rn3 ~/rn3
    rm -f ~/lastRn
    ln -s /cluster/store4/rn2 ~/lastRn
    cd ~/rn3
    cp -Rp ~/lastRn/jkStuff .
    rm jkStuff/*.{out,lst,lft} jkStuff/*~


CREATING DATABASE (DONE - 2003-06-23 - Hiram)

    # Create the database.
    ssh hgwdev
    echo 'create database rn3' | hgsql ''
    # make a semi-permanent read-only alias:
    #	(I haven't noticed any use of this ?  Useless ? - Hiram)
    alias rn3 "mysql -u hguser -phguserstuff -A rn3"
    # Use df to ake sure there is at least 5 gig free on 
    #		hgwdev:/var/lib/mysql
    # [hiram@hgwdev /cluster/home/hiram] df -h /var/lib/mysql
    # Filesystem            Size  Used Avail Use% Mounted on
    # /dev/sda1             472G  384G   64G  86% /var/lib/mysql


CREATING GRP TABLE FOR TRACK GROUPING (DONE - 2003-06-23 - Hiram)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from rn1.grp" \
      | hgsql rn3


REPEAT MASKING (RUNNING - 2003-06-30 - Hiram)
   Split contigs, run RepeatMasker, lift results
   Notes: 
   * If there is a new version of RepeatMasker, build it and ask the admins 
     to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
   * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
     RepeatMasker runs manageable on the cluster ==> results need lifting.
   * For the NCBI assembly we repeat mask on the sensitive mode setting
     (RepeatMasker -m -s)

    #- Split contigs into 500kb chunks:
    ssh kkstore
    cd ~/rn3
    foreach d ( */chr*_?{,?} )
	cd $d
	echo "splitting $d"
	set contig = $d:t
	faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
	    -maxN=500000
	cd ../..
    end

    #- Make the run directory and job list:
    cd ~/rn3
    cat << '_EOF_' > jkStuff/RMRat
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/rn3/$2
/bin/cp $2 /tmp/rn3/$2/
cd /tmp/rn3/$2
/cluster/bluearc/RepeatMasker030619/RepeatMasker -ali -s -spec rat -comp mouse $2
popd
/bin/cp /tmp/rn3/$2/$2.out ./
if (-e /tmp/rn3/$2/$2.align) /bin/cp /tmp/rn3/$2/$2.align ./
if (-e /tmp/rn3/$2/$2.tbl) /bin/cp /tmp/rn3/$2/$2.tbl ./
if (-e /tmp/rn3/$2/$2.cat) /bin/cp /tmp/rn3/$2/$2.cat ./
/bin/rm -fr /tmp/rn3/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn3/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn3
'_EOF_'
    chmod +x jkStuff/RMRat
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
    foreach d ( ?{,?}/chr*_?{,?} )
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/store3/rn3/jkStuff/RMRat \
                 /cluster/store3/rn3/$d $f \
               '{'check out line+ /cluster/store3/rn3/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
    end

    #- Do the run
    ssh kk
    cd ~/rn3/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
# Completed: 6209 of 6209 jobs
# CPU time in finished jobs:   37009055s  616817.58m 10280.29h  428.35d  1.174 y
# IO & Wait Time:                 96849s    1614.15m    26.90h    1.12d  0.003 y
# Average job time:                5976s      99.60m     1.66h    0.07d
# Longest job:                    16048s     267.47m     4.46h    0.19d
# Submission to last job:         49589s     826.48m    13.77h    0.57d

        #- Lift up the split-contig .out's to contig-level .out's
	ssh kkstore
    cd ~/rn3
        foreach d ( ?{,?}/chr*_?{,?} )
          cd $d
          set contig = $d:t
          /cluster/home/hiram/bin/i386/liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
          cd ../..
        end

        #- Lift up the contig-level .out's to chr-level
        cd ~/rn3
        ./jkStuff/liftOut5.sh

        # soft-mask contig .fa's with .out's
        foreach i (?{,?})
            foreach j ($i/chr${i}_?{,?}/chr${i}_?{,?}.fa \
                       $i/chr${i}_random_?{,?}/chr${i}_random_?{,?}.fa)
                /cluster/home/hiram/bin/i386/maskOutFa $j $j.out $j -soft
            end
            echo done $i
        end
	# You will see a few WARNING lines from maskOutFa.  This is a
	# a good sign.  Much better than when maskOutFa used to exit.
	# With the fix, everything is getting masked properly.
	# Fixing a temporary glitch in repeat masker.  This hasn't
	# affected anything above, but it will change the result of
	# the load below.  Since the repeat masker run above, the
	# processrepeats script of RepeatMasker has been fixed.  This
	# would not be necessary after that fix.
        foreach i (?{,?})
	    /cluster/bluearc/RepeatMasker030619/MakeRMoutSane.pl ${i}/*.fa.out
		foreach k ($i/chr${i}_?{,?}/chr${i}_?{,?}.fa.out \
			$i/chr${i}_random_?{,?}/chr${i}_random_?{,?}.fa.out)
	    /cluster/bluearc/RepeatMasker030619/MakeRMoutSane.pl ${k}
		end
	end

        #- Load the .out files into the database with:
        ssh hgwdev
	cd ~/rn3
        hgLoadOut rn3 ?{,?}/*.fa.out

MAKE LIFTALL.LFT (DONE - 2003-07-01 - Hiram)

    ssh kkstore
    cd ~/rn3
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft
    cp -p jkStuff/liftAll.lft /cluster/bluearc/rat/rn3

VERIFY REPEATMASKER RESULTS (DONE - 2003-06-24 - Hiram)

    # Something about this is too early at this point.  It errors with:
    #	Can't start query:
    #	select chrom,size,fileName from chromInfo
    #	mySQL error 1146: Table 'rn3.chromInfo' doesn't exist
    # you have to wait until the nibs have been loaded below and the
    # chrom.sizes works

    # Run featureBits on rn3 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits rn3 rmsk
    #   1117328265 bases of 2571104688 (43.457%) in intersection
    featureBits rn1 rmsk
    #	1081814344 bases of 2555848684 (42.327%) in intersection
    featureBits rn2 rmsk
    #	1100534407 bases of 2495551408 (44.100%) in intersection


STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE - 2003-07-02 - Hiram)

    # Make (unmasked) nibs
    ssh kkstore
    cd ~/rn3
    mkdir nibNotMasked
    foreach i (?{,?})
	cd $i
	foreach j ( chr?{,?}{,_random}.fa )
	echo "nibbing $j"
	~/bin/i386/faToNib $j ../nibNotMasked/$j:r.nib
	end
	cd ..
    end

    # Make symbolic links from /gbdb/rn3/nib to the real nibs.
    # It is unclear to me what kind of nibs these links are supposed to
    # point to.  Below, after the soft masked nibs are created, I am
    # going to reset these links to point to the soft masked nibs.
    ssh hgwdev
    mkdir -p /gbdb/rn3/nib
    foreach f (/cluster/store3/rn3/nibNotMasked/chr*.nib)
      ln -s $f /gbdb/rn3/nib
    end
    # Load /gbdb/rn3/nib paths into database and save size info.
     ssh hgwdev
     hgsql rn3  < ~/kent/src/hg/lib/chromInfo.sql
     cd ~/rn3
     hgNibSeq -preMadeNib rn3 /gbdb/rn3/nib ?{,?}/chr?{,?}{,_random}.fa
    #	2835152425 total bases
     echo "select chrom,size from chromInfo" | hgsql -N rn3 > chrom.sizes
    # take a look at chrom.sizes, should be 44 lines and reasonable
    # numbers
    wc chrom.sizes
    #	44      88     778 chrom.sizes


GOLD AND GAP TRACKS (DONE - 2003-07-02 - Hiram)
    ssh hgwdev
    cd ~/rn3
    hgGoldGapGl -noGl rn3 /cluster/store3/rn3 .


MAKE GCPERCENT (DONE - 2003-07-02 - Hiram)
     ssh hgwdev
     mkdir -p /cluster/store3/rn3/bed/gcPercent
     cd /cluster/store3/rn3/bed/gcPercent
     hgsql rn3  < ~/kent/src/hg/lib/gcPercent.sql
     hgGcPercent rn3 ../../nibNotMasked


MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR RN3 (DONE - 2003-06-24 - Hiram)
    # Enter rn3 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb values("rn3", "Jun 2003", \
        "/gbdb/rn3/nib", "Rat", "Espn", 1, \
        30, "Rat");' | hgsql -h genome-testdb hgcentraltest
    # Temporary entry until mrna tables come along.  Approximate
    # calculated position the same as rn2
    # Note: for next assembly, set scientificName column to "Rattus norvegicus"
    echo 'insert into dbDb values("rn3", "Jun 2003", \
        "/gbdb/rn3/nib", "Rat", "chr5:168054448-168086858", 1, \
        30, "Rat");' | hgsql -h genome-testdb hgcentraltest
    # since Espn is the specified position here, this default position
    # will not function as the make trackDb is done next since there are
    # no tables in which to look up Espn.  But you can run the browser
    # if you enter actual coodinates, e.g. chr1:1-1000, etc ...
    #	Espn in Jan 2003 rat is: chr5:186572879-186605289
    #	The new rat is much shorter for chr5
    #  If you need to delete this dbDb entry to rewrite it:
        echo 'delete from dbDb where name="rn3";' \
        | hgsql -h genome-testdb hgcentraltest


    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add rn3 in all the right places and do
    make update
    make alpha
    cvs commit makefile


MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR RN3 (TO DO)
    ssh hgwdev
    echo 'insert into blatServers values("rn3", "blat10", "17778", "1"); \
          insert into blatServers values("rn3", "blat10", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


SIMPLE REPEAT TRACK (DONE - 2003-07-01 - Hiram)
    #  Need to be careful with this one on the cluster.  This trf
    #  thing does a lot of I/O on the input and output file.
    #  Place the splits on /cluster/bluearc for cluster access
    ssh kkstore
    mkdir -p /cluster/bluearc/rat/rn3
    cd /cluster/store3/rn3/
    ls ?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa  \
	| tar -c -T - -f - | (cd /cluster/bluearc/rat/rn3.1.split; tar xfBp -)'

    # now, a safe cluster job to trf mask
    ssh kk
    mkdir ~/rn3/bed/simpleRepeat
    cd ~/rn3/bed/simpleRepeat
    mkdir trf
 ls /cluster/bluearc/rat/rn3.1.split/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa \
	> genome.lst

    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'

    gensub2 genome.lst single gsub spec
    para create spec
    para try
    para check
    para push
    ... etc ...
Completed: 591 of 591 jobs
CPU time in finished jobs:      27837s     463.95m     7.73h    0.32d  0.001 y
IO & Wait Time:                 13105s     218.41m     3.64h    0.15d  0.000 y
Average job time:                  69s       1.15m     0.02h    0.00d
Longest job:                      205s       3.42m     0.06h    0.00d
Submission to last job:           263s       4.38m     0.07h    0.00d

    ssh kkstore
    cd ~/rn3/bed/simpleRepeat
    liftUp simpleRepeat.bed ~/rn3/jkStuff/liftAll.lft warn trf/*.bed

    # Load this into the database as so
    ssh hgwdev
    cd ~/rn3/bed/simpleRepeat
    hgLoadBed rn3 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql

PROCESS SIMPLE REPEATS INTO MASK (DONE - 2003-07-02 - Hiram)

    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kkstore
    cd ~/rn3/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd ~/rn3
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
        $c/lift/ordered.lst > $c/lift/oTrf.lst
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
      endif
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
        jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      if (-e $c/lift/rTrf.lst) then
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end


MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
			(DONE - 2003-07-02 - Hiram)

    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above.
    ssh kkstore
    cd ~/rn3
    #- Soft-mask (lower-case) the contig and chr .fa's
    ./jkStuff/makeFaMasked.sh
    # You will see warnings from the above command, these are OK:
    # WARNING: negative rEnd: -203 chr1:36149039-36149198 L1M3c
    # WARNING: negative rEnd: -14 chr1:185432802-185432864 PB1D10
    #- Make hard-masked .fa.masked files as well:
    ./jkStuff/makeHardMasked.sh
    #- Rebuild the nib, mixedNib, maskedNib files:
    ./jkStuff/makeNib.sh
    # Copy the masked contig fa to /scratch:
    ssh kkstore
    rm -rf /cluster/bluearc/rat/rn3/trfFa
    mkdir -p /cluster/bluearc/rat/rn3/trfFa
    cp -p ~/rn3/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa \
	/cluster/bluearc/rat/rn3/trfFa

RESET NIB POINTERS TO softNib (DONE - 2003-07-02 - Hiram)

    # As mentioned above the first time this was done, I don't know if
    # this needs to done to reset the links, but I'm going to do it.
    # In fact, if you have been watching carefully, I am actually
    # changing the names of where things are.  This used to be
    # nibNotMasked, now it is softNib which is both masks.
    ssh hgwdev
    cd /gbdb/rn3/nib
    rm -f *
    foreach f (/cluster/store3/rn3/softNib/chr*.nib)
      ln -s $f /gbdb/rn3/nib
    end
    #  I wonder if this needs to be run again ?  I'm going to do it
    #	anyway.
    # Load /gbdb/rn3/nib paths into database and save size info.
     ssh hgwdev
     cd ~/rn3
     hgNibSeq -preMadeNib rn3 /gbdb/rn3/nib ?{,?}/chr?{,?}{,_random}.fa
    #	2835152425 total bases
     echo "select chrom,size from chromInfo" | hgsql -N rn3 > chrom.sizes
    # take a look at chrom.sizes, should be 44 lines and reasonable
    # numbers
    wc chrom.sizes
    #	44      88     778 chrom.sizes

MAKE DOWNLOADABLE SEQUENCE FILES (TO DO)
    ssh kkstore
    cd ~/rn3
    #- Build the .zip files
    ./jkStuff/zipAll.sh |& tee zipAll.log
    mkdir zip
    mv *.zip* zip
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd ~/rn3/zip
    ../jkStuff/cpToWeb.sh
    cd /usr/local/apache/htdocs/goldenPath/rnJun2003
    #- Take a look at bigZips/* and chromosomes/*, update their README.txt's

    # Then make the upstream sequence files.
    cd bigZips
    featureBits rn3 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits rn3 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits rn3 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa


PREPARE CLUSTER FOR BLASTZ RUN (DONE - 2003-06-27 - Hiram)
    # This needs to be done after trf-masking and nib generation.
    ssh kkstore
    # Extract lineage-specific repeats using Arian Smit's script:
    mkdir -p ~/rn3/bed/linSpecRep
    cd ~/rn3/bed/linSpecRep
    foreach f (~/rn3/*/chr*.out)
        ln -sf $f .
    end
    /cluster/bin/scripts/rodentSpecificRepeats.pl *.out
    /cluster/bin/scripts/perl-rename 's/(\.fa|\.nib)//' *.out.*spec
    /cluster/bin/scripts/perl-rename 's/\.(rod|prim)spec/.spec/' *.out.*spec
    rm *.out
    cd ~/rn3/bed
    rm -rf /cluster/bluearc/rat/rn3/linSpecRep
    #  This dir already exists from above
    # mkdir -p /cluster/bluearc/rat/rn3
    cp -Rp linSpecRep /cluster/bluearc/rat/rn3
    # RepeatMasker .out:
    cd ~/rn3
    rm -rf /cluster/bluearc/rat/rn3/rmsk
    mkdir -p /cluster/bluearc/rat/rn3/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /cluster/bluearc/rat/rn3/rmsk
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /cluster/bluearc/rat/rn3/softNib
    mkdir -p /cluster/bluearc/rat/rn3/softNib
    cp -p softNib/chr*.nib /cluster/bluearc/rat/rn3/softNib

    # Jim's comments Feb 12 '03 about the order in which to run blastz:
    # In general we should do
    # 1) hg/mm
    # 2) mm/rn
    # 3) rn/hg
    # 4) hg/hg
    # 5) mm/mm
    # 6) rn/rn
    # There is now an 'axtSwap' program that might let us
    # get out of having to run the inverse of 1,2 & 3,  though
    # 2 in particular is so fast perhaps it's just as well to
    # do the inverse explicitly.

AUTO UPDATE GENBANK MRNA RUN  (DONE - 2003-07-07 - Hiram)

    ssh eieio
    cd /cluster/store5/genbank
    set db = rn3
    set nibGlob = '/cluster/bluearc/rat/rn3/bothMaskedNibs/chr*.nib'
    set liftFile = /cluster/bluearc/rat/rn3/liftAll.lft
    # the iservers were acting up, the following uses the bluearc instead
    # make sure 'ssh localhost' works before running this:
    nice bin/gbAlignStep -verbose=1 -initial -iserver=localhost \
	-clusterdir=/cluster/bluearc/genbank/work \
	-srcDb=genbank $db "$nibGlob" $liftFile &
    # This job took almost two days
# Checking finished jobsCompleted: 216306 of 216306 jobs
# CPU time in finished jobs:   74560544s 1242675.73m 20711.26h  862.97d  2.364 y
# IO & Wait Time:               1371840s   22864.00m   381.07h   15.88d  0.044 y
# Average job time:                 351s       5.85m     0.10h    0.00d
# Longest job:                     2478s      41.30m     0.69h    0.03d
# Submission to last job:        151934s    2532.23m    42.20h    1.76d

    # To watch the progress of your cluster job, go to machine kk and
    # cd /cluster/store5/genbank/work/initial.rn3/align
    # where the batch file is.  You can now do normal parasol checking
    # operations.  Beware of "para check" it can take quite a bit of time
    # if your batch job is very large.  'parasol list batches' or
    # 'parasol list users' may be quicker to take a look at status.

    #  After that is finished successfully, load the mRNAs:
    #  The drop and load is faster if tables have been loaded before.
    ssh hgwdev
    cd /cluster/store5/genbank
    ./bin/i386/gbLoadRna -drop  rn3
    nice ./bin/gbDbLoadStep -verbose=1 -initialLoad rn3
    # This load took about 7 hours

CREATE REFSEQ GENES TRACK (TO DO)
    # Load the refSeq mRNA
    ssh hgwdev
    mkdir -p /gbdb/rn3/mrna.133
    ln -s /cluster/store2/mrna.133/refSeq/org/Rattus_norvegicus/refSeq.fa \
      /gbdb/rn3/mrna.133
    hgLoadRna new rn3
    hgLoadRna add -type=refSeq rn3 /gbdb/rn3/mrna.133/refSeq.fa \
      /cluster/store2/mrna.133/refSeq/org/Rattus_norvegicus/refSeq.ra

    # Produce refGene, refPep, refMrna, and refLink tables as so:
    # Get the proteins:
    ssh kkstore
    cd ~/rn3/bed/refSeq
    wget ftp://ftp.ncbi.nih.gov/refseq/R_norvegicus/mRNA_Prot/rat.faa.gz
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/loc2ref
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/mim2loc
    gunzip rat.faa.gz
    ssh hgwdev
    cd ~/rn3/bed/refSeq
    hgRefSeqMrna rn3 \
      /gbdb/rn3/mrna.133/refSeq.fa \
      /cluster/store2/mrna.133/refSeq/org/Rattus_norvegicus/refSeq.ra \
      all_refSeq.psl loc2ref rat.faa mim2loc
    # Don't worry about the "No gene name" errors

    # Add RefSeq status info
    hgRefSeqStatus -rat rn3 loc2ref


REFFLAT (TO DO)
    # create precomputed join of refFlat and refGene:
    echo 'CREATE TABLE refFlat (KEY geneName (geneName), KEY name (name), KEY chrom (chrom)) SELECT refLink.name as geneName, refGene.* FROM refLink,refGene WHERE refLink.mrnaAcc = refGene.name' | hgsql rn3


LOAD MRNA DATA (TO DO)
    ssh hgwdev
    ln -s /cluster/store2/mrna.133/org/Rattus_norvegicus/mrna.fa /gbdb/rn3/mrna.133
    ln -s /cluster/store2/mrna.133/org/Rattus_norvegicus/est.fa /gbdb/rn3/mrna.133
    hgLoadRna add -type=mRNA rn3 /gbdb/rn3/mrna.133/mrna.fa \
      /cluster/store2/mrna.133/org/Rattus_norvegicus/mrna.ra
    hgLoadRna add -type=EST rn3 /gbdb/rn3/mrna.133/est.fa \
      /cluster/store2/mrna.133/org/Rattus_norvegicus/est.ra


PRODUCING ESTORIENTINFO TABLE (TO DO)

This table is needed for proper orientation of ESTs in the
browser.  Many will appear on the wrong strand without it.
This involves a cluster run.  First load the EST psl files
as so:
     ssh kkstore
     cd ~/rn3/bed/est
     pslSortAcc nohead contigs /cluster/store2/temp contig.psl
     ssh kkstore
     mkdir /mnt/scratch/hg/rn3/est
     cd ~/rn3/bed/est
     cp -r contigs /mnt/scratch/hg/rn3/est

Wait for these to finish.
     mkdir -p ~/rn3/bed/estOrientInfo
     cd ~/rn3/bed/estOrientInfo
     mkdir ei
     ls -1S /mnt/scratch/hg/rn3/est/contigs/* > psl.lst
     echo placeholder > single
     cp ~/rn1/bed/estOrientInfo/gsub .
Update gsub to refer to rat contig sequence currently on
/mnt//scratch/hg/rn3/trfFa, and rat ESTs on /mnt/scratch/hg/rn3/est/contigs
and the rat est in /scratch/hg/mrna.133/Rattus_norvegicus/est.fa.
     gensub2 psl.lst single gsub spec

     ssh kk
     para create spec
Then run the  job on the cluster
     cd ~/rn3/bed/estOrientInfo
     para try
     sleep 60
     para check
If things look good
     para push
Wait for this to finish then
     liftUp estOrientInfo.bed ../../jkStuff/liftAll.lft warn ei/*.tab
Load them into database as so:
     ssh hgwdev
     cd ~/rn3/bed/estOrientInfo
     hgLoadBed rn3 estOrientInfo estOrientInfo.bed \
       -sqlTable=$HOME/kent/src/hg/lib/estOrientInfo.sql
     
PRODUCING MRNAORIENTINFO TABLE (TO DO)
    ssh kkstore
    cd ~/rn3/bed/mrna
    pslSortAcc nohead contig /cluster/store2/temp contig.psl
    ssh kkstore
    mkdir /mnt/scratch/hg/rn3/mrna
    cp -r ~/rn3/bed/mrna/contig /mnt/scratch/hg/rn3/mrna
    mkdir -p ~/rn3/bed/mrnaOrientInfo/oi
    cd ~/rn3/bed/mrnaOrientInfo
    ls -1S /mnt/scratch/hg/rn3/mrna/contig/* > psl.lst
    cp ~/lastRn/bed/mrnaOrientInfo/gsub .
    echo placeholder > single
    gensub2 psl.lst single gsub spec

    ssh kk
    cd ~/rn3/bed/mrnaOrientInfo
    para create spec
    para try, para check, para push, para check,...
    liftUp mrnaOrientInfo.bed ../../jkStuff/liftAll.lft warn oi/*.tab

    ssh hgwdev
    cd ~/rn3/bed/mrnaOrientInfo
    hgLoadBed rn3 mrnaOrientInfo mrnaOrientInfo.bed \
       -sqlTable=$HOME/kent/src/hg/lib/mrnaOrientInfo.sql


CREATE RNACLUSTER TABLE (TO DO)
    # Make sure that refSeqAli, estOrientInfo and mrnaOrientInfo tables are 
    # made already (see above).
    ssh hgwdev
    mkdir -p ~/rn3/bed/rnaCluster/chrom
    cd ~/rn3/bed/rnaCluster
    foreach i (~/rn3/?{,?})
      foreach f ($i/chr*.fa)
        set c = $f:t:r
        clusterRna rn3 /dev/null chrom/$c.bed -chrom=$c
        echo done $c
      end
    end
    hgLoadBed rn3 rnaCluster chrom/*.bed


PRODUCING GENSCAN PREDICTIONS (TO DO)
    
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. (genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    mkdir -p ~/rn3/bed/genscan
    cd ~/rn3/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/store3/rn3/?{,?}/chr*/chr?{,?}{,_random}_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/home/hiram/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push

    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    # chr14_21, chr16_4
    
    # Convert these to chromosome level files as so:
    ssh kkstore
    cd ~/rn3/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/rn3/bed/genscan
    ldHgGene rn3 genscan genscan.gtf
    hgPepPred rn3 generic genscanPep genscan.pep
    hgLoadBed rn3 genscanSubopt genscanSubopt.bed


SWAPPING HUMAN-RAT BLASTZ ALIGNMENTS TO RAT-HUMAN: (TO DO)

    ssh kkstore
    # Human-rat alignments were already run and processed into axt.  
    # Swap target and query to get rat-human alignments.  
    set aliDir = "/cluster/store3/gs.14/build31/bed/blastz.rn3.2003-03-13-ASH"
    set revAliDir = "/cluster/store3/rn3/bed/blastz.hg13.2003-03-13-SWAP"
    mkdir $revAliDir
    cd $revAliDir
    # axtBest will need .len files - copy those, swap S1<->S2
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    # Swap target and query coords, then re-apportion alignments so that 
    # unsorted/chrN.axt has all the alignments with chrN as target.
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSplitByTarget stdin unsorted
    # Sorted the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    rm -r unsorted
    # Don't bother creating psl for these unfiltered alignments -- but 
    # tell Jim so he can do chaining/netting.


MAKING THE BLASTZBESTHUMAN TRACK FROM PENN STATE RN3 AXT FILES (TO DO)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store3/rn3/bed/blastz.hg13.2003-03-13-SWAP"
    set seq1_dir="/cluster/store3/rn3/mixedNib/"
    set seq2_dir="/cluster/store3/gs.14/build31/mixedNib/"
    set tbl="blastzBestHg13"
    cd $base
    mkdir -p axtBest pslBest
    foreach f (axtChrom/chr*.axt)
      set chr=$f:t:r
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    # If some chromosome's alignments were too big and caused axtSort to 
    # run out of memory, split it in half (by 4-line axt records) and 
    # run axtBest just on the halves.  
    foreach chr (chr1)
      echo two-pass axtBesting $chr
      set len = `wc -l < axtChrom/$chr.axt`
      set numRec = `expr $len / 4`
      if (($numRec * 4) != $len) then
        echo "Uh-oh: length of axtChrom/$chr.axt is $len, not a multiple of 4"
        break
      endif
      set halfRec   = `expr $numRec / 2`
      set halfLen   = `expr $halfRec \* 4`
      set halfLenp1 = `expr $halfLen + 1`
      head -$halfLen   axtChrom/$chr.axt > axtChrom/$chr.h0.axt
      tail +$halfLenp1 axtChrom/$chr.axt > axtChrom/$chr.h1.axt
      axtBest axtChrom/$chr.h0.axt $chr axtChrom/$chr.h0.axtBest -minScore=300
      axtBest axtChrom/$chr.h1.axt $chr axtChrom/$chr.h1.axtBest -minScore=300
      cat axtChrom/$chr.h{0,1}.axtBest > axtBest/$chr.axt
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
      rm axtChrom/$chr.h*
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store3/rn3/bed/blastz.hg13.2003-03-13-SWAP"
     set tbl="blastzBestHg13"
     cd $base/pslBest
     hgLoadPsl rn3 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/rn3/axtBestHg13
     cd /gbdb/rn3/axtBestHg13
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/rn3/axtBestHg13/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('hg13','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql rn3 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql rn3 < axtInfoInserts.sql

MAKING THE HUMAN AXTTIGHT FROM AXTBEST (TO DO)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/rn3/bed/blastz.hg13.2003-03-13-SWAP/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightHg13.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/rn3/bed/blastz.hg13.2003-03-13-SWAP/pslTight
    hgLoadPsl rn3 chr*_blastzTightHg13.psl


TWINSCAN GENE PREDICTIONS (TO DO)

    mkdir -p ~/rn3/bed/twinscan
    cd ~/rn3/bed/twinscan
    wget http://genome.cse.wustl.edu/~bio/rat/Jan03/rat_Jan03_03-26-03.tgz
    gunzip -c *.tgz | tar xvf -
    rm -r chr_tx
    # clean up chrom field of GTF files
    foreach f (chr_gtf/chr*.gtf)
      set chr = $f:t:r
      sed -e "s/^[a-zA-Z0-9]*/$chr/" $f > chr_gtf/$chr-fixed.gtf
    end
    # pare down protein FASTA header to id and add missing .a:
    foreach f (chr_ptx/chr*.ptx)
      set chr = $f:t:r
      perl -wpe 's/^\>.*\s+source_id\s*\=\s*(\S+).*$/\>$1.a/;' < \
        chr_ptx/$chr.ptx > chr_ptx/$chr-fixed.fa
    end
    ldHgGene rn3 twinscan chr_gtf/chr*-fixed.gtf -exon=CDS
    hgPepPred rn3 generic twinscanPep chr_ptx/chr*-fixed.fa


PRODUCING CROSS_SPECIES mRNA ALIGMENTS (TO DO)

    # Here you align non-mouse mRNAs against the masked genome on the
    # cluster you set up during the previous step.
    # Make sure that gbpri, gbmam, gbrod, and gbvert are downloaded from 
    # Genbank into /cluster/store2/genbank.133 and unpacked by organism into 
    # /cluster/store2/mrna.133/org. 

    # Set up cluster run more or less as so:
      ssh kk
      cd ~/rn3/bed
      mkdir xenoMrna
      cd xenoMrna
      ls -1S /scratch/hg/rn3/trfFa/* > genome.lst
      cp -R /cluster/store2/mrna.133/org /mnt/scratch/hg/mrna.133
    # The below ls command fails when you have too many files so skip it and 
    # instead run the find command after it.
    #      ls -1S /mnt/scratch/hg/mrna.133/org/*/mrna.fa > allMrna.lst
      find /mnt/scratch/hg/mrna.133/org -name mrna.fa -ls \
        | awk '{print $7,$11}' | grep -v /Rattus_norvegicus/ \
        | sort -gr | awk '{print $2}' \
        >  allMrna.lst
    # Put the first line of allMrna.lst into 1.org, the second line into 
    # 2.org, and so forth:
      foreach n (1 2 3 4 5 6)
        head -$n allMrna.lst | tail -1 > $n.org
      end
    # After the 6th line just leave the rest in 7.org.
      tail +7 allMrna.lst > 7.org
    # Then
      ls -1 *.org > mrna.lst
      cp ~/lastRn/bed/xenoMrna/gsub .
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      para try
      para check
    # If all looks well do
      para push

    # Sort xeno mRNA alignments as so:
       ssh kkstore
       cd ~/rn3/bed/xenoMrna
       pslSort dirs raw.psl /cluster/store2/temp psl
       pslReps raw.psl cooked.psl /dev/null -minAli=0.25
       liftUp chrom.psl ../../jkStuff/liftAll.lft warn cooked.psl
       pslSortAcc nohead chrom /cluster/store2/temp chrom.psl
       pslCat -dir chrom > xenoMrna.psl
       rm -r chrom raw.psl cooked.psl chrom.psl

    # Load into database as so:
       ssh hgwdev
       cd ~/rn3/bed/xenoMrna
       hgLoadPsl rn3 xenoMrna.psl -tNameIx

    # Make the xenoRna file
       # Make a /gbdb symlink for the .fa (not .ra)
       cd /gbdb/rn3/mrna.133
       ln -s /cluster/store2/mrna.133/ratXenoRna.fa ratXenoRna.fa
       hgLoadRna add -type=xenoRna rn3 /gbdb/rn3/mrna.133/ratXenoRna.fa \
         /cluster/store2/mrna.133/ratXenoRna.ra


PRODUCING TETRAODON FISH ALIGNMENTS (TO DO)

o - Download sequence from ... and put it on the cluster local disk
    at
       /scratch/hg/fish
o - Do fish/rat alignments.
       ssh kk
       cd ~/rn3/bed
       mkdir blatFish
       cd blatFish
       mkdir psl
       ls -1S /scratch/hg/fish/* > fish.lst
       ls -1S /scratch/hg/rn3/trfFa/* > rat.lst
       cp ~/lastRn/blatFish/gsub .
       gensub2 rat.lst fish.lst gsub spec
       para create spec
       para try
     Make sure jobs are going ok with para check.  Then
       para push
     wait about 2 hours and do another
       para push
     do para checks and if necessary para pushes until done
     or use para shove.
o - Sort alignments as so 
       pslCat -dir psl | liftUp -type=.psl stdout ~/rn3/jkStuff/liftAll.lft warn stdin | pslSortAcc nohead chrom /cluster/store2/temp stdin
o - Copy to hgwdev:/scratch.  Rename to correspond with tables as so and 
    load into database:
       ssh hgwdev
       cd ~/rn3/bed/blatFish/chrom
       foreach i (chr?{,?}{,_random}.psl)
           set r = $i:r
           mv $i ${r}_blatFish.psl
       end
       hgLoadPsl rn3 *.psl
       hgLoadRna addSeq rn3 /cluster/store2/fish/seq15jun2001/*.fa

# PRODUCING SQUIRT ALIGNMENTS  (TO DO)
    ssh kkstore
    mkdir -p ~/rn3/bed/blatCi1
    cd ~/rn3/bed/blatCi1
    ls -1S /iscratch/i/squirt/ci1/queryFa/*.fa > squirt.lst
    ls -1S /scratch/hg/rn3/trfFa/* > rat.lst

    rm -rf psl
    foreach ctg (`cat rat.lst`)
      mkdir -p psl/$ctg:t:r
    end
    # get gsub2D from someplace
    gensub2 rat.lst squirt.lst gsub2D spec

    ssh kk
    cd ~/rn3/bed/blatCi1
    para create spec
    ....
    # When cluster run is done, sort alignments:
    ssh kkstore
    cd ~/rn3/bed/blatCi1
    mkdir /tmp/$LOGNAME
    pslSort dirs raw.psl /tmp/$LOGNAME psl/*
    pslReps raw.psl cooked.psl /dev/null -minAli=0.05
    liftUp -nohead lifted.psl ../../jkStuff/liftAll.lft warn cooked.psl
    pslSortAcc nohead chrom /tmp/$LOGNAME lifted.psl

    # Rename to correspond with tables as so and load into database:
    ssh hgwdev
    cd ~/rn3/bed/blatCi1/chrom
    rm -f chr*_blatCi1.psl
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        mv $i ${r}_blatCi1.psl
    end
    hgLoadPsl rn3 *.psl

    # Make squirt /gbdb/ symlink
    mkdir /gbdb/rn3/squirtSeq
    cd /gbdb/rn3/squirtSeq
    ln -s /cluster/store5/squirt/ci1/ciona.rm.fasta

PRODUCING FUGU FISH ALIGNMENTS (TO DO)

    # (Already done, for mm2:)
    # Download sequence to /cluster/store3/fuguSeq from ... and put it on the 
    # cluster local disk at /scratch/hg/fugu on kkstore.
    # Sequence was downloaded from:
    # ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_mask.fasta.Z
    # ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_prot.fasta.Z
    # mkdir split2.5Mb; cd split2.5Mb;
    # faSplit about ../fugu_v3_mask.fasta 2500000 fuguSplit

    ssh kkr1u00
    rm -rf /iscratch/i/fugu
    mkdir /iscratch/i/fugu
    cp -p /cluster/store3/fuguSeq/split2.5Mb/*.fa /iscratch/i/fugu
    ~kent/bin/iSync

    ssh kk
    mkdir ~/rn3/bed/blatFugu
    cd ~/rn3/bed/blatFugu
    ls -1S /iscratch/i/fugu/* > fugu.lst
    ls -1S /scratch/hg/rn3/trfFa/* > rat.lst
    cp ~/lastRn/bed/blatFugu/gsub .
    mkdir psl
    foreach f (~/rn3/?{,?}/chr*/chr?{,?}{,_random}_?{,?}.fa)
      set c=$f:t:r
      mkdir psl/$c
    end
    gensub2 rat.lst fugu.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check
    # Sort alignments:
    ssh kkstore
    cd ~/rn3/bed/blatFugu
    pslCat -dir psl/* \
      | liftUp -type=.psl stdout ~/rn3/jkStuff/liftAll.lft warn stdin \
      | pslSortAcc nohead chrom /cluster/store2/temp stdin

    # load into database:
    ssh hgwdev
    cd ~/rn3/bed/blatFugu/chrom
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        mv $i ${r}_blatFugu.psl
    end
    hgLoadPsl rn3 *.psl
    mkdir -p /gbdb/rn3/fuguSeq
    cd /gbdb/rn3/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta
    cd /cluster/store2/temp
    hgLoadRna addSeq rn3 /gbdb/rn3/fuguSeq/fugu_v3_mask.fasta


MAKE LIFT FILE FOR AGPS (TO DO)
    ssh kkstore
    cd ~/rn3/jkStuff
    ./jkStuff/agpToLift.pl chrom.sizes ?{,?}/chr?{,?}{,_random}.agp \
      > jkStuff/liftRNOR.lft


LOAD BACTIG POSITIONS (TO DO)

    ssh hgwdev
    mkdir -p ~/rn3/bed/bactigPos
    cd ~/rn3/bed/bactigPos
    # Paul Havlak havlak@swan.hgsc.bcm.tmc.edu sent us a BED 4+ email 
    # attachment.  
    # Save the attachment as ~/rn3/bed/bactigPos/Rnor2-1.extreme.fix
    # Fix the 1-based starts to 0-based:
    awk "-F\t" '{printf "%s\t%d\t%s\t%s\t%s\t%s\n", $1, $2-1, $3, $4, $5, $6;}' < Rnor2-1.extreme.fix > bactigPos.bed
    hgLoadBed rn3 bactigPos bactigPos.bed \
      -noBin -sqlTable=$HOME/kent/src/hg/lib/bactigPos.sql


LOAD CPGISSLANDS (DONE - 2003-07-08 - Hiram)
    ssh hgwdev
    mkdir -p ~/rn3/bed/cpgIsland
    cd ~/rn3/bed/cpgIsland
    # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
    # copy the tar file to the current directory
    cp -p /cluster/store4/rn2/bed/cpgIsland/cpg_dist.tar .
    tar xvf cpg_dist.tar 
    cd cpg_dist
    gcc readseq.c cpg_lh.c -o cpglh.exe
    
    ssh kkstore
    cd ~/rn3/bed/cpgIsland
    foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpg_dist/cpglh.exe $f > $fout.cpg
    end
    # copy filter.awk from a previous release
    cp -p /cluster/store4/rn2/bed/cpgIsland/filter.awk .
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd ~/rn3/bed/cpgIsland
    hgLoadBed rn3 cpgIsland -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed


LOAD SOFTBERRY GENES (TO DO)
     cd /cluster/store3/rn3/bed
     mkdir softberry
     cd softberry
     wget ftp://www.softberry.com/pub/SC_RAT_JAN03/Softb_rat_gff_j03.tar.gz
     gunzip -c Softb_rat_gff_j03.tar.gz | tar xvf -
     ldHgGene rn3 softberryGene chr*.gff
     hgPepPred rn3 softberry *.protein
     hgSoftberryHom rn3 *.protein

LOAD GENEID GENES (DONE - 2003-07-08 - Hiram)
    mkdir -p ~/rn3/bed/geneid/download
    cd ~/rn3/bed/geneid/download
    foreach f (~/rn3/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/R.norvegicus/rnJun2003/geneid_v1.1/$chr.gtf
      wget http://genome.imim.es/genepredictions/R.norvegicus/rnJun2003/geneid_v1.1/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene rn3 geneid download/*.gtf -exon=CDS
    hgPepPred rn3 generic geneidPep download/*-fixed.prot

SGP GENE PREDICTIONS (TO DO)
    mkdir -p ~/rn3/bed/sgp/download
    cd ~/rn3/bed/sgp/download
    foreach f (~/rn3/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/R.norvegicus/rnJan2003/SGP/humangp20021114/$chr.gtf
      wget http://genome.imim.es/genepredictions/R.norvegicus/rnJan2003/SGP/humangp20021114/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene rn3 sgpGene download/*.gtf -exon=CDS
    hgPepPred rn3 generic sgpPep download/*-fixed.prot


TIGR GENE INDEX (TO DO)
    mkdir -p ~/rn3/bed/tigr
    cd ~/rn3/bed/tigr
    wget ftp://ftp.tigr.org/private/NHGI_mgi_jiashu/TGI_track_RatGenome_Feb2002.tgz
    gunzip -c TGI_track_RatGenome_Feb2002.tgz | tar xvf -
    foreach f (*cattle*)
      set f1 = `echo $f | sed -e 's/cattle/cow/g'`
      mv $f $f1
    end
    foreach o (rat cow human pig rat)
      setenv O $o
      foreach f (chr*_$o*s)
        tail +2 $f | perl -wpe 's /THC/TC/; s/(TH?C\d+)/$ENV{O}_$1/;' > $f.gff
      end
    end
    ldHgGene -exon=TC rn3 tigrGeneIndex *.gff


LOAD STS MAP (todo)
     - login to hgwdev
      cd ~/rn3/bed
      rn3 < ~/src/hg/lib/stsMap.sql
      mkdir stsMap
      cd stsMap
      bedSort /projects/cc/hg/mapplots/data/tracks/build28/stsMap.bed stsMap.bed
      - Enter database with "rn3" command.
      - At mysql> prompt type in:
          load data local infile 'stsMap.bed' into table stsMap;
      - At mysql> prompt type

LOAD MGI IDs (TO DO)
      - The Locuslink ID to MGI IDs converstion data file,
        LL2MGI.txt, from Jackson Lab should be found under
        ~/rn3/bed/refSeq
      - login to hgwdev
      
      cd ~/rn3/bed/refSeq
      rn3 < ~/src/hg/lib/mgiID.sql
      - Enter database with "rn3" command.
      - At mysql> prompt type in:
          load data local infile 'LL2MGI.txt' into table MGIid;
      - At mysql> prompt type
          quit

LOAD CHROMOSOME BANDS (todo)
      - login to hgwdev
      cd /cluster/store3/rn3/bed
      mkdir cytoBands
      cp /projects/cc/hg/mapplots/data/tracks/build28/cytobands.bed cytoBands
      rn3 < ~/src/hg/lib/cytoBand.sql
      Enter database with "rn3" command.
      - At mysql> prompt type in:
          load data local infile 'cytobands.bed' into table cytoBand;
      - At mysql> prompt type
          quit

LOAD RATREF TRACK (todo)
    First copy in data from kkstore to ~/rn3/bed/ratRef.  
    Then substitute 'genome' for the appropriate chromosome 
    in each of the alignment files.  Finally do:
       hgRefAlign webb rn3 ratRef *.alignments

LOAD AVID RAT TRACK (todo)
      ssh cc98
      cd ~/rn3/bed
      mkdir avidRat
      cd avidRat
      wget http://pipeline.lbl.gov/tableCS-LBNL.txt
      hgAvidShortBed *.txt avidRepeat.bed avidUnique.bed
      hgLoadBed avidRepeat avidRepeat.bed
      hgLoadBed avidUnique avidUnique.bed

LOAD SNPS (TO DO)
      - ssh hgwdev
      - cd ~/rn3/bed
      - mkdir snp
      - cd snp
      - Download SNPs from ftp://ftp.ncbi.nlm.nih.gov/pub/sherry/rat.b27.out.gz
      - Unpack.
        createBed < rat.b27.out > snpNih.bed
        hgLoadBed rn3 snpNih snpNih.bed

LOAD ENSEMBL ESTs (TO DO)
     ln -s /cluster/store3/rn3 ~/rn3
     mkdir -p ~/rn3/bed/ensembl
     cd ~/rn3/bed/ensembl
     wget http://www.ebi.ac.uk/~stabenau/rat-est.gz
     wget http://www.ebi.ac.uk/~stabenau/rat-est.pep.gz
     gunzip -c rat-est.gz | \
       perl -w -p -e 's/^(\w)/chr$1/' > rat-est-fixed.gtf
     ldHgGene rn3 ensEst rat-est-fixed.gtf
> The id behind '>' is internal and was not in our gtf dump, so
> you have to do some more parsing.
     # pick out the transcript= attribute -- that's the id to use:
     # also remove the first line:
     gunzip -c rat-est.pep.gz | tail +2 | \
       perl -w -p -e 's/^\>gene_id=.*transcript=(\w+)\s+.*$/\>$1/' > \
       rat-est-fixed.pep
     hgPepPred rn3 generic ensEstPep rat-est-fixed.pep

LOAD ENSEMBLE GENES (TO DO)
     mkdir -p ~/rn3/bed/ensembl
     cd ~/rn3/bed/ensembl
     wget http://www.ebi.ac.uk/~stabenau/rat-ensembl.gz
     wget http://www.ebi.ac.uk/~stabenau/rat-ensembl.pep.gz
     gunzip -c rat-ensembl.gz | \
       perl -w -p -e 's/^(\w)/chr$1/' > rat-ensembl-fixed.gtf
     ldHgGene rn3 ensGene rat-ensembl-fixed.gtf
> rat-ensembl contains stopcodons, due to some glitches in our
> genebuild. The id behind '>' is internal and was not in our gtf dump, so
> you have to do some more parsing.
# pick out the transcript= attribute -- that's the id to use:
# also remove the first line:
     tail +2 rat-ensembl.pep | \
       perl -w -p -e 's/^\>gene_id=.*transcript=(\w+)\s+.*$/\>$1/' > \
       rat-ensembl-fixed.pep
     hgPepPred rn3 generic ensPep rat-ensembl-fixed.pep

LOAD RNAGENES (todo)
      - login to hgwdev
      - cd ~kent/src/hg/lib
      - rn3 < rnaGene.sql
      - cd /cluster/store3/rn3/bed
      - mkdir rnaGene
      - cd rnaGene
      - download data from ftp.genetics.wustl.edu/pub/eddy/pickup/ncrna-oo27.gff.gz
      - gunzip *.gz
      - liftUp chrom.gff ../../jkStuff/liftAll.lft carry ncrna-oo27.gff
      - hgRnaGenes rn3 chrom.gff

LOAD EXOFISH (todo)
     - login to hgwdev
     - cd /cluster/store3/rn3/bed
     - mkdir exoFish
     - cd exoFish
     - rn3 < ~kent/src/hg/lib/exoFish.sql
     - Put email attatchment from Olivier Jaillon (ojaaillon@genoscope.cns.fr)
       into /cluster/store3/rn3/bed/exoFish/all_maping_ecore
     - awk -f filter.awk all_maping_ecore > exoFish.bed
     - hgLoadBed rn3 exoFish exoFish.bed

LOAD GENIE (TO DO)
     mkdir -p ~/rn3/bed/genieAlt
     cd ~/rn3/bed/genieAlt
     wget http://www.neomorphic.com/mgap/mgscv3/gtf/mgscv3.genie.gtf.tgz
     gunzip -c mgscv3.genie.gtf.tgz | tar xvf -
     ldHgGene rn3 genieAlt mgscv3.genie.gtf/chr*.gtf
     wget http://www.neomorphic.com/mgap/mgscv3/fa/mgscv3.aa.tgz
     gunzip -c mgscv3.aa.tgz | tar xvf -
     hgPepPred rn3 genie geniePep chr*.aa.fa

LOAD GENIE CLONE BOUNDS (TO DO)
     mkdir -p ~/rn3/bed/genieBounds
     cd ~/rn3/bed/genieBounds
     wget http://www.neomorphic.com/mgap/mgscv3/cb.bed/mgscv3_cb.bed.tgz
     gunzip -c mgscv3_cb.bed.tgz | tar xvf -
     - Trim the track definition from each file (these are actually custom 
       track files):
     foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Un)
       tail +2 chr${c}_cb.bed > chr${c}_cb-fixed.bed
     end
     hgLoadBed rn3 genieBounds *-fixed.bed

LOAD SOFTBERRY GENES (todo)
     - ln -s /cluster/store3/rn3 ~/rn3
     - cd ~/rn3/bed
     - mkdir softberry
     - cd softberry
     - get ftp://www.softberry.com/pub/SC_MOU_NOV01/softb_mou_genes_nov01.tar.gz
     ldHgGene rn3 softberryGene chr*.gff
     hgPepPred rn3 softberry *.protein
     hgSoftberryHom rn3 *.protein

LOAD GENOMIC DUPES (todo)
o - Load genomic dupes
    ssh hgwdev
    cd ~/rn3/bed
    mkdir genomicDups
    cd genomicDups
    wget http://codon/jab/web/takeoff/oo33_dups_for_kent.zip
    unzip *.zip
    awk -f filter.awk oo33_dups_for_kent > genomicDups.bed
    hgsql rn3 < ~/src/hg/lib/genomicDups.sql
    hgLoadBed rn3 -oldTable genomicDups genomicDupes.bed

LOAD RGD CURATED GENES TRACK
    - cd rn3
    - cd bed
    - mkdir rgdGene
    - Browse to http://zephyrus.brc.mcw.edu/cgi-bin/pub/viewcvs.cgi/pub_gbrowse/gff_files/RGD_curated_genes.gff
        This is a web-based CVS page. Click the download link and save the file to ~/rn3/bed/RGD_curated_genes.gff
     - Now massage the data format using:
         rn3/bed/rgdGene/massage.pl
     - Load the data:
        ldHgGene rn3 rgdGene Fixed_RGD_Curated_genes.gff
     - Create the link table for searching
        In mysql for the rn3 database do:
        create table rgdLink (id int primary key, name varchar(32) not null);
        LOAD DATA LOCAL INFILE 'RGD.links' into table rgdLink; 
     

FAKING DATA FROM PREVIOUS VERSION
(This is just for until proper track arrives.  Rescues about
97% of data  Just an experiment, not really followed through on).

o - Rescuing STS track:
     - log onto hgwdev
     - mkdir ~/rn3/rescue
     - cd !$
     - mkdir sts
     - cd sts
     - bedDown hg3 mapGenethon sts.fa sts.tab
     - echo ~/rn3/sts.fa > fa.lst
     - pslOoJobs ~/rn3 ~/rn3/rescue/sts/fa.lst ~/rn3/rescue/sts g2g
     - log onto cc01
     - cc ~/rn3/rescue/sts
     - split all.con into 3 parts and condor_submit each part
     - wait for assembly to finish
     - cd psl
     - mkdir all
     - ln ?/*.psl ??/*.psl *.psl all
     - pslSort dirs raw.psl temp all
     - pslReps raw.psl contig.psl /dev/null
     - rm raw.psl
     - liftUp chrom.psl ../../../jkStuff/liftAll.lft carry contig.psl
     - rm contig.psl
     - mv chrom.psl ../convert.psl
