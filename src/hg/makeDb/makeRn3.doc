# This file describes how we made the browser database on the Rattus 
# Norvegicus genome, June 2003 update.
#
#	Things got a bit confused because the first Rat for June
#	got started about June 22.  Processing proceeded on that for
#	that week, then it was annnounced that portions of Chr 7 and Chr X
#	were being moved around and a new Rat was released June 29.
#	Also, had some difficulty with RepeatMasker.
#	And, there were cluster difficulties to work around.
#	What happens is that some things may not be exactly where they
#	are claimed to be.  Although I believe everything has been
#	corrected.

DOWNLOAD SEQUENCE (DONE Rnor3.1 - 2003-06-29 - Hiram)

    ssh kkstore
    mkdir /cluster/store3/rn3
    cd /cluster/store3/rn3
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/README
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/conditions_for_use
    #  Three extra files that were not in Rn2:
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bac.clones
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bacfile.gz
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bactigs.bacs
    wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/bactigs.contigs

    # Get BCM's chrom assemblies -- we will assemble our own chr*.fa from 
    # contig fa + agp, and cross-check against this.  
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 X Un)
      mkdir $c
      wget -O $c/chr$c.fa.bcm.gz \
       ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/chromosome/chr$c.fa.gz
      wget -O $c/chr${c}_random.fa.bcm.gz \
 ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/chromosome/chr$c.random.fa.gz
    end

    # Get BCM's contig fa + agp.  We will split into our own conveniently-sized
    # pseudo-contigs, and assemble chrom fa.  
    # These two files are not available in this rat June 2003
    #  But they don't seem to be used anywhere else here anyway
    # wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/bacfile2-1.gz
    # wget ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/record.dat.gz
    #  Perhaps the extra three files bac.clones, bactigs.bacs and
    #  bactigs.contigs can be used ?
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 X Un)
      wget -O $c/chr$c.agp \
       ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.agp
      wget -O $c/chr$c.contig.fa.gz \
   ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.contig.fa.gz
      wget -O $c/chr${c}_random.agp \
   ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.random.agp
      wget -O $c/chr${c}_random.contig.fa.gz \
   ftp://rat-ftp.hgsc.bcm.tmc.edu/pub/analysis/rat/contigs/chr$c.random.contig.fa.gz
    end

BUILD AND CHECK CHROM-LEVEL SEQUENCE (DONE - 2003-06-29 - Hiram)

    # Make chrom fa:
    ssh kkstore
    # The contig sequences are delivered with various upper and lower
    # case.  We need them all in upper case to begin with.  The first
    # line of the file is not a problem, it is already all upper case.
    # According to Kim Worley: <kworley@swan.hgsc.bcm.tmc.edu>
    # "The lowercase letters are regions where Phrap assigns a quality score
    #	of less than 20.  These can safely be ignored."
    foreach c (?{,?})
	set f = $c/chr$c.contig.fa.gz
	set g = $f:r
	echo "${f}"
	zcat ${f} | tr '[a-z]' '[A-Z]' > ${g}
    end
    foreach c (?{,?})
	set f = $c/chr${c}_random.contig.fa.gz
	set g = $f:r
	if (-e ${f}) then
	    echo "${f}"
	    zcat ${f} | tr '[a-z]' '[A-Z]' > ${g}
	endif
    end

    foreach c (?{,?})
      echo "Processing ${c}"
      $HOME/bin/i386/agpToFa -simpleMultiMixed $c/chr$c.agp chr$c \
	$c/chr$c.fa $c/chr$c.contig.fa
      if (-e $c/chr${c}_random.agp) then
        $HOME/bin/i386/agpToFa -simpleMultiMixed $c/chr${c}_random.agp \
	chr${c}_random $c/chr${c}_random.fa $c/chr${c}_random.contig.fa
      endif
      echo "${c} - DONE"
    end
    # Check that the size of each chromosome .fa file is equal to the 
    # last coord of the .agp:
    foreach f ( ?{,?}/*.agp )
      set agpLen = `tail -1 $f | awk '{print $3;}'`
      set g = $f:r
      set faLen = `faSize $g.fa | awk '{print $1;}'`
      if ($agpLen == $faLen) then
        echo "   OK: $f length = $g length = $faLen"
      else
        echo "ERROR:  $f length = $agpLen, but $g length = $faLen"
      endif
    end
    # Check that our assembled chrom fa jive with the BCM chrom fa
    #	You will want a long window size in your terminal to run this
    #	It outputs quite a few lines
    foreach c ( ?{,?} )
      set ucscLen = `faSize $c/chr$c.fa | awk '{print $1;}'`
      set bcmLen  = `gunzip -c $c/chr$c.fa.bcm.gz | faSize stdin \
                       | awk '{print $1;}'`
      if ($ucscLen == $bcmLen) then
        echo "   OK: chr$c.fa length = chr$c.fa.bcm length = $bcmLen"
      else
        echo -n "ERROR:  chr$c.fa length = $ucscLen, but chr$c.fa.bcm length"
	echo " = $bcmLen"
        echo -n "ERROR:  chr$c.fa length = $ucscLen, but chr$c.fa.bcm length"
	echo " = $bcmLen"
      endif
      if (-e $c/chr${c}_random.fa) then
        set ucscLen = `faSize $c/chr${c}_random.fa | awk '{print $1;}'`
        set bcmLen  = `gunzip -c $c/chr${c}_random.fa.bcm.gz | faSize stdin \
                        | awk '{print $1;}'`
        if ($ucscLen == $bcmLen) then
          echo -n "   OK: chr${c}_random.fa length = chr${c}_random.fa.bcm"
	  echo " length = $bcmLen"
        else
          echo -n "ERROR:  chr${c}_random.fa length = $ucscLen, but"
	  echo " chr${c}_random.fa.bcm length = $bcmLen"
        endif
      endif
    end

BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON_BRIDGED CONTIGS (DONE - 2003-06-29)
					(DONE - 2003-06-29 - Hiram)

    # This will split the rat sequence into approx. 5 Mbase
    # supercontigs between non-bridged clone contigs and drop the
    # resulting dir structure in /cluster/store3/rn3.  The resulting
    # dir structure will include 1 dir for each chromosome, each of
    # which has a set of subdirectories, one subdir per supercontig.
    ssh kkstore
    cd /cluster/store3/rn3
    foreach c (?{,?})
      echo "Working ${c}"
      cp -p $c/chr$c.agp $c/chr$c.agp.bak
      cp -p $c/chr$c.fa $c/chr$c.fa.bak
      splitFaIntoContigs $c/chr$c.agp $c/chr$c.fa . -nSize=5000000
      if (-e $c/chr${c}_random.fa) then
        cp -p $c/chr${c}_random.agp $c/chr${c}_random.agp.bak
        cp -p $c/chr${c}_random.fa $c/chr${c}_random.fa.bak
        rm -fr ${c}_random
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        rm -fr $c/chr${c}_random_1
        rm -fr $c/chr${c}_random_2
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
      echo "DONE ${c}"
    end
    # Make sure the reconstructed .fa jives with the original:
    #	four lines output for each chrom, long window required to be
    #	able to catch all the output.  Look for non-zero numbers.  The
    #	wc -l should always output zero
    foreach f ( */*.fa.bak )
      echo -n $f:r " "
      diff $f $f:r | wc -l
    end
    # The .agp goes through a slight format change, but make sure it 
    # at least ends up with the same number of lines:
    foreach f ( ?{,?}/*.agp.bak )
      set l1 = `wc -l $f | awk '{print $1}'`
      set l2 = `wc -l $f:r | awk '{print $1}'`
      if ($l1 == $l2) then
        echo "   OK: $f and $f:r have the same #lines"
      else
        echo "ERROR:  $f has $l1 lines, but $f:r has $l2"
      endif
    end
    # Save some space - NO - the *.contig.fa.gz files already existing
    # here are the original downloads.  These non-zipped versions are
    # the translated to upper case versions.
#	foreach c (?{,?})
#	echo $c
#	gzip $c/chr*.contig.fa
#	end
    # Do need to at least move these out of the way because later
    # wild card expansions are looking for things like *.fa and we
    # don't want these in those expansions.
	foreach c (?{,?})
	echo "$c/chr${c}.contig.fa -> $c/chr${c}.contig.fa.UC"
	mv $c/chr${c}_random.contig.fa $c/chr${c}_random.contig.fa.UC
	mv $c/chr${c}.contig.fa $c/chr${c}.contig.fa.UC
	end
    # This rm may be a good thing to do.  But later, after repeat
    # masking is done and thus the soft masked results can be compared
    # with the *.bak originals.
#	rm */*.bak

COPY OVER JKSTUFF SCRIPTS DIRECTORY (DONE - 2003-06-29 - Hiram)
	# Some of these scripts are being edited after they were
	#	copied to here.  Some cases of binaries in
	#	~kent/bin/i386 need to be changed either to
	#	/cluster/bin/i386 or ~hiram/bin/i386 depending upon what
	#	was being fixed as all this proceeded.
	#	The "real" place should be /cluster/bin/i386 but before
	#	we go that route, we need to have our build processes
	#	working properly to keep that bin up to date.

    ssh kkstore
    ln -s /cluster/store3/rn3 ~/rn3
    rm -f ~/lastRn
    ln -s /cluster/store4/rn2 ~/lastRn
    cd ~/rn3
    cp -Rp ~/lastRn/jkStuff .
    rm jkStuff/*.{out,lst,lft} jkStuff/*~


CREATING DATABASE (DONE - 2003-06-23 - Hiram)

    # Create the database.
    ssh hgwdev
    echo 'create database rn3' | hgsql ''
    # make a semi-permanent read-only alias:
    #	(I haven't noticed any use of this ?  Useless ? - Hiram)
    alias rn3 "mysql -u hguser -phguserstuff -A rn3"
    # Use df to ake sure there is at least 5 gig free on 
    #		hgwdev:/var/lib/mysql
    # [hiram@hgwdev /cluster/home/hiram] df -h /var/lib/mysql
    # Filesystem            Size  Used Avail Use% Mounted on
    # /dev/sda1             472G  384G   64G  86% /var/lib/mysql


CREATING GRP TABLE FOR TRACK GROUPING (DONE - 2003-06-23 - Hiram)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from rn1.grp" \
      | hgsql rn3


REPEAT MASKING (RUNNING - 2003-06-30 - Hiram)
   Split contigs, run RepeatMasker, lift results
   Notes: 
   * If there is a new version of RepeatMasker, build it and ask the admins 
     to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
   * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
     RepeatMasker runs manageable on the cluster ==> results need lifting.
   * For the NCBI assembly we repeat mask on the sensitive mode setting
     (RepeatMasker -m -s)

    #- Split contigs into 500kb chunks:
    ssh kkstore
    cd ~/rn3
    foreach d ( */chr*_?{,?} )
	cd $d
	echo "splitting $d"
	set contig = $d:t
	faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
	    -maxN=500000
	cd ../..
    end

    #- Make the run directory and job list:
    cd ~/rn3
    cat << '_EOF_' > jkStuff/RMRat
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/rn3/$2
/bin/cp $2 /tmp/rn3/$2/
cd /tmp/rn3/$2
/cluster/bluearc/RepeatMasker030619/RepeatMasker -ali -s -spec rat -comp mouse $2
popd
/bin/cp /tmp/rn3/$2/$2.out ./
if (-e /tmp/rn3/$2/$2.align) /bin/cp /tmp/rn3/$2/$2.align ./
if (-e /tmp/rn3/$2/$2.tbl) /bin/cp /tmp/rn3/$2/$2.tbl ./
if (-e /tmp/rn3/$2/$2.cat) /bin/cp /tmp/rn3/$2/$2.cat ./
/bin/rm -fr /tmp/rn3/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn3/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn3
'_EOF_'
    chmod +x jkStuff/RMRat
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
    foreach d ( ?{,?}/chr*_?{,?} )
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/store3/rn3/jkStuff/RMRat \
                 /cluster/store3/rn3/$d $f \
               '{'check out line+ /cluster/store3/rn3/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
    end

    #- Do the run
    ssh kk
    cd ~/rn3/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
# Completed: 6209 of 6209 jobs
# CPU time in finished jobs:   37009055s  616817.58m 10280.29h  428.35d  1.174 y
# IO & Wait Time:                 96849s    1614.15m    26.90h    1.12d  0.003 y
# Average job time:                5976s      99.60m     1.66h    0.07d
# Longest job:                    16048s     267.47m     4.46h    0.19d
# Submission to last job:         49589s     826.48m    13.77h    0.57d

        #- Lift up the split-contig .out's to contig-level .out's
	ssh kkstore
    cd ~/rn3
        foreach d ( ?{,?}/chr*_?{,?} )
          cd $d
          set contig = $d:t
          /cluster/home/hiram/bin/i386/liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
          cd ../..
        end

        #- Lift up the contig-level .out's to chr-level
        cd ~/rn3
        ./jkStuff/liftOut5.sh

        # soft-mask contig .fa's with .out's
        foreach i (?{,?})
            foreach j ($i/chr${i}_?{,?}/chr${i}_?{,?}.fa \
                       $i/chr${i}_random_?{,?}/chr${i}_random_?{,?}.fa)
                /cluster/home/hiram/bin/i386/maskOutFa $j $j.out $j -soft
            end
            echo done $i
        end
	# You will see a few WARNING lines from maskOutFa.  This is a
	# a good sign.  Much better than when maskOutFa used to exit.
	# With the fix, everything is getting masked properly.
	# Fixing a temporary glitch in repeat masker.  This hasn't
	# affected anything above, but it will change the result of
	# the load below.  Since the repeat masker run above, the
	# processrepeats script of RepeatMasker has been fixed.  This
	# would not be necessary after that fix.
        foreach i (?{,?})
	    /cluster/bluearc/RepeatMasker030619/MakeRMoutSane.pl ${i}/*.fa.out
		foreach k ($i/chr${i}_?{,?}/chr${i}_?{,?}.fa.out \
			$i/chr${i}_random_?{,?}/chr${i}_random_?{,?}.fa.out)
	    /cluster/bluearc/RepeatMasker030619/MakeRMoutSane.pl ${k}
		end
	end

        #- Load the .out files into the database with:
        ssh hgwdev
	cd ~/rn3
        hgLoadOut rn3 ?{,?}/*.fa.out

MAKE LIFTALL.LFT (DONE - 2003-07-01 - Hiram)

    ssh kkstore
    cd ~/rn3
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft
    cp -p jkStuff/liftAll.lft /cluster/bluearc/rat/rn3

VERIFY REPEATMASKER RESULTS (DONE - 2003-06-24 - Hiram)

    # Something about this is too early at this point.  It errors with:
    #	Can't start query:
    #	select chrom,size,fileName from chromInfo
    #	mySQL error 1146: Table 'rn3.chromInfo' doesn't exist
    # you have to wait until the nibs have been loaded below and the
    # chrom.sizes works

    # Run featureBits on rn3 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits rn3 rmsk  (rat version 3.1)
    #	1117483165 bases of 2571104688 (43.463%) in intersection
    featureBits rn3 rmsk  (rat version 3.0)
    #   1117328265 bases of 2571104688 (43.457%) in intersection
    featureBits rn2 rmsk  (Jan 2003)
    #	1100534407 bases of 2495551408 (44.100%) in intersection
    featureBits rn1 rmsk  (Nov 2002)
    #	1081814344 bases of 2555848684 (42.327%) in intersection


STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE - 2003-07-02 - Hiram)

    # XXXXX - These unmasked nibs are unnecessary.  They will be
    # replaced below by soft masked nibs.  This is only done here in
    # order to quickly get a browser going so that other tracks and
    # tests can be begun.

    # Make (unmasked) nibs
    ssh kkstore
    cd ~/rn3
    mkdir nibNotMasked
    foreach i (?{,?})
	cd $i
	foreach j ( chr?{,?}{,_random}.fa )
	echo "nibbing $j"
	~/bin/i386/faToNib $j ../nibNotMasked/$j:r.nib
	end
	cd ..
    end

    # Make symbolic links from /gbdb/rn3/nib to the real nibs.
    # Below, after the soft masked nibs are created, these
    # links will be reset to point to the soft masked nibs.
    ssh hgwdev
    mkdir -p /gbdb/rn3/nib
    foreach f (/cluster/store3/rn3/nibNotMasked/chr*.nib)
      ln -s $f /gbdb/rn3/nib
    end
    # Load /gbdb/rn3/nib paths into database and save size info.
     ssh hgwdev
     hgsql rn3  < ~/kent/src/hg/lib/chromInfo.sql
     cd ~/rn3
     hgNibSeq -preMadeNib rn3 /gbdb/rn3/nib ?{,?}/chr?{,?}{,_random}.fa
    #	2835152425 total bases
     echo "select chrom,size from chromInfo" | hgsql -N rn3 > chrom.sizes
    # take a look at chrom.sizes, should be 44 lines and reasonable
    # numbers
    wc chrom.sizes
    #	44      88     778 chrom.sizes


GOLD AND GAP TRACKS (DONE - 2003-07-02 - Hiram)
    ssh hgwdev
    cd ~/rn3
    hgGoldGapGl -noGl rn3 /cluster/store3/rn3 .


MAKE GCPERCENT (DONE - 2003-07-02 - Hiram)
     ssh hgwdev
     mkdir -p /cluster/store3/rn3/bed/gcPercent
     cd /cluster/store3/rn3/bed/gcPercent
     hgsql rn3  < ~/kent/src/hg/lib/gcPercent.sql
     hgGcPercent rn3 ../../nibNotMasked


MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR RN3 (DONE - 2003-06-24 - Hiram)
    # Enter rn3 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb values("rn3", "Jun 2003", \
        "/gbdb/rn3/nib", "Rat", "Espn", 1, \
        30, "Rat");' | hgsql -h genome-testdb hgcentraltest
    # Temporary entry until mrna tables come along.  Approximate
    # calculated position the same as rn2
    # Note: for next assembly, set scientificName column to "Rattus norvegicus"
    echo 'insert into dbDb (name, description, nibPath, organism, defaultPos, active, orderKey, genome, scientificName) values("rn3", "June 2003", \
        "/gbdb/rn3/nib", "Rat", "chr5:169359914-169392264", 1, \
        30, "Rat", "Rattus norvegicus");' | hgsql -h genome-testdb hgcentraltest

    # Trying to request Espn in this new rat results in 4 different
    # hits on the genome.  Thus, the specified position here is the
    # desired Espn position as was in the previous Rat
    #  If you need to delete this dbDb entry to rewrite it:
        echo 'delete from dbDb where name="rn3";' \
        | hgsql -h genome-testdb hgcentraltest
    # To change the default version of the Rat on the organism
    #	menu.  First delete it, then add the new one:

    echo 'delete from defaultDb where genome="Rat";' \
	| hgsql -h genome-testdb hgcentraltest

    echo 'insert into defaultDb values("Rat", "rn3");' \
	| hgsql -h genome-testdb hgcentraltest


    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add rn3 in all the right places and do
    make update
    make alpha
    cvs commit makefile


MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR RN3 (DONE - 2003-07-04 - Jorge)
    ssh hgwdev
    echo 'insert into blatServers values("rn3", "blat11", "17778", "1"); \
          insert into blatServers values("rn3", "blat11", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


SIMPLE REPEAT TRACK (DONE - 2003-07-01 - Hiram)
    #  Need to be careful with this one on the cluster.  This trf
    #  thing does a lot of I/O on the input and output file.
    #  Place the splits on /cluster/bluearc for cluster access
    ssh kkstore
    mkdir -p /cluster/bluearc/rat/rn3
    cd /cluster/store3/rn3/
    ls ?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa  \
	| tar -c -T - -f - | (cd /cluster/bluearc/rat/rn3.1.split; tar xfBp -)

    # now, a safe cluster job to trf mask
    ssh kk
    mkdir ~/rn3/bed/simpleRepeat
    cd ~/rn3/bed/simpleRepeat
    mkdir trf
 ls /cluster/bluearc/rat/rn3.1.split/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa \
	> genome.lst

    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'

    gensub2 genome.lst single gsub spec
    para create spec
    para try
    para check
    para push
    ... etc ...
Completed: 591 of 591 jobs
CPU time in finished jobs:      27837s     463.95m     7.73h    0.32d  0.001 y
IO & Wait Time:                 13105s     218.41m     3.64h    0.15d  0.000 y
Average job time:                  69s       1.15m     0.02h    0.00d
Longest job:                      205s       3.42m     0.06h    0.00d
Submission to last job:           263s       4.38m     0.07h    0.00d

    ssh kkstore
    cd ~/rn3/bed/simpleRepeat
    liftUp simpleRepeat.bed ~/rn3/jkStuff/liftAll.lft warn trf/*.bed

    # Load this into the database as so
    ssh hgwdev
    cd ~/rn3/bed/simpleRepeat
    hgLoadBed rn3 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql

PROCESS SIMPLE REPEATS INTO MASK (DONE - 2003-07-02 - Hiram)

    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    # XXXX The next time we do this, we want to experiment with period <= 8
    ssh kkstore
    cd ~/rn3/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd ~/rn3
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
        $c/lift/ordered.lst > $c/lift/oTrf.lst
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
      endif
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
        jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      if (-e $c/lift/rTrf.lst) then
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end


MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE - 2003-07-02)
			(DONE - 2003-07-02 - Hiram)

    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above.
    ssh kkstore
    cd ~/rn3
    #- Soft-mask (lower-case) the contig and chr .fa's
    ./jkStuff/makeFaMasked.sh
    # You will see warnings from the above command, these are OK:
    # WARNING: negative rEnd: -203 chr1:36149039-36149198 L1M3c
    # WARNING: negative rEnd: -14 chr1:185432802-185432864 PB1D10
    #- Make hard-masked .fa.masked files as well:
    ./jkStuff/makeHardMasked.sh
    #- Rebuild the nib, mixedNib, maskedNib files:
    ./jkStuff/makeNib.sh
    # Copy the masked contig fa to /scratch:
    ssh kkstore
    rm -rf /cluster/bluearc/rat/rn3/trfFa
    mkdir -p /cluster/bluearc/rat/rn3/trfFa
    cp -p ~/rn3/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa \
	/cluster/bluearc/rat/rn3/trfFa

RESET NIB POINTERS TO softNib (DONE - 2003-07-02 - Hiram)

    # As mentioned above the first time this was done, the first set
    # of nibs linked to were unnecessary.  Here, we change the links to
    # point to softNib which is both repeat masker and trf masked
    ssh hgwdev
    cd /gbdb/rn3/nib
    rm -f *
    foreach f (/cluster/store3/rn3/softNib/chr*.nib)
      ln -s $f /gbdb/rn3/nib
    end
    #  I wonder if this needs to be run again ?  I'm going to do it
    #	anyway.
    # Load /gbdb/rn3/nib paths into database and save size info.
     ssh hgwdev
     cd ~/rn3
     hgNibSeq -preMadeNib rn3 /gbdb/rn3/nib ?{,?}/chr?{,?}{,_random}.fa
    #	2835152425 total bases
     echo "select chrom,size from chromInfo" | hgsql -N rn3 > chrom.sizes
    # take a look at chrom.sizes, should be 44 lines and reasonable
    # numbers
    wc chrom.sizes
    #	44      88     778 chrom.sizes

MAKE DOWNLOADABLE SEQUENCE FILES (DONE - 2003-07-03 - 2003-07-09 - Hiram)
    ssh kkstore
    cd ~/rn3
    #- Build the .zip files
    ./jkStuff/zipAll.sh |& tee zipAll.log
    mkdir zip
    mv *.zip* zip
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd ~/rn3/zip
    ../jkStuff/cpToWeb.sh
    cd /usr/local/apache/htdocs/goldenPath/rnJun2003
    #- Take a look at bigZips/* and chromosomes/*, update their README.txt's

    # Then make the upstream sequence files.
    cd bigZips
    featureBits rn3 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits rn3 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits rn3 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa


# PREPARE CLUSTER FOR BLASTZ RUN (IN PROGRESS - 2003-07-10 - kate)
    # This needs to be done after trf-masking and nib generation.

    # NOTE: generated lineage-specific .out files
    # using "old" script, for use vs. human 
    # Will need species-specific version for mouse 
    # 2003-07-09 kate
    # Before mouse run:
    # XXXXXXXXX  Currently stuck on this one 2003-07-09 - the lineage specific
    # XXXXXXXXX  repeats business is now different.
    # XXXXXXXXX  Trying to work the kinks out of that. Hiram
    ssh kkstore
    # Extract lineage-specific repeats using Arian Smit's script:
    mkdir -p /cluster/data/rn3/bed/linSpecRep
    cd /cluster/data/rn3/bed/linSpecRep
    # foreach f (~/rn3/*/chr*.out)
        # ln -sf $f .
    # end
    # don't step on existing .out's
    foreach f (/cluster/data/rn3/*/chr*.out)
        cp $f .
    end
    
    /cluster/bin/scripts/rodentSpecificRepeats.pl *.out
    /cluster/bin/scripts/perl-rename 's/(\.fa|\.nib)//' *.out.*spec
    /cluster/bin/scripts/perl-rename 's/\.(rod|prim)spec/.spec/' *.out.*spec
    rm *.out
    cd /cluster/data/rn3/bed
    rm -rf /cluster/bluearc/rat/rn3/linSpecRep
    #  This dir already exists from above
    # mkdir -p /cluster/bluearc/rat/rn3
    cp -Rp linSpecRep /cluster/bluearc/rat/rn3
    # RepeatMasker .out:
    cd ~/rn3
    rm -rf /cluster/bluearc/rat/rn3/rmsk
    mkdir -p /cluster/bluearc/rat/rn3/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /cluster/bluearc/rat/rn3/rmsk
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /cluster/bluearc/rat/rn3/softNib
    mkdir -p /cluster/bluearc/rat/rn3/softNib
    cp -p softNib/chr*.nib /cluster/bluearc/rat/rn3/softNib

    # New RepeatMasker lineage-specific annotation
    # Hiram ran /cluster/bluearc/rat/rn3/rmsk.spec/runArian
    # to generate /cluster/bluearc/rat/rn3/rmsk.spec/chrN.fa.out_mus_hum
    # This script loops through .out's, running 
    # DateRepsinRMoutput.pl <.out> -query rat -comp mouse -comp human
    # Extract repeats not in mouse (0 in column 1)
    cd /cluster/bluearc/rat/rn3
    mkdir linSpecRep.notInMouse
    foreach f (rmsk.spec/*.out_mus_hum)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end

    # copy to iscratch and sync
    ssh kkr1u00
    cd /iscratch/i
    mkdir -p mm3.RM030619
    cd mm3.RM030619
    #cp -r /cluster/bluearc/rat/rn3/linSpecRep.notInMouse .
    /cluster/bin/scripts/iSync


# BLASTZ MOUSE MM3 (IN PROGRESS 2003-07-17 kate) 
# NOTE: This uses mm3.RM030619, which is MM3 masked with new RepeatMasker

    ssh kkstore
    mkdir -p /cluster/data/rn3/bed/blastz.mm3
    mkdir -p /cluster/bluearc/hg/rn3/bed/blastz.mm3
    cd /cluster/data/rn3/bed/blastz.mm3
    cat << '_EOF_' > DEF
# mouse vs. rat
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=50000
BLASTZ_T=2
# scoring matrix
BLASTZ_Q=/cluster/data/blastz/mus_rat.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Rat
SEQ1_DIR=/scratch/rat/rn3/softNib/
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInMouse/
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/iscratch/i/mm3.RM030619/mixedNib/
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/mm3.RM030619/linSpecRep.notInRat/
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/bluearc/hg/rn3/bed/blastz.mm3

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'


# Save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.rn3-mm3.RM030619 

    ssh kk
    cd /cluster/data/rn3/bed/blastz.mm3

    # source the DEF file
    bash
    . ./DEF
    cp DEF $BASE

    # follow the next set of directions slavishly
    mkdir -p run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > run/j

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    cp $BASE/xdir.sh .
    sh xdir.sh
    cd run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2

    # make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
        # 36504 jobs
    para try
    para check
    para push
    # ... etc ...
       # 37 min longest job
       # 2.3 hours elapsed

    # post-process blastz
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3
        #   source the DEF file again in case you are coming back to this
    bash
    . ./DEF
    
    # a new run directory
    mkdir -p run.1
    
    mkdir -p $BASE/lav
    
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1

    # make sure the job list is OK
    wc -l jobList
       # 312 jobs 
    head jobList

    # run on cluster
    #ssh kkr9u01
    ssh kk
    cd /cluster/data/rn3/bed/blastz.mm3/run.1
    para create jobList
    para try
    para check
    para push
    # etc.
    # 10 minutes total 

    # convert lav files to axt
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3
    mkdir axtChrom
    
    # a new run directory
    mkdir run.2
    cd run.2

    # create template file for gensub2
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-chromlav2axt /cluster/bluearc/hg/rn3/bed/blastz.mm3/lav/$(root1) {check out line+ /cluster/data/rn3/bed/blastz.mm3/axtChrom/$(root1).axt} /cluster/bluearc/rat/rn3/softNib /iscratch/i/mm3.RM030619/mixedNib
#ENDLOOP
'_EOF_'
    ls -1S /cluster/bluearc/hg/rn3/bed/blastz.mm3/lav > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 44 jobs
    head jobList

    ssh kk
    # NOTE: would have run this on rack 9, but /iscratch/i/mm3.RM030619
    # not available there
    cd /cluster/data/rn3/bed/blastz.mm3
    cd run.2
    para create jobList
    para try
    para check
    para push
        # 10 minutes ?

    # copy chrom axt's back to fileserver
    cd /cluster/data/rn3/bed/blastz.mm3
    mkdir -p axtChrom
    cp $base/axtChrom/*.axt axtChrom
    
    # translate sorted axt files into psl
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3
    mkdir -p pslChrom
    set tbl = "blastzMm3"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load database tables
    ssh hgwdev
    set tbl = "blastzMm3"
    cd /cluster/data/rn3/bed/blastz.mm3
    cd pslChrom
    /cluster/bin/i386/hgLoadPsl rn3 chr*_${tbl}.psl
    # create trackDb/rat/rn3/trackDb.ra entry:
# track blastzMm3
# shortLabel BLASTZ Mouse
# longLabel All BLASTZ Mouse alignments
# group compGeno
# priority 111
# visibility hide
# color 100,50,0
# altColor 255,240,200
# spectrum on
# type psl xeno hg15


# MAKE BLASTZ BEST MOUSE MM3 (DONE 2003-07-23 kate)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3
    
    # copy chrom axt's to bluearc, to avoid hitting fileserver too hard
    cp -r axtChrom /cluster/bluearc/hg/rn3/bed/blastz.mm3
    mkdir -p axtBest pslBest
    mkdir run.3
    cd run.3

    # create script to filter files 
    cat << '_EOF_' > doBestAxt
#!/bin/csh -f
# usage: doBestAxt chr axt-file best-file psl-file
/cluster/bin/i386/axtBest $2 $1 $3 -minScore-300
sleep 1
/cluster/bin/i386/axtToPsl $3 /cluster/data/rn3/bed/blastz.mm3/S1.len /cluster/data/rn3/bed/blastz.mm3/S2.len $4
'_EOF_'
    chmod +x doBestAxt
    cd axtChrom
    ls -1S | sed 's/.axt$//' > ../run.3/chrom.list
    cd ../run.3

    # create template for cluster job
    cat << '_EOF_' > gsub
#LOOP
doBestAxt $(root1) /cluster/bluearc/hg/rn3/bed/blastz.mm3/axtChrom/$(root1).axt {check out line+ /cluster/data/rn3/bed/blastz.mm3/axtBest/$(root1).axt} {check out line+  /cluster/data/rn3/bed/blastz.mm3/pslBest/$(root1)_blastzBestMm3.psl}
#ENDLOOP
'_EOF_'
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 44 jobs
    head jobList

    ssh kk
    cd /cluster/data/rn3/bed/blastz.mm3
    cd run.3
    para create jobList
    para try
    para check
    para push
        # 1 hour ?

    # chr1 too large for kk nodes -- reran on kkr1u00 (fileserver would do)

    ./doBestAxt chr1 /cluster/bluearc/hg/rn3/bed/blastz.mm3/axtChrom/chr1.axt /cluster/data/rn3/bed/blastz.mm3/axtBest/chr1.axt /cluster/data/rn3/bed/blastz.mm3/pslBest/chr1_blastzBestMm3.psl
        # Read 186121 elements from /cluster/bluearc/hg/rn3/bed/blastz.mm3/axtChrom/chr1.axt
        # Allocated 268113159 elements in array
        # 118172 elements in after soft filter.
        # Output 115210 alignments including 0 trimmed from overlaps
        # Bases in 236687179, bases out 164536193 (69.52%)

    # Load tables
     ssh hgwdev
     set base="/cluster/data/rn3/bed/blastz.mm3"
     set tbl="blastzBestMm3"
     cd $base/pslBest
     /cluster/bin/i386/hgLoadPsl rn3 chr*_${tbl}.psl

     # check results
     featureBits rn3 blastzBestMm3
        # 1667035238 bases of 2571104688 (64.837%) in intersection
     # no mouse alignment on rn2 
     featureBits rn3 blastzMm3
        # 1669090687 bases of 2571104688 (64.917%) in intersection


    # create trackDb/rat/rn3/trackDb.ra entry:
# track blastzBestMm3
# shortLabel BLASTZ Mouse
# longLabel All BLASTZ Mouse alignments
# group compGeno
# priority 111
# visibility hide
# color 100,50,0
# altColor 255,240,200
# spectrum on
# type psl xeno hg15

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/rn3/axtBestMm3
     cd /gbdb/rn3/axtBestMm3
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/rn3/axtBestMm3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('mm3','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     # already done, above
     # hgsql rn3 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql rn3 < axtInfoInserts.sql


# CHAIN MOUSE BLASTZ (DONE 2003-07-24 kate)

    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain

# Run axtChain on little cluster
    ssh kkr1u00
    cd /cluster/data/rn3/bed/blastz.mm3
    mkdir -p axtChain/run1
    cd /cluster/data/rn3/bed/blastz.mm3/axtChain/run1
    ls -1S /cluster/data/rn3/bed/blastz.mm3/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'

    cat << '_EOF_' > doChain
#!/bin/csh
    axtFilter -notQ=chrUn_random $1 | axtChain stdin /iscratch/i/rn3/bothMaskedNibs /iscratch/i/mm3.RM030619/mixedNib $2 > $3
'_EOF_'
    chmod a+x doChain
    mkdir out chain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...

    # now on the cluster server, sort chains
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    # these steps take ~20 minutes
    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/rn3/bed/blastz.mm3/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain rn3 ${c}_chainMm3 $i
        echo done $c
    end


# NET MOUSE BLASTZ (IN PROGRESS 2003-07-24 kate)

    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      chainPreNet $i /cluster/data/rn3/chrom.sizes \
                        /cluster/data/mm3/chrom.sizes ../preNet/$i
    end
    cd ..
    # This foreach loop will take about 15 min to execute.

    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      chainNet $i -minSpace=1 /cluster/data/rn3/chrom.sizes \
                            /cluster/data/mm3/chrom.sizes ../n1/$n /dev/null
    end
    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net

    ssh hgwdev
    cd /cluster/store3/rn3/bed/blastz.mm3/axtChain
    netClass hNoClass.net rn3 mm3 mouse.net -tNewR=/cluster/bluearc/rat/rn3/linSpecRep.notInMouse -qNewR=/cluster/bluearc/mm3.RM030619/linSpecRep.notInRat

    # If things look good do
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.mm3/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn mouse.net > mouseSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/rn3/bed/blastz.mm3/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet rn3 netMm3 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet rn3 syntenyMm3 stdin

    # Add entries for net and chain to rat/rn3 trackDb


# BLASTZ Self (IN PROGRESS 2003-07-18 kate) 

    ssh kkstore
    mkdir -p /cluster/data/rn3/bed/blastz.rn3
    cd /cluster/data/rn3/bed/blastz.rn3
    cat << '_EOF_' > DEF
# rat vs. rat
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET
# Rat
SEQ1_DIR=/iscratch/i/rn3/bothMaskedNibs/
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
# not used
SEQ1_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInMouse/
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/iscratch/i/rn3/bothMaskedNibs/
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInMouse/
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/store3/rn3/bed/blastz.rn3

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'


# Save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.rn3-rn3

    ssh kk
    cd /cluster/data/rn3/bed/blastz.rn3

    # source the DEF file
    bash
    . ./DEF

    # follow the next set of directions slavishly
    mkdir -p $BASE/run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > $BASE/run/j

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    sh $BASE/xdir.sh
    cd $BASE/run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2

    # make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
        # 97344 jobs 
    para try
    para check
    para push
    # ... etc ...
       # 1.3 hr longest job

    # post-process blastz

# BLASTZ Human hg15 (IN PROGRESS 2003-07-20 kate) 

    # Extract lineage-specific repeats vs. human
    ssh kkstore
    cd /cluster/bluearc/rat/rn3
    mkdir linSpecRep.notInHuman
    foreach f (rmsk.spec/*.out_mus_hum)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInHuman/$base.out.spec
    end

    mkdir -p /cluster/data/rn3/bed/blastz.hg15
    cd /cluster/data/rn3/bed/blastz.hg15
    cat << '_EOF_' > DEF
# rat vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Rat
SEQ1_DIR=/iscratch/i/rn3/bothMaskedNibs/
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
# not used
SEQ1_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman/
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
SEQ2_DIR=/iscratch/i/gs.16/build33/chromTrfMixedNib/
SEQ2_RMSK=/iscratch/i/gs.16/build33/rmsk/
SEQ2_SMSK=/iscratch/i/gs.16/build33/linSpecRep/
SEQ2_FLAG=-primate
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/store3/rn3/bed/blastz.hg15

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'


# Save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.rn3-hg15

    ssh kk
    cd /cluster/data/rn3/bed/blastz.hg15

    # source the DEF file
    bash
    . ./DEF

    # follow the next set of directions slavishly
    mkdir -p $BASE/run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > $BASE/run/j

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    sh $BASE/xdir.sh
    cd $BASE/run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2

    # make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
        # 42120 jobs
    para try
    para check
    para push
    # ... etc ...

    # post-process blastz


# SWAPPING HUMAN-RAT BLASTZ ALIGNMENTS TO RAT-HUMAN (DONE 2003-07-11 kate)
    ssh kkstore
    # Human-rat alignments were already run and processed into axt.  
    # Swap target and query to get rat-human alignments.  
    set aliDir = "/cluster/data/hg15/bed/blastz.rn3"
    set revAliDir = "/cluster/data/rn3/bed/blastz.hg15.swap"
    mkdir $revAliDir
    cd $revAliDir
    # axtBest will need .len files - copy those, swap S1<->S2
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    # Swap target and query coords, then re-apportion alignments so that 
    # unsorted/chrN.axt has all the alignments with chrN as target.
    cat $aliDir/axtChrom/chr*.axt \
    | /cluster/bin/i386/axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | /cluster/bin/i386/axtSplitByTarget stdin unsorted
    # Sort the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    rm -r unsorted

    # Create psl from sorted axt
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.hg15.swap
    set tbl = "blastzHg15"
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # load blastz results
    ssh hgwdev
    cd /cluster/data/rn3/bed
    mv blastz.hg15.swap blastz.hg15
    cd blastz.hg15
    cd pslChrom
    /cluster/bin/i386/hgLoadPsl rn3 chr*_*.psl
    # create trackDb/rat/rn3/trackDb.ra entry:
# track blastzHg15
# shortLabel BLASTZ Human
# longLabel All BLASTZ Human alignments
# group compGeno
# priority 111
# visibility hide
# color 100,50,0
# altColor 255,240,200
# spectrum on
# type psl xeno hg15


# CHAIN HUMAN BLASTZ (DONE 2003-07-16 kate)

    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.hg15
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    # create shell script to run jobs on file server
    # cat << '_EOF_' > serialJobList
#LOOP
# something like this
#doChain $1 chain/$1.chain  out/$1.out}
#ENDLOOP
# '_EOF_'
    cat << '_EOF_' > doChain
#!/bin/csh
    axtFilter -notQ=chrUn_random $1 | axtChain stdin /cluster/bluearc/rn3/softNib /cluster/data/hg15/nib $2 > $3
'_EOF_'
    chmod a+x doChain
    csh serialJobList &
    # this took 8.5 hours on kkstore

# Run axtChain on little cluster
    # ssh kkr1u00
    # cd /cluster/data/rn3/bed/blastz.hg15
    # mkdir -p axtChain/run1
    # cd /cluster/data/rn3/bed/blastz.hg15/axtChain/run1
    # ls -1S /cluster/data/rn3/bed/blastz.hg15/axtChrom/*.axt > input.lst
    # cat << '_EOF_' > gsub
#LOOP
# doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
 #ENDLOOP
#'_EOF_'
    # cat << '_EOF_' > doChain
#!/bin/csh
    # axtFilter -notQ=chrUn_random $1 | axtChain stdin /iscratch/i/rn3/bothMaskedNibs /scratch/hg/gs.16/build33/chromTrfMixedNib $2 > $3
#'_EOF_'
    # chmod a+x doChain
    # mkdir out chain
    # gensub2 input.lst single gsub jobList
    # para create jobList
    # para try
    # para push # ... etc ...

    # now on the cluster server, sort chains
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.hg15/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    # these steps take ~20 minutes
    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/rn3/bed/blastz.hg15/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain rn3 ${c}_chainHg15 $i
        echo done $c
    end

# NET HUMAN BLASTZ (DONE 2003-07-16 kate)

    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.hg15/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      chainPreNet $i /cluster/data/rn3/chrom.sizes \
                        /cluster/data/hg15/chrom.sizes ../preNet/$i
    end
    cd ..
    This foreach loop will take about 15 min to execute.

    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      chainNet $i -minSpace=1 /cluster/data/rn3/chrom.sizes \
                            /cluster/data/hg15/chrom.sizes ../n1/$n /dev/null
    end
    cd ..
    cat n1/*.net | netSyntenic stdin hNoClass.net

    ssh hgwdev
    cd /cluster/store3/rn3/bed/blastz.hg15/axtChain
    netClass hNoClass.net rn3 hg15 human.net -tNewR=/cluster/data/rn3/bed/linSpecRep -qNewR=/cluster/data/hg15/bed/linSpecRep

    # If things look good do
    ssh kkstore
    cd /cluster/data/rn3/bed/blastz.hg15/axtChain
    rm -r n1 hNoClass.net
    Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/rn3/bed/blastz.hg15/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet rn3 netHg15 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet rn3 syntenyHg15 stdin

    # Add entries for net and chain to rat/rn3 trackDb


# MAKE THE BLASTZBESTHUMAN TRACK FROM RN3 AXT FILES (DONE 2003-07-16 baertsch, kate)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/data/rn3/bed/blastz.hg15"
    set seq1_dir="/cluster/data/rn3/mixedNib/"
    set seq2_dir="/cluster/data/hg15/mixedNib/"
    set tbl="blastzBestHg15"
    cd $base
    mkdir -p axtBest pslBest
    foreach f (axtChrom/chr*.axt)
      set chr=$f:t:r
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    # If some chromosome's alignments were too big and caused axtSort to 
    # run out of memory, split it in half (by 4-line axt records) and 
    # run axtBest just on the halves.  
    foreach chr (chr1)
      echo two-pass axtBesting $chr
      set len = `wc -l < axtChrom/$chr.axt`
      set numRec = `expr $len / 4`
      if (($numRec * 4) != $len) then
        echo "Uh-oh: length of axtChrom/$chr.axt is $len, not a multiple of 4"
        break
      endif
      set halfRec   = `expr $numRec / 2`
      set halfLen   = `expr $halfRec \* 4`
      set halfLenp1 = `expr $halfLen + 1`
      head -$halfLen   axtChrom/$chr.axt > axtChrom/$chr.h0.axt
      tail +$halfLenp1 axtChrom/$chr.axt > axtChrom/$chr.h1.axt
      axtBest axtChrom/$chr.h0.axt $chr axtChrom/$chr.h0.axtBest -minScore=300
      axtBest axtChrom/$chr.h1.axt $chr axtChrom/$chr.h1.axtBest -minScore=300
      cat axtChrom/$chr.h{0,1}.axtBest > axtBest/$chr.axt
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
      rm axtChrom/$chr.h*
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store3/rn3/bed/blastz.hg15"
     set tbl="blastzBestHg15"
     cd $base/pslBest
     hgLoadPsl rn3 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/rn3/axtBestHg15
     cd /gbdb/rn3/axtBestHg15
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/rn3/axtBestHg15/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('hg15','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql rn3 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql rn3 < axtInfoInserts.sql


# MAKE AXTTIGHT FROM AXTBEST (DONE 2003-07-21 kate)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    # NOTE: currently the axtBest's are the blastz.hg15.2003-07-09 directory
    # since blastz.hg15 is in use for rerun of blastz with
    # updated lineage-specific repeats for new RepeatMasker
     
    ssh kkstore
    cd ~/rn3/bed/blastz.hg15.2003-07-09/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        /cluster/data/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      /cluster/bin/i386/axtToPsl $i \
                ../S1.len ../S2.len ../pslTight/${c}_blastzTightHg15.psl
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/rn3/bed/blastz.hg15.2003-07-09
    cd pslTight
    hgLoadPsl rn3 chr*_blastzTightHg15.psl


# MAKE MULTIPLE ALIGNMENT (MAF) FILES FROM BEST AXT'S (In Progress 2003-07-22 kate)

    ssh kkstore

    # rat/human
    cd /cluster/data/rn3/bed/blastz.hg15.2003-07-09
    mkdir maf
    cd axtBest
    foreach i (*.axt)
      set c = $i:r
      echo "Making maf for chr $c"
      /cluster/bin/i386/axtToMaf -tPrefix=rn3. -qPrefix=hg15. $i \
            /cluster/data/rn3/chrom.sizes /cluster/data/hg15/chrom.sizes  \
                ../maf/${c}.rh.maf
    end
    # 30 minutes ?

    # rat/mouse
    cd /cluster/data/rn3/bed/blastz.mm3
    mkdir maf
    cd axtBest
    foreach i (*.axt)
      set c = $i:r
      echo "Making maf for chr $c"
      /cluster/bin/i386/axtToMaf -tPrefix=rn3. -qPrefix=mm3. $i \
            /cluster/data/rn3/chrom.sizes /cluster/data/mm3/chrom.sizes  \
                ../maf/${c}.rm.maf
    end
    # 30 minutes ?

    # Run multiple alignment using Webb Miller's multiz
    # Note: use - for 3rd arg when doing rodent/rodent (close species)
    # See penn/multiz/README for details 
    ssh kkstore
    cd /cluster/data/rn3/bed
    mkdir -p multiz.hg15-mm3/maf
    cd  multiz.hg15-mm3
cat << "EOF" > doMultiz
#!/bin/csh -f    
    cd /cluster/data/rn3/bed
    cd blastz.hg15.2003-07-09/maf
    foreach f (*.rh.maf)
        set c = $f:r:r
        echo "Multiz on $c"
        nice /cluster/bin/penn/multiz $f ../../blastz.mm3/maf/${c}.rm.maf - \
                                 > ../../multiz.hg15-mm3/maf/${c}.rmh.maf
    end
"EOF"
    csh doMultiz >&! doMultiz.log &
    tail -100f doMultiz.log
    # 3 hours ? 

    # copy files to cluster I/O server
    mkdir -p /cluster/bluearc/hg/rn3/bed/blastz.hg15.2003-07-09/maf
    cp -r cluster/data/rn3/bed/blastz.hg15.2003-07-09/maf /cluster/bluearc/hg/rn3/bed/blastz.hg15.2003-07-09
    mkdir -p /cluster/bluearc/hg/rn3/bed/blastz.mm3/maf
    cp -r cluster/data/rn3/bed/blastz.mm3/maf /cluster/bluearc/hg/rn3/bed/blastz.mm3

    set multizDir = /cluster/data/rn3/bed/multiz.hg15-mm3
    cd $multizDir
    mkdir run
    cd run
cat << "EOF" > doMultiz.kk
#LOOP
/cluster/bin/penn/multiz /cluster/bluearc/hg/rn3/bed/blastz.hg15.2003-07-09/maf/$1.rh.maf /cluster/bluearc/hg/rn3/bed/blastz.mm3/maf/$1.rm.maf - > /cluster/data/rn3/bed/multiz.hg15-mm3/maf/$1.rmh.maf
#ENDLOOP
"EOF"
    chmod +x doMultiz.kk

cat << "EOF" > gsub
#LOOP
doMultiz.kk $(root1) {check out line+ /cluster/data/rn3/bed/multiz.hg15-mm3/maf/$(root1).rmh.maf}
#ENDLOOP
"EOF"
    cd /cluster/bluearc/hg/rn3/bed/blastz.hg15.2003-07-09/maf
    ls *.maf | awk -F. '{print $1}' > $multizDir/run/chrom.list
    gensub2 chrom.list single gsub jobList
    ssh kkr9u01
    para create jobList
    para try
    para check
    para push

    # setup up external files for database to reference
    ssh hgwdev
    mkdir -p /gbdb/rn3/multizHg15Mm3
    cd /gbdb/rn3/multizHg15Mm3
    foreach f (/cluster/data/rn3/bed/multiz.hg15-mm3/maf/*.maf)
        ln -s $f .
    end

    # load into database
    /cluster/bin/i386/hgLoadMaf rn3 multizHg15Mm3
        #Couldn't find rn3. sequence line 819945 of /gbdb/rn3/multizHg15Mm3/chrX.rmh.maf
        #Indexing and tabulating /gbdb/rn3/multizHg15Mm3/chrX_random.rmh.maf
        #Couldn't find rn3. sequence line 4341 of /gbdb/rn3/multizHg15Mm3/chrX_random.rmh.maf
        #Loading multizHg15Mm3 into database
        #Warning: load of multizHg15Mm3 did not go as planned: 3512170 record(s), 0 row(s) skipped, 27410 warning(s) loading ./multizHg15Mm3.tab



# AUTO UPDATE GENBANK MRNA RUN  (DONE - 2003-07-07 - Hiram)

    ssh eieio
    cd /cluster/store5/genbank
    set db = rn3
    set nibGlob = '/cluster/bluearc/rat/rn3/softNib/chr*.nib'
    set liftFile = /cluster/bluearc/rat/rn3/liftAll.lft
    # the iservers were acting up, the following uses the bluearc instead
    # make sure 'ssh localhost' works before running this:
    nice bin/gbAlignStep -verbose=1 -initial -iserver=localhost \
	-clusterdir=/cluster/bluearc/genbank/work \
	-srcDb=genbank $db "$nibGlob" $liftFile &
    # This job took almost two days
# Checking finished jobsCompleted: 216306 of 216306 jobs
# CPU time in finished jobs:   74560544s 1242675.73m 20711.26h  862.97d  2.364 y
# IO & Wait Time:               1371840s   22864.00m   381.07h   15.88d  0.044 y
# Average job time:                 351s       5.85m     0.10h    0.00d
# Longest job:                     2478s      41.30m     0.69h    0.03d
# Submission to last job:        151934s    2532.23m    42.20h    1.76d

    # To watch the progress of your cluster job, go to machine kk and
    # cd /cluster/store5/genbank/work/initial.rn3/align
    # where the batch file is.  You can now do normal parasol checking
    # operations.  Beware of "para check" it can take quite a bit of time
    # if your batch job is very large.  'parasol list batches' or
    # 'parasol list users' may be quicker to take a look at status.

    #  After that is finished successfully, load the mRNAs:
    #  The drop and load is faster if tables have been loaded before.
    ssh hgwdev
    cd /cluster/store5/genbank
    ./bin/i386/gbLoadRna -drop  rn3
    nice ./bin/gbDbLoadStep -verbose=1 -initialLoad rn3
    # This load took about 7 hours

    # native mRNAs were suspect due to bug in gbBlat script, redoing them.
    # alignment now uses a config file, so add rn3 to etc/genbank.conf
        
    # remove suspect mRNAs.
    rm -f data/aligned/genbank.136.0/rn3/*/mrna.*

    # align genbank and refseq mrnas, using bluearc for cluster fs:
    nice bin/gbAlignStep -type=mrna -verbose=1 -initial -iserver=no -clusterRootDir=/cluster/bluearc/genbank rn3&

    # need to clean out all mRNAs from database, but leave ESTs inplace.
      - drop these tables: chr*_mrna all_mrna xenoMrna mrnaOrientInfo
      - selectively delete mrna related rows:
        delete from imageClone where type = 'mRNA';
        delete from mrna where type = 'mRNA';
        delete from gbStatus where type = 'mRNA';
        delete from gbSeq where type = 'mRNA';
        delete from gbExtFile where path like '%/mrna.fa';

    # load genbank and refseq mRNAs into database
    nice ./bin/gbDbLoadStep -type=mrna -verbose=1 rn3

    # refseq protein ids included version, which caused searches to fail.
    # clean our refseq sequences and reload:
      drop table refFlat,refGene,refLink,refSeqAli,refSeqStatus;
      delete from gbSeq where acc like 'NM_%' or acc like 'NP_%';
      delete from gbStatus where acc like 'NM_%' or acc like 'NP_%';
      delete from mrna where acc like 'NM_%';
      delete from gbLoaded where srcDb='RefSeq';
     nice ./bin/gbDbLoadStep -verbose=1 rn3

CREATE RNACLUSTER TABLE (TO DO)
    # Make sure that refSeqAli, estOrientInfo and mrnaOrientInfo tables are 
    # made already (see above).
    ssh hgwdev
    mkdir -p ~/rn3/bed/rnaCluster/chrom
    cd ~/rn3/bed/rnaCluster
    foreach i (~/rn3/?{,?})
      foreach f ($i/chr*.fa)
        set c = $f:t:r
        clusterRna rn3 /dev/null chrom/$c.bed -chrom=$c
        echo done $c
      end
    end
    hgLoadBed rn3 rnaCluster chrom/*.bed


PRODUCING GENSCAN PREDICTIONS (DONE - 2003-07-09 - Hiram)
    
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. (genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    mkdir -p ~/rn3/bed/genscan
    cd ~/rn3/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/store3/rn3/?{,?}/chr*/chr?{,?}{,_random}_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/home/hiram/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push

    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    # chr14_21, chr16_4
    #	There was one job that did crash in this manner.
    #	It was run manually:
    # /cluster/home/hiram/bin/i386/gsBig /cluster/store3/rn3/10/chr10_3/chr10_3.fa.masked gtf/chr10_3.fa.gtf -trans=pep/chr10_3.fa.pep -subopt=subopt/chr10_3.fa.bed -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=1200000
# Checking finished jobsCompleted: 590 of 591 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:     312553s    5209.22m    86.82h    3.62d  0.010 y
# IO & Wait Time:                  1927s      32.11m     0.54h    0.02d  0.000 y
# Average job time:                 533s       8.88m     0.15h    0.01d
# Longest job:                    23072s     384.53m     6.41h    0.27d
# Submission to last job:         43744s     729.07m    12.15h    0.51d

    
    # Convert these to chromosome level files as so:
    ssh kkstore
    cd ~/rn3/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/rn3/bed/genscan
    ldHgGene rn3 genscan genscan.gtf
    hgPepPred rn3 generic genscanPep genscan.pep
    hgLoadBed rn3 genscanSubopt genscanSubopt.bed


TWINSCAN GENE PREDICTIONS (TO DO)

    mkdir -p ~/rn3/bed/twinscan
    cd ~/rn3/bed/twinscan
    wget http://genome.cse.wustl.edu/~bio/rat/Jan03/rat_Jan03_03-26-03.tgz
    gunzip -c *.tgz | tar xvf -
    rm -r chr_tx
    # clean up chrom field of GTF files
    foreach f (chr_gtf/chr*.gtf)
      set chr = $f:t:r
      sed -e "s/^[a-zA-Z0-9]*/$chr/" $f > chr_gtf/$chr-fixed.gtf
    end
    # pare down protein FASTA header to id and add missing .a:
    foreach f (chr_ptx/chr*.ptx)
      set chr = $f:t:r
      perl -wpe 's/^\>.*\s+source_id\s*\=\s*(\S+).*$/\>$1.a/;' < \
        chr_ptx/$chr.ptx > chr_ptx/$chr-fixed.fa
    end
    ldHgGene rn3 twinscan chr_gtf/chr*-fixed.gtf -exon=CDS
    hgPepPred rn3 generic twinscanPep chr_ptx/chr*-fixed.fa


PRODUCING TETRAODON FISH ALIGNMENTS (TO DO)

o - Download sequence from ... and put it on the cluster local disk
    at
       /scratch/hg/fish
o - Do fish/rat alignments.
       ssh kk
       cd ~/rn3/bed
       mkdir blatFish
       cd blatFish
       mkdir psl
       ls -1S /scratch/hg/fish/* > fish.lst
       ls -1S /scratch/hg/rn3/trfFa/* > rat.lst
       cp ~/lastRn/blatFish/gsub .
       gensub2 rat.lst fish.lst gsub spec
       para create spec
       para try
     Make sure jobs are going ok with para check.  Then
       para push
     wait about 2 hours and do another
       para push
     do para checks and if necessary para pushes until done
     or use para shove.
o - Sort alignments as so 
       pslCat -dir psl | liftUp -type=.psl stdout ~/rn3/jkStuff/liftAll.lft warn stdin | pslSortAcc nohead chrom /cluster/store2/temp stdin
o - Copy to hgwdev:/scratch.  Rename to correspond with tables as so and 
    load into database:
       ssh hgwdev
       cd ~/rn3/bed/blatFish/chrom
       foreach i (chr?{,?}{,_random}.psl)
           set r = $i:r
           mv $i ${r}_blatFish.psl
       end
       hgLoadPsl rn3 *.psl
       hgLoadRna addSeq rn3 /cluster/store2/fish/seq15jun2001/*.fa

# PRODUCING SQUIRT ALIGNMENTS  (TO DO)
    ssh kkstore
    mkdir -p ~/rn3/bed/blatCi1
    cd ~/rn3/bed/blatCi1
    ls -1S /iscratch/i/squirt/ci1/queryFa/*.fa > squirt.lst
    ls -1S /scratch/hg/rn3/trfFa/* > rat.lst

    rm -rf psl
    foreach ctg (`cat rat.lst`)
      mkdir -p psl/$ctg:t:r
    end
    # get gsub2D from someplace
    gensub2 rat.lst squirt.lst gsub2D spec

    ssh kk
    cd ~/rn3/bed/blatCi1
    para create spec
    ....
    # When cluster run is done, sort alignments:
    ssh kkstore
    cd ~/rn3/bed/blatCi1
    mkdir /tmp/$LOGNAME
    pslSort dirs raw.psl /tmp/$LOGNAME psl/*
    pslReps raw.psl cooked.psl /dev/null -minAli=0.05
    liftUp -nohead lifted.psl ../../jkStuff/liftAll.lft warn cooked.psl
    pslSortAcc nohead chrom /tmp/$LOGNAME lifted.psl

    # Rename to correspond with tables as so and load into database:
    ssh hgwdev
    cd ~/rn3/bed/blatCi1/chrom
    rm -f chr*_blatCi1.psl
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        mv $i ${r}_blatCi1.psl
    end
    hgLoadPsl rn3 *.psl

    # Make squirt /gbdb/ symlink
    mkdir /gbdb/rn3/squirtSeq
    cd /gbdb/rn3/squirtSeq
    ln -s /cluster/store5/squirt/ci1/ciona.rm.fasta

PRODUCING FUGU FISH ALIGNMENTS (TO DO)

    # (Already done, for mm2:)
    # Download sequence to /cluster/store3/fuguSeq from ... and put it on the 
    # cluster local disk at /scratch/hg/fugu on kkstore.
    # Sequence was downloaded from:
    # ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_mask.fasta.Z
    # ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_prot.fasta.Z
    # mkdir split2.5Mb; cd split2.5Mb;
    # faSplit about ../fugu_v3_mask.fasta 2500000 fuguSplit

    ssh kkr1u00
    rm -rf /iscratch/i/fugu
    mkdir /iscratch/i/fugu
    cp -p /cluster/store3/fuguSeq/split2.5Mb/*.fa /iscratch/i/fugu
    ~kent/bin/iSync

    ssh kk
    mkdir ~/rn3/bed/blatFugu
    cd ~/rn3/bed/blatFugu
    ls -1S /iscratch/i/fugu/* > fugu.lst
    ls -1S /scratch/hg/rn3/trfFa/* > rat.lst
    cp ~/lastRn/bed/blatFugu/gsub .
    mkdir psl
    foreach f (~/rn3/?{,?}/chr*/chr?{,?}{,_random}_?{,?}.fa)
      set c=$f:t:r
      mkdir psl/$c
    end
    gensub2 rat.lst fugu.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check
    # Sort alignments:
    ssh kkstore
    cd ~/rn3/bed/blatFugu
    pslCat -dir psl/* \
      | liftUp -type=.psl stdout ~/rn3/jkStuff/liftAll.lft warn stdin \
      | pslSortAcc nohead chrom /cluster/store2/temp stdin

    # load into database:
    ssh hgwdev
    cd ~/rn3/bed/blatFugu/chrom
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        mv $i ${r}_blatFugu.psl
    end
    hgLoadPsl rn3 *.psl
    mkdir -p /gbdb/rn3/fuguSeq
    cd /gbdb/rn3/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta
    cd /cluster/store2/temp
    hgLoadRna addSeq rn3 /gbdb/rn3/fuguSeq/fugu_v3_mask.fasta


MAKE LIFT FILE FOR AGPS (TO DO)
    ssh kkstore
    cd ~/rn3/jkStuff
    ./jkStuff/agpToLift.pl chrom.sizes ?{,?}/chr?{,?}{,_random}.agp \
      > jkStuff/liftRNOR.lft


LOAD BACTIG POSITIONS (DONE - 2003-07-14 - Hiram)

    ssh hgwdev
    mkdir -p ~/rn3/bed/bactigPos
    cd ~/rn3/bed/bactigPos
    awk "-F\t" '{printf "%s\t%d\t%s\t%s\t%s\t%s\n", $1, $2-1, $3, $4, $5, $6;}' < ../../bactigs.contigs > bactigPos.bed
    hgLoadBed rn3 bactigPos bactigPos.bed \
      -noBin -sqlTable=$HOME/kent/src/hg/lib/bactigPos.sql


LOAD CPGISSLANDS (DONE - 2003-07-08 - Hiram)
    ssh hgwdev
    mkdir -p ~/rn3/bed/cpgIsland
    cd ~/rn3/bed/cpgIsland
    # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
    # copy the tar file to the current directory
    cp -p /cluster/store4/rn2/bed/cpgIsland/cpg_dist.tar .
    tar xvf cpg_dist.tar 
    cd cpg_dist
    gcc readseq.c cpg_lh.c -o cpglh.exe
    
    ssh kkstore
    cd ~/rn3/bed/cpgIsland
    foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpg_dist/cpglh.exe $f > $fout.cpg
    end
    # copy filter.awk from a previous release
    cp -p /cluster/store4/rn2/bed/cpgIsland/filter.awk .
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd ~/rn3/bed/cpgIsland
    hgLoadBed rn3 cpgIsland -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed


LOAD SOFTBERRY GENES (DONE - 2003-07-17 - Hiram)
     cd /cluster/store3/rn3/bed
     mkdir softberry
     cd softberry
     wget \
	ftp://www.softberry.com/pub/SC_RAT_JUN03/Softb_fgenesh_rat_jun03.tar.gz
     tar xvzf Softb_fgenesh_rat_jun03.tar.gz
     ldHgGene rn3 softberryGene chr*.gff
#	43912 groups 22 seqs 1 sources 4 feature types
#	43912 gene predictions
     hgPepPred rn3 softberry *.protein
     hgSoftberryHom rn3 *.protein

LOAD GENEID GENES (DONE - 2003-07-08 - Hiram)
    mkdir -p ~/rn3/bed/geneid/download
    cd ~/rn3/bed/geneid/download
    foreach f (~/rn3/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/R.norvegicus/rnJun2003/geneid_v1.1/$chr.gtf
      wget http://genome.imim.es/genepredictions/R.norvegicus/rnJun2003/geneid_v1.1/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene rn3 geneid download/*.gtf -exon=CDS
    hgPepPred rn3 generic geneidPep download/*-fixed.prot

SGP GENE PREDICTIONS (DONE - 2003-07-30 - Hiram)
    mkdir -p ~/rn3/bed/sgp/download
    cd ~/rn3/bed/sgp/download
    foreach f (~/rn3/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget http://monstre1.imim.es/genepredictions/R.norvegicus/rnJun2003/SGP/humangp20030410/$chr.gtf
      wget http://monstre1.imim.es/genepredictions/R.norvegicus/rnJun2003/SGP/humangp20030410/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene rn3 sgpGene download/*.gtf -exon=CDS
    hgPepPred rn3 generic sgpPep download/*-fixed.prot


TIGR GENE INDEX (TO DO)
    mkdir -p ~/rn3/bed/tigr
    cd ~/rn3/bed/tigr
    wget ftp://ftp.tigr.org/private/NHGI_mgi_jiashu/TGI_track_RatGenome_Feb2002.tgz
    gunzip -c TGI_track_RatGenome_Feb2002.tgz | tar xvf -
    foreach f (*cattle*)
      set f1 = `echo $f | sed -e 's/cattle/cow/g'`
      mv $f $f1
    end
    foreach o (rat cow human pig rat)
      setenv O $o
      foreach f (chr*_$o*s)
        tail +2 $f | perl -wpe 's /THC/TC/; s/(TH?C\d+)/$ENV{O}_$1/;' > $f.gff
      end
    end
    ldHgGene -exon=TC rn3 tigrGeneIndex *.gff


LOAD STS MAP (TO DO )
     - login to hgwdev
      cd ~/rn3/bed
      rn3 < ~/src/hg/lib/stsMap.sql
      mkdir stsMap
      cd stsMap
      bedSort /projects/cc/hg/mapplots/data/tracks/build28/stsMap.bed stsMap.bed
      - Enter database with "rn3" command.
      - At mysql> prompt type in:
          load data local infile 'stsMap.bed' into table stsMap;
      - At mysql> prompt type

LOAD MGI IDs (TO DO)
      - The Locuslink ID to MGI IDs converstion data file,
        LL2MGI.txt, from Jackson Lab should be found under
        ~/rn3/bed/refSeq
      - login to hgwdev
      
      cd ~/rn3/bed/refSeq
      rn3 < ~/src/hg/lib/mgiID.sql
      - Enter database with "rn3" command.
      - At mysql> prompt type in:
          load data local infile 'LL2MGI.txt' into table MGIid;
      - At mysql> prompt type
          quit

LOAD RATREF TRACK (TO DO)
    First copy in data from kkstore to ~/rn3/bed/ratRef.  
    Then substitute 'genome' for the appropriate chromosome 
    in each of the alignment files.  Finally do:
       hgRefAlign webb rn3 ratRef *.alignments

LOAD AVID RAT TRACK (TO DO)
      ssh cc98
      cd ~/rn3/bed
      mkdir avidRat
      cd avidRat
      wget http://pipeline.lbl.gov/tableCS-LBNL.txt
      hgAvidShortBed *.txt avidRepeat.bed avidUnique.bed
      hgLoadBed avidRepeat avidRepeat.bed
      hgLoadBed avidUnique avidUnique.bed

LOAD SNPS (TO DO)
      - ssh hgwdev
      - cd ~/rn3/bed
      - mkdir snp
      - cd snp
      - Download SNPs from ftp://ftp.ncbi.nlm.nih.gov/pub/sherry/rat.b27.out.gz
      - Unpack.
        createBed < rat.b27.out > snpNih.bed
        hgLoadBed rn3 snpNih snpNih.bed

LOAD ENSEMBL ESTs (TO DO)
     ln -s /cluster/store3/rn3 ~/rn3
     mkdir -p ~/rn3/bed/ensembl
     cd ~/rn3/bed/ensembl
     wget http://www.ebi.ac.uk/~stabenau/rat-est.gz
     wget http://www.ebi.ac.uk/~stabenau/rat-est.pep.gz
     gunzip -c rat-est.gz | \
       perl -w -p -e 's/^(\w)/chr$1/' > rat-est-fixed.gtf
     ldHgGene rn3 ensEst rat-est-fixed.gtf
> The id behind '>' is internal and was not in our gtf dump, so
> you have to do some more parsing.
     # pick out the transcript= attribute -- that's the id to use:
     # also remove the first line:
     gunzip -c rat-est.pep.gz | tail +2 | \
       perl -w -p -e 's/^\>gene_id=.*transcript=(\w+)\s+.*$/\>$1/' > \
       rat-est-fixed.pep
     hgPepPred rn3 generic ensEstPep rat-est-fixed.pep

LOAD ENSEMBLE GENES (TO DO)
     mkdir -p ~/rn3/bed/ensembl
     cd ~/rn3/bed/ensembl
     wget http://www.ebi.ac.uk/~stabenau/rat-ensembl.gz
     wget http://www.ebi.ac.uk/~stabenau/rat-ensembl.pep.gz
     gunzip -c rat-ensembl.gz | \
       perl -w -p -e 's/^(\w)/chr$1/' > rat-ensembl-fixed.gtf
     ldHgGene rn3 ensGene rat-ensembl-fixed.gtf
> rat-ensembl contains stopcodons, due to some glitches in our
> genebuild. The id behind '>' is internal and was not in our gtf dump, so
> you have to do some more parsing.
# pick out the transcript= attribute -- that's the id to use:
# also remove the first line:
     tail +2 rat-ensembl.pep | \
       perl -w -p -e 's/^\>gene_id=.*transcript=(\w+)\s+.*$/\>$1/' > \
       rat-ensembl-fixed.pep
     hgPepPred rn3 generic ensPep rat-ensembl-fixed.pep

LOAD RNAGENES (TO DO)
      - login to hgwdev
      - cd ~kent/src/hg/lib
      - rn3 < rnaGene.sql
      - cd /cluster/store3/rn3/bed
      - mkdir rnaGene
      - cd rnaGene
      - download data from ftp.genetics.wustl.edu/pub/eddy/pickup/ncrna-oo27.gff.gz
      - gunzip *.gz
      - liftUp chrom.gff ../../jkStuff/liftAll.lft carry ncrna-oo27.gff
      - hgRnaGenes rn3 chrom.gff

LOAD EXOFISH (TO DO)
     - login to hgwdev
     - cd /cluster/store3/rn3/bed
     - mkdir exoFish
     - cd exoFish
     - rn3 < ~kent/src/hg/lib/exoFish.sql
     - Put email attatchment from Olivier Jaillon (ojaaillon@genoscope.cns.fr)
       into /cluster/store3/rn3/bed/exoFish/all_maping_ecore
     - awk -f filter.awk all_maping_ecore > exoFish.bed
     - hgLoadBed rn3 exoFish exoFish.bed

LOAD GENIE (TO DO)
     mkdir -p ~/rn3/bed/genieAlt
     cd ~/rn3/bed/genieAlt
     wget http://www.neomorphic.com/mgap/mgscv3/gtf/mgscv3.genie.gtf.tgz
     gunzip -c mgscv3.genie.gtf.tgz | tar xvf -
     ldHgGene rn3 genieAlt mgscv3.genie.gtf/chr*.gtf
     wget http://www.neomorphic.com/mgap/mgscv3/fa/mgscv3.aa.tgz
     gunzip -c mgscv3.aa.tgz | tar xvf -
     hgPepPred rn3 genie geniePep chr*.aa.fa

LOAD GENIE CLONE BOUNDS (TO DO)
     mkdir -p ~/rn3/bed/genieBounds
     cd ~/rn3/bed/genieBounds
     wget http://www.neomorphic.com/mgap/mgscv3/cb.bed/mgscv3_cb.bed.tgz
     gunzip -c mgscv3_cb.bed.tgz | tar xvf -
     - Trim the track definition from each file (these are actually custom 
       track files):
     foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Un)
       tail +2 chr${c}_cb.bed > chr${c}_cb-fixed.bed
     end
     hgLoadBed rn3 genieBounds *-fixed.bed

LOAD SOFTBERRY GENES (TO DO)
     - ln -s /cluster/store3/rn3 ~/rn3
     - cd ~/rn3/bed
     - mkdir softberry
     - cd softberry
     - get ftp://www.softberry.com/pub/SC_MOU_NOV01/softb_mou_genes_nov01.tar.gz
     ldHgGene rn3 softberryGene chr*.gff
     hgPepPred rn3 softberry *.protein
     hgSoftberryHom rn3 *.protein

LOAD GENOMIC DUPES (TO DO)
o - Load genomic dupes
    ssh hgwdev
    cd ~/rn3/bed
    mkdir genomicDups
    cd genomicDups
    wget http://codon/jab/web/takeoff/oo33_dups_for_kent.zip
    unzip *.zip
    awk -f filter.awk oo33_dups_for_kent > genomicDups.bed
    hgsql rn3 < ~/src/hg/lib/genomicDups.sql
    hgLoadBed rn3 -oldTable genomicDups genomicDupes.bed

LOAD RGD CURATED GENES TRACK
    - cd rn3
    - cd bed
    - mkdir rgdGene
    - Browse to http://zephyrus.brc.mcw.edu/cgi-bin/pub/viewcvs.cgi/pub_gbrowse/gff_files/RGD_curated_genes.gff
        This is a web-based CVS page. Click the download link and save the file to ~/rn3/bed/RGD_curated_genes.gff
     - Now massage the data format using:
         rn3/bed/rgdGene/massage.pl
     - Load the data:
        ldHgGene rn3 rgdGene Fixed_RGD_Curated_genes.gff
     - Create the link table for searching
        In mysql for the rn3 database do:
        create table rgdLink (id int primary key, name varchar(32) not null);
        LOAD DATA LOCAL INFILE 'RGD.links' into table rgdLink; 
TWINSCAN GENE PREDICTIONS (DONE 07/14/03)

    mkdir -p ~/rn3/bed/twinscan
    cd ~/rn3/bed/twinscan
    wget http://genome.cse.wustl.edu/~bio/rat/Jun03/rat_Jun03_07-11-03.tgz
    gunzip -c *.tgz | tar xvf -
    rm -r chr_tx
    # clean up chrom field of GTF files
    foreach f (chr_gtf/chr*.gtf)
      set chr = $f:t:r
      sed -e "s/^[a-zA-Z0-9]*/$chr/" $f > chr_gtf/$chr-fixed.gtf
    end
    # pare down protein FASTA header to id and add missing .a:
    foreach f (chr_ptx/chr*.ptx)
      set chr = $f:t:r
      perl -wpe 's/^\>.*\s+source_id\s*\=\s*(\S+).*$/\>$1.a/;' < \
        chr_ptx/$chr.ptx > chr_ptx/$chr-fixed.fa
    end
    ldHgGene rn3 twinscan chr_gtf/chr*-fixed.gtf -exon=CDS
    hgPepPred rn3 generic twinscanPep chr_ptx/chr*-fixed.fa

AXTBEST

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    tcsh
    set base="/cluster/store3/rn3/bed/blastz.hg15"
    set tbl="blastzBestHg15"
    cd $base
    mkdir -p axtBest pslBest
    #chrom 1 is too big
    axtFilter -tStartMax=99999999 chr1.axt >chr1FirstHalf.axt
    axtFilter -tStartMin=100000000 chr1.axt >chr1SecondHalf.axt
    foreach chrdir (`cat chrom.lst`)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
    end
    axtBest axtChrom/chr1FirstHalf.axt chr1 axtBest/chr1FirstHalf.axt -minScore=300
    axtBest axtChrom/chr1SecondHalf.axt chr1 axtBest/chr1SecondHalf.axt -minScore=300
    cd axtBest
    cat chr1FirstHalf.axt chr1SecondHalf.axt > chr1.axt
    rm chr1FirstHalf.axt chr1SecondHalf.axt
    cd ../axtChrom
    rm chr1FirstHalf.axt chr1SecondHalf.axt
    cd ..
    foreach chrdir (`cat chrom.lst`)
      set chr=$chrdir:t
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    # Load tables
    ssh hgwdev
    set base="/cluster/store3/rn3/bed/blastz.hg15"
    set tbl="blastzBestHg15"
    cd $base/pslBest
    hgLoadPsl hg15 chr*_${tbl}.psl

                                                                                
# LIFTING REPEATMASKER .ALIGN FILES (TODO)
foreach f (~/rn3/?{,?}/chr?{,?}{,_random}.fa)

ssh kkstore
cd rn3
foreach c (?{,?})
  foreach d ($c/chr${c}_?{,?} $c/chr${c}_random_?{,?})
    pushd . > /dev/null
    set contig=$d:t
    cd $d
    echo $contig to $contig.fa.align
    /cluster/bin/scripts/liftRMAlign.pl ${contig}.lft > ${contig}.fa.align
    popd > /dev/null
    end
end
#  There are some FYI warnings from the above script, but they
#	are for contigs that RepeatMasker said there was nothing
#	to work with in those contigs so it did not make an align file.

foreach chr (?{,?})
  cd $chr
  echo making symbolic links for chr$chr .fa.align files
  foreach ctg (chr${chr}_?{,?} chr${chr}_random_?{,?})
    ln -s $ctg/$ctg.fa.align .
  end
  cd ..
  if (-e $chr/lift/ordered.lft) then
    echo making $chr/chr$chr.fa.align
    ls -og $chr/lift/ordered.lft
    /cluster/bin/scripts/liftRMAlign.pl $chr/lift/ordered.lft \
      > $chr/chr$chr.fa.align
  endif
  if (-e $chr/lift/random.lft) then
    echo making $chr/chr${chr}_random.fa.align
    ls -og $chr/lift/random.lft
    /cluster/bin/scripts/liftRMAlign.pl $chr/lift/random.lft \
      > $chr/chr${chr}_random.fa.align
  endif
  echo removing symbolic links for chr$chr .fa.align files
  cd $chr
  foreach ctg (chr${chr}_?{,?} chr${chr}_random_?{,?})
    echo rm $ctg/$ctg.fa.align
  end
  cd ..
end
