#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on 
# NCBI build 35 (May 2004 freeze)

# HOW TO BUILD A ASSEMBLY FROM NCBI FILES 
# ---------------------------------------

    # Make gs.18 directory, gs.18/build35 directory, and gs.18/ffa directory.
    ssh eieio
    mkdir /cluster/store5/gs.18
    mkdir /cluster/store5/gs.18/build35
    mkdir /cluster/store5/gs.18/agp
    mkdir /cluster/store5/gs.18/ffa

    #    Make a symbolic link from /cluster/store1 to this location
    #	(I assume there is some use for this later ?)
	
    cd /cluster/store1
    ln -s /cluster/store5/gs.18 ./gs.18
    ln -s /cluster/store5/gs.18/build35 /cluster/data/hg17

    #    Make a symbolic link from your home directory to the build dir:
    #	(Investigate what this is used for, may no longer be necessary)

    ln -s /cluster/store5/gs.18/build35 ~/oo

# NCBI download site, fetch everything into this one directory:

    #	with the machine and password in your $HOME/.netrc file, this
    #	wget command will require no login.  Your $HOME/.netrc file
    #	is set to 'chmod 600 .netrc' to prevent anyone from finding
    #	the data.  (There were some early files that later moved
    #		into an OLD subdirectory.  They were broken.)
    mkdir /cluster/store5/gs.18/ncbi
    cd /cluster/store5/gs.18/ncbi
    wget --timestamping ftp://ftp.ncbi.nlm.nih.gov/build_35/*

    # FYI: agp file format documented at:
    #	http://www.ncbi.nlm.nih.gov/Genbank/WGS.agpformat.html
    # fixup a couple of names for our own purposes here
    cd /cluster/store5/gs.18/agp
    ln -s ../ncbi/chr*.agp ../ncbi/chr*.fa.gz .
    sed -e "s#MT/NC_001807.4#NC_001807#" ../ncbi/chrMT.agp > chrM.agp
    sed -e "s/NG_002392.2/NG_002392/" ../ncbi/DR52.agp > chr6_hla_hap1.agp
    sed -e "s/NG_002433.1/NG_002433/" ../ncbi/DR53.agp > chr6_hla_hap2.agp
    zcat ../ncbi/DR52.fa.gz | \
	sed -e "s/gi|29124352|ref|NG_002392.2/ref|NG_002392/" | \
	gzip > chr6_hla_hap1.fa.gz
    zcat ../ncbi/DR53.fa.gz | \
	sed -e "s/gi|28212470|ref|NG_002433.1/ref|NG_002433/" | \
	gzip > chr6_hla_hap2.fa.gz
    zcat ../ncbi/chrMT.fa.gz | \
	sed -e "s/gi|17981852|ref|NC_001807.4/ref|NC_001807/" | \
	gzip > chrM.fa.gz
    

    #  Put all the agp files together into one.
    cd /cluster/store5/gs.18/build35
    #	The chrM sequence now has its own agp, remove it from
    #	ref_placed.agp
    sed -e "/^NC_001807/d" ../ncbi/ref_placed.agp > ref_placed.agp
    cat ref_placed.agp ../agp/chrM.agp ../ncbi/ref_unplaced.agp \
	../agp/chr6_hla_hap1.agp ../agp/chr6_hla_hap2.agp \
	../ncbi/PAR.agp > ncbi_build35.agp

    #	and into ffa
    cd /cluster/store5/gs.18/ffa
    #	There is a single bogus line at the end of ref_placed.fa.gz
    #	declaring the NC_001807 MT sequence, this was later replaced by
    #	chrMT.fa.gz, so remove that one line:
    zcat ../ncbi/ref_placed.fa.gz | sed -e "/^>ref|NC_001807/d" | \
	gzip > ref_placed.fa.gz
    #	(That's a 40 minute job)

    #	sequence.inf is usually here, symlink it
    ln -s ../ncbi/sequence.inf
    #	put all the fa.gz files together in one big fa.gz
    time zcat ref_placed.fa.gz ../agp/chrM.fa.gz ../ncbi/ref_unplaced.fa.gz \
	../agp/chr6_hla_hap?.fa.gz ../ncbi/PAR.fa.gz | gzip \
	> ncbi_build35.fa.gz
    #	real    37m42.208s
    #	user    37m3.490s
    #	sys     0m31.430s

    #	Make a listing of all the fasta record headers, just FYI:
    cd /cluster/store5/gs.18/ffa
    zcat ffa/ncbi_build35.fa.gz | grep "^>" > ncbi.fa.headers


    #	New to this build is the sequence: NC_001807 which is the
    #	mitochondria sequence.  This prefix NC_ is new to the process
    #	and will have to be accounted for below.  The other two special
    #	prefixes are similar to what was seen before:
    #	from DR52.agp NG_002392
    #	Homo sapiens major histocompatibility complex, class II,
    #		DR52 haplotype (DR52) on chromosome 6
    #	and from DR53.agp NG_002433
    #	Homo sapiens major histocompatibility complex, class II,
    #		DR53 haplotype (DR53) on chromosome 6

    #	Fixup seq_contig.md
    #
    #	It has a bunch of stuff belonging to the Celera
    #	genome assembly.  Filter those out.  I don't know what the
    #	NT_07959[0-7] items are, but there are no definitions for them
    #	in the agp files and no sequence in any fa.gz file.
    #	Fixup the names for the NG_ items, and change chrom MT to be M
    cd /cluster/store5/gs.18/build35
    egrep -v "Celera|NT_07959[0-7]" ../ncbi/seq_contig.md | \
	sed -e "s/6|NG_002392/6_hla_hap1/" \
	-e "s/6|NG_002433/6_hla_hap2/" \
	-e "s/^9606\tMT|NC_001807/9606\tM/" \
	> temp_contig.md

    #	get the randoms sorted in proper order.  The createNcbiLifts
    #	does not work correctly if the randoms are not grouped together
    #	by chromosome
    grep -v "|" temp_contig.md  > seq_contig.md
    #	This pulls out all the randoms and groups them within the
    #	same chrom but leaving them in the same order as they orginally
    #	were  (warning this is BASH code ...)
    grep "|" temp_contig.md | awk -F"|" '{print $1}' | \
        awk '{print $2}' | sort -n -u | while read CHR
do
        grep "[^0-9]${CHR}|" temp_contig.md
done >> seq_contig.md


    # Sanity check, checkYbr was updated to handle the NC_ identifier
    time zcat ../ffa/ncbi_build35.fa.gz | $HOME/bin/i386/checkYbr \
	ncbi_build35.agp stdin seq_contig.md > check.seq_contig
    #	real    2m34.143s
    #	user    2m24.970s
    #	sys     0m8.900s
    #	result should be clean:
    cat check.seq_contig
    #	Read 380 contigs from ncbi_build35.agp
    #	Verifying sequence sizes in stdin
    #	0 problems detected


    # Convert fa files into UCSC style fa files and place in "contigs"
    # directory inside the gs.18/build35 directory 
    #	(a check that can be done here is make a list of the contigs
    #	in this ./contigs directory before and compare it with the
    #	list of distributed contigs created after they have been
    #	disbursed.)
    #	faNcbiToUcsc was fixed to handle the NC_ identifier

    cd /cluster/store5/gs.18/build35
    #	We've been through this often
    mv contigs contigs.0
    time zcat ../ffa/ncbi_build35.fa.gz | $HOME/bin/i386/faNcbiToUcsc \
	-split -ntLast stdin contigs
    #	real    5m10.938s
    #	user    2m20.070s
    #	sys     0m51.020s
    #	If you want to compare anything to previous work, check now, then:
    rm -fr contigs.0

    # Determine the chromosome sizes from agps
    #	Watch carefully how chrY gets constructed.  I'm not sure
    #	this chrom_sizes represents the whole length of chrY with
    #	the PAR added.  We will see about that.
    #	Script updated to handle new chrom names:
    #	my @chroms = (1 .. 22, 'X', 'Y', 'M', '6_hla_hap1', '6_hla_hap2');

    cd /cluster/store5/gs.18/build35
    /cluster/bin/scripts/getChromSizes ../agp
    #	Create chrom.lst list for use in foreach() loops
    awk '{print $1}' chrom_sizes | sed -e "s/chr//" > chrom.lst

    # Create lift files (this will create chromosome directory structure) and
    #	inserts file
  
    /cluster/bin/scripts/createNcbiLifts -s chrom_sizes seq_contig.md .

    # Create contig agp files (will create contig directory structure)
	
    /cluster/bin/scripts/createNcbiCtgAgp seq_contig.md ncbi_build35.agp .

    # Create chromsome random agp files.

    /cluster/bin/scripts/createNcbiChrAgp -randomonly .

    # Copy the original chrN.agp files from the gs.18/agp directory 
    #    into each of the chromosome directories since they contain better 
    #    gap information. Delete the comments at top from these.
    cd /cluster/store5/gs.18/build35
    foreach c ( `cat chrom.lst` )
	sed -e "/^#.*/d" ../agp/chr${c}.agp > ./${c}/chr${c}.agp
    end
    #	chrM needs a name fixup
    sed -e "s#NC_001807#chrM#" ../agp/chrM.agp > M/chrM.agp

    # Distribute contig .fa to appropriate directory (assumes all files
    # are in "contigs" directory).

    # create global data link for everyone.  No more home directory
    # links required.
    ln -s /cluster/store5/gs.18/build35 /cluster/data/hg17
    cd /cluster/data/hg17
    /cluster/bin/scripts/distNcbiCtgFa contigs .
    #	Verify that everything was moved properly, the contigs directory
    #	should be empty:
    ls contigs
    #	Nothing there, then remove it
    rmdir  contigs

    #	Make a list of the contigs for use later
    rm contig.lst
    touch contig.lst
    foreach chrom ( `cat chrom.lst` )
	foreach c ( $chrom/N{C,G,T}_?????? )
	    set contig = $c:t
	    echo "${chrom}/${contig}/${contig}.fa" >> contig.lst
	end
    end
    #   For later comparisons, this is how many contigs we have:
    wc -l contig.lst
    #	380

    #	Note 2004-06-30 - there are some clone numbers left in some of
    #	the NCBI files that are incorrect.  Due to version number
    #	changes, more than one version is listed.  Namely for accession
    #	numbers: AC004491 AC004921 AC004983 AC005088 AC006014 AC099654
    #	The AGP files are correct, the sequence.inf file lists these
    #	twice: AC004491.1 AC004491.2
    #	AC004921.1 AC004921.2 AC004983.2 AC004983.3
    #	AC005088.2 AC005088.3 AC006014.2 AC006014.3
    #	AC099654.4 AC099654.5 

    # FILES ARE NOW READY FOR REPEAT MASKING - start that process as
    #	other steps here can proceed in parallel.

    #	Previous practice used to copy everything over for jkStuff from a
    #	previous build.  Rather than do that, pick up whatever is needed
    #	at the time it is needed and verify that it is going to do what
    #	you expect.

    cd /cluster/data/hg17
    mkdir jkStuff

    # Create the contig.gl files - XXX - NCBI doesn't deliver
    # contig_overlaps.agp - 2004-06-18 - this is beginning to come
    # together and there is now a contig_overlaps.agp file

    #	This is properly done below with a combination of psLayout
    #	alignments to create the contig_overlaps.agp file
    # /cluster/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md
    # Create chromosome gl files
    # jkStuff/liftGl.csh contig.gl

# CREATING DATABASE  (DONE - 2004-05-20 - Hiram)
    #	RE-DONE for new NIBS - 2004-06-03
    ssh hgwdev
    # Make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#	Filesystem            Size  Used Avail Use% Mounted on
#	/dev/sdc1             1.8T  303G  1.4T  19% /var/lib/mysql

    # Create the database.
    hgsql -e 'create database hg17' mysql
    # Copy over grp table (for track grouping) from another database:
    hgsql -e "create table grp (PRIMARY KEY(NAME)) select * from hg16.grp" hg17

# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS
#	(DONE - 2004-05-21 - Hiram)
    #	RE-DONE with new NIBS - 2004-06-03
    # Make nib/, unmasked until RepeatMasker and TRF steps are done.
    # Do this now so that the chromInfo table will exist and thus the
    #	trackDb tables can be built in the next step.
    #	These unmasked nibs will be replaced by the masked nibs after
    #	repeat mask and trf are done.
    ssh eieio
    cd /cluster/data/hg17
    # Make chr*.fa from contig .fa
    #  Copied chrFa.sh from hg16/jkStuff, renamed it to chrFa.csh
    time ./jkStuff/chrFa.csh
    #	real    13m24.710s
    #	user    9m0.360s
    #	sys     1m15.820s

    mkdir nib
    foreach c (`cat chrom.lst`)
      foreach f ($c/chr${c}{,_random}.fa)
        if (-e $f) then
          echo "nibbing $f"
          /cluster/bin/i386/faToNib $f nib/$f:t:r.nib
        endif
      end
    end

    # Make symbolic links from /gbdb/hg17/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/hg17/nib
    ln -s /cluster/data/hg17/nib/chr*.nib /gbdb/hg17/nib
    # Load /gbdb/hg17/nib paths into database and save size info.
    cd /cluster/data/hg17
    hgsql hg17  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib hg17 /gbdb/hg17/nib */chr*.fa
    hgsql -N -e "select chrom,size from chromInfo order by chrom" hg17 \
	> chrom.sizes
    # You can compare this chrom.sizes with the previously created
    # chrom_sizes.  Should be no difference
    sort chrom_sizes > s0
    sort chrom.sizes | grep -v random > s1
    diff s0 s1
    rm s0 s1

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE - 2004-05-21 - Hiram)
    #	dbDb orderKey updated 2004-06-08 - Hiram
    ssh hgwdev
    #	reset dbDb orderKey - these have never been ordered properly
    #	before, this will get them on the program.
    hgsql -e 'update dbDb set orderKey=11 where name = "hg16";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=12 where name = "hg15";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=13 where name = "hg13";' \
	-h genome-testdb hgcentraltest

    # Enter hg17 into hgcentraltest.dbDb so test browser knows about it:
    hgsql -e 'INSERT INTO dbDb (name, description, nibPath, organism, \
	defaultPos, active, orderKey, genome, scientificName, \
	htmlPath, hgNearOk) \
	VALUES("hg17", "May 2004", "/gbdb/hg17/nib", "Human", \
	"chr4:56214201-56291736", 1, 10, "Human", "Homo sapiens", \
	"/gbdb/hg17/html/description.html", 0);' \
	-h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~kent/src/hg/makeDb/trackDb
    cvs up -d -P .
    # Edit the makefile to add hg17 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE LIFTALL.LFT, NCBI.LFT (DONE - 2004-05-21 - Hiram)
    #	Re-DONE with new randoms - 2004-06-03 - Hiram)
    cd /cluster/data/hg17
    mkdir -p jkStuff
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft
    # Create jkStuff/ncbi.lft for lifting stuff built with the NCBI assembly.
    # Note: this ncbi.lift will not lift floating contigs to chr_random coords,
    # but it will show the strand orientation of the floating contigs 
    # (grep for '|').
    #   mdToNcbiLift seq_contig.md jkStuff/ncbi.lft 
    #	XXXX - appears to be unused, not done - Hiram

# REPEAT MASKING (DONE - 2004-05-24 - Hiram)
    #	The randoms were rearranged after this was first done,
    #	they are re-made below 2004-06-02)

    # Split contigs, run RepeatMasker, lift results

    #	This split takes about 8 minutes
    ssh eieio
    cd /cluster/data/hg17
    foreach chrom ( `cat chrom.lst` )
	foreach c ( $chrom/N{C,G,T}_?????? )
	    set contig = $c:t
	    echo "splitting ${chrom}/${contig}/${contig}.fa"
	    faSplit size ${chrom}/${contig}/$contig.fa 500000 \
		${chrom}/${contig}/${contig}_ \
		-lift=${chrom}/${contig}/$contig.lft -maxN=500000
	end
    end

    #- Make the run directory and job list:
    cd /cluster/data/hg17
    mkdir -p jkStuff
    #  According to RepeatMasker help file, no arguments are required to
    #	specify species because its default is set for primate (human)
    #  This run script saves the .tbl file to be sent to Arian.  He uses
    # those for his analysis.  Sometimes he needs the .cat and .align files for
    # checking problems.  Krish needs the .align files, they are large.

    cat << '_EOF_' > jkStuff/RMHuman
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/hg17/$2
/bin/cp $2 /tmp/hg17/$2/
cd /tmp/hg17/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s $2
popd
/bin/cp /tmp/hg17/$2/$2.out ./
 if (-e /tmp/hg17/$2/$2.align) /bin/cp /tmp/hg17/$2/$2.align ./
if (-e /tmp/hg17/$2/$2.tbl) /bin/cp /tmp/hg17/$2/$2.tbl ./
# if (-e /tmp/hg17/$2/$2.cat) /bin/cp /tmp/hg17/$2/$2.cat ./
/bin/rm -fr /tmp/hg17/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg17/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg17
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMHuman

    ssh eieio
    cd /cluster/data/hg17
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
    foreach d ( `cat chrom.lst` )
     foreach c ( ${d}/N{C,G,T}_*/N{C,G,T}_*_*.fa )
        set f = $c:t
        set cc = $c:h
        set contig = $cc:t
        echo /cluster/store5/gs.18/build35/jkStuff/RMHuman \
   		/cluster/store5/gs.18/build35/${d}/${contig} $f \
   '{'check out line+ /cluster/store5/gs.18/build35/${d}/${contig}/$f.out'}' \
          >> RMRun/RMJobs
      end
    end

    # We have 5971 jobs in RMJobs:
    wc RMRun/RMJobs
    #	5970   41790 1105804 RMRun/RMJobs

    #- Do the run
    ssh kk
    cd /cluster/data/hg17/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...

    #- While that is running, you can run TRF (simpleRepeat) on the small
    # cluster.  See SIMPLE REPEAT section below
# Completed: 5970 of 5970 jobs
# CPU time in finished jobs:   45189516s  753158.60m 12552.64h  523.03d  1.433 y
# IO & Wait Time:                141333s    2355.55m    39.26h    1.64d  0.004 y
# Average job time:                7593s     126.55m     2.11h    0.09d
# Longest job:                    10268s     171.13m     2.85h    0.12d
# Submission to last job:         81484s    1358.07m    22.63h    0.94d

    #	Lift up the split-contig .out's to contig-level .out's
    #
    #	If a mistake is made in the following it would be possible to
    #	destroy all the RM output.  So, just to be paranoid, save all
    #	the RM output in bluearc for the time being:
    ssh eieio

    cd /cluster/data/hg17
    mkdir /cluster/bluearc/hg17/RMOutput
    foreach c ( `cat chrom.lst` )
     foreach d ( ${c}/N{C,G,T}_* )
	set T = /cluster/bluearc/hg17/RMOutput/${d}
	mkdir -p ${T}
        cd ${d}
        set contig = $d:t
        cp -p ${contig}_?{,?,??}.fa.out ${T}
        cd ../..
	echo "${d} done"
     end
    end
    #	Make sure we got them all:
    #	(this doesn't work later since there are more *.fa.out files
    #	after the lifting.  More explicitly to find just these:
    #		find . -name "N?_*_*.fa.out" -print | wc -l
    find . -name "*.fa.out" -print | wc -l
    #	5970
    find /cluster/bluearc/hg17/RMOutput -type f | wc -l
    #	5970
    #	same count

    #	OK, now you can try this operation, do it in a script like this
    #	and save the output of the script for a record of what happened.

    cat << '_EOF_' > jkStuff/liftRM.csh
#!/bin/csh -fe
foreach c ( `cat chrom.lst` )
 foreach d ( ${c}/N{C,G,T}_* )
    cd $d
    set contig = $d:t
    liftUp $contig.fa.out $contig.lft warn ${contig}_?{,?,??}.fa.out 
    cd ../..
 end
end
'_EOF_'
    chmod +x jkStuff/liftRM.csh
    mkdir scriptsOutput
    time jkStuff/liftRM.csh > scriptsOutput/liftRM.1 2>&1
    #	real    4m37.572s
    #	user    1m19.130s
    #	sys     0m32.950s
    #	Check that they all were done:
    grep "fa.out" scriptsOutput/liftRM.1 | wc -l
    #	5959
    #	same count as above

    #- Lift up RepeatMask .out files to chromosome coordinates via
    # picked up jkStuff/liftOut2.sh from the hg16 build.  Renamed to
    # liftOut2.csh, changed the line that does the chrom listing

    time ./jkStuff/liftOut2.csh > scriptsOutput/liftOut2 2>&1
    #	real    9m46.780s
    #	user    1m18.900s
    #	sys     7m33.990s

    #- By this point, the database should have been created (above):
    ssh hgwdev
    cd /cluster/data/hg17
    time hgLoadOut hg17 ?/*.fa.out ??/*.fa.out 6_hla_hap?/*.fa.out > \
	scriptsOutput/hgLoadOut 2>&1
    #	real    5m59.137s
    #	user    1m47.550s
    #	sys     0m15.410s

    # errors during this load:  (there are always a couple of these)
    #	Strange perc. field -6.1 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -6.1 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -0.2 line 30322 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30324 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30326 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30328 of 17/chr17.fa.out
    #	Strange perc. field -18.6 line 77034 of 19/chr19.fa.out

    #	Verify we have similar results to previous assembly:
    #	featureBits hg17 rmsk
    #	1391378842 bases of 2867328468 (48.525%) in intersection
    #	featureBits hg16 rmsk
    #	1388770568 bases of 2865248791 (48.469%) in intersection
    #	Now proceed to MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
    #	following the SIMPLE REPEAT sections below

# Re-Running REPEAT_MASKER on the new Randoms (DONE - 2004-06-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17
    grep "|" seq_contig.md | awk '{print $2}' | sed -e "s#|#/#" > randoms.lst

    mkdir /cluster/data/hg17/RMRandoms
    foreach r ( `cat randoms.lst` )
	set d = $r:h
	set contig = $r:t
	foreach c ( ${r}/N{C,G,T}_*_*.fa )
	    set f = $c:t
	    echo /cluster/store5/gs.18/build35/jkStuff/RMHuman \
   		/cluster/store5/gs.18/build35/${d}/${contig} $f \
   '{'check out line+ /cluster/store5/gs.18/build35/${d}/${contig}/$f.out'}' \
          >> RMRandoms/RMJobs
	end
    end

    ssh kk
    cd /cluster/data/hg17/RMRandoms
    para create RMJobs
    para try, para check, para check, para push, para check,...
# Completed: 94 of 94 jobs
# CPU time in finished jobs:     221454s    3690.91m    61.52h    2.56d  0.007 y
# IO & Wait Time:                   866s      14.43m     0.24h    0.01d  0.000 y
# Average job time:                2365s      39.42m     0.66h    0.03d
# Longest job:                     9062s     151.03m     2.52h    0.10d
# Submission to last job:          9106s     151.77m     2.53h    0.11d

    #	Continuing with the paranoia theme, let's backup all the RM output
    #
    ssh eieio

    cd /cluster/data/hg17
    mkdir /cluster/bluearc/hg17/RMRandoms
    foreach c ( `cat chrom.lst` )
     foreach d ( ${c}/N{C,G,T}_* )
	set T = /cluster/bluearc/hg17/RMRandoms/${d}
	mkdir -p ${T}
        cd ${d}
        set contig = $d:t
        cp -p ${contig}_?{,?,??}.fa.out ${T}
        cd ../..
	echo "${d} done"
     end
    end
    #	Make sure we got them all:
    find . -name "N?_*_*.fa.out" -print | wc -l
    #	5959
    find /cluster/bluearc/hg17/RMRandoms -type f | wc -l
    #	5959
    #	same count


    time jkStuff/liftRM.csh > scriptsOutput/liftRM2.1 2>&1
    #	real    4m46.302s
    #	user    1m18.260s
    #	sys     0m18.000s
    #	Check that they all were done:
    grep "fa.out" scriptsOutput/liftRM2.1 | wc -l
    #	5959
    #	same count as above

    #- Lift up RepeatMask .out files to chromosome coordinates via
    # picked up jkStuff/liftOut2.sh from the hg16 build.  Renamed to
    # liftOut2.csh, changed the line that does the chrom listing

    time ./jkStuff/liftOut2.csh > scriptsOutput/liftOut2.1 2>&1
    #	real    2m46.347s
    #	user    1m18.650s
    #	sys     0m15.990s

    #- By this point, the database should have been created (above):
    ssh hgwdev
    cd /cluster/data/hg17
    time hgLoadOut hg17 ?/*.fa.out ??/*.fa.out 6_hla_hap?/*.fa.out > \
	scriptsOutput/hgLoadOut 2>&1
    #	real    5m59.137s
    #	user    1m47.550s
    #	sys     0m15.410s

    # errors during this load:  (there are always a couple of these)
    #	Strange perc. field -6.1 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -6.1 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -0.2 line 30322 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30324 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30326 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30328 of 17/chr17.fa.out
    #	Strange perc. field -18.6 line 77034 of 19/chr19.fa.out

    #	Verify we have similar results to previous assembly:
    #	featureBits hg17 rmsk
    #	1390952984 bases of 2866216770 (48.529%) in intersection
    #	featureBits hg17 rmsk  #with previous randoms:
    #	1391378842 bases of 2867328468 (48.525%) in intersection
    #	featureBits hg16 rmsk
    #	1388770568 bases of 2865248791 (48.469%) in intersection
    #	Now proceed to MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
    #	following the SIMPLE REPEAT sections below

# SIMPLE REPEAT [TRF] TRACK (DONE - 2004-05-21 - Hiram)
    #	Re-done with new randoms, 2004-06-02 - Hiram
    #	Copy the contigs, first to the bluearc, then to /iscratch/i
    ssh eieio
    mkdir /cluster/bluearc/hg17
    mkdir /cluster/bluearc/hg17/contigs

    cd /cluster/data/hg17
    foreach ctg ( `cat contig.lst` )
	set c = $ctg:t
 	echo "$ctg > /cluster/bluearc/hg17/contigs/$c"
	cp -p $ctg /cluster/bluearc/hg17/contigs/$c
    end
    #	Check how much is there:
    #	du -hsc /cluster/bluearc/hg17/contigs
    #	2.8G    /cluster/bluearc/hg17/contigs

    # Distribute contigs to /iscratch/i
    ssh kkr1u00
    mkdir /iscratch/i/gs.18/build35/unmaskedContigs
    cd /iscratch/i/gs.18/build35/unmaskedContigs
    cp -p /cluster/bluearc/hg17/contigs/* .

    # Verify same amount made it there:
    #	du -hsc /iscratch/i/gs.18/build35/unmaskedContigs
    #	2.8G    /iscratch/i/gs.18/build35/unmaskedContigs
    #	Then send them to the other 7 Iservers
    /cluster/bin/iSync

    #	Go to the small cluster for this business:
    ssh kki

    mkdir -p /cluster/data/hg17/bed/simpleRepeat
    cd /cluster/data/hg17/bed/simpleRepeat
    mkdir trf
    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    ls -1S /iscratch/i/gs.18/build35/unmaskedContigs/*.fa > genome.lst
    gensub2 genome.lst single gsub jobList
    para create jobList
    para try
    para check
    para push
    para check
# Completed: 380 of 380 jobs
# CPU time in finished jobs:      13230s     220.49m     3.67h    0.15d  0.000 y
# IO & Wait Time:                  2078s      34.64m     0.58h    0.02d  0.000 y
# Average job time:                  40s       0.67m     0.01h    0.00d
# Longest job:                     1590s      26.50m     0.44h    0.02d
# Submission to last job:          2504s      41.73m     0.70h    0.03d

    liftUp simpleRepeat.bed /cluster/data/hg17/jkStuff/liftAll.lft \
	warn trf/*.bed  > lu.out 2>&1

    # Load into the database:
    ssh hgwdev
    cd /cluster/data/hg17/bed/simpleRepeat
    /cluster/bin/i386/hgLoadBed hg17 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
    #	Loaded 629076 elements of size 16
    #	Compare with previous assembly
    featureBits hg17 simpleRepeat
    #	54952425 bases of 2866216770 (1.917%) in intersection

    #	with previous randoms
    featureBits hg17 simpleRepeat
    #	54964044 bases of 3096628158 (1.775%) in intersection
    featureBits hg16 simpleRepeat
    #	54320136 bases of 2865248791 (1.896%) in intersection
    #	GAPS weren't in hg17 yet at this point, after gaps added:
    #	featureBits hg17 simpleRepeat
    #	54964044 bases of 2867328468 (1.917%) in intersection
    #	featureBits -countGaps hg17 simpleRepeat
    #	54964044 bases of 3096628158 (1.775%) in intersection


# PROCESS SIMPLE REPEATS INTO MASK (DONE - 2004-05-21 - Hiram)
    #	re-done with new randoms - 2004-06-03 - Hiram
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd /cluster/data/hg17/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

    #	EXPERIMENT, at a filter of <= 12, we have coverage:
    #	20904399 bases of 2867328468 (0.729%) in intersection
    #	at a filter of <= 9, we have coverage:
    #	19271270 bases of 2867328468 (0.672%) in intersection


    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/hg17
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c ( `cat chrom.lst` )
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end

# MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE - 2004-05-25)
#							 -Hiram
    #	re-done with new randoms - 2004-06-03 - Hiram
    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above,
    #	and after Repeat Masker is complete.
    ssh eieio
    cd /cluster/data/hg17

    # copied these scripts from hg16 - reset the lines that make
    # the chrom list to work on, reset the wild cards that find all the
    # contig .fa's

    # Make chr*.fa from contig .fa
    #  Copied chrFa.sh from hg16/jkStuff, renamed it to chrFa.csh
    time ./jkStuff/chrFa.csh > scriptsOutput/chrFa.out 2>&1 &
    #	real    13m18.512s
    #	user    9m1.670s
    #	sys     1m7.290s

    #- Soft-mask (lower-case) the contig and chr .fa's
    time ./jkStuff/makeFaMasked.csh > scriptsOutput/maFaMasked.out 2>&1
    #	real    29m31.623s
    #	user    13m49.700s
    #	sys     5m58.750s
    #- Make hard-masked .fa.masked files as well:
    time ./jkStuff/makeHardMasked.csh > scriptsOutput/maHardMasked.out 2>&1

    #- Create the bothMasksNib/ directory
    time ./jkStuff/makeNib.csh > scriptsOutput/maNib.out 2>&1
    #	real    14m41.694s
    #	user    6m28.000s
    #	sys     1m42.500s

    # Make symbolic links from /gbdb/hg17/nib to the real nibs.
    ssh hgwdev
    mv nib nib.raw
    mv bothMasksNib nib
    rm /gbdb/hg17/nib/*.nib
    ln -s `pwd`/nib/* /gbdb/hg17/nib

    # Load /gbdb/hg17/nib paths into database and save size info.
    hgsql hg17  < ~/kent/src/hg/lib/chromInfo.sql
    cd /cluster/data/hg17
    hgNibSeq -preMadeNib hg17 /gbdb/hg17/nib */chr*.fa
    #	3096628158 total bases

    #	Should be the same size as before
    hgsql -N -e "select chrom,size from chromInfo order by chrom" hg17 \
	> chrom.sizes.masked
    diff chrom.sizes chrom.sizes.masked
    #	should be no output at all, thus:
    rm chrom.sizes.masked

    # Copy the masked contig fa to /scratch and /iscratch
    #	And everything else we will need for blastz runs, etc ...
    #	Best to do this sequence first to /cluster/bluearc/scratch,
    #	which is going to be the source for the /scratch copy.
    #	And then from there to the /iscratch
    #	Make sure you are on the fileserver for the original source:
    ssh eieio
    mkdir -p /cluster/bluearc/scratch/hg/gs.18/build35
    cd /cluster/bluearc/scratch/hg/gs.18/build35

    #	these copies take less than 2 minutes each
    mkdir bothMaskedNibs
    cp -p /cluster/data/hg17/nib/*.nib ./bothMaskedNibs
    mkdir maskedContigs
    foreach chrom ( `cat /cluster/data/hg17/chrom.lst` )
	cp -p /cluster/data/hg17/${chrom}/N{C,G,T}_*/N{C,G,T}_??????.fa \
		./maskedContigs
	echo "done ${chrom}"
    end
    #	make sure you have them all:
    ls maskedContigs | wc -l
    #	380
    wc -l /cluster/data/hg17/contig.lst
    #	380
    mkdir rmsk
    foreach chrom ( `cat /cluster/data/hg17/chrom.lst` )
	cp -p /cluster/data/hg17/${chrom}/*.out ./rmsk
	echo "done ${chrom}"
    end

    #	Now, go to the destination for /iscratch and copy from the
    #	bluearc
    ssh kkr1u00
    mkdir -p /iscratch/i/gs.18/build35
    cd /iscratch/i/gs.18/build35
    #	This takes about 5 minutes
    rsync -arlv /cluster/bluearc/scratch/hg/gs.18/build35/ .

    time /cluster/bin/iSync
    #	real    7m27.649s

    # request rsync of /cluster/bluearc/scratch to the KiloKluster /scratch

# LOAD ctgPos table - Contig position track (DONE - 2004-06-08 - Hiram)
    #	After fixing up hgCtgPos to accept the -chromLst argument, simply:
    cd /cluster/data/hg17
    hgCtgPos -chromLst=chrom.lst hg17 .

# GOLD AND GAP TRACKS (DONE - 2004-05-21 - Hiram)
    #	RE-DONE with new randoms - 2004-06-03 - Hiram
    ssh hgwdev
    cd /cluster/data/hg17
    hgGoldGapGl -noGl -chromLst=chrom.lst hg17 /cluster/data/hg17 .
    #	Disappointing to see this create so many tables ...
    #	_gap and _gold for each chrom

    # Create the contig.gl files - XXX - NCBI doesn't deliver
    # contig_overlaps.agp - 2004-06-18 - this is beginning to come
    # together and there is now a contig_overlaps.agp file
    cd /cluster/store5/gs.18/build35
    ./combineContigOverlaps.sh
    ./fixPhase.pl contig_overlaps.placed_and_splits.agp > contig_overlaps.agp

    ~hiram/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md
    # Create chromosome gl files  (had to fix liftUp to do the NC_ properly)
    jkStuff/liftGl.csh contig.gl

#  After contig.gl files have been made from contig_overlaps.agp
#	The sed fixes the Celera clones that are marked phase W
#	Call that phase 3 instead,
#	Delete the Celera AACC clones, they are not in this assembly,
#	And fix the line of AC018743 to add it to the assembly, it was a
#	last minute addition by Terry that didn't get carried into the
#	NCBI sequence.inf file.  And remove the older versions of five
#	clones that got left in by mistake at NCBI
    #	AC004491.1=AC004491.2 AC004921.1=AC004921.2 AC004983.2=AC004983.3
    #	AC005088.2=AC005088.3 AC006014.2=AC006014.3 AC099654.4=AC099654.5 
    cd /cluster/data/hg17
    sed -e "s/\tW\t/\t3\t/" \
	-e "/^AACC010000.*/d" \
	-e "/^AC004491.1.*/d" \
	-e "/^AC004921.1.*/d" \
	-e "/^AC004983.2.*/d" \
	-e "/^AC005088.2.*/d" \
	-e "/^AC006014.2.*/d" \
	-e "/^AC099654.4.*/d" \
	-e "s/AC018743.27\t31791062\t466818\t1\tD\tUn\t-\tBCM\tRP11-289M22\tSIZE:2big/AC018743.27\t31791062\t466818\t1\t-\t(12)\t-\tBCM\tRP11-289M22\tfor_assembly/" \
	/cluster/store5/gs.18/ncbi/sequence.inf \
	> sequence.inf
    cd /cluster/store5/gs.18/build35
    hgGoldGapGl -chromLst=chrom.lst hg17 /cluster/store5/gs.18 build35
    cd /cluster/data/hg17
    $HOME/bin/i386/hgClonePos -chromLst=chrom.lst hg17 \
	/cluster/data/hg17 ./sequence.inf /cluster/store5/gs.18 -maxErr=3
    #	We have the following errors
# Processing /cluster/data/hg17/Y/chrY.gl
# Clone BX640545 is on chromosomes chrX and chrY.  Ignoring chrY
# Clone AL954722 is on chromosomes chrX and chrY.  Ignoring chrY
# ... etc for all the PAR clones
# ... And there are an unknown number of these:
# AB000359 is in ./sequence.inf but not in ooDir/*/*.gl
# AB000360 is in ./sequence.inf but not in ooDir/*/*.gl

#  gc5Base wiggle TRACK (DONE - 2004-05-22 - Hiram)
    #	This previously was a script that ran through each nib
    #	Recently transformed into a mini cluster run.
    #	Re-DONE with the new randoms - 2004-06-04
    ssh kki
    mkdir /cluster/data/hg17/bed/gc5Base
    cd /cluster/data/hg17/bed/gc5Base

    mkdir wigData5 dataLimits5 wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRun.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 hg17 \
        /iscratch/i/gs.18/build35/bothMaskedNibs | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigAsciiToBinary -dataSpan=5 -chrom=${chr} \
        -wibFile=wigData5/gc5Base_${chrom} \
            -name=${chrom} stdin 2> dataLimits5/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRun.sh

    ls /iscratch/i/gs.18/build35/bothMaskedNibs > nibList
    cat << '_EOF_' > gsub
#LOOP
./kkRun.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsub jobList
    para create jobList
    para try, check, ... etc
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       5251s      87.51m     1.46h    0.06d  0.000 y
# IO & Wait Time:                   130s       2.17m     0.04h    0.00d  0.000 y
# Average job time:                 117s       1.95m     0.03h    0.00d
# Longest job:                      413s       6.88m     0.11h    0.00d
# Submission to last job:           475s       7.92m     0.13h    0.01d

    # load the .wig files back on hgwdev:
    ssh hgwdev
    cd /cluster/data/hg17/bed/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/hg17/wib/gc5Base hg17 gc5Base wigData5/*.wig
    # and symlink the .wib files into /gbdb
    mkdir /gbdb/hg17/wib/gc5Base
    ln -s `pwd`/wigData5/*.wib /gbdb/hg17/wib/gc5Base

    #	And then the zoomed data view
    ssh kki
    cd /cluster/data/hg17/bed/gc5Base
    mkdir wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRunZoom.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 hg17 \
        /iscratch/i/gs.18/build35/bothMaskedNibs | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigZoom -dataSpan=1000 stdin | wigAsciiToBinary -dataSpan=1000 \
	-chrom=${chr} -wibFile=wigData5_1K/gc5Base_${chrom}_1K \
            -name=${chrom} stdin 2> dataLimits5_1K/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRunZoom.sh

    cat << '_EOF_' > gsubZoom
#LOOP
./kkRunZoom.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsubZoom jobListZoom
    para create jobListZoom
    para try ... check ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       5216s      86.93m     1.45h    0.06d  0.000 y
# IO & Wait Time:                    34s       0.57m     0.01h    0.00d  0.000 y
# Average job time:                 114s       1.90m     0.03h    0.00d
# Longest job:                      415s       6.92m     0.12h    0.00d
# Submission to last job:           469s       7.82m     0.13h    0.01d

    #	Then load these .wig files into the same database as above
    ssh hgwdev
    hgLoadWiggle -pathPrefix=/gbdb/hg17/wib/gc5Base \
	-oldTable hg17 gc5Base wigData5_1K/*.wig
    # and symlink these .wib files into /gbdb
    mkdir -p /gbdb/hg17/wib/gc5Base
    ln -s `pwd`/wigData5_1K/*.wib /gbdb/hg17/wib/gc5Base

# AUTO UPDATE GENBANK MRNA RUN  (DONE - 2004-06-08 - Hiram)
    ssh eieio
    cd /cluster/data/genbank
    # This is a new organism, edit the etc/genbank.conf file and add:
	# hg17
	hg17.genome = /scratch/hg/gs.18/build35/bothMaskedNibs/chr*.nib
	hg17.lift = /cluster/store5/gs.18/build35/jkStuff/liftAll.lft
	hg17.genbank.est.xeno.load = yes
	hg17.mgcTables.default = full
	hg17.mgcTables.mgc = all
	hg17.downloadDir = hg17

    #	Do the refseq's first, they are the quick ones
    ssh eieio
    cd /cluster/data/genbank
    nice bin/gbAlignStep -srcDb=refseq -type=mrna -verbose=1 -initial hg17
    #	 logFile: var/build/logs/2004.05.25-13:41:07.hg17.initalign.log
    #	checking that log, or watching the batch on kk, you can find
    #	where the batch is running and after it is done get the time:
    cd /cluster/store6/genbank/work/initial.hg17/align
    para time > time
    cat time
# Completed: 9500 of 9500 jobs
# CPU time in finished jobs:      62241s    1037.35m    17.29h    0.72d  0.002 y
# IO & Wait Time:                 33719s     561.98m     9.37h    0.39d  0.001 y
# Average job time:                  10s       0.17m     0.00h    0.00d
# Longest job:                     1062s      17.70m     0.29h    0.01d
# Submission to last job:          1063s      17.72m     0.30h    0.01d

    # Load the results from the above
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg17

#	To get the genbank started, the above results need to be
#	moved out of the way.  These things can be removed if there are
#	no problems to debug
    ssh eieio
    cd /cluster/data/genbank/work
    mv initial.hg17 initial.hg17.refseq.mrna

    cd /cluster/data/genbank
    nice bin/gbAlignStep -srcDb=genbank -type=mrna -verbose=1 -initial hg17
    #	logFile: var/build/logs/2004.06.04-10:47:21.hg17.initalign.log
    #	One job was hung up, after killing it on its node, the batch
    #	finished in a few minutes.
# Completed: 35720 of 35720 jobs
# CPU time in finished jobs:    5161424s   86023.74m  1433.73h   59.74d  0.164 y
# IO & Wait Time:                144149s    2402.48m    40.04h    1.67d  0.005 y
# Average job time:                 149s       2.48m     0.04h    0.00d
# Longest job:                    18306s     305.10m     5.08h    0.21d
# Submission to last job:         35061s     584.35m     9.74h    0.41d

    ssh hgwdev
    cd /cluster/data/genbank
    #	some kind of error happened here, had to remove a lock file to
    #	get this to proceed  (this same thing happened again the second
    #	time around)
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg17

    ssh eieio
    cd /cluster/data/genbank/work
    mv initial.hg17 initial.hg17.genbank.mrna
    cd /cluster/data/genbank
    nice bin/gbAlignStep -srcDb=genbank -type=est -verbose=1 -initial hg17
# Completed: 189240 of 189240 jobs
# CPU time in finished jobs:   97172120s 1619535.33m 26992.26h 1124.68d  3.081 y
# IO & Wait Time:               1507789s   25129.82m   418.83h   17.45d  0.048 y
# Average job time:                 521s       8.69m     0.14h    0.01d
# Longest job:                    33165s     552.75m     9.21h    0.38d
# Submission to last job:        126988s    2116.47m    35.27h    1.47d

    ssh hgwdev
    cd /cluster/data/genbank
    time nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg17
    #	real    440m42.750s
    #	user    69m7.810s
    #	sys     23m18.640s
    #	This is ~7.5 hours

    #	If the above is all OK, ask Mark to put this assembly on
    #	the daily updates.

# CPGISLANDS (DONE - 2004-05-25 - Hiram)
    #	Re-DONE with new randoms - 2004-06-04 - Hiram
    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/cpgIsland
    cd /cluster/data/hg17/bed/cpgIsland

    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    #	gcc readseq.c cpg_lh.c -o cpglh.exe
    mv cpglh.exe /cluster/data/hg17/bed/cpgIsland/
    
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    ssh eieio
    cd /cluster/data/hg17/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpglh.exe $f > $fout
    end
    #	the warnings:
    # Bad char 0x52 = 'R' at line 2046, base 102229, sequence chr16_random
    # Bad char 0x4d = 'M' at line 1216113, base 60805573, sequence chr3
    # Bad char 0x52 = 'R' at line 1216118, base 60805801, sequence chr3
    # Bad char 0x52 = 'R' at line 1216118, base 60805801, sequence chr3
    #	real    21m47.823s
    #	user    18m30.810s
    #	sys     1m13.420s

    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    ssh hgwdev
    cd /cluster/data/hg17/bed/cpgIsland
    hgLoadBed hg17 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed
    #	Reading cpgIsland.bed
    #	Loaded 27801 elements of size 10
    #	Sorted
    #	Saving bed.tab
    #	Loading hg17

# MAKE HGCENTRALTEST BLATSERVERS ENTRY (DONE - 2004-05-25 - Heather)
    ssh hgwdev
    hgsql -e 'INSERT INTO blatServers (db, host, port, isTrans) \
	VALUES("hg17", "blat12", "17778", "1"); \
	INSERT INTo blatServers (db, host, port, isTrans) \
	VALUES("hg17", "blat12", "17779", "0");' \
	-h genome-testdb hgcentraltest

# PREPARE CLUSTER FOR BLASTZ RUNS (DONE - 2004-05-26 - Hiram)
    #	Re-DONE with new randoms - 2004-06-03 - Hiram

    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/rmsk.spec
    cd /cluster/bluearc/scratch/hg/gs.18/build35/rmsk.spec
    ln -s ../rmsk/*.out .
    #	This takes 40 minutes run as a script, to hurry it up it has
    #	been converted to a mini cluster run
    cat << '_EOF_' > runArian.sh
#!/bin/sh
for FN in *.out
do
    echo /cluster/bluearc/RepeatMasker030619/DateRepsinRMoutput.pl \
	${FN} -query human -comp rat -comp mouse
done
'_EOF_'
    chmod +x runArian.sh
    ssh kki
    cd /cluster/bluearc/scratch/hg/gs.18/build35/rmsk.spec
    ./runArian.sh > jobList
    para create jobList
    para try, ... check ... push ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:        668s      11.14m     0.19h    0.01d  0.000 y
# IO & Wait Time:                   514s       8.56m     0.14h    0.01d  0.000 y
# Average job time:                  26s       0.43m     0.01h    0.00d
# Longest job:                       86s       1.43m     0.02h    0.00d
# Submission to last job:           108s       1.80m     0.03h    0.00d

    #	Now extract each one, 1 = Rat, 2 = Mouse
    ssh eieio
    cd /cluster/bluearc/scratch/hg/gs.18/build35

    mkdir linSpecRep.notInRat linSpecRep.notInMouse
    foreach f (rmsk.spec/*.out_rat_mus)
        set base = $f:t:r:r
        echo "$f -> $base.out.spec"
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInRat/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    #	There is actually no difference at all between these two results.
    #	copy to iscratch
    ssh kkr1u00
    cd /iscratch/i/gs.18/build35
    rsync -arlv /cluster/bluearc/scratch/hg/gs.18/build35/ .
    /cluster/bin/iSync
    # request rsync of /cluster/bluearc/scratch to the KiloKluster /scratch

# COPY DATA TO GOLDEN PATH LOCATIONS (DONE - 2004-06-04 - Hiram)
    ssh hgwdev
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/chromosomes
    cd /cluster/data/hg17
    #	Beware, this backgrounding of the gzips can be hard on hgwdev.
    #	You could wait until after the copy then run one gzip to do them all
    foreach chrom ( `cat chrom.lst` )
	cp -p ${chrom}/*.fa /usr/local/apache/htdocs/goldenPath/hg17/chromosomes
	gzip \
	/usr/local/apache/htdocs/goldenPath/hg17/chromosomes/chr${chrom}*.fa &
	echo "done ${chrom}"
    end
    cd /usr/local/apache/htdocs/goldenPath/hg17/chromosomes
    gzip *.fa


# FOSMID END PAIRS TRACK (WORKING - 2004-06-09 kate)

    # Use latest fosmid ends data prepared by Terry Furey.
    # He says there is no on-going work on fosmid ends, so this
    # should suffice indefinitely ?  Move/link this stuff into
    # central data area.
    ssh eieio
    cd /cluster/data/ncbi
    mkdir -p fosends/human
    ln -s /cluster/store1/fosends.3 fosends/human
    cd fosends/human/fosends.3
    faSize fosEnds.fa
       # 579735181 bases (369769 N's 579365412 real) in 1087670 sequences 
       # 580M bases in 1M sequences
    # create link in /gbdb/ncbi/fosends/human ?

    # use pre-split fosend files, and associated list for cluster run
    # Sequences are in /cluster/bluearc/hg/fosEnds
    cp /cluster/bluearc/booch/fosends/fosEnds.lst /cluster/bluearc/hg/fosEnds
    
    # run on rack9 since kilokluster is busy
    ssh kk9
    cd /cluster/data/hg17
    mkdir -p bed/fosends
    cd bed/fosends
    mkdir -p run
    cd run
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa \
                > contigs.lst
    cp /cluster/bluearc/hg/fosEnds/fosEnds.lst fosEnds.lst
        # 380 contigs vs 97 fosEnd files -> 40K jobs
    # send output to kksilo, as it can better handle the NFS load
    mkdir -p /cluster/store7/kate/hg17/fosends/out
    ln -s /cluster/store7/kate/hg17/fosends/out ../out
cat > gsub << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -ooc=/scratch/hg/h/11.ooc {check out line+ /cluster/data/hg17/bed/fosends/out/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst fosEnds.lst gsub jobList
    foreach f (`cat fosEnds.lst`)
        set d = $f:r:t
        echo $d
        mkdir -p /cluster/data/hg17/bed/fosends/out/$d
    end

    para create jobList
        # 36860 jobs
    para try
    para check
    para push
# CPU time in finished jobs:    1655943s   27599.05m   459.98h   19.17d  0.053 y
# IO & Wait Time:                101145s    1685.75m    28.10h    1.17d  0.003 y
# Average job time:                  48s       0.79m     0.01h    0.00d
# Longest job:                     1294s      21.57m     0.36h    0.01d
# Submission to last job:         19269s     321.15m     5.35h    0.22d

    # sort, filter, and lift alignments
    ssh eieio
    cd /cluster/data/hg17/bed/fosends
    pslSort dirs raw.psl temp out/fosEnds*
    pslReps  -nearTop=0.01 -minCover=0.70 -minAli=0.85 -noIntrons raw.psl \
                        fosEnds.psl /dev/null
        # Processed 84096767 alignments

    rm -r temp
    rm raw.psl

    mkdir lifted
    liftUp lifted/fosEnds.lifted.psl \
                /cluster/data/hg17/jkStuff/liftAll.lft warn fosEnds.psl
    pslSort dirs fosEnds.sorted.psl temp lifted
    rmdir temp
    wc -l *.sorted.psl
        # 1693693 fosEnds.sorted.psl
 
    set ncbiDir = /cluster/data/ncbi/fosends/human/fosends.3
    ~/bin/i386/pslPairs -tInsert=5000 -minId=0.94 -noBin -min=30000 -max=500000 -slop -short -long -orphan -mismatch -verbose fosEnds.sorted.psl $ncbiDir/fosEnds.pairs all_fosends fosEnds

    # create header required by "rdb" tools
    # TODO: replace w/ awk & sort
    echo 'chr\tstart\tend\tclone\tscore\tstrand\tall\tfeatures\tstarts\tsizes' > header
    echo '10\t10N\t10N\t10\t10N\t10\t10\t10N\t10\t10' >> header
    cat header fosEnds.pairs | row score ge 300 | sorttbl chr start | headchg -del > fosEndPairs.bed
    cat header fosEnds.slop fosEnds.short fosEnds.long fosEnds.mismatch \
         fosEnds.orphan \
    | row score ge 300 | sorttbl chr start | headchg -del > fosEndPairsBad.bed

    extractPslLoad -noBin fosEnds.sorted.psl fosEndPairs.bed \
                fosEndPairsBad.bed | \
                        sorttbl tname tstart | headchg -del > fosEnds.load.psl

    # load into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/fosends
    hgLoadBed hg17 fosEndPairs fosEndPairs.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/fosEndPairs.sql 
        # Loaded 387542 elements
    # note - this track isn't pushed to RR, just used for assembly QA
    hgLoadBed hg17 fosEndPairsBad fosEndPairsBad.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/fosEndPairsBad.sql
        # Loaded  27919 elements
    #hgLoadPsl hg17 -nobin -table=all_fosends fosEnds.load.psl
    # NOTE: truncates file to 0 if -nobin is used
    hgLoadPsl hg17 -table=all_fosends fosEnds.load.psl
        #load of all_fosends did not go as planned: 441072 record(s), 0 row(s) skipped, 30 warning(s) loading psl.tab
    # load sequences

    mkdir -p /gbdb/hg17/fosends
    ln -s /cluster/data/ncbi/fosends/human/fosends.3/fosEnds.fa \
                                /gbdb/hg17/fosends/fosEnds.fa
    hgLoadSeq hg17 /gbdb/hg17/fosends/fosEnds.fa
        # 1087670 sequences
       # NOTE: extFile ID is 832625 (shouldn't be so large ??) 
       # may want to reset this.


# BAC END PAIRS TRACK (DONE - 2004-06-09 kate)

    # Use latest BAC ends data from NCBI
    # Checked  ftp.ncbi.nih.gov/genomes/BACENDS/homo_sapiens,
    #  and files were unchanged from Terry's last download
    #  (to /cluster/store1/bacends.4)
    # Link this stuff into central data area.
    ssh eieio
    cd /cluster/data/ncbi
    mkdir -p bacends/human
    ln -s /cluster/store1/bacends.4 bacends/human
    cd bacends/human/bacends.4
    faSize BACends.fa
        # 400230494 bases (2743171 N's 397487323 real) in 832614 sequences
        # 400M bases in 800K sequences

    # use pre-split bacends files, and associated list for cluster run
    ssh kk
    cd /cluster/data/hg17
    mkdir -p bed/bacends
    cd bed/bacends
    mkdir run
    cd run
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/hg/bacEnds/hs/*.fa > bacends.lst
        # 380 contigs vs 98 bacends files -> 40K jobs

    # send output to kksilo, as it can better handle the NFS load
    # (these are quick jobs)
    mkdir -p /cluster/store7/kate/hg17/bacends/out
    ln -s /cluster/store7/kate/hg17/bacends/out ../out
cat > gsub << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -ooc=/scratch/hg/h/11.ooc {check out line+ /cluster/data/hg17/bed/bacends/out/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst bacends.lst gsub jobList
    foreach f (`cat bacends.lst`)
        set d = $f:r:t
        echo $d
        mkdir -p /cluster/data/hg17/bed/bacends/out/$d
    end

    para create jobList
        # 37240 jobs written to batch
    para try
    para check
    para push
# CPU time in finished jobs:    1573932s   26232.19m   437.20h   18.22d  0.050 y
# IO & Wait Time:                122751s    2045.86m    34.10h    1.42d  0.004 y
# Average job time:                  46s       0.76m     0.01h    0.00d
# Longest job:                     3312s      55.20m     0.92h    0.04d
# Submission to last job:          7148s     119.13m     1.99h    0.08d

    cd ../out/BACends000
    pslCheck *.psl
#Error: invalid PSL: AZ519021:1-575 NT_004559:1306426-1608347 - NT_004559.BACends000.psl:1101
#AZ519021 query block 3 start 283 < previous block end 575
    # NOTE: inquired with JK regarding these results

    # lift alignments
    ssh eieio
    cd /cluster/data/hg17/bed/bacends
    pslSort dirs raw.psl temp out/BACends*
    # takes hours ?

        # 37240 files in 98 dirs
        # Got 37240 files 193 files per mid file
    pslReps -nearTop=0.02 -minCover=0.60 -minAli=0.85 -noIntrons \
                raw.psl  bacEnds.psl /dev/null
        # Processed 52291246 alignments
    mkdir lifted
    liftUp lifted/bacEnds.lifted.psl \
                /cluster/data/hg17/jkStuff/liftAll.lft warn bacEnds.psl
    pslSort dirs bacEnds.sorted.psl temp lifted
    rmdir temp
    wc -l *.sorted.psl
        # 2497227 bacEnds.sorted.psl

    set ncbiDir = /cluster/data/ncbi/bacends/human/bacends.4
    ~/bin/i386/pslPairs -tInsert=10000 -minId=0.91 -noBin -min=25000 -max=350000 -slopval=10000 -hardMax=500000 -slop -short -long -orphan -mismatch -verbose bacEnds.sorted.psl $ncbiDir/bacEndPairs.txt all_bacends bacEnds

    # create header required by "rdb" tools
    # TODO: replace w/ awk & sort
    echo 'chr\tstart\tend\tclone\tscore\tstrand\tall\tfeatures\tstarts\tsizes' > header
    echo '10\t10N\t10N\t10\t10N\t10\t10\t10N\t10\t10' >> header
    cat header bacEnds.pairs | row score ge 300 | sorttbl chr start | headchg -del > bacEndPairs.bed
    cat header  bacEnds.slop bacEnds.short bacEnds.long bacEnds.mismatch bacEnds.orphan \
        | row score ge 300 | sorttbl chr start | headchg -del > bacEndPairsBad.bed

    extractPslLoad -noBin bacEnds.sorted.psl bacEndPairs.bed \
                bacEndPairsBad.bed | \
                        sorttbl tname tstart | headchg -del > bacEnds.load.psl

    # load into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/bacends
    hgLoadBed hg17 bacEndPairs bacEndPairs.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/bacEndPairs.sql 
        # Loaded 201380  
    # note - this track isn't pushed to RR, just used for assembly QA
    hgLoadBed hg17 bacEndPairsBad bacEndPairsBad.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/bacEndPairsBad.sql
        # Loaded 81773
    #hgLoadPsl hg17 -nobin -table=all_bacends bacEnds.load.psl
    # NOTE: truncates file to 0 if -nobin is used
    hgLoadPsl hg17 -table=all_bacends bacEnds.load.psl
        #load of all_bacends did not go as planned: 441072 record(s), 0 row(s) skipped, 30 warning(s) loading psl.tab
    # load BAC end sequences

    mkdir -p /gbdb/hg17/bacends
    ln -s /cluster/data/ncbi/bacends/human/bacends.4/BACends.fa \
                                /gbdb/hg17/bacends/BACends.fa
    hgLoadSeq hg17 /gbdb/hg17/bacends/BACends.fa
        # 158588 sequences


# PLACE ASSEMBLY CLONES ON CONTIGS AND SEQUENCE (WORKING - 2004-06-04 - Hiram)
    ssh eieio
    mkdir /cluster/data/hg17/bed/contig_overlaps
    cd /cluster/data/hg17/bed/contig_overlaps
    #	find all the clones that were used in the assembly
    sed -e "/^#.*/d" /cluster/data/hg17/ncbi_build35.agp | \
        awk '{if (!match($5,"N")) {print $6}}' | \
        sort -u > placed_in_assembly.list
    wc -l placed_in_assembly.list
    #	26872 placed_in_assembly.list
    #	These may be available from the phases files at:
    #	ftp://ftp.ncbi.nih.gov/genbank/genomes/H_sapiens
    #	Which are easily fetched with wget.  However I took a look
    #	at those and could not find all the clones in them.  There may
    #	be a versioning problem because these phases files are often
    #	updated.
    #	Fetch them from Genbank with the following three PERL scripts:
    #	[hiram@hgwdev /cluster/data/hg17/bed/contig_overlaps] ls -og *.pl
    #	-rwxrwxr-x    1     3047 May 24 18:43 bioPerlFetch.pl
    #	-rwxrwxr-x    1     2370 Jun  4 15:21 fetchGenbank.pl
    #	-rwxrwxr-x    1      700 May 24 21:47 foldEm.pl

    #	Which takes about 4 days ...
    #	Example, 
    cat << '_EOF_' > terrys.list
AC011841.7
AC018692.9
AC018743.27
AC037482.14
AL163540.11
'_EOF_'
    # << this line makes emacs coloring happy
    #	only works on hgwdev
    ssh hgwdev
    cd /cluster/data/hg17/bed/contig_overlaps
    mkdir fasta
    time ./fetchGenbank.pl terrys.list > fetchResult.out 2>&1

    #	There is a bit of behind the scenes hocus pocus going on here.
    #	This is a tedious task of comparing various lists with each
    #	other and making sure everything matches.  Manual fixups are
    #	done for the newly named 6_hla_hap* items, copies of the PAR
    #	business were duplicated so that X and Y both have the same set
    #	of clones for that.  The end result should be a directory hierarchy
    #	here with a directory for each chrom, each random, the 6_hla_hap?
    #	items and each directory contains the clones that belong to that
    #	chromosome.  The leftovers are the unplaced clones which end up
    #	in the directory called: unPlaced.  The instructions here are
    #	merely a guideline of possibilities.  Care should be taken to
    #	make sure all listings are correct and everything gets in the
    #	right place.
    ssh eieio
    #	And then make a list of all clones considered for assembly:
    sed -e "/^#.*/d" /cluster/store5/gs.18/ncbi/sequence.inf | \
	grep for_assembly | awk '{print $1}' | sort -u > sequence.list
    wc -l sequence.list
    #	46733 sequence.list
    #	Verify overlaps are correct:
    comm -12 placed_in_assembly.list sequence.list > inBoth
    comm -23 placed_in_assembly.list sequence.list > inAssemblyNotSequence
    comm -13 placed_in_assembly.list sequence.list > inSequenceNotAssembly
    wc in*
    #	    1       1      12 inAssemblyNotSequence
    #	26871   26871  301709 inBoth
    #	19862   19862  219050 inSequenceNotAssembly
    #	46734   46734  520771 total
    #	This stray one is from Terry's five additions in the final fixup
    #	phase with Greg:
    cat inAssemblyNotSequence
    #	AC018743.27
    #	Terry added: AC011841.7 AC018692.9 AC018743.27 AC037482.14 AL163540.11
    #
    #	Generate a listing that relates clones to their contigs
    sed -e "/^#.*/d" /cluster/store5/gs.18/build35/ncbi_build35.agp | \
	./contigAcc.pl > disburseEm.list
    #
    #	Using that list, sort the downloaded clones into their
    #	respective chrom directories:
    ./disburse.sh

    #	Check the number of sequences obtained:
    find ./? ./?? ./*_random ./6_hla* -type f | wc -l
    #	26872
    #	So, why is this number one more than the inBoth list ?
    #	Because, the official NCBI sequence.inf file is missing one of
    #	the clones that Terry added: AC018743.27
    #	And it shows up in our check list above as inAssemblyNotSequence
    #	It isn't exactly missing, it just isn't marked "for_assembly"

    #	OK, with everything in place, we are ready to try and find
    #	all these items in the assembly.  To run a Kluster job on one of
    #	the chroms, matching the items that are supposed to be included
    #	in that chrom.  We need to get things set up on the Iservers,
    #	psLayout is heavy into disk I/O and it brings everything down if
    #	allowed to work on any NFS filesystems for input.

    #	It appears that psLayout wants an ooc file of tile size 10
    #	I tried making one for the whole assembly but it seemed to
    #	include too much for some contigs and it caused a lot of
    #	alignments to be missed.  Thus, create an ooc file for each
    #	contig

    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/contigOoc10
    cd /cluster/bluearc/scratch/hg/gs.18/build35/contigOoc10
    ls ../maskedContigs | sed -e "s/.fa//" | while read CONTIG
    do
	blat -repMatch=256 -makeOoc=${CONTIG}.10.ooc -tileSize=10 \
	    ../maskedContigs/${CONTIG}.fa \
	    ../maskedContigs/${CONTIG}.fa /dev/null
	echo "done: ${CONTIG}"
    done

    #	Copy that result to the Iservers:
    ssh kkr1u00
    mkdir /iscratch/i/gs.18/build35/contigOoc10
    cd /iscratch/i/gs.18/build35/contigOoc10
    rsync -arlv /cluster/bluearc/scratch/hg/gs.18/build35/contigOoc10/ .
    #	And, copy the clone sequences:
    mkdir /iscratch/i/gs.18/build35/clones
    cd /cluster/store5/gs.18/build35/bed/contig_overlaps
    for D in ? ?? *_random 6_hla_hap?
    do
	rsync -arlv `pwd`/${D} /iscratch/i/gs.18/build35/clones
    done
    
    /cluster/bin/iSync

    ssh kk
    cd /cluster/data/hg17/bed/contig_overlaps
    mkdir psl
    cat << '_EOF_' > runPsLayout.sh
#!/bin/sh
#       kkiPsLayout.sh <chrom> <clone> <contig>
#       where <chrom> is the chrom this contig is on
#       <clone> is one of the .fa.gz files in
#               /cluster/data/hg17/bed/contig_overlaps/*/<clone>.fa.gz
#               without the .fa.gz extension
#               This stuff has been mirrored to:
#               /iscratch/i/gs.18/clones/*/<clone>.fa.gz
#       <contig> is one of the contigs found in:
#               /cluster/store5/gs.18/build35/<chrom>/<contig>/<contig>.fa
#
CHROM=$1
CLONE=$2
CONTIG=$3
TARGET=/iscratch/i/gs.18/build35/maskedContigs/${CONTIG}.fa
FAZ=/iscratch/i/gs.18/build35/clones/${CHROM}/${CLONE}.fa.gz
OOC=/iscratch/i/gs.18/build35/contigOoc10/${CONTIG}.10.ooc
mkdir -p psl/${CONTIG}
if [ ! -s ${FAZ} ]; then
        echo "Can not find: ${FAZ}"
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}"
        exit 255
fi
if [ ! -s ${OOC} ]; then
        echo "Can not find: ${OOC}"
        exit 255
fi
zcat ${FAZ} > /tmp/${CLONE}.fa
$HOME/bin/i386/psLayout ${TARGET} \
        /tmp/${CLONE}.fa genomic ${OOC} psl/${CONTIG}/${CLONE}.psl
RET=$?
rm -f /tmp/${CLONE}.fa
exit ${RET}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runPsLayout.sh

    #	make up a listing of chrom, clone, contig from:
    grep -v "^#" disburseEm.list | sed -e "s/.fa.gz//" > chr.clone.contig.list
    wc -l chr.clone.contig.list
    #	26872 chr.clone.contig.list
    awk '{
printf "./runPsLayout.sh %s %s %s {check out line+ psl/%s/%s.psl}\n",
        $1, $2, $3, $3, $2
}' chr.clone.contig.list > jobList
    # << this line makes emacs coloring happy
    #	To do a quick test, run just chr22:
    grep -v "^22" chr.clone.contig.list | awk '{
printf "./runPsLayout.sh %s %s %s {check out line+ psl/%s/%s.psl}\n",
        $1, $2, $3, $3, $2
}' > jobList
    para create jobList
    para try ... check ... etc ...
    #	One run on chr22 took:
# Completed: 561 of 561 jobs
# CPU time in finished jobs:     927068s   15451.14m   257.52h   10.73d  0.029 y
# IO & Wait Time:                  6295s     104.91m     1.75h    0.07d  0.000 y
# Average job time:                1664s      27.73m     0.46h    0.02d
# Longest job:                    69745s    1162.42m    19.37h    0.81d
# Submission to last job:         69780s    1163.00m    19.38h    0.81d


    #	put the results together, filter, lift and load:
    cd /cluster/data/hg17/bed/contig_overlaps/psl
    pslSort dirs raw.psl tmp N*
    pslReps -singleHit raw.psl repsSingle.psl /dev/null
    liftUp chr22.psl /cluster/data/hg17/jkStuff/liftAll.lft \
	warn repsSingle.psl
    hgLoadPsl -table=cloneTest hg17 chr22.psl

    #	There are a number of clones listed in the sequence.inf file
    #	as status W with names beginning AACC AADB AADC AADD
    #	These are the Whole shotgun assemblies for the Celera genome.
    #	A few of them were used in the assembly of the NCBI genome, namely:
./11/AADB01066164.1.fa.gz
./11/AADC01095577.1.fa.gz
./11/AADD01116830.1.fa.gz
./11/AADD01118406.1.fa.gz
./11/AADD01116787.1.fa.gz
./11/AADD01112371.1.fa.gz
./11/AADD01116788.1.fa.gz
./11/AADD01115518.1.fa.gz
./11/AADD01118410.1.fa.gz
./11/AADD01117999.1.fa.gz
./21/AADD01172789.1.fa.gz
./21/AADD01172788.1.fa.gz
./21/AADD01209098.1.fa.gz
./21/AADD01172902.1.fa.gz
    #	And these have been distributed properly in their corresponding
    #	chromosome.  The rest of them, 26, all with names starting AACC are in
    #	the directory here: celeraOnly

    #	To run the unPlaced alignments.
    #	Prepare scratch and iscratch
    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/clones/unPlaced
    rsync -arlv /cluster/data/hg17/bed/contig_overlaps/unPlaced/ \
	/cluster/bluearc/scratch/hg/gs.18/build35/clones/unPlaced
    #	request scratch sync to cluster admins

    ssh kkr1u00
    mkdir /iscratch/i/gs.18/build35/clones/unPlaced
    rsync -arlv /cluster/data/hg17/bed/contig_overlaps/unPlaced/ \
	/iscratch/i/gs.18/build35/clones/unPlaced
    /cluster/bin/iSync

    ssh hgwdev
    cd /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    #	There are too many to try them all, obtain guildelines from hg16
    #	of clone to contig mapping:
    hgsql -N -e "select name,chrom from clonePos;" hg16 > hg16.clone.chrom
    hgsql -N -e "select contig,chrom from ctgPos;" hg16 > hg16.contig.chrom

    ssh kk
    mkdir /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    cd /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    ls ../unPlaced | sed -e "s/.fa.gz//" > unPlaced.clone.list
    wc -l unPlaced.clone.list
    #	19836 unPlaced.clone.list
    ls -1S /scratch/hg/gs.18/build35/maskedContigs > contig.list
    wc -l contig.list
    #	380 contig.list

    cat << '_EOF_' > runPsLayout.sh
#!/bin/sh
#       kkiPsLayout.sh <clone> <contig>
#       <clone> is one of the .fa.gz files in
#               /scratch/hg/gs.18/build35/clones/unPlaced
#               without the .fa.gz extension
#       <contig> is one of the contigs found in:
#               /iscratch/i/gs.18/build35/maskedContigs
#
CLONE=$1
CONTIG=$2
TARGET=/iscratch/i/gs.18/build35/maskedContigs/${CONTIG}.fa
FAZ=/scratch/hg/gs.18/build35/clones/unPlaced/${CLONE}.fa.gz
OOC=/iscratch/i/gs.18/build35/contigOoc10/${CONTIG}.10.ooc
mkdir -p psl/${CONTIG}
if [ ! -s ${FAZ} ]; then
        echo "Can not find: ${FAZ}"
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}"
        exit 255
fi
if [ ! -s ${OOC} ]; then
        echo "Can not find: ${OOC}"
        exit 255
fi
zcat ${FAZ} > /tmp/${CLONE}.fa
$HOME/bin/i386/psLayout ${TARGET} \
        /tmp/${CLONE}.fa genomic ${OOC} psl/${CONTIG}/${CLONE}.psl
RET=$?
rm -f /tmp/${CLONE}.fa
exit ${RET}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runPsLayout.sh

    cat << '_EOF_' > gsub
#LOOP
./runPsLayout.sh $(path1) $(path2) {check out line+ psl/$(path2)/$(path1).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

-
    gensub2 unPlaced.clone.list contig.list gsub jobList


# BUILD KNOWN GENES TABLES (DONE 6/8/04 Fan)

  Build sp040515 and proteins040515 DBs first.
  
  hgsql hg17 -e "create database kgHg17"
  
  cd /cluster/store6/kgDB/bed
  mkdir kgHg17
  cd /cluster/store6/kgDB/bed/kgHg17

  ~/src/hg/protein/KGprocess.sh kgHg17 hg17 040515
  
  The script was run successfully with the last message:

  	Tue Jun  8 15:36:52 PDT 2004 DONE 

  After initial inspection of tables in kgHg17, do the following
  from mySql prompt:

  alter table kgHg17.cgapAlias rename as hg17.cgapAlias;
  alter table kgHg17.cgapBiocDesc rename as hg17.cgapBiocDesc;
  alter table kgHg17.cgapBiocPathway rename as hg17.cgapBiocPathway;
  alter table kgHg17.dupSpMrna rename as hg17.dupSpMrna;
  alter table kgHg17.keggMapDesc rename as hg17.keggMapDesc;
  alter table kgHg17.keggPathway rename as hg17.keggPathway;
  alter table kgHg17.kgAlias rename as hg17.kgAlias;
  alter table kgHg17.kgProtAlias rename as hg17.kgProtAlias;
  alter table kgHg17.kgXref rename as hg17.kgXref;
  alter table kgHg17.knownGene rename as hg17.knownGene;
  alter table kgHg17.knownGeneLink rename as hg17.knownGeneLink;
  alter table kgHg17.knownGeneMrna rename as hg17.knownGeneMrna;
  alter table kgHg17.knownGenePep rename as hg17.knownGenePep;
  alter table kgHg17.mrnaRefseq rename as hg17.mrnaRefseq;
  alter table kgHg17.spMrna rename as hg17.spMrna;

  hg17.knownGene has 43,401 entries and hg16.knownGene has 43,232 entries.
  and running featireBits shows:
  
   	featureBits hg17 knownGene
   	63983072 bases of 2866216770 (2.232%) in intersection
   
   	featureBits hg16 knownGene
   	63781799 bases of 2865248791 (2.226%) in intersection
  
  Connect to genome-testdb and use hgcentraltest DB.
  Add a new entry in gdbPdb table:
 
        insert into gdbPdb values('hg17', 'proteins040515');


# CREATE LINEAGE-SPECIFIC REPEATS FOR BLASTZ WITH ZEBRAFISH
# (DONE, 2004-06-08, hartera)
    # Treat all repeats as lineage-specific
    mkdir /iscratch/i/gs.18/build35/linSpecRep.notInZebrafish
    foreach f (/iscratch/i/gs.18/build35/rmsk/chr*.fa.out)
 cp -p $f /iscratch/i/gs.18/build35/linSpecRep.notInZebrafish/$f:t:r:r.out.spec
    end
    iSync
  

# PREP FOR LIFTOVER CHAINS TO THIS ASSEMBLY (2004-06-10 kate)

    # split into 3K chunks
    ssh eieio
    set tempDir = /cluster/data/hg17/bed/liftOver/liftSplit
    mkdir -p $tempDir
    cd $tempDir
cat > split.csh << 'EOF'
    set split = /iscratch/i/hg17/liftOver/split
    mkdir -p $split
    set tempDir = /cluster/data/hg17/bed/liftOver/liftSplit
    foreach i (`cat /cluster/data/hg17/chrom.lst`)
        echo chr$i
        faSplit -lift=$tempDir/chr$i.lft size /cluster/data/hg17/$i/chr$i.fa -oneFile 3000 $split/chr$i
    end
'EOF'
    csh split.csh >&! split.log &
    tail -100f split.log

    ssh kkr1u00
    iSync


# STS MARKERS (2004-06-09 kate)

   # update from NCBI
    ssh eieio
   ln -s /cluster/store5/sts.2004-06 /cluster/data/ncbi
   cd /cluster/data/ncbi/sts.2004-06
    ln -s /cluster/data/ncbi/sts.2004-06 sts.9
    wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.sts
    wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.aliases
    wget ftp://ftp.ncbi.nih.gov/blast/db/FASTA/sts.gz
    gunzip sts.gz
    mv sts dbSTS.fa

    # incremental update from previous build
    # NOTE: could mysql dump this, unless hand-updated (like hg16)
    # First - copy from Terry's dir
    ssh eieio
    ln -s /cluster/store1/sts.8 /cluster/data/ncbi
    cd /cluster/data/ncbi/sts.9

    # this time, snag from Terry's dir
    cp ~booch/tracks/update/all.STS.fa.new /cluster/data/sts.9/all.STS.fa.old
    cp ~booch/tracks/update/stsInfo2.bed .

    # NOTE: checkStsIds modifies stsInfo2.bed and all.STS.fa
    # It creates all.primers, all.primers.fa, stsAlias.bed
    cp /cluster/data/ncbi/sts.8/all.STS.fa all.STS.fa.old
    /cluster/bin/scripts/checkStsIds stsInfo2.bed dbSTS.aliases dbSTS.sts \
                        dbSTS.fa all.STS.fa.old
    # Copy stsInfo2.bed and stsAlias.bed to data directory becuase
    # these will be loaded into the database later
    mkdir -p /cluster/data/hg17/bed/sts
    cp stsInfo2.bed /cluster/data/hg17/bed/sts/
    cp stsAlias.bed /cluster/data/hg17/bed/sts/

    # Create sts sequence alignments
    mkdir -p /cluster/bluearc/sts.9/sts
    faSplit sequence all.STS.fa 10 /cluster/bluearc/sts.9/sts/sts

    ssh kk
    cd /cluster/data/hg17/bed/sts
    mkdir run
    cd run
    cp /cluster/data/ncbi/sts.9/all.STS.fa /cluster/bluearc/sts.9
    ls -1S /scratch/hg/hg17/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/sts.9/sts/sts*.fa > sts.lst
    mkdir -p /cluster/bluearc/hg17/sts/sts/out
cat > template << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -ooc=/scratch/hg/h/11.ooc {check out line+ /cluster/bluearc/hg17/sts/sts/out/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst sts.lst template jobList
    para create jobList
        # 3420 jobs
    para try
    para check
    para push

# Final run
# Completed: 3420 of 3420 jobs
# CPU time in finished jobs:      36777s     612.95m    10.22h    0.43d  0.001 y
# IO & Wait Time:                 18962s     316.04m     5.27h    0.22d  0.001 y
# Average job time:                  16s       0.27m     0.00h    0.00d
# Longest job:                      157s       2.62m     0.04h    0.00d
# Submission to last job:           328s       5.47m     0.09h    0.00d

# Initial run
# CPU time in finished jobs:      36148s     602.47m    10.04h    0.42d  0.001 y
# IO & Wait Time:                 22211s     370.18m     6.17h    0.26d  0.001 y
# Average job time:                  17s       0.28m     0.00h    0.00d
# Longest job:                      154s       2.57m     0.04h    0.00d
# Submission to last job:           362s       6.03m     0.10h    0.00d

    # NOTE: this went really fast -- probably not even necessary
    #   to split the all.STS.fa file

    # Compile sts sequence results
    ssh eieio
    cd /cluster/bluearc/hg17/sts/sts
    pslSort dirs raw.psl temp out
    rm -rf temp
    pslReps -nearTop=0.01 -minCover=0.6 -minAli=0.8 -noIntrons raw.psl \ 
	stsMarkers.psl /dev/null
    cp stsMarkers.psl /cluster/data/hg17/bed/sts/run

    # primers
    ssh eieio
    cd /cluster/data/ncbi/sts.9
    # strip out N's and wobbles (KS) from primers, as isPcr
    # can't currently handle them
    # strip out primers < 10 as isPcr can't handle them
    #awk '$0 !~ /[^ACGT0-9\t]/ && (length($2) > 10) && (length($3) > 10) {printf "dbSTS_%s\t%s\t%s\n", $1,$2,$3}' \
    awk '$0 !~ /[^ACGT0-9\-\t]/ && (length($2) > 10) && (length($3) > 10) {printf "dbSTS_%s\t%s\t%s\n", $1,$2,$3}' \
                all.primers > all.primers.ispcr
    mkdir -p /cluster/bluearc/sts.9/primers
    cd /cluster/bluearc/sts.9/primers
    split -l 2000 /cluster/data/ncbi/sts.9/all.primers.ispcr primers_

    ssh kk
	cd /cluster/data/hg17/bed/sts
    mkdir primers
    cd primers
    mkdir run
    cd run
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/sts.9/primers/primers_* > primers.lst
    mkdir -p /cluster/bluearc/hg17/sts/primers/out
    # first run used minPerfect=0
cat > template << 'EOF'
#LOOP
/cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=2 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc  $(path1) $(path2) {check out line /cluster/bluearc/hg17/sts/primers/out/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst primers.lst template jobList
    para create jobList
        ## 9500 jobs
        # 11020 jobs
	# 27360 jobs
    para try
    para check
    para push

    # para time
    # Completed: 25979 of 27360 jobs
    # Crashed: 1379 jobs
    # CPU time in finished jobs:    1151897s   19198.29m   319.97h   13.33d  0.037 y
    # IO & Wait Time:                 75325s    1255.41m    20.92h    0.87d  0.002 y
    # Average job time:                  47s       0.79m     0.01h    0.00d
    # Longest job:                     1056s      17.60m     0.29h    0.01d
    # Submission to last job:          3012s      50.20m     0.84h    0.03d

    # Of the 1379 jobs that crashed, 1325 are because the resulting psl file
    # was empty.  This shouldn't happen anymore as the '+' in the 
    # 'check out line' is now removed and shouldn't consider an empty file an error.

    # The remaining 4 seg faulted due to -minPerfect=2.
    # These were re-run with higher minPerfect values until they completed
    # normally.  The final jobs were :

    /cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=3 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc /scratch/hg/gs.18/build35/maskedContigs/NT_086608.fa /cluster/bluearc/sts.9/primers/primers_ad /cluster/bluearc/hg17/sts/primers/out/NT_086608_primers_ad.psl
        
    /cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=3 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc /scratch/hg/gs.18/build35/maskedContigs/NT_035158.fa /cluster/bluearc/sts.9/primers/primers_cb /cluster/bluearc/hg17/sts/primers/out/NT_035158_primers_cb.psl

    /cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=3 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc /scratch/hg/gs.18/build35/maskedContigs/NT_079540.fa /cluster/bluearc/sts.9/primers/primers_cg /cluster/bluearc/hg17/sts/primers/out/NT_079540_primers_cg.psl

/cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=5 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc  /scratch/hg/gs.18/build35/maskedContigs/NT_025965.fa /cluster/bluearc/sts.9/primers/primers_cr /cluster/bluearc/hg17/sts/primers/out/NT_025965_primers_cr.psl

    # In addition, two other jobs were run manually due to cluster errors
    
    /cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=2 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc  /scratch/hg/gs.18/build35/maskedContigs/NT_022139.fa /cluster/bluearc/sts.9/primers/primers_by /cluster/bluearc/hg17/sts/primers/out/NT_022139_primers_by.psl
Loaded 1426129 letters in 1 sequences

    /cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=2 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc  /scratch/hg/gs.18/build35/maskedContigs/NT_006238.fa /cluster/bluearc/sts.9/primers/primers_bw /cluster/bluearc/hg17/sts/primers/out/NT_006238_primers_bw.psl
Loaded 9040907 letters in 1 sequences



    # This not necessary anymore
    # ssh eieio
    # cd /cluster/bluearc/hg17/sts/primers/out
    # Note: got error that -4 is invalid number -- must remove all
    # these before liftUp
    # ls | xargs sed '/-[1-9]/d' > all.psl.unlifted
    # Do the lift later after epcr alignments added

    # Alternative to above paragrapgh
    # Filter output file quickly based on simple parameters
    ssh kolossus
    cd /cluster/bluearc/hg17/sts/primers/
    mkdir -p filter
    pslQuickFilter -minMatch=26 -maxMismatch=5 -maxTinsert=5000 -verbose out/ filter/
    pslSort dirs all.psl.unlifted temp filter
    cp all.psl.unlifted  /cluster/bluearc/hg17/sts/primers/

    # filter primer alignments and create not found primer file for ePCR run (booch)
    cd /cluster/data/hg17/bed/sts/primers
    pslFilterPrimers /cluster/bluearc/hg17/sts/primers/all.psl.unlifted  \
	/cluster/data/ncbi/sts.9/all.primers all.filter.psl
    wc all.filter.psl.notfound.primers
    # 22125  110625 1354325 all.filter.psl.notfound.primers

    # use Greg Schuler's ePCR to attempt alignment of primers missed
    # by isPcr (kate)
    ssh eieio
    cd /cluster/data/hg17/bed/sts/primers
    mkdir run.epcr
    cd run.epcr
    cp /cluster/data/hg17/bed/sts/primers/all.filter.psl.notfound.primers .

# The following is not necessary anymore
#cat > listPrimers.sh << 'EOF'
#    sed -n "s/^$1\t/dbSTS_$1\t/p" /cluster/data/ncbi/sts.9/all.primers 
#'EOF'
#    chmod +x listPrimers.sh
#    # this takes a few hours -- but shouldn't (ac to Hiram) ? 
#    cat /cluster/data/hg17/bed/sts/primers/missing.primers.list | \
#                xargs -n 1 listPrimers.sh > missing.primers

    mkdir -p /cluster/bluearc/hg17/sts/epcr
    cd /cluster/bluearc/hg17/sts/epcr
    split -l 2500 /cluster/data/hg17/bed/sts/primers/all.filter.psl.notfound.primers \
                        primers_
    cd /cluster/data/hg17/bed/sts/primers/run.epcr
    ls -1S /cluster/bluearc/hg17/sts/epcr/primers_* > primers.lst
    #ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > contigs.lst
    #ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > \
        #/cluster/bluearc/hg17/sts/epcr/contigs.lst
    #ls -1S /iscratch/i/hg17/maskedContigs/*.fa > \
        #/cluster/bluearc/hg17/sts/epcr/contigs.lst
    /cluster/bin/scripts/splitContigList -ncbi /cluster/data/hg17 1
    mkdir -p /cluster/bluearc/hg17/sts/epcr/out

    ssh kk
    cd /cluster/data/hg17/bed/sts/primers/run.epcr

cat > template << 'EOF'
#LOOP
/cluster/bin/scripts/runEpcr $(path1) $(path2) {check out line /cluster/bluearc/hg17/sts/epcr/out/$(root1).$(root2).epcr}
#ENDLOOP
'EOF'
    gensub2 primers.lst contig.lst template jobList
    para create jobList
	# 3420 jobs
    para try
    para check
    para push

#Completed: 3420 of 3420 jobs
#CPU time in finished jobs:      82224s    1370.40m    22.84h    0.95d  0.003 y
#IO & Wait Time:                 55877s     931.28m    15.52h    0.65d  0.002 y
#Average job time:                  40s       0.67m     0.01h    0.00d
#Longest job:                      522s       8.70m     0.14h    0.01d
#Submission to last job:           875s      14.58m     0.24h    0.01d

#Completed: 8 of 8 jobs
#CPU time in finished jobs:      33914s     565.23m     9.42h    0.39d  0.001 y
#IO & Wait Time:                  3104s      51.74m     0.86h    0.04d  0.000 y
#Average job time:                4627s      77.12m     1.29h    0.05d
#Longest job:                     5248s      87.47m     1.46h    0.06d
#Submission to last job:          5248s      87.47m     1.46h    0.06d


    ssh eieio
    cd /cluster/bluearc/hg17/sts/epcr

    # merge output - not expecting 4-column format
    cat out/*.epcr > all.epcr
    wc all.epcr
    # 3482   13928  178794 all.epcr

    # This not needed anymore
    # merge results, convert to 4 column format, and add rdb header
    #cat out/*.epcr | sed 's/\.\./\t/' > all.epcr
    #wc -l all.epcr
    #    # 375977 all.epcr
    #sed 's/dbSTS_//' all.epcr | awk '{print $4}' | sort -g | uniq | wc -l
    #    # total aligned =
    #    # 18511 (out of 39000 total missing)
    #sed 's/dbSTS_//' all.epcr | sort -g -k 4 | \
    #    awk '{printf "%s\t%s\t%s\tdbSTS_%s\n", $1, $2, $3, $4}' \
    #            > all.epcr.initial

    # use all.epcr file to re-filter alignemnts and determine which
    # ePCR records to keep
    cp all.epcr /cluster/data/hg17/bed/sts/primers
    cd /cluster/data/hg17/bed/sts/primers
    pslFilterPrimers -epcr=all.epcr -verbose=1 \
	/cluster/bluearc/hg17/sts/primers/all.psl.unlifted \
	/cluster/data/ncbi/sts.9/all.primers all.filter.epcr.psl

    # convert to PSL and combine with other psl file
    /cluster/bin/scripts/epcrToHgPsl epcr.not.found /cluster/data/ncbi/sts.9/all.primers \
	/cluster/data/hg17

    # GOT HERE

    cat all.filter.epcr.psl epcr.not.found.psl | sort -k 10n > primers.psl.unlifted

    # lift results from contigs to chrom coordinates, and create final file
    liftUp /cluster/data/hg17/bed/sts/primers/primers.psl \
	/cluster/data/hg17/jkStuff/liftAll.lft warn primers.psl.unlifted
    extractPslInfo primers.filter
    # need to do more stuff to merge sequence and primer alignments
    

    
# LOAD AFFYRATIO (WORKING - 2004-06-09 - Hiram)
#	Copied from Hg16 doc
    # Set up cluster job to align consenesus/exemplars to hg17
    ssh eieio
    mkdir /cluster/bluearc/hg17/affyGnf
    cp -p /projects/compbio/data/microarray/affyGnf/sequences/HG-U95/HG-U95Av2_all.fa /cluster/bluearc/hg17/affyGnf

    ssh kkr1u00
    mkdir -p /iscratch/i/affyGnf
    cp -p /cluster/bluearc/hg17/affyGnf/* /iscratch/i/affyGnf
    /cluster/bin/iSync

    ssh kki
    mkdir /cluster/data/hg17/bed/affyGnf.2004-06-09
    cd /cluster/data/hg17/bed/affyGnf.2004-06-09
    ls -1 /iscratch/i/affyGnf/* > affy.lst
    ls -1 /iscratch/i/gs.18/build35/maskedContigs/* > allctg.lst
    cat << '_EOF_' > template.sub
#LOOP
/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/iscratch/i/gs.18/build35/hg17.11.ooc  $(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 allctg.lst affy.lst template.sub jobList
    mkdir psl
    para create jobList
# Completed: 380 of 380 jobs
# CPU time in finished jobs:       2922s      48.70m     0.81h    0.03d  0.000 y
# IO & Wait Time:                  1146s      19.10m     0.32h    0.01d  0.000 y
# Average job time:                  11s       0.18m     0.00h    0.00d
# Longest job:                       80s       1.33m     0.02h    0.00d
# Submission to last job:           333s       5.55m     0.09h    0.00d

XXXX - pause here while going to fishClone mapping

Also do:
# Load AFFYUCLANORM, extended version of affyUcla track. Hopefully
# final freeze of data set.
    cp /projects/compbio/data/microarray/affyUcla/sequences/HG-U133AB_all ./
and
# GNF ATLAS 2  [Done jk 3/29/2004]
    # Align probes from GNF1H chip.

######	 A second attempt at clone alignment###
    #	Split the clones into 3K pieces into about 1000 fa files

    #	Example:
zcat Z99916.1.fa.gz Z99774.1.fa.gz Z99756.7.fa.gz | faSplit size stdin 3000 /tmp/name.fa -lift=/tmp/name.lft -oneFile

    #	Trying this idea in unPlacedBatch
    ssh kk0
    mkdir /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    cd /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    ls -1S /scratch/hg/gs.18/build35/bothMaskedNibs > nibList
    ls -1S /cluster/data/hg17/bed/contig_overlaps/blatClones > cloneList
cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -fastMap -ooc=/scratch/hg/h/11.ooc -q=dna -t=dna {check in exists /scratch/hg/gs.18/build35/bothMaskedNibs/$(path1)} {check in exists+ /cluster/data/hg17/bed/contig_overlaps/blatClones/$(path2)} {check out line+ psl/$(root1)/$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    mkdir psl
    cat nibList | sed -e "s/.nib//" | while read D
do
mkdir psl/$D
done

    gensub2 nibList cloneList gsub jobList
    para create jobList


# MAKE LINEAGE-SPECIFIC REPEATS FOR CHICKEN & FUGU (DONE 2004-06-10 kate)
    # In an email 2/13/04 to Angie, Arian said we could treat all 
    # human repeats as 
    # lineage-specific for human-chicken blastz.  
    # and Angie did the same for fugu.
    # Lacking input from Arian, and using blastzSelf as a model,
    # I'm also using all human repeats for the human/chimp blastz.
    # Scripts expect *.out.spec filenames.
    ssh kkr1u00
    cd /cluster/data/hg17
    mkdir /iscratch/i/hg17/linSpecRep.chicken
    foreach f (/iscratch/i/hg17/rmsk/chr*.fa.out)
      cp -p $f /iscratch/i/hg17/linSpecRep.chicken/$f:t:r:r.out.spec
    end
    ln -s /iscratch/i/hg17/linSpecRep.chicken \
          /iscratch/i/hg17/linSpecRep.fugu
    ln -s /iscratch/i/hg17/linSpecRep.chicken \
          /iscratch/i/hg17/linSpecRep.chimp
    iSync


# BLASTZ FUGU (FR1) (DONE 2004-06-24 kate)
    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.fr1.2004-06-10
    ln -s /cluster/data/hg17/bed/blastz.fr1.2004-06-10 \
            /cluster/data/hg17/bed/blastz.fr1
    cd /cluster/data/hg17/bed/blastz.fr1
    # Set L=6000 (more relaxed than chicken) and abridge repeats.
    # Treat all repeats as lineage-specific (reuse linSpecRep.Chicken).
    cat << '_EOF_' > DEF
# human vs. fugu
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Reuse parameters from human-chicken.
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human
SEQ1_DIR=/iscratch/i/hg17/bothMaskedNibs
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/hg17/linSpecRep.fugu
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Fugu
SEQ2_DIR=/iscratch/i/fr1/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/iscratch/i/fr1/linSpecRep
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.fr1

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    bash # if a csh/tcsh user
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    # GOT HERE
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
        # 11935 jobs
    para try
    para check
    para push
# Completed: 11935 of 11935 jobs
# CPU time in finished jobs:    4673316s   77888.60m  1298.14h   54.09d  0.148 y
# IO & Wait Time:                329249s    5487.48m    91.46h    3.81d  0.010 y
# Average job time:                 419s       6.99m     0.12h    0.00d
# Longest job:                      714s      11.90m     0.20h    0.01d
# Submission to last job:          5575s      92.92m     1.55h    0.06d

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    cd /cluster/data/hg17/bed/blastz.fr1
    bash # if a csh/tcsh user
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
        # 341 jobs
    para try
    para check 
    para push
# CPU time in finished jobs:        315s       5.26m     0.09h    0.00d  0.000 y
# IO & Wait Time:                  4451s      74.18m     1.24h    0.05d  0.000 y
# Average job time:                  14s       0.23m     0.00h    0.00d
# Longest job:                      107s       1.78m     0.03h    0.00d
# Submission to last job:           368s       6.13m     0.10h    0.00d

    # third run: lav -> axt
    ssh kki
    cd /cluster/data/hg17/bed/blastz.fr1
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << 'EOF' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| lavToAxt stdin \
        /iscratch/i/hg17/bothMaskedNibs /iscratch/i/fr1/nib stdout \
| axtSort stdin ../../axtChrom/$chr.axt 
axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
        ../../pslChrom/$chr.psl
'EOF'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
        # 41 jobs
    para try
    para check
    para push


# CHAIN FUGU BLASTZ (2004-06-11 kate)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/hg17/bed/blastz.fr1
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/hg17/bed/blastz.fr1/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    # Reuse gap penalties from chicken run.
    cat << '_EOF_' > temp.gap
tablesize	11
smallSize	111
position	1	2	3	11	111	2111	12111	32111	72111	152111	252111
qGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
tGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
bothGap	625	660	700	750	900	1400	4000	8000	16000	32000	57000
'_EOF_'
    # << this line makes emacs coloring happy
    sed 's/  */\t/g' temp.gap > ../../fuguHumanTuned.gap
    rm -f temp.gap

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
                      -linearGap=../../fuguHumanTuned.gap \
                      -minScore=5000 $1 \
    /iscratch/i/hg17/bothMaskedNibs \
    /iscratch/i/fr1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
        # 46 jobs
    para try
    para check
    para push
        # 1 crashed job -- chr6_hla_hap1.chain is empty
# CPU time in finished jobs:        610s      10.16m     0.17h    0.01d  0.000 y
# IO & Wait Time:                  1644s      27.40m     0.46h    0.02d  0.000 y
# Average job time:                  50s       0.83m     0.01h    0.00d
# Longest job:                      233s       3.88m     0.06h    0.00d
# Submission to last job:           339s       5.65m     0.09h    0.00d

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain hg17 ${c}_chainFr1 $i
    end
    featureBits hg16 chainFr1Link
        # 50709290 bases of 2865248791 (1.770%) in intersection


# ANCIENT REPEAT TABLE (2004-06-11 kate)

    # The netClass operations requires an "ancientRepeat" table in one 
    # of the databases.
    # This is a hand curated table obtained from Arian.

    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/ancientRepeat
    cd /cluster/data/hg17/bed/ancientRepeat
    # mysqldump needs write permission to this directory
    chmod 777 .
    hgsqldump --all --tab=. hg15 ancientRepeat
    chmod 775 .
    hgsql hg17 < ancientRepeat.sql
    echo "LOAD DATA LOCAL INFILE 'ancientRepeat.txt' into table ancientRepeat"\
                | hgsql hg17


# NET FUGU BLASTZ (2004-06-11 kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    netClass noClass.net hg17 fr1 human.net

    # Make a 'syntenic' subset:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netFr1 stdin
    #netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 netSyntenyFr1 stdin


# EXTRACT AXT'S AND MAF'S FROM THE NET (kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    netSplit human.net humanNet
    mkdir -p ../axtNet ../mafNet
cat > makeMaf.csh << 'EOF'
    foreach f (humanNet/chr*.net)
        set c = $f:t:r
        echo "axtNet on $c"
        netToAxt humanNet/$c.net chain/$c.chain /cluster/data/hg17/nib /cluster/data/fr1/nib stdout | axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/fr1/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=fr1.
    end
'EOF'
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

#  BLASTZ RAT RN3 (DONE - 2004-06-14 - Hiram)

    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.rn3.2004-06-11
    cd /cluster/data/hg17/bed
    ln -s  blastz.rn3.2004-06-11 blastz.rn3
    cd blastz.rn3

    cat << '_EOF_' > DEF
# rat vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Rat
SEQ2_DIR=/iscratch/i/rn3/bothMaskedNibs
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/store5/gs.18/build35/bed/blastz.rn3

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.rn3
    source DEF
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run0.sh
    #	it is a generic script and works for any assembly
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
Completed: 41943 of 41943 jobs
CPU time in finished jobs:   15330421s  255507.02m  4258.45h  177.44d  0.486 y
IO & Wait Time:                673809s   11230.15m   187.17h    7.80d  0.021 y
Average job time:                 382s       6.36m     0.11h    0.00d
Longest job:                     4651s      77.52m     1.29h    0.05d
Submission to last job:        169197s    2819.95m    47.00h    1.96d

    #	Second cluster run to convert the .out's to .lav's
    #	You do NOT want to run this on the big cluster.  It brings
    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.rn3
    source DEF
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run1.sh
    #	fixup machine check, should be kki, not kk
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       1894s      31.56m     0.53h    0.02d  0.000 y
# IO & Wait Time:                  6271s     104.52m     1.74h    0.07d  0.000 y
# Average job time:                  24s       0.40m     0.01h    0.00d
# Longest job:                      131s       2.18m     0.04h    0.00d
# Submission to last job:           590s       9.83m     0.16h    0.01d

    #	Third cluster run to convert lav's to axt's
    source DEF
    cd /cluster/data/hg17/bed/blastz.rn3
    #	The copy of this in mm4 was broken, fixed here
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:        426s       7.09m     0.12h    0.00d  0.000 y
# IO & Wait Time:                  7283s     121.39m     2.02h    0.08d  0.000 y
# Average job time:                 168s       2.79m     0.05h    0.00d
# Longest job:                      642s      10.70m     0.18h    0.01d
# Submission to last job:           642s      10.70m     0.18h    0.01d

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3
    mkdir pslChrom
    set tbl = "blastzRn3"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 30 minutes

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/pslChrom
    for I in *.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done: ${I}"
    done
    # this is a 55 minute job
    #	Check results
    #	featureBits hg16 blastzRn3
    #	1013603401 bases of 2865248791 (35.376%) in intersection
    #	featureBits hg17 blastzRn3
    #	1013003285 bases of 2866216770 (35.343%) in intersection

# CHAIN RN3 BLASTZ (DONE - 2004-06-14 - Hiram)
#  re-worked with no 'axtFilter -notQ_random' on the axtChain step - 2004-06-23
    axtFilter -notQ_random $1 | axtChain stdin \

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kki
    mkdir -p /cluster/data/hg17/bed/blastz.rn3/axtChain/run1
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastz.rn3/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
    axtChain $1 \
	/iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/rn3/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       4645s      77.41m     1.29h    0.05d  0.000 y
# IO & Wait Time:                  6840s     114.00m     1.90h    0.08d  0.000 y
# Average job time:                 250s       4.16m     0.07h    0.00d
# Longest job:                     1539s      25.65m     0.43h    0.02d
# Submission to last job:          3761s      62.68m     1.04h    0.04d


    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    36m42.170s
    #	user    4m55.970s
    #	sys     1m49.840s

    time chainSplit chain all.chain
    #	real    13m54.860s
    #	user    4m50.370s
    #	sys     1m3.260s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg17 ${c}_chainRn3 $i
        echo done $c
    end
    #	featureBits hg17 chainRn3
    #	2827052992 bases of 2866216770 (98.634%) in intersection
    #	(with filter:) 2826192649 bases of 2866216770 (98.604%) in intersection
    #	featureBits hg16 chainRn3
    #	2830563493 bases of 2865248791 (98.789%) in intersection

# NET RN3 (DONE - 2004-06-15 - Hiram)
#	Re-done due to Chain being re-done 2004-06-23

    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg17/chrom.sizes \
                        /cluster/data/rn3/chrom.sizes ../preNet/$i
    end

    cd ..
    mkdir n1
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg17/chrom.sizes \
                            /cluster/data/rn3/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2510467072, utime 19307 s/100, stime 3181

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    time netClass hNoClass.net hg17 rn3 rat.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInRat \
	-qNewR=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman
    #	real    34m29.829s
    #	user    11m30.440s
    #	sys     1m52.730s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn rat.net > ratSyn.net
    #	real    16m25.640s
    #	user    7m41.330s
    #	sys     1m1.150s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    netFilter -minGap=10 rat.net |  hgLoadNet hg17 netRn3 stdin
    netFilter -minGap=10 ratSyn.net | hgLoadNet hg17 syntenyNetRn3 stdin
    #	real    37m0.199s
    #	user    15m13.770s
    #	sys     1m41.540s

    # check results
    # featureBits hg17 netRn3
    # 2817656275 bases of 2866216770 (98.306%) in intersection
    # (with axtFilter) 2816623107 bases of 2866216770 (98.270%) in intersection
    # featureBits hg16 netRn3
    # 2820958389 bases of 2865248791 (98.454%) in intersection

    # featureBits hg17 syntenyNetRn3
    # 2781748096 bases of 2866216770 (97.053%) in intersection
    # (with axtFilter) 2780883450 bases of 2866216770 (97.023%) in intersection
    # featureBits hg16 syntenyNetRn3
    # 2784011730 bases of 2865248791 (97.165%) in intersection

    # Add entries for net and chain to rat/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    mkdir ratNet
    time netSplit rat.net ratNet
    #	real    12m1.478s
    #	user    8m35.050s
    #	sys     1m7.230s

    # extract axts from net 
    mkdir ../axtNet 
    foreach n (ratNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt ratNet/$c.net chain/$c.chain \
		/cluster/data/hg17/nib \
		/cluster/data/rn3/nib stdout ../axtNet/$c.axt
	echo "Complete: $c.net -> axtNet/$c.axt"
    end
    # sort axt's and convert to maf format
    mkdir ../mafNet
cat << 'EOF' > makeMaf.csh
    foreach f (../axtNet/chr*.axt)
        set c=$f:t:r
        echo $c.axt
        mv ../axtNet/$c.axt ../axtNet/$c.unsorted.axt
        axtSort ../axtNet/$c.unsorted.axt ../axtNet/$c.axt
        rm ../axtNet/$c.unsorted.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/rn3/chrom.sizes \
                ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=rn3.
    end
'EOF'
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestRn3.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestRn3.psl
	echo "Done: ${c}_blastzBestRn3.psl"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/pslBest
    for I in chr*BestRn3.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits hg17 blastzBestRn3
    #	975533772 bases of 2866216770 (34.036%) in intersection
    # (with axtFilter) 970005525 bases of 2866216770 (33.843%) in intersection
    # featureBits hg16 blastzBestRn3
    #	976121391 bases of 2865248791 (34.068%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg17/axtBest/Rn3
     cd /gbdb/hg17/axtBest/Rn3
     ln -s /cluster/data/hg17/bed/blastz.rn3/axtNet/chr*.axt .
     cd /cluster/data/hg17/bed/blastz.rn3/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/hg17/axtBest/Rn3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('rn3','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
    hgsql hg17 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql hg17 < axtInfoInserts.sql

# MAKING RAT SYNTENY (DONE - 2004-06-30 - Hiram)
#	Re-Done after above done without the axtFilter

ssh hgwdev
mkdir /cluster/data/hg17/bed/syntenyRn3
cd /cluster/data/hg17/bed/syntenyRn3

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyMm3
cp -p /cluster/data/hg16/bed/syntenyMm3/*.pl .
cp -p /cluster/data/hg16/bed/syntenyMm3/*.sh .

./syntenicBest.pl -db=hg17 -table=blastzBestRn3
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg17 -table=blastzBestRn3
./synteny2bed.pl
#	The five commands above
#	real    196m2.565s
#	user    0m21.170s
#	sys     0m4.690s

#	Used to load this in syntenyRn3, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
sed -e 's/ensPhusionBlast/ensRn3MusHom/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRn3MusHom.sql
hgLoadBed hg17 ensRn3MusHom ucsc100k.bed -sqlTable=ensRn3MusHom.sql

    #	featureBits hg17 ensRn3MusHom
    #	2592164486 bases of 2866216770 (90.439%) in intersection
    #	featureBits hg16 syntenyRn3
    #	2595919851 bases of 2865248791 (90.600%) in intersection


# MAKING RAT AXTTIGHT FROM AXTBEST (DONE - 2004-06-15 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtNet
    mkdir -p ../axtTight
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightRn3.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/pslTight
    for I in chr*TightRn3.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly
    #	featureBits hg17 blastzTightRn3
    #	153936720 bases of 2866216770 (5.371%) in intersection
    #	featureBits hg16 blastzTightRn3
    #	153151903 bases of 2865248791 (5.345%) in intersection


    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtTight
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

# BLASTZ RN3 CLEAN UP (DONE - 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3
    nice rm -rf raw &
    nice rm axtChain/run1/chain/* &
    nice gzip {axt,psl}Chrom/* lav/*/* axtChain/{all.chain,*.net} &

# BLASTZ CHICKEN (GALGAL2) (DONE - 2004-06-14 - Fan)

    ssh kk
    mkdir /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    cd /cluster/data/hg17/bed
    ln -s /cluster/data/hg17/bed/blastz.galGal2.2004-06-14 blastz.galGal2
    cd blastz.galGal2
    # Set L=10000 (higher threshold on blastz's outer loop) and abridge 
    # repeats.
    cat << '_EOF_' > DEF
# human vs. chicken
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Specific settings for chicken (per Webb email to Brian Raney)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=10000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human
SEQ1_DIR=/iscratch/i/hg17/bothMaskedNibs
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.chicken
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Chicken
SEQ2_DIR=/iscratch/i/galGal2/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/iscratch/i/galGal2/linSpecRep
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/store5/gs.18/build35/bed/blastz.galGal2

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.galGal2
    bash
    source DEF
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run0.sh
    #	it is a generic script and works for any assembly
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
Completed: 41943 of 41943 jobs
CPU time in finished jobs:   15330421s  255507.02m  4258.45h  177.44d  0.486 y
IO & Wait Time:                673809s   11230.15m   187.17h    7.80d  0.021 y
Average job time:                 382s       6.36m     0.11h    0.00d
Longest job:                     4651s      77.52m     1.29h    0.05d
Submission to last job:        169197s    2819.95m    47.00h    1.96d

    #	Second cluster run to convert the .out's to .lav's
    #	You do NOT want to run this on the big cluster.  It brings
    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.galGal2
    bash
    source DEF
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run1.sh
    #	fixup machine check, should be kki, not kk
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       1894s      31.56m     0.53h    0.02d  0.000 y
# IO & Wait Time:                  6271s     104.52m     1.74h    0.07d  0.000 y
# Average job time:                  24s       0.40m     0.01h    0.00d
# Longest job:                      131s       2.18m     0.04h    0.00d
# Submission to last job:           590s       9.83m     0.16h    0.01d

    #	Third cluster run to convert lav's to axt's
    source DEF
    cd /cluster/data/hg17/bed/blastz.galGal2
    #	The copy of this in mm4 was broken, fixed here
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:        426s       7.09m     0.12h    0.00d  0.000 y
# IO & Wait Time:                  7283s     121.39m     2.02h    0.08d  0.000 y
# Average job time:                 168s       2.79m     0.05h    0.00d
# Longest job:                      642s      10.70m     0.18h    0.01d
# Submission to last job:           642s      10.70m     0.18h    0.01d

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2
    mkdir pslChrom
    set tbl = "blastzGalGal2"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 30 minutes

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2/pslChrom
    bash
    for I in *.psl
    do
        /cluster/bin/i386/hgLoadPsl hg17 ${I}
        echo "done: ${I}"
    done   


    # CHIMP ALIGNMENTS (2004-06-15, 2004-06-21 kate)

    # Align with nucleotide blat, unmasked (same method as liftOver chains
    # Use 1K split of panTro1 doc'ed in makePanTro1.doc
    ssh kk
    cd /cluster/data/hg17
    mkdir -p bed/blat.panTro1.2004-06-23
    cd bed/blat.panTro1.2004-06-23
    mkdir run raw
    cd run
cat > gsub << 'EOF'
#LOOP
do.csh $(path1) $(path2) $(root1) $(root2) {check out line+ ../raw/$(root1)/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'
cat > do.csh << 'EOF'
#!/bin/csh -fe
set c = $3
set f = ${c}_${4}.psl
blat $1 $2 /tmp/$f -tileSize=11 -ooc=/cluster/bluearc/hg/h/11.ooc \
                -minScore=100 -minIdentity=93 -fastMap
set ret = $status
mv -f /tmp/$f $5
exit $ret
'EOF'
    chmod +x do.csh
    ls -1S /scratch/hg/hg17/bothMaskedNibs/*.nib > human.lst
    ls -1S /cluster/bluearc/panTro1/blatSplit/splitChrom.3K/*.fa > chimp.lst
    gensub2 human.lst chimp.lst gsub spec
    foreach f (`cat human.lst`)
        set d = $f:t:r
        echo $d
        mkdir ../raw/$d
    end
    para create spec
        # 2438 jobs
    para try 
    para check
    para push

    ssh kksilo
    cd /cluster/data/hg17
    cd bed/blat.panTro1/raw

    # lift results to chrom coordinates
    # takes about an hour -- might want to
    # run this on the minicluster
    ssh eieio
    cd /cluster/bluearc/panTro1/blatSplit/liftChrom.3K
    cat chr*.lft > all.lft
    cd /cluster/data/hg17
    cd bed/blat.panTro1.2004-06-23/raw
    mkdir -p ../psl
cat << 'EOF' > liftup.csh
    foreach c (chr*)
        echo $c
        pslCat $c/*.psl | \
            liftUp -pslQ ../psl/$c.psl \
                /cluster/bluearc/panTro1/blatSplit/liftChrom.3K/all.lft warn stdin
    end
'EOF'
    csh liftup.csh >&! liftup.log &
    tail -100f liftup.log
    rm -r raw


# LOAD AffyUclaRatio (WORKING - 2004-06-15 - Hiram)
#LOAD AffyUclaRatio and AFFY U133A and U133B sequences[DONE hartera Feb 3, 2004]
# Used consensus/exemplar sequences instead of target sequences
    # Set up cluster job to align consensus/exemplars to hg17
    ssh kkr1u00
    cd /cluster/data/hg17/bed
    rm -rf affyUcla.2004-02-04/
    mkdir affyUcla.2004-02-04
    cd affyUcla.2004-02-04/
    mkdir -p /iscratch/i/affy
    cp /projects/compbio/data/microarray/affyUcla/sequences/HG-U133AB_all.fa /iscratch/i/affy
    iSync

XXXX use affyU133 directory here, not affyUcla

    ssh kk
    cd /cluster/data/hg17/bed/affyUcla.2004-02-04/
    ls -1 /iscratch/i/affy/HG-U133AB_all.fa > affy.lst
    ls -1 /scratch/hg/gs.17/build34/trfFa/ > allctg.lst
    echo '#LOOP\n/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc  /scratch/hg/gs.17/build34/trfFa/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > template.sub
    gensub2 allctg.lst affy.lst template.sub para.spec
    mkdir psl
    para create para.spec

    # Actually do the job with usual para try/check/push/time etc.
# on 2/4/04:
#Completed: 491 of 491 jobs
#CPU time in finished jobs:      23137s     385.61m     6.43h    0.27d  0.001 y
#IO & Wait Time:                 23057s     384.29m     6.40h    0.27d  0.001 y
#Average job time:                  94s       1.57m     0.03h    0.00d
#Longest job:                      617s      10.28m     0.17h    0.01d
#Submission to last job:           747s      12.45m     0.21h    0.01d

    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create affyU133.psl.
    pslSort dirs raw.psl tmp psl
    
    # change filter parameters for these sequences. only use alignments that
    # cover 30% of sequence and have at least 95% identity in aligned region. 
    # minAli = 0.97 too high. low minCover as a lot of n's in these sequences
    pslReps -minCover=0.3 -sizeMatters -minAli=0.95 -nearTop=0.005 raw.psl contig.psl /dev/null
    liftUp affyU133.psl ../../jkStuff/liftAll.lft warn contig.psl

XXX ready to load this here, done

    # Merge with spot data and load into database.
    ssh hgwdev
    cd /cluster/data/hg17/bed/affyUcla.2004-01-28/
    # added to hashPsls to process shorter Affy probe set names
    # assumes that names has 2 colons but when shortened to fit in the seq 
    # database, there is only 1.
    # e.g. full name: "consensus:HG-U133A:212933_x_at;" short name: "HG-U133A:212933_x_at;"
    affyUclaMergePslData affyUclaMergePslData -pslFile=affyU133.psl -affyFile=/projects/compbio/data/microarray/affyUcla/data/030602_ucla_normal_human_tissue_snapshot.txt -bedOut=affyUcla.bed -expRecordOut=affyUcla.expRecords -expFile=/projects/compbio/data/microarray/affyUcla/data/expNames -toDiffFile=toDiff.txt
    hgLoadBed -sqlTable=$HOME/src/hg/lib/affyUcla.sql hg17 affyUcla affyUcla.bed
    hgLoadPsl hg17 affyU133.psl
    
    # Clean up
    rm -r psl tmp err affyUcla.bed affyUcla.expRecords bed.tab *.debug batch.bak contig.psl raw.psl
    
    # Add in sequence data for affyU95 and affyU133 tracks.
    # Copy probe sequence to /gbdb if it isn't already
    mkdir -p /gbdb/hgFixed/affyProbes
    cd /gbdb/hgFixed/affyProbes
    ln -s /projects/compbio/data/microarray/affyGnf/sequences/HG-U95/HG-U95Av2_all.fa .
    ln -s /projects/compbio/data/microarray/affyUcla/sequences/HG-U133AB_all.fa .
    
    # use perl -pi.bak -e 's/;/ /' <file> to remove ";" after probe name
    # in HG-U95Av2_all.fa seque
    # reload sequences with "U95Av2" prefix removed so acc matches name used 
    # in other dependent tables for affyU95Av2 only
    hgLoadSeq -abbr=U95Av2: hg17 /gbdb/hgFixed/affyProbes/HG-U95Av2_all.fa
    hgLoadSeq hg17 /gbdb/hgFixed/affyProbes/HG-U133AB_all.fa

# GNF ATLAS 2 (WORKING - 2004-06-15 - Hiram
    # Align probes from GNF1H chip.
    ssh kk
    cd /cluster/data/hg17/bed
    mkdir -p geneAtlas2/run/psl
    cd geneAtlas2/run
    #	This bluearc/geneAtlas2 directory already exists
    # mkdir -p /cluster/bluearc/geneAtlas2
    # cp /projects/compbio/data/microarray/geneAtlas2/human/gnf1h.fa /cluster/bluearc/geneAtlas2
    ls -1 /scratch/hg/gs.18/build35/maskedContigs > genome.lst
    ls -1 /cluster/bluearc/geneAtlas2/gnf1h.fa > mrna.lst
    cat << '_EOF_' > gsub
#LOOP
blat -fine -ooc=/scratch/hg/h/11.ooc  /scratch/hg/gs.18/build35/maskedContigs/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 genome.lst mrna.lst gsub jobList
    para create jobList
    para try
    para check
    para push
    para time
# Completed: 380 of 380 jobs
# CPU time in finished jobs:      10599s     176.65m     2.94h    0.12d  0.000 y
# IO & Wait Time:                  3893s      64.88m     1.08h    0.05d  0.000 y
# Average job time:                  38s       0.64m     0.01h    0.00d
# Longest job:                      649s      10.82m     0.18h    0.01d
# Submission to last job:           663s      11.05m     0.18h    0.01d

    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create gnf1h.psl.
    pslSort dirs raw.psl tmp psl
    pslReps -minCover=0.3 -minAli=0.95 -nearTop=0.005 raw.psl \
	contig.psl /dev/null
    #	Processed 80818 alignments
    liftUp ../affyGnf1h.psl ../../../jkStuff/liftAll.lft warn contig.psl
    rm -r contig.psl raw.psl psl

    # Load probes and alignments from GNF1H into database.
    ssh hgwdev
    cd /cluster/data/hg17/bed/geneAtlas2
    #	Already symlinked
    # ln -s /projects/compbio/data/microarray/geneAtlas2/human/gnf1h.fa \
    #	/gbdb/hgFixed/affyProbes
    hgLoadPsl hg17 affyGnf1h.psl
    hgLoadSeq hg17 /gbdb/hgFixed/affyProbes/gnf1h.fa

XXXX - need affyUcla 2004-06-15

    grep -v U133B ../affyUcla.2004-02-04/affyU133.psl | sed 's/exemplar://' \
	| sed 's/consensus://' \
        | sed 's/HG-U133A://' | sed 's/;//' > affyU133A.psl
    hgMapMicroarray gnfAtlas2.bed hgFixed.gnfHumanAtlas2MedianRatio \
    	affyU133A.psl  /cluster/data/hg17/bed/geneAtlas2/affyGnf1h.psl
    # Note that the unmapped 11000 records are from all-N sequences.
    hgLoadBed hg17 gnfAtlas2 gnfAtlas2.bed

# GENE SORTER (AKA: FAMILY BROWSER) (WORKING - 2004-06-15 - Hiram)
#	to be done after knownGene tables are complete from known gene
#	process.
#
# Cluster together various alt-splicing isoforms.
#	Creates the knownIsoforms and knownCanonical tables
ssh hgwdev
mkdir /cluster/data/hg17/bed/geneSorter.2004-06-15
ln -s /cluster/data/hg17/bed/geneSorter.2004-06-15 \
	/cluster/data/hg17/bed/geneSorter
cd /cluster/data/hg17/bed/geneSorter
hgClusterGenes hg17 knownGene knownIsoforms knownCanonical

# Extract peptides from knownGenes into fasta file
# and create a blast database out of them.
mkdir /cluster/data/hg17/bed/geneSorter/blastp
cd /cluster/data/hg17/bed/geneSorter/blastp
pepPredToFa hg17 knownGenePep known.faa
#	You may need to build this binary in src/hg/near/pepPredToFa
/scratch/blast/formatdb -i known.faa -t known -n known
#	This command is in /projects/compbio/bin/$MACH/formatdb

# Copy over database to bluearc
rm -fr /cluster/bluearc/hg17/blastp
mkdir -p /cluster/bluearc/hg17/blastp
cp -p /cluster/data/hg17/bed/geneSorter/blastp/known.* \
	/cluster/bluearc/hg17/blastp

#	Had to pick up a new blastall binary (2004-06-15)
#	Our old one would no longer run on our systems that have
#	updated Linux versions
mkdir /cluster/bluearc/blast229
cd /cluster/bluearc/blast229
wget --timestamping \
    ftp://ftp.ncbi.nlm.nih.gov/blast/executables/release/2.2.9/blast-2.2.9-ia32-linux.tar.gz
wget --timestamping \
    ftp://ftp.ncbi.nlm.nih.gov/blast/executables/release/2.2.9/ChangeLog.txt
wget --timestamping \
    ftp://ftp.ncbi.nlm.nih.gov/blast/executables/release/2.2.9/ReleaseNotes.txt
tar xvzf blast-2.2.9-ia32-linux.tar.gz


# Split up fasta file into bite sized chunks for cluster
cd /cluster/data/hg17/bed/geneSorter/blastp
mkdir split
faSplit sequence known.faa 8000 split/kg

# Make parasol run directory  (this does not work on kk, need an older
#				Linux version)
ssh kk
mkdir /cluster/data/hg17/bed/geneSorter/blastp/self
cd /cluster/data/hg17/bed/geneSorter/blastp/self
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data
export BLASTMAT
/cluster/bluearc/blast229/blastall -p blastp \
	-d /cluster/bluearc/hg17/blastp/known -i $1 -o $2 \
	-e 0.01 -m 8 -b 1000
'_EOF_'
chmod +x blastSome

# Make gensub2 file
cat  << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'

# Create parasol batch
#	'ls ../../split/*.fa' is too much, hence the echo
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push
# This should finish in ~15 minutes if the cluster is free.
Completed: 7749 of 7749 jobs
CPU time in finished jobs:     182148s    3035.81m    50.60h    2.11d  0.006 y
IO & Wait Time:                 22954s     382.56m     6.38h    0.27d  0.001 y
Average job time:                  26s       0.44m     0.01h    0.00d
Longest job:                      372s       6.20m     0.10h    0.00d
Submission to last job:           871s      14.52m     0.24h    0.01d

# Load into database.  This takes about 30 minutes
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/self/run/out
time hgLoadBlastTab hg17 knownBlastTab *.tab
# Scanning through 7749 files
# Loading database with 11799667 rows
#	Hg16 was:       11376875 rows
# real    30m10.761s
# user    5m25.490s
# sys     1m0.630s

cd /cluster/data/hg17/bed/geneSorter
# Create table that maps between known genes and RefSeq
hgMapToGene hg17 refGene knownGene knownToRefSeq
#	may need to build this command in src/hg/near/hgMapToGene
#	hgsql -e "select count(*) from knownToRefSeq;" hg17
#	row count changed from 36078 in Hg16 to 36082

# Create table that maps between known genes and LocusLink
hgsql --skip-column-names -e "select mrnaAcc,locusLinkId from refLink" hg17 \
	> refToLl.txt
hgMapToGene hg17 refGene knownGene knownToLocusLink -lookup=refToLl.txt
#	hgsql -e "select count(*) from knownToLocusLink;" hg17
#	row count went from 36078 in Hg16 to 36082

# Create table that maps between known genes and Pfam domains
hgMapViaSwissProt hg17 knownGene name proteinID Pfam knownToPfam
#	hgsql -e "select count(*) from knownToPfam;" hg17
#	row count dropped from 30467 in Hg16 to 29725

XXXX - 2004-06-15 - gnfAtlas2 table does not exist

# Create table to map between known genes and GNF Atlas2
# expression data.
    hgMapToGene hg17 gnfAtlas2 knownGene knownToGnfAtlas2 '-type=bed 12'

# Create expression distance table - takes about an hour
# (Regenerated April 16, 2004 in response to knownToGnfAtlas2 update)
    hgExpDistance hg17 hgFixed.gnfHumanAtlas2MedianRatio \
    	hgFixed.gnfHumanAtlas2MedianExps gnfAtlas2Distance \
	-lookup=knownToGnfAtlas2

# Create a table that maps between known genes and 
# the nice affy expression data.
hgMapToGene "-type=bed 12" hg17 affyUcla knownGene knownToU133
#	row count went from 34148 to 36818

# Create expression distance table.  This will take about an hour.
cd ~/kent/src/hg/near/hgExpDistance
time hgExpDistance hg17 affyUcla affyUclaExp knownExpDistance \
	-weights=affyUcla.weight -lookup=knownToU133
# 42 genes, 42 weights, 26.500000 total wieght
# Got 36818 unique elements in affyUcla
# Made knownExpDistance.tab
# Loaded knownExpDistance
# Made query index
# real    80m50.113s
# user    62m33.290s
# sys     2m15.200s

#	This command should be done elsewhere, /tmp or something like that
#	It makes a temporary .tab file of almost 1 Gb
#	row count went from 34148000 to 36818000

# Create table that maps between known genes and 
# the GNF data.
hgMapToGene hg17 affyU95 knownGene knownToU95
cd /tmp
#	hgFixed.gnfHumanU95Exps argument is unused, no need to exist
hgExpDistance hg17 hgFixed.gnfHumanU95MedianRatio hgFixed.gnfHumanU95Exps gnfU95Distance  -lookup=knownToU95
#	row count went from 11718000 to 17330000
#  original makeNear.doc had this as:
# hgExpDistance hg17 affyGnfU95 affyGnfU95Exps knownGnfDistance -lookup=knownToU95

# Make sure that GO database is up to date.
See README in /cluster/store1/geneOntology.
#	I update this GO database very carefully, checking that all
#	structures in it remain the same from release to release and
#	backing up the current go DB in a backup database.  In this case
#	the backup is go040107 - when it was loaded for Mm4, and the new
#	go database is based on data from Dec 17th 2003 and Feb 2004 according
#	to the time stamp on the fetched data.  This build was done in
#	/cluster/store1/geneOntology/20040217

cd /cluster/data/hg17/bed/geneSorter

# Create knownToEnsembl column
hgMapToGene hg17 ensGene knownGene knownToEnsembl
#	table row count went from previous version: 36068 to 38251

# Make knownToCdsSnp column.  This is a little complicated by
# having to merge data form the snpTsc and the snpNih tracks.
hgMapToGene hg17 snpTsc knownGene knownToCdsSnp -createOnly -all -cds
hgMapToGene hg17 snpTsc knownGene snp1 -noLoad -all -cds
hgMapToGene hg17 snpNih knownGene snp2 -noLoad -all -cds
sort snp1.tab snp2.tab > knownToCdsSnp.tab
rm snp1.tab snp2.tab
hgsql \
    -e 'load data local infile "knownToCdsSnp.tab" into table knownToCdsSnp;' \
	hg17
#	row count went from 87273 to 106199

# Make C. elegans ortholog column using blastp on wormpep.
# First make C. elegans protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/ce1/blastp should have data

# Create the ceBlastTab  (the blastall binary only works on kk9 for now ...)
ssh kk9
mkdir /cluster/data/hg17/bed/geneSorter/blastp/ce1
cd /cluster/data/hg17/bed/geneSorter/blastp/ce1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast/data /cluster/bluearc/blast/blastall \
	-p blastp -d /cluster/bluearc/ce1/blastp/wormPep \
	-i $1 -o $2 -e 0.01 -m 8 -b 1
'_EOF_'
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# This should finish in ~10 minutes if the cluster is free.
# Here's the para time results
# Completed: 7748 of 7748 jobs
# CPU time in finished jobs:      28869s     481.16m     8.02h    0.33d  0.001 y
# IO & Wait Time:                 20454s     340.89m     5.68h    0.24d  0.001 y
# Average job time:                   6s       0.11m     0.00h    0.00d
# Longest job:                       52s       0.87m     0.01h    0.00d
# Submission to last job:           584s       9.73m     0.16h    0.01d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/ce1/run/out
hgLoadBlastTab hg17 ceBlastTab -maxPer=1 *.tab
#	row count went from 25599 to 26958

# Make mouse ortholog column using blastp on mouse known genes.
# First make mouse protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This already exists.  See makeMm4.doc for procedure
#	the directory: /cluster/bluearc/mm4/blastp should have data

# Make parasol run directory 
ssh kk9
mkdir /cluster/data/hg17/bed/geneSorter/blastp/mm4
cd /cluster/data/hg17/bed/geneSorter/blastp/mm4
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast/data /cluster/bluearc/blast/blastall \
	-p blastp -d /cluster/bluearc/mm4/blastp/known \
	-i $1 -o $2 -e 0.001 -m 8 -b 1
'_EOF_'
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'

# Create parasol batch
# (wordLine wouldn't run on kk9:
#	wordLine: /lib/i686/libc.so.6: version `GLIBC_2.3' not found
#	run this echo statement on hgwdev
#	this echo trick is used because otherwise the command line is
#	too long and you can not do a simple ls

echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

#	takes about 15 minutes:
# Completed: 7748 of 7748 jobs
# CPU time in finished jobs:      54179s     902.98m    15.05h    0.63d  0.002 y
# IO & Wait Time:                 20428s     340.47m     5.67h    0.24d  0.001 y
# Average job time:                  10s       0.16m     0.00h    0.00d
# Longest job:                       76s       1.27m     0.02h    0.00d
# Submission to last job:          2031s      33.85m     0.56h    0.02d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/mm4/run/out
hgLoadBlastTab hg17 mmBlastTab -maxPer=1 *.tab
# Scanning through 7748 files
# Loading database with 35611 rows
#	row count went from 33191 to 35611

# Make Danio rerio (zebrafish) ortholog column using blastp on Ensembl.
# First make protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/dr1/blastp should have data

# Make parasol run directory 
ssh kk9
mkdir /cluster/data/hg17/bed/geneSorter/blastp/dr1
cd /cluster/data/hg17/bed/geneSorter/blastp/dr1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast/data /cluster/bluearc/blast/blastall \
	-p blastp -d /cluster/bluearc/dr1/blastp/ensembl \
	-i $1 -o $2 -e 0.005 -m 8 -b 1
'_EOF_'
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# Completed: 7748 of 7748 jobs
# CPU time in finished jobs:      40575s     676.24m    11.27h    0.47d  0.001 y
# IO & Wait Time:                 19781s     329.69m     5.49h    0.23d  0.001 y
# Average job time:                   8s       0.13m     0.00h    0.00d
# Longest job:                       95s       1.58m     0.03h    0.00d
# Submission to last job:          2036s      33.93m     0.57h    0.02d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/dr1/run/out
hgLoadBlastTab hg17 drBlastTab -maxPer=1 *.tab
# Scanning through 7748 files
# Loading database with 32204 rows
#	row count went from 30339 to 32204

# Make Saccharomyces cerevisiae (yeast) ortholog column using blastp on RefSeq.
# First make protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/sc1/blastp should have data

# Make parasol run directory 
ssh kk9
mkdir /cluster/data/hg17/bed/geneSorter/blastp/sc1
cd /cluster/data/hg17/bed/geneSorter/blastp/sc1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast/data /cluster/bluearc/blast/blastall \
	-p blastp -d /cluster/bluearc/sc1/blastp/sgd \
	-i $1 -o $2 -e 0.01 -m 8 -b 1
'_EOF_'
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# Completed: 7748 of 7748 jobs
# CPU time in finished jobs:       8577s     142.96m     2.38h    0.10d  0.000 y
# IO & Wait Time:                 19756s     329.26m     5.49h    0.23d  0.001 y
# Average job time:                   4s       0.06m     0.00h    0.00d
# Longest job:                       15s       0.25m     0.00h    0.00d
# Submission to last job:          1172s      19.53m     0.33h    0.01d
# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/sc1/run/out
hgLoadBlastTab hg17 scBlastTab -maxPer=1 *.tab
#	row count went from 17089 to 17886

# Make Drosophila melanagaster ortholog column using blastp on FlyBase.
# First make SwissProt protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/dm1/blastp should have data

# Make parasol run directory 
ssh kk9
mkdir /cluster/data/hg17/bed/geneSorter/blastp/dm1
cd /cluster/data/hg17/bed/geneSorter/blastp/dm1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast/data /cluster/bluearc/blast/blastall \
	-p blastp -d /cluster/bluearc/dm1/blastp/flyBase \
	-i $1 -o $2 -e 0.01 -m 8 -b 1
'_EOF_'
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# Completed: 7748 of 7748 jobs
# CPU time in finished jobs:      33371s     556.18m     9.27h    0.39d  0.001 y
# IO & Wait Time:                 19546s     325.77m     5.43h    0.23d  0.001 y
# Average job time:                   7s       0.11m     0.00h    0.00d
# Longest job:                       53s       0.88m     0.01h    0.00d
# Submission to last job:          1657s      27.62m     0.46h    0.02d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/dm1/run/out
hgLoadBlastTab hg17 dmBlastTab -maxPer=1 *.tab
# Scanning through 7748 files
# Loading database with 28645 rows
#	row count went from 27173 to 28645

####  Blat knownGene proteins to determine exons (braney 2004-06-20)
    ssh hgwdev
    cd /cluster/data/hg17/bed
    mkdir blat.hg17KG.2004-06-20
    rm blat.hg17KG
    ln -s  blat.hg17KG.2004-06-20 blat.hg17KG
    cd blat.hg17KG
    pepPredToFa hg17 knownGenePep known.fa
    grep ">" known.fa | sed "s/>//" > kgName.lst
    kgName hg17 kgName.lst kg.mapNames
    ssh kk
    cd /cluster/data/hg17/bed/blat.hg17KG
    cat << '_EOF_' > blatSome
#!/bin/csh -fe
/cluster/bin/i386/blat -t=dnax -q=prot -out=pslx $1 $2 $3
'_EOF_'
    chmod +x blatSome
    ls -1S /scratch/hg/gs.18/build35/bothMaskedNibs/*.nib > human.lst
    mkdir kgfa
    cd kgfa
    faSplit sequence ../known.fa 3000 kg
    cd ..
    ls -1S kgfa/*.fa > kg.lst
    cat << '_EOF_' > blatGsub
#LOOP
blatSome $(path1) {check in line $(path2)} {check out line psl/$(root1)/$(root2).psl}
#ENDLOOP
'_EOF_'
    gensub2 human.lst kg.lst blatGsub blatSpec
    mkdir psl
    cd psl
    foreach i (`cat ../human.lst`)
	mkdir `basename $i .nib`
    end
    cd ..
    para create blatSpec
    para push

# Completed: 133676 of 133676 jobs
# CPU time in finished jobs:   29661130s  494352.16m  8239.20h  343.30d  0.941 y
# IO & Wait Time:               2181179s   36352.99m   605.88h   25.25d  0.069 y
# Average job time:                 238s       3.97m     0.07h    0.00d
# Longest job:                   105972s    1766.20m    29.44h    1.23d

    ssh eieio
    cd /cluster/data/hg17/bed/blat.hg17KG
    pslSort dirs raw.psl /tmp psl/*
    pslReps -nohead -minCover=0.9 -minAli=0.9 raw.psl cooked.psl /dev/null
    pslUniq cooked.psl hg17KG.psl
    pslxToFa hg17KG.psl hg17KG_ex.fa -liftTarget=genome.lft -liftQuery=protein.lft

# BLASTZ MM4 (DONE - 2004-06-22 - Hiram)
    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.mm4.2004-06-21
    cd /cluster/data/hg17/bed
    ln -s  blastz.mm4.2004-06-21 blastz.mm4
    cd blastz.mm4

    cat << '_EOF_' > DEF
# human vs. mouse
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/scratch/mus/mm4/softNib
# RMSK not currently used
SEQ2_RMSK=/scratch/mus/mm4/rmsk
# FLAG not currently used
SEQ2_FLAG=-rodent
SEQ2_SMSK=/scratch/mus/mm4/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.mm4

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm4
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
# Completed: 43648 of 43648 jobs
# CPU time in finished jobs:   16448001s  274133.36m  4568.89h  190.37d  0.522 y
# IO & Wait Time:                751666s   12527.76m   208.80h    8.70d  0.024 y
# Average job time:                 394s       6.57m     0.11h    0.00d
# Longest job:                     8323s     138.72m     2.31h    0.10d
# Submission to last job:         44244s     737.40m    12.29h    0.51d

    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.mm4
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       3925s      65.42m     1.09h    0.05d  0.000 y
# IO & Wait Time:                  6208s     103.46m     1.72h    0.07d  0.000 y
# Average job time:                  30s       0.50m     0.01h    0.00d
# Longest job:                      289s       4.82m     0.08h    0.00d
# Submission to last job:          2800s      46.67m     0.78h    0.03d

    #	Third cluster run to convert lav's to axt's
    #	Does not work on kki since /scratch on the iservers is not the
    #	same as /scratch on the other clusters.
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm4
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 45 of 46 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       2389s      39.82m     0.66h    0.03d  0.000 y
# IO & Wait Time:                 13374s     222.90m     3.71h    0.15d  0.000 y
# Average job time:                 350s       5.84m     0.10h    0.00d
# Longest job:                     1426s      23.77m     0.40h    0.02d
# Submission to last job:          1440s      24.00m     0.40h    0.02d

    #	chr19 failing due to out of memory.  Run this job individually
    #	on kolossus, adjusting the location of the nib directories:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.mm4
    sed -e "s/i386/x86_64/g" /cluster/bin/scripts/blastz-chromlav2axt > \
	x86_64-chromlav2axt
    chmod +x x86_64-chromlav2axt
    time ./x86_64-chromlav2axt \
	/cluster/data/hg17/bed/blastz.mm4/lav/chr19 \
	/cluster/data/hg17/bed/blastz.mm4/axtChrom/chr19.axt \
	/cluster/bluearc/scratch/hg/gs.18/build35/bothMaskedNibs \
	/cluster/bluearc/scratch/mus/mm4/softNib
    #	real    24m28.955s
    #	user    6m40.990s
    #	sys     1m16.500s

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4
    mkdir -p pslChrom
    set tbl = "blastzMm4"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	This takes more than an hour.  You can shorten this by changing
    #	that command to a simple echo, put the results into a file,
    #	split the file into four parts and run the four files as shell
    #	scripts on eieio to have four processes running at the same
    #	time.  Load on eieio gets up to about 20 which is reasonable.

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/pslChrom
    bash
    for F in chr*_blastzMm4.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${F}
	echo "${F} done"
    done
    # this is a 55 minute job
    # exit bash if you are tcsh

    # featureBits on blastzMm3 or 4 will not work on hgwdev, runs out of
    # memory.  But if you reset your ~/.hg.conf to use the read-only
    #	user and contact the hgwdev host, then use the x86_64 featureBits
    # featureBits hg16 blastzMm4
    # 1056761609 bases of 2865248791 (36.882%) in intersection
    # featureBits hg17 blastzMm4
    # 1056201417 bases of 2866216770 (36.850%) in intersection

# CHAIN MM4 BLASTZ (DONE - 2004-06-29 - Hiram)
# redone with the 'axtFilter -notQ_random' removed - 2004-06-23

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kk9
    mkdir -p /cluster/data/hg17/bed/blastz.mm4/axtChain/run1
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastz.mm4/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#  May need -minScore=5000 for all chroms if chr19 won't finish on kolossus

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 /iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/mm4/softNib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 45 of 46 jobs
# CPU time in finished jobs:       6575s     109.58m     1.83h    0.08d  0.000 y
# IO & Wait Time:                  9274s     154.57m     2.58h    0.11d  0.000 y
# Average job time:                 352s       5.87m     0.10h    0.00d
# Longest job:                     3121s      52.02m     0.87h    0.04d
# Submission to last job:          3121s      52.02m     0.87h    0.04d
    #	one job wouldn't finish due to memory usage
    #	run the chr19 job on kolossus, takes an hour, gets up to 4 Gb
    #	memory usage

    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    17m17.639s
    #	user    9m54.240s
    #	sys     1m31.210s
    #	(1.9 Gb result file !)

    time chainSplit chain all.chain
    #	real    27m32.278s
    #	user    9m46.970s
    #	sys     2m45.960s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg17 ${c}_chainMm4 $i
        echo done $c
    end

    #	featureBits hg17 chainMm4
    #	2829135227 bases of 2866216770 (98.706%) in intersection
    #	featureBits hg16 chainMm4
    #	2828363353 bases of 2865248791 (98.713%) in intersection

# NET MM4 (DONE - 2004-06-29 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg17/chrom.sizes \
                        /cluster/data/mm4/chrom.sizes ../preNet/$i
    end

    cd ..
    mkdir n1
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg17/chrom.sizes \
	/cluster/data/mm4/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2504171520, utime 19373 s/100, stime 5906

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    time netClass hNoClass.net hg17 mm4 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/scratch/mus/mm4/linSpecRep.notInHuman
    #	real    19m33.421s
    #	user    10m37.130s
    #	sys     1m45.630s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn mouse.net > mouseSyn.net
    #	real    13m24.885s
    #	user    7m37.100s
    #	sys     1m5.760s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg17 netMm4 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg17 syntenyNetMm4 stdin
    #	real    44m20.735s
    #	user    15m58.620s
    #	sys     1m58.720s
    # check results
    # featureBits hg17 netMm4
    #	2824272033 bases of 2866216770 (98.537%) in intersection
    # featureBits hg16 netMm4
    #	2823565051 bases of 2865248791 (98.545%) in intersection

    # featureBits hg17 syntenyNetMm4
    #	2785830955 bases of 2866216770 (97.195%) in intersection
    # featureBits hg16 syntenyNetMm4
    #	2786960572 bases of 2865248791 (97.268%) in intersection

    # Add entries for net and chain to mouse/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    mkdir mouseNet
    time netSplit mouse.net mouseNet
    #	real    12m1.478s
    #	user    8m35.050s
    #	sys     1m7.230s

    #	extract axt's from net, and convert to maf's (DONE - Kate - 2004-06-24)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    mkdir ../axtNet ../mafNet
cat > makeMaf.csh << '_EOF_'
    foreach f (mouseNet/chr*.net)
        set c = $f:t:r
        echo "netToAxt: $c.net -> $c.axt"
        rm -f ../axtNet/$c.axt
        netToAxt mouseNet/$c.net chain/$c.chain \
	    /cluster/data/hg17/nib /cluster/data/mm4/nib stdout | \
	    axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/mm4/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=mm4.
	echo "Complete: $c.net -> axtNet/$c.axt -> mafNet/$c.maf"
    end
'_EOF_'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/blastz.mm4/axtBest
    cd /cluster/data/hg17/bed/blastz.mm4/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestMm4.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestMm4.psl
	echo "Done: ${c}_blastzBestMm4.psl"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/pslBest
    for I in chr*BestMm4.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits hg17 blastzBestMm4
    #	1017319919 bases of 2866216770 (35.493%) in intersection
    # featureBits hg16 blastzBestMm4
    #	996722004 bases of 2865248791 (34.787%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg17/axtBest/Mm4
     cd /gbdb/hg17/axtBest/Mm4
     ln -s /cluster/data/hg17/bed/blastz.mm4/axtNet/chr*.axt .
     cd /cluster/data/hg17/bed/blastz.mm4/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/hg17/axtBest/Mm4/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('mm4','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
    hgsql hg17 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql hg17 < axtInfoInserts.sql

# MAKING MOUSE SYNTENY (DONE - 2004-06-29 - Hiram)

ssh hgwdev
mkdir /cluster/data/hg17/bed/syntenyMm4
cd /cluster/data/hg17/bed/syntenyMm4

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyMm3
cp -p /cluster/data/hg17/bed/syntenyRn3/*.pl .

./syntenicBest.pl -db=hg17 -table=blastzBestMm4
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg17 -table=blastzBestMm4
./synteny2bed.pl
#	The five commands above
#	real    220m16.227s
#	user    0m22.940s
#	sys     0m3.960s

#	Used to load this in syntenyMm4, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
#	Need a new name here for the Mm4 to not conflict with Rn3
sed -e 's/ensPhusionBlast/ensRatMm4Hom/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRatMm4Hom.sql
hgLoadBed hg17 ensRatMm4Hom ucsc100k.bed -sqlTable=ensRatMm4Hom.sql
    #	featureBits hg17 ensRatMm4Hom
    #	2549307611 bases of 2866216770 (88.943%) in intersection
    #	featureBits hg16 syntenyMm4
    #	2560252977 bases of 2865248791 (89.355%) in intersection

# MAKING MOUSE AXTTIGHT FROM AXTBEST (DONE - 2004-06-29 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtNet
    mkdir -p ../axtTight
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMm4.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/pslTight
    for I in chr*TightMm4.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly:
    #	featureBits hg17 blastzTightMm4
    #	166569246 bases of 2866216770 (5.811%) in intersection
    #	featureBits hg16 blastzTightMm4
    #	162641577 bases of 2865248791 (5.676%) in intersection

    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtTight
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

# BLASTZ MM4 CLEAN UP (DONE - 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4
    nice rm -rf raw &
    nice rm axtChain/run1/chain/* &
    nice gzip {axt,psl}Chrom/* lav/*/* axtChain/{all.chain,*.net} &

# BLASTZ CHIMP panTro1 (2004-06-21 kate)
# NOTE: Ran with abridge repeats=0, although SMSK was set
# Looked better than running with abridge=1, which had very
# chopped-up alignments

    ssh kk
    cd /cluster/data/hg17/bed
    mkdir -p blastz.panTro1.2004-06-22
    rm -f blastz.panTro1
    cd blastz.panTro1.2004-06-22

    cat << 'EOF' > DEF
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# Specific settings for chimp
BLASTZ_Y=3400
BLASTZ_T=2
BLASTZ_K=4500
BLASTZ_Q=/cluster/data/penn/human_chimp.q

# TARGET: Human
SEQ1_DIR=/scratch/hg/gs.18/build35/bothMaskedNibs
# not used 
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/hg17/linSpecRep.chimp
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Chimp
SEQ2_DIR=/scratch/chimp/panTro1/nib
# not currently used
SEQ2_RMSK=/iscratch/i/chimp/panTro1/linSpecRep.human
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.panTro1.2004-06-22

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'EOF'
    # << this line keeps emacs coloring happy

    # first cluster run: raw blastz alignments
    ssh kk
    bash # if a csh/tcsh user
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
        # 160270 jobs written to batc
    para try, check, push, check, ....

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    bash # if a csh/tcsh user
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
        # 341 jobs
    para try, check, push, etc ...
# CPU time in finished jobs:       3458s      57.63m     0.96h    0.04d  0.000 y
# IO & Wait Time:                 57996s     966.60m    16.11h    0.67d  0.002 y
# Average job time:                 180s       3.00m     0.05h    0.00d
# Longest job:                      483s       8.05m     0.13h    0.01d
# Submission to last job:          1498s      24.97m     0.42h    0.02d

    # third run: lav -> axt -> psl
    ssh kki
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| /cluster/bin/x86_64/lavToAxt stdin \
    /iscratch/i/hg17/bothMaskedNibs /iscratch/i/chimp/panTro1/nib stdout \
| /cluster/bin/x86_64/axtSort stdin ../../axtChrom/$chr.axt 
/cluster/bin/x86_64/axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
  ../../pslChrom/$chr.psl
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    for d in ../lav/chr*; do
      echo "do.csh $d" >> jobList
    done
    para create jobList
        # 46 jobs
    para try, check, push, check
#Completed: 42 of 42 jobs
#Average job time:                  38s       0.64m     0.01h    0.00d
#Longest job:                      147s       2.45m     0.04h    0.00d
#Submission to last job:           147s       2.45m     0.04h    0.00d

    # Load database tables (takes an hour or so)
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/pslChrom
cat > load.csh << 'EOF'
    foreach f (chr*.psl)
	set table = $f:r_blastzPanTro1
	echo "loading ${table}"
	/cluster/bin/i386/hgLoadPsl hg17 -table=$f:r_${table} $f
    end
'EOF'
# << for emacs
    csh load.csh >&! load.log & 
    tail -100f load.log


# CHAIN CHIMP BLASTZ (6/23/04 kate)
    # Run axtChain on little cluster
    # first copy input to bluearc, as eieo bogs down if even mini-cluster
    # gets input from it !?
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    cp -rp axtChrom /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom

    ssh kki
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -fe
set c = $1:r:t
axtChain $1 -scoreScheme=/cluster/data/blastz/human_chimp.q \
        /iscratch/i/hg17/bothMaskedNibs \
        /iscratch/i/chimp/panTro1/nib /tmp/$c.chain.$$ > /tmp/$c.out.$$
set ret = $status
mv -f /tmp/$c.chain.$$ $2
mv -f /tmp/$c.out.$$ $3
exit $status
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # TODO
    rm -fr /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom
    echo "remove after 7/1/04" > /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom/README

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    # TODO
    rm run1/chain/*.chain
    echo "remove after 7/1/04" > run1/chain/README

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain hg17 ${c}_chainPanTro1 $i
    end
    # TODO
    featureBits hg16 chainPanTro1Link
        #2627280557 bases of 2865248791 (91.695%) in intersection
    featureBits hg17 chainPanTro1Link
        # 2633869032 bases of 2866216770 (91.894%) in intersection


# NET CHIMP (DONE 2004-6-24 kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    #chainPreNet all.chain ../S1.len ../S2.len stdout \
    #| chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    #| netSyntenic stdin noClass.net

    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=10 ../S1.len ../S2.len human.net chimp.net
    netSyntenic human.net noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    netClass noClass.net hg17 panTro1 human.net

    # Make a 'syntenic' subset:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    # TODO
    #rm noClass.net
    # Make a 'syntenic' subset of these with
    # NOTE: we used -chimpSyn filtering for the reciprocal best nets
    # on hg16 -- perhaps should use for nets here as well
    netFilter -chimpSyn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netPanTro1 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 netSyntenyPanTro1 stdin
    # Add entries for chainPanTro1, netPanTro1, syntenyPanTro1 to 
    # human/hg17 trackDb


# GENERATE CHIMP MAF FOR MULTIZ FROM NET (IN PROGRESS 2004-06-24 kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    netSplit human.net net

    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    mkdir axtNet mafNet
cat > makeMaf.csh << 'EOF'
foreach f (axtChain/net/*.net)
    set c = $f:t:r
    netToAxt $f axtChain/chain/$c.chain /cluster/data/hg17/nib \
        /cluster/data/panTro1/nib stdout | axtSort stdin axtNet/$c.axt
    axtToMaf axtNet/$c.axt  \
        /cluster/data/hg17/chrom.sizes /cluster/data/panTro1/chrom.sizes \
        mafNet/$c.maf -tPrefix=hg17. -qPrefix=panTro1.
    end
'EOF'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log
    # TODO


# RESCORE CHICKEN BLASTZ (DONE 6/23/04 angie)
    # Webb noticed low scores when using non-default BLASTZ_Q scoring matrix 
    # and repeats abridged --
    # PSU's restore_rpts program rescored alignments with default matrix 
    # instead of BLASTZ_Q matrix.  Rescore them here so the chainer sees 
    # the higher scores:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    mkdir axtChrom.rescore
    foreach f (axtChrom/chr*.axt)
      axtRescore -scoreScheme=/cluster/data/blastz/HoxD55.q \
        $f axtChrom.rescore/$f:t
    end
    mv axtChrom axtChrom.preRescore
    mv axtChrom.rescore axtChrom


# CHAIN CHICKEN BLASTZ (DONE 6/23/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -minScore=5000 $1 \
    /iscratch/i/hg17/bothMaskedNibs \
    /iscratch/i/galGal2/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # axtChrom/chr18_random.axt is empty, so the {out line +} check failed:
#Completed: 45 of 46 jobs
#Crashed: 1 jobs
#Average job time:                  46s       0.76m     0.01h    0.00d
#Longest job:                      273s       4.55m     0.08h    0.00d
#Submission to last job:           519s       8.65m     0.14h    0.01d

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain hg17 ${c}_chainGalGal2 $i
    end


# NET CHICKEN BLASTZ (DONE 6/23/04 angie)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    netClass noClass.net hg17 galGal2 human.net

    # Make a 'syntenic' subset:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netGalGal2 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 netSyntenyGalGal2 stdin
    # Add entries for chainGalGal2, netGalGal2, syntenyGalGal2 to 
    # human/hg17 trackDb


# GENERATE GALGAL2 MAF FOR MULTIZ FROM NET (DONE 6/23/04 angie)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    netSplit human.net net
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/hg17/nib \
        /cluster/data/galGal2/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.hg.maf
      axtToMaf $f \
            /cluster/data/hg17/chrom.sizes /cluster/data/galGal2/chrom.sizes \
            $maf -tPrefix=hg17. -qPrefix=galGal2.
    end


# MAKE VSGALGAL2 DOWNLOADABLES (DONE 6/23/04 angie)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    ln all.chain chicken.chain
    zip /cluster/data/hg17/zip/chicken.chain.zip chicken.chain
    rm chicken.chain
    ln human.net chicken.net
    zip /cluster/data/hg17/zip/chicken.net.zip chicken.net
    rm chicken.net
    ln humanSyn.net chickenSyn.net
    zip /cluster/data/hg17/zip/chickenSyn.net.zip chickenSyn.net
    rm chickenSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/hg17/vsGalGal2
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsGalGal2
    mv /cluster/data/hg17/zip/chicken*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# 7-WAY MULTIZ MULTIPLE ALIGNMENT

    ssh eieio
    set multizDir = multiz.2004-06-24
    set workingDir = /cluster/bluearc/hg17/$multizDir
    mkdir -p $workingDir
    mkdir -p /cluster/data/hg17/bed/$multizDir
    cd /cluster/data/hg17/bed/$multizDir

    # copy over mafs
    mkdir $workingDir/panTro1
    cp /cluster/data/hg17/bed/blastz.panTro1/mafNet/*.maf \
                $workingDir/panTro1

    # first multiz - add mouse in to human/chimp
    mkdir $workingDir/mm4
    cp /cluster/data/hg17/bed/blastz.mm4/mafNet/chr*.maf $workingDir/mm4

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    # wrapper script for multiz
    # NOTE: first arg is pairwise, 2nd arg is multiple (to add to) 
    # NOTE: next time, modify script so it only needs one arg -- saves the
    # multiple dirname in a file for use by the next run
    cat << 'EOF' > doMultiz.csh
#!/bin/csh -fe
mkdir -p $3:h
/cluster/bin/penn/multiz $1 $2 - > $3
'EOF'
    cat << 'EOF' > gsub
#LOOP
../doMultiz.csh {check in line /cluster/bluearc/hg17/multiz.2004-06-24/$(dir1)/$(root2).maf} {check in line /cluster/bluearc/hg17/multiz.2004-06-24/$(root1)/$(root2).maf} {check out line+ /cluster/bluearc/hg17/multiz.2004-06-24/$(root1)$(dir1)/$(root2).maf}
#ENDLOOP
'EOF'
    chmod +x doMultiz.csh
    ls /cluster/bluearc/hg17/multiz.2004-06-24/panTro1/*.maf > chrom.lst

    # mouse
    mkdir run.mm4
    cd run.mm4
    echo "mm4/panTro1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       6637s     110.62m     1.84h    0.08d  0.000 y
# IO & Wait Time:                  3788s      63.13m     1.05h    0.04d  0.000 y
# Average job time:                 227s       3.78m     0.06h    0.00d
# Longest job:                      950s      15.83m     0.26h    0.01d
# Submission to last job:          3058s      50.97m     0.85h    0.04d

    # rat
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/rn3
    cp /cluster/data/hg17/bed/blastz.rn3/mafNet/chr*.maf $workingDir/rn3

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24

    mkdir run.rn3
    cd run.rn3
    echo "rn3/panTro1mm4" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # chicken
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/galGal2
    foreach f (/cluster/data/hg17/bed/blastz.galGal2/mafNet/chr*.maf)
        set c = $f:r:r:t
        cp $f $workingDir/galGal2/$c.maf
    end

    ssh kki
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.galGal2
    cd run.galGal2
    echo "galGal2/panTro1mm4rn3" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # no alignment file for chr18_random -- create one so we can create jobList
    touch $workingDir/galGal2/chr18_random
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # fugu
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/fr1
    cp /cluster/data/hg17/bed/blastz.fr1/mafNet/chr*.maf $workingDir/fr1

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.fr1
    cd run.fr1
    echo "fr1/panTro1mm4rn3galGal2" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    touch /cluster/bluearc/hg17/multiz.2004-06-24/fr1/chr6_hla_hap1.maf
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # zebrafish
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/danRer1
    cp /cluster/data/hg17/bed/blastz.danRer1.swap/mafNet/chr*.maf $workingDir/danRer1

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.danRer1
    cd run.danRer1
    echo "danRer1/panTro1mm4rn3galGal2fr1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # 7-WAY mafs are now in $workingDir/panTro1mm4rn3galGal2fr1/danRer1


# PHYLO-HMM CONSERVATION FOR 7-WAY (2004-06-25 kate)

    ssh eieio
    set path = ($path /cluster/bin/phast)

    #Create "sufficient statistics" (SS) file from maf
    cd /cluster/data/hg17/bed/multiz
    mkdir cons
    cd cons

    # Model provided by Adam, based on 25-way plus HMR
cat > hg17panTro1mm4rn3galGal2fr1danRer1.mod << 'EOF'
ALPHABET: A C G T 
ORDER: 0
SUBST_MOD: REV
NRATECATS: 10
ALPHA: 4.43
BACKGROUND: 0.286083 0.213573 0.213691 0.286652 
RATE_MAT:
  -0.891523    0.166770    0.574850    0.149902 
   0.223389   -1.146311    0.153784    0.769137 
   0.769591    0.153699   -1.147159    0.223869 
   0.149605    0.573055    0.166888   -0.889548 
TREE: ((((1:0.0056,2:0.0057):0.1043,(3:0.076303,4:0.083043):0.2753):0.4099,5:0.5293):0.5557,(6:0.9558,7:0.9375):0.5557);
'EOF'

    #break up the genome-wide MAFs into pieces
    mkdir /cluster/bluearc/hg17/chrom
    cd /cluster/data/hg17
    foreach f (`cat chrom.lst`)
        echo $f
        cp $f/*.fa /cluster/bluearc/hg17/chrom
    end

    cd /cluster/data/hg17/bed/multiz/cons
    # NOTE: next time, split to WINDOWS dir directly on bluearc
    cat << 'EOF' > doSplit.sh
#!/bin/sh

PHAST=/cluster/bin/phast
# hg17 chrom fasta files
FA_SRC=/cluster/bluearc/hg17/chrom
WINDOWS=/cluster/data/hg17/bed/multiz/cons/WINDOWS

maf=$1
c=`basename $maf .maf`
echo $c
mkdir -p /scratch/msa_split
${PHAST}/msa_split $maf -i MAF -M ${FA_SRC}/$c.fa -O hg17,panTro1,mm4,rn3,galGal2,fr1,danRer1 -w 1000000,0 -r /scratch/msa_split/$c -o SS -I 1000 -B 5000
echo "Copying..."
cd /scratch/msa_split
for file in $c.*.ss ; do gzip -c $file > ${WINDOWS}/$file.gz ; done
rm -f /scratch/msa_split/$c.*.ss
echo "Done copying"
'EOF'
    chmod +x doSplit.sh
    mkdir -p WINDOWS
    rm -f WINDOWS/* jobList
    foreach file (/cluster/bluearc/hg17/multiz/7way/*.maf) 
	echo "doSplit.sh $file" >> jobList
    end
    
    #run on kki
    ssh kki
    cd /cluster/data/hg17/bed/multiz/cons
    para create jobList
        # 46 jobs
    para try
    para check
    para push

    ## PHASTCONS CONSERVATION FOR 7-WAY (IN PROGRESS 2004-06-25 kate)

    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz/cons
    mkdir run.cons
    cd run.cons
    
    # set up wrapper for phastCons
    cat << '_EOF_' > doPhastCons
#!/bin/sh

PHAST=/cluster/bin/phast
TMP=/tmp/phastCons

file=$1
root=`basename $file .ss.gz`
chrom=`echo $root | awk -F\. '{print $1}'`

mkdir -p $TMP 
zcat $file | $PHAST/phastCons - hg17panTro1mm4rn3galGal2fr1danRer1.mod --rates-cut 1 --nrates 40 --suppress-missing --cut-params 0.080,0.008 --quiet > $TMP/$root.pp
mkdir -p PHASTCONS/$chrom
gzip -c $TMP/$root.pp > PHASTCONS/$chrom/$root.pp.gz
rm $TMP/$root.pp
'_EOF_'
    chmod u+x doPhastCons

    # the --cut-params arguments are approximate maximum likelihood
    # estimates obtained by running the program *without* --cut-params
    # (causes estimation by EM) on five randomly selected 1M bp
    # windows.  All estimates were in the same ballpark (took a rough average)

    # set up cluster job
    ssh eieio
    cd /cluster/data/hg17/bed/multiz/cons
    mkdir -p /cluster/bluearc/hg17/multiz/cons/WINDOWS
    cp WINDOWS/*.ss.gz /cluster/bluearc/hg17/multiz/cons/WINDOWS
    # TODO cleanup
    rm -fr WINDOWS

    ssh kk
    cd /cluster/data/hg17/bed/multiz/cons
    cd run.cons
    rm -f jobList
    foreach f (/cluster/bluearc/hg17/multiz/cons/WINDOWS/*.ss.gz)
        echo $f
        echo doPhastCons $f >> jobList
    end
    para create jobList
        # 2932 jobs
    para try ; para push ... etc.
    
    # now create tracks
    # load wiggle table
    ssh eieio
    cd /cluster/data/hg17/bed/multiz/cons
    cd run.cons
    mkdir -p PHASTCONS/wib
    bash
    for dir in PHASTCONS/chr* ; do \
	echo $dir ;\
	chr=`basename $dir` ;\
	zcat `ls $dir/*.pp.gz | sort -t\. -k2,2n` | \
	    wigAsciiToBinary -chrom=$chr \
	    -wibFile=PHASTCONS/wib/${chr}_phastCons stdin ;\
    done

    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz/cons
    cd run.cons
    hgLoadWiggle hg17 phastCons PHASTCONS/wib/chr*_phastCons.wig
    mkdir -p /gbdb/hg17/wib
    rm -f /gbdb/hg17/wib/chr*phastCons.wib
    ln -s `pwd`/PHASTCONS/wib/*.wib /gbdb/hg17/wib
    chmod 775 . PHASTCONS PHASTCONS/wib
    chmod 664 PHASTCONS/wib/*.wib
    
    # load multiz maf tables 
    # TODO: move mafs to /cluster/data (need to free up space on store5)
    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz
    mkdir -p /gbdb/hg17/multiz7way
    ln -s /cluster/bluearc/hg17/multiz/7way/*.maf /gbdb/hg17/multiz7way
    hgLoadMaf hg17 -warn multiz7way
        # Indexing and tabulating /gbdb/hg17/multiz7way/chr14.maf
        # 11489 warnings
        # TODO: check this out

    # load blastz maf tables
    # TODO: change mafWiggle to use db names instead of species names
    # in speciesOrder 
    # TODO: move mafs to /cluster/data (need to free up space on store5)
    cd /cluster/bluearc/hg17/multiz
    ln -s panTro1 chimp
    ln -s mm4 mouse
    ln -s rn3 rat
    ln -s galGal2 chicken
    ln -s fr1 fugu
    ln -s danRer1 zebrafish
    #foreach s (chimp mouse rat chicken fugu zebrafish)
    foreach s (mouse rat chicken fugu zebrafish)
        mkdir -p /gbdb/hg17/${s}_netBlastz
        ln -s /cluster/bluearc/hg17/multiz/$s/*.maf /gbdb/hg17/${s}_netBlastz
        hgLoadMaf hg17 -warn ${s}_netBlastz
    end

    # trackDb entry:
# track multiz7way
# shortLabel Conservation
# longLabel Human/Chimp/Mouse/Rat/Chicken/Fugu/Zebrafish Multiz Alignments & PhyloHMM Cons
# group compGeno
# priority 149
# visibility pack
#color 0, 10, 100
# type wigMaf 0.0 1.0
# maxHeightPixels 100:40:11
# wiggle phastCons
# yLineOnOff Off
# autoScaleDefault Off
# pairwise netBlastz
# speciesOrder chimp mouse rat chicken fugu zebrafish


    # GOT HERE
    # tweak scores and names of predictions
    cat PREDICTIONS/*/*.bed | sed 's/id //' | \
	awk '{printf "%s\t%s\t%s\tlod=%d\t%d\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", \
	    $1, $2, $3, $5, 147.49 * log($5) - 240.34, $6, $7, $8, $9, \
	    $10, $11, $12}' > all.bed
    hgLoadBed hg17 phastConsElements all.bed

    # Scores are transformed as follows, for a reasonable-looking 
    # "spectrum".  Let x_max be the maximum score (here
    # x_max  = 4490) and let x_med be the median score (here x_med =
    # 39).  The  scores are transformed via the function f(x) = a *
    # log x + b, s.t. f(x_med) = 300 and f(x_max) = 1000.  Solving
    # for a and b, you get b = (300 log x_max - 1000 log x_med) /
    # (log x_max - log x_med), a = (1000 - b) / log x_max.  Here a =
    # 147.49, b = -240.34

#track phastCons
#shortLabel phastCons 
#longLabel phastCons Conservation Score, Human/Chimp/Mouse/Rat/Chicken
#group compGeno
#priority 103
#visibility hide
#color 0,10,100
#maxHeightPixels 40
#type wig 0.0 1.0
#autoScaleDefault off

#track phastConsElements
#shortLabel phastConsElements
#longLabel phastCons Conserved Elements, Human/Chimp/Mouse/Rat/Chicken
#group compGeno
#priority 104
#visibility hide
#spectrum on
#color 0,60,120
#altColor 200,220,255
#exonArrows off
#type bed 12 .


# PRODUCING GENSCAN PREDICTIONS (DONE - 2004-07-01 - Hiram)
#	Needed to download a new binary for this run.  Our Linux systems
#  XXX - I thought a new binary was needed.  Turned out it was already
#  here in our hg3rdParty CVS project.  All of this discussed here can
#  be simply fetched from cvs:  cvs co hg3rdParty/genscanlinux
#	have been updated since the last time, the old binary would not
#	run.  Go to: http://genes.mit.edu/GENSCAN.html
#	and then to: http://genes.mit.edu/license.html
#	Fill in the license agreement and you can then pick up the
#	README and the Linux version: genscanlinux.tar.uue.tgz
#	To uudecode that file, go to one of the Solaris home machines
#	and use the uudecode command:
#	uudecode genscanlinux.tar.uue.tgz
#	That produces the file: genscanlinux.tar
#	Which contains the files:
# drwxr-xr-x chris/burgelab    0 2003-02-17 11:48:44 ./
# -rw-r--r-- chris/burgelab 219056 2000-09-07 12:39:26 ./Arabidopsis.smat
# -rw-r--r-- chris/burgelab   6622 2000-09-07 12:39:26 ./HUMRASH
# -rw-r--r-- chris/burgelab    849 2000-09-07 12:39:26 ./HUMRASH.sample
# -rw-r--r-- chris/burgelab 219050 2000-09-07 12:39:26 ./HumanIso.smat
# -rw-r--r-- chris/burgelab 155735 2000-09-07 12:39:26 ./Maize.smat
# -rw-r--r-- chris/burgelab  24465 2000-09-07 12:39:26 ./README
# -rw-r--r-- chris/burgelab   6344 2000-09-07 12:39:27 ./HUMRASH.ps
# -rwxr-xr-x chris/burgelab 126365 2003-02-17 11:48:44 ./genscan
#
#	I placed these currently in: /cluster/home/hiram/GENSCAN/
#	I'll check with Angie where it should properly live ...
#  XXX - it already lives in 'cvs co hg3rdParty/genscanlinux'
#  These instructions should simple check it out right here in
#  bed/genscan and make the gsub command refer to these copies.

    ssh eieio
    mkdir /cluster/data/hg17/bed/genscan
    cd /cluster/data/hg17/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequencable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    bash
    for f in `cat /cluster/data/hg17/contig.lst`
    do
      egrep '[ACGT]' /cluster/data/hg17/$f > /dev/null
	if [ $? = 0 ]; then
	    echo /cluster/data/hg17/$f >> genome.list
	fi
    done
    # exit your bash shell if you are [t]csh ...
    #	This egrep matched all the contigs in hg17.  I guess none of
    #	them are complete Ns* at this point.

    # Log into kki (not kk !).  kki is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kki
    cd /cluster/data/hg17/bed/genscan
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/home/hiram/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/hiram/GENSCAN/genscan -par=/cluster/home/hiram/GENSCAN/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push
# Completed: 370 of 380 jobs
# Crashed: 10 jobs
# CPU time in finished jobs:      69632s    1160.53m    19.34h    0.81d  0.002 y
# IO & Wait Time:                  1547s      25.78m     0.43h    0.02d  0.000 y
# Average job time:                 192s       3.21m     0.05h    0.00d
# Longest job:                     2846s      47.43m     0.79h    0.03d
# Submission to last job:          6350s     105.83m     1.76h    0.07d
    #	Ten of these jobs failed due to out of memory.

    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.  In build33, this was 22/NT_011519.
    #  In build34 there were NO failures !

    #	Evidently this new version of genscan is quite different than
    #	was used in Hg16 - in fact the results below indicate a vast
    #	difference.

    #	One works OK with no change in window on kolossus: NT_005403
    #	Trying the last 9 with a window of 2000000.  Four worked at that size:
    #	NT_022184 NT_026437 NT_010783 NT_008583
    #	Trying the remaining 5 at 1800000
    #	done: NT_010194 NT_005612 NT_008470 NT_024524
    #	Only one failed at that setting: NT_011520
    #	Run it with a window of 1600000 - that worked
    #	It doesn't make any difference to run these on kolossus or not,
    #	the memory limitation is in the genscan program itself.

    # Convert these to chromosome level files as so:     
    ssh eieio
    cd /cluster/data/hg17/bed/genscan
    $HOME/bin/i386/liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/N*.gtf
    $HOME/bin/i386/liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft \
	warn subopt/N*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/hg17/bed/genscan
    ldHgGene hg17 genscan genscan.gtf
    #	This command is taking a very long time to run ...
    #	It finished, but it took many hours.
    #	Read 100444 transcripts in 496249 lines in 1 files
    #	100444 groups 46 seqs 1 sources 1 feature types

    #	Note the difference from Hg16 which used to be:
    #	Reading genscan.gtf
    #	Read 42974 transcripts in 326300 lines in 1 files
    #	  42974 groups 41 seqs 1 sources 1 feature types
    #	42974 gene predictions
    hgPepPred hg17 generic genscanPep genscan.pep
    #	Processing genscan.pep
    hgLoadBed hg17 genscanSubopt genscanSubopt.bed
    #	Reading genscanSubopt.bed
    #	Loaded 231850 elements of size 6
    #	Sorted
    #	Creating table definition for 
    #	Saving bed.tab
    #	Loading hg17

    #	featureBits hg17 genscan
    #	102287267 bases of 2866216770 (3.569%) in intersection
    #	featureBits hg16 genscan
    #	55333689 bases of 2865248791 (1.931%) in intersection

    #	featureBits hg17 genscanSubopt
    #	28718435 bases of 2866216770 (1.002%) in intersection
    #	featureBits hg16 genscanSubopt
    #	56082952 bases of 2865248791 (1.957%) in intersection

# BLASTZ MM5 (DONE - 2004-06-22 - Hiram)
    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.mm5.2004-07-01
    cd /cluster/data/hg17/bed
    ln -s  blastz.mm5.2004-07-01 blastz.mm5
    cd blastz.mm5

    cat << '_EOF_' > DEF
# human vs. mouse
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/scratch/mus/mm5/softNib
# RMSK not currently used
SEQ2_RMSK=/scratch/mus/mm5/rmsk
# FLAG not currently used
SEQ2_FLAG=-rodent
SEQ2_SMSK=/scratch/mus/mm5/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.mm5

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm5
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
# Completed: 44330 of 44330 jobs
# CPU time in finished jobs:   16250628s  270843.80m  4514.06h  188.09d  0.515 y
# IO & Wait Time:                387936s    6465.60m   107.76h    4.49d  0.012 y
# Average job time:                 375s       6.26m     0.10h    0.00d
# Longest job:                     4417s      73.62m     1.23h    0.05d
# Submission to last job:         43754s     729.23m    12.15h    0.51d

    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.mm5
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       2189s      36.48m     0.61h    0.03d  0.000 y
# IO & Wait Time:                  7714s     128.57m     2.14h    0.09d  0.000 y
# Average job time:                  29s       0.48m     0.01h    0.00d
# Longest job:                      165s       2.75m     0.05h    0.00d
# Submission to last job:           830s      13.83m     0.23h    0.01d


    #	Third cluster run to convert lav's to axt's
    #	Does not work on kki since /scratch on the iservers is not the
    #	same as /scratch on the other clusters.
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm5
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 45 of 46 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       1638s      27.30m     0.46h    0.02d  0.000 y
# IO & Wait Time:                 12068s     201.13m     3.35h    0.14d  0.000 y
# Average job time:                 305s       5.08m     0.08h    0.00d
# Longest job:                     1124s      18.73m     0.31h    0.01d
# Submission to last job:          2519s      41.98m     0.70h    0.03d
    #	chr19 takes too long, the axtSort becomes too large and the poor
    #	node ends up swapping forever.  When you are down to that last
    #	job running, stop it and go to kolossus.
    #	Adjusting the location of the nib directories, and fixing the
    #	MACHTYPE on the commands in the blastz script:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.mm5
    sed -e "s/i386/x86_64/g" /cluster/bin/scripts/blastz-chromlav2axt > \
	x86_64-chromlav2axt
    chmod +x x86_64-chromlav2axt
    time ./x86_64-chromlav2axt \
	/cluster/data/hg17/bed/blastz.mm5/lav/chr19 \
	/cluster/data/hg17/bed/blastz.mm5/axtChrom/chr19.axt \
	/cluster/bluearc/scratch/hg/gs.18/build35/bothMaskedNibs \
	/cluster/bluearc/scratch/mus/mm5/softNib
    #	real    7m41.719s
    #	user    2m2.850s
    #	sys     0m23.070s

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5
    mkdir -p pslChrom
    set tbl = "blastzMm5"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	This takes more than an hour.  You can shorten this by changing
    #	that command to a simple echo, put the results into a file,
    #	split the file into four parts and run the four files as shell
    #	scripts on eieio to have four processes running at the same
    #	time.  Load on eieio gets up to about 20 which is reasonable.

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/pslChrom
    bash		#	for tcsh users
    for F in chr*_blastzMm5.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${F}
	echo "${F} done"
    done
    # this is a 40 minute job
    # exit bash if you are tcsh

    # featureBits on blastzMm3 or 4 will not work on hgwdev, runs out of
    # memory.  But if you reset your ~/.hg.conf to use the read-only
    #	user and contact the hgwdev host, then use the x86_64 featureBits
    # featureBits hg16 blastzMm5
    # 1056761609 bases of 2865248791 (36.882%) in intersection
    # featureBits hg17 blastzMm5
    #	1052077141 bases of 2866216770 (36.706%) in intersection
    # featureBits hg17 blastzMm4
    #  1056201417 bases of 2866216770 (36.850%) in intersection

# CHAIN MM5 BLASTZ (DONE - 2004-07-02 - Hiram)

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kki
    mkdir -p /cluster/data/hg17/bed/blastz.mm5/axtChain/run1
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastz.mm5/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#  May need -minScore=5000 for all chroms if chr19 won't finish on kolossus

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 /iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/mus/mm5/softNib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       4856s      80.94m     1.35h    0.06d  0.000 y
# IO & Wait Time:                 20083s     334.71m     5.58h    0.23d  0.001 y
# Average job time:                 542s       9.04m     0.15h    0.01d
# Longest job:                     2929s      48.82m     0.81h    0.03d
# Submission to last job:          2929s      48.82m     0.81h    0.03d


    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    8m42.853s
    #	user    5m59.100s
    #	sys     0m40.320s

    time chainSplit chain all.chain
    #	real    10m52.224s
    #	user    5m52.360s
    #	sys     0m34.870s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain/chain
    bash	#	for tcsh users
    for i in *.chain
    do
        c=${i/.chain/}
        hgLoadChain hg17 ${c}_chainMm5 $i
        echo done $c
    done
    # exit bash if you are tcsh
    #	This is a 50 minute job

    #	featureBits hg17 chainMm5
    #	2834490112 bases of 2866216770 (98.893%) in intersection
    #	featureBits hg17 chainMm4
    #	2829135227 bases of 2866216770 (98.706%) in intersection
    #	featureBits hg16 chainMm4
    #	2828363353 bases of 2865248791 (98.713%) in intersection

# NET MM5 (WORKING - 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    mkdir preNet
    cd chain
    bash	#	for tcsh users
    for i in *.chain
    do
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg17/chrom.sizes \
                        /cluster/data/mm5/chrom.sizes ../preNet/$i
    done
    # exit bash if you are tcsh
    #	15 minute job

    cd ..
    mkdir n1
    cd preNet
    bash	#	for tcsh users
    for i in *.chain
    do
      n=${i/.chain/}.net
      echo primary netting $i $n
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg17/chrom.sizes \
	/cluster/data/mm5/chrom.sizes ../n1/$n /dev/null
    done
    # exit bash if you are tcsh
    #	9 minute job

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2546110464, utime 16327 s/100, stime 3546

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    time netClass hNoClass.net hg17 mm5 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/scratch/mus/mm5/linSpecRep.notInHuman
    #	real    16m38.098s
    #	user    11m38.490s
    #	sys     1m48.470s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn mouse.net > mouseSyn.net
    #	real    12m3.701s
    #	user    8m44.180s
    #	sys     1m1.610s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg17 netMm5 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg17 syntenyNetMm5 stdin

    # check results
    #	featureBits hg17 netMm5
    #	2830625630 bases of 2866216770 (98.758%) in intersection

    #	featureBits hg17 netMm4
    #	2824272033 bases of 2866216770 (98.537%) in intersection
    # featureBits hg16 netMm5
    #	2823565051 bases of 2865248791 (98.545%) in intersection

    # featureBits hg17 syntenyNetMm5
    #	2799194300 bases of 2866216770 (97.662%) in intersection
    # featureBits hg17 syntenyNetMm4
    #	2785830955 bases of 2866216770 (97.195%) in intersection
    # featureBits hg16 syntenyNetMm5
    #	2786960572 bases of 2865248791 (97.268%) in intersection

    # Add entries for net and chain to mouse/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    mkdir mouseNet
    time netSplit mouse.net mouseNet
    #	real    11m45.243s
    #	user    8m48.490s
    #	sys     1m13.490s

    #	extract axt's from net, and convert to maf's
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    mkdir ../axtNet ../mafNet
cat > makeMaf.csh << '_EOF_'
#!/bin/csh -ef
    foreach f (mouseNet/chr*.net)
        set c = $f:t:r
        echo "netToAxt: $c.net -> $c.axt"
        rm -f ../axtNet/$c.axt
        netToAxt mouseNet/$c.net chain/$c.chain \
	    /cluster/data/hg17/nib /cluster/data/mm5/nib stdout | \
	    axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/mm5/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=mm5.
	echo "Complete: $c.net -> axtNet/$c.axt -> mafNet/$c.maf"
    end
'_EOF_'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

XXX - DONE 2004-07-02 15:37

    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/blastz.mm5/axtBest
    cd /cluster/data/hg17/bed/blastz.mm5/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestMm5.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestMm5.psl
	echo "Done: ${c}_blastzBestMm5.psl"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/pslBest
    for I in chr*BestMm5.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits hg17 blastzBestMm5
    #	1017319919 bases of 2866216770 (35.493%) in intersection
    # featureBits hg16 blastzBestMm5
    #	996722004 bases of 2865248791 (34.787%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg17/axtBest/Mm5
     cd /gbdb/hg17/axtBest/Mm5
     ln -s /cluster/data/hg17/bed/blastz.mm5/axtNet/chr*.axt .
     cd /cluster/data/hg17/bed/blastz.mm5/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/hg17/axtBest/Mm5/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('mm5','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
    hgsql hg17 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql hg17 < axtInfoInserts.sql

# MAKING MOUSE SYNTENY (DONE - 2004-06-29 - Hiram)

ssh hgwdev
mkdir /cluster/data/hg17/bed/syntenyMm5
cd /cluster/data/hg17/bed/syntenyMm5

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyMm3
cp -p /cluster/data/hg17/bed/syntenyRn3/*.pl .

./syntenicBest.pl -db=hg17 -table=blastzBestMm5
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg17 -table=blastzBestMm5
./synteny2bed.pl
#	The five commands above
#	real    220m16.227s
#	user    0m22.940s
#	sys     0m3.960s

#	Used to load this in syntenyMm5, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
#	Need a new name here for the Mm5 to not conflict with Rn3
sed -e 's/ensPhusionBlast/ensRatMm5Hom/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRatMm5Hom.sql
hgLoadBed hg17 ensRatMm5Hom ucsc100k.bed -sqlTable=ensRatMm5Hom.sql
    #	featureBits hg17 ensRatMm5Hom
    #	2549307611 bases of 2866216770 (88.943%) in intersection
    #	featureBits hg16 syntenyMm5
    #	2560252977 bases of 2865248791 (89.355%) in intersection

# MAKING MOUSE AXTTIGHT FROM AXTBEST (DONE - 2004-06-29 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtNet
    mkdir -p ../axtTight
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMm5.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/pslTight
    for I in chr*TightMm5.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly:
    #	featureBits hg17 blastzTightMm5
    #	166569246 bases of 2866216770 (5.811%) in intersection
    #	featureBits hg16 blastzTightMm5
    #	162641577 bases of 2865248791 (5.676%) in intersection

    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtTight
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

#  MAKING BLASTZ SELF (WORKING - 2004-07-01 - Hiram)

    # The procedure for lineage spec business with self is to simply
    # use the actual repeat masker output for this human assembly as
    # the lineage specific repeats for itself.  Thus, merely make
    # symlinks to the repeat masker out files and name them as expected
    # for blastz.  In this case they are called notInHuman but they
    # really mean InHuman.  Yes, it is confusing, but that's just the
    # nature of the game in this case.

    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
    cd /cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
    foreach f (../rmsk/*.fa.out)
	set base = $f:t:r:r
	echo $base.out.spec
	ln -s $f $base.out.spec
    end
    #	Same thing done on iscratch
    #	Not worried about pushing this scratch yet, it will get done
    #	sometime later.  Using the actual /cluster/bluearc/scratch/
    #	location below.

    ssh kk
    mkdir /cluster/data/hg17/bed/blastzSelf.2004-07-01
    cd /cluster/data/hg17/bed
    ln -s blastzSelf.2004-07-01 blastzSelf
    cd blastzSelf

    cat << '_EOF_' > DEF
# human vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Human
SEQ2_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/data/hg17/bed/blastzSelf

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastzSelf
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
    #	you need a -maxPush=200000 on this one, it is more than 100000
    #	jobs the default push limit.  Also be aware of maxQueue limits
    #	on the KK, may need something more than the default of 200000 if
    #	the KK is busy.
XXX - running 2004-07-01 11:26
