#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on 
# NCBI build 35 (May 2004 freeze)

# HOW TO BUILD A ASSEMBLY FROM NCBI FILES 
# ---------------------------------------

    # Make gs.18 directory, gs.18/build35 directory, and gs.18/ffa directory.
    ssh eieio
    mkdir /cluster/store5/gs.18
    mkdir /cluster/store5/gs.18/build35
    mkdir /cluster/store5/gs.18/agp
    mkdir /cluster/store5/gs.18/ffa

    #    Make a symbolic link from /cluster/store1 to this location
    #	(I assume there is some use for this later ?)
	
    cd /cluster/store1
    ln -s /cluster/store5/gs.18 ./gs.18
    ln -s /cluster/store5/gs.18/build35 /cluster/data/hg17

    #    Make a symbolic link from your home directory to the build dir:
    #	(Investigate what this is used for, may no longer be necessary)

    ln -s /cluster/store5/gs.18/build35 ~/oo

# NCBI download site, fetch everything into this one directory:

    #	with the machine and password in your $HOME/.netrc file, this
    #	wget command will require no login.  Your $HOME/.netrc file
    #	is set to 'chmod 600 .netrc' to prevent anyone from finding
    #	the data.  (There were some early files that later moved
    #		into an OLD subdirectory.  They were broken.)
    mkdir /cluster/store5/gs.18/ncbi
    cd /cluster/store5/gs.18/ncbi
    wget --timestamping ftp://ftp.ncbi.nlm.nih.gov/build_35/*

    # FYI: agp file format documented at:
    #	http://www.ncbi.nlm.nih.gov/Genbank/WGS.agpformat.html    # fixup a couple of names for our own purposes here
    cd /cluster/store5/gs.18/agp
    ln -s ../ncbi/chr*.agp ../ncbi/chr*.fa.gz .
    sed -e "s#MT/NC_001807.4#NC_001807#" ../ncbi/chrMT.agp > chrM.agp
    sed -e "s/NG_002392.2/NG_002392/" ../ncbi/DR52.agp > chr6_hla_hap1.agp
    sed -e "s/NG_002433.1/NG_002433/" ../ncbi/DR53.agp > chr6_hla_hap2.agp
    zcat ../ncbi/DR52.fa.gz | \
	sed -e "s/gi|29124352|ref|NG_002392.2/ref|NG_002392/" | \
	gzip > chr6_hla_hap1.fa.gz
    zcat ../ncbi/DR53.fa.gz | \
	sed -e "s/gi|28212470|ref|NG_002433.1/ref|NG_002433/" | \
	gzip > chr6_hla_hap2.fa.gz
    zcat ../ncbi/chrMT.fa.gz | \
	sed -e "s/gi|17981852|ref|NC_001807.4/ref|NC_001807/" | \
	gzip > chrM.fa.gz
    

    #  Put all the agp files together into one.
    cd /cluster/store5/gs.18/build35
    #	The chrM sequence now has its own agp, remove it from
    #	ref_placed.agp
    sed -e "/^NC_001807/d" ../ncbi/ref_placed.agp > ref_placed.agp
    cat ref_placed.agp ../agp/chrM.agp ../ncbi/ref_unplaced.agp \
	../agp/chr6_hla_hap1.agp ../agp/chr6_hla_hap2.agp \
	../ncbi/PAR.agp > ncbi_build35.agp

    #	and into ffa
    cd /cluster/store5/gs.18/ffa
    #	There is a single bogus line at the end of ref_placed.fa.gz
    #	declaring the NC_001807 MT sequence, this was later replaced by
    #	chrMT.fa.gz, so remove that one line:
    zcat ../ncbi/ref_placed.fa.gz | sed -e "/^>ref|NC_001807/d" | \
	gzip > ref_placed.fa.gz
    #	(That's a 40 minute job)

    #	sequence.inf is usually here, symlink it
    ln -s ../ncbi/sequence.inf
    #	put all the fa.gz files together in one big fa.gz
    time zcat ref_placed.fa.gz ../agp/chrM.fa.gz ../ncbi/ref_unplaced.fa.gz \
	../agp/chr6_hla_hap?.fa.gz ../ncbi/PAR.fa.gz | gzip \
	> ncbi_build35.fa.gz
    #	real    37m42.208s
    #	user    37m3.490s
    #	sys     0m31.430s

    #	Make a listing of all the fasta record headers, just FYI:
    cd /cluster/store5/gs.18/ffa
    zcat ffa/ncbi_build35.fa.gz | grep "^>" > ncbi.fa.headers


    #	New to this build is the sequence: NC_001807 which is the
    #	mitochondria sequence.  This prefix NC_ is new to the process
    #	and will have to be accounted for below.  The other two special
    #	prefixes are similar to what was seen before:
    #	from DR52.agp NG_002392
    #	Homo sapiens major histocompatibility complex, class II,
    #		DR52 haplotype (DR52) on chromosome 6
    #	and from DR53.agp NG_002433
    #	Homo sapiens major histocompatibility complex, class II,
    #		DR53 haplotype (DR53) on chromosome 6

    #	Fixup seq_contig.md
    #
    #	It has a bunch of stuff belonging to the Celera
    #	genome assembly.  Filter those out.  I don't know what the
    #	NT_07959[0-7] items are, but there are no definitions for them
    #	in the agp files and no sequence in any fa.gz file.
    #	Fixup the names for the NG_ items, and change chrom MT to be M
    cd /cluster/store5/gs.18/build35
    egrep -v "Celera|NT_07959[0-7]" ../ncbi/seq_contig.md | \
	sed -e "s/6|NG_002392/6_hla_hap1/" \
	-e "s/6|NG_002433/6_hla_hap2/" \
	-e "s/^9606\tMT|NC_001807/9606\tM/" \
	> temp_contig.md

    #	get the randoms sorted in proper order.  The createNcbiLifts
    #	does not work correctly if the randoms are not grouped together
    #	by chromosome
    grep -v "|" temp_contig.md  > seq_contig.md
    #	This pulls out all the randoms and groups them within the
    #	same chrom but leaving them in the same order as they orginally
    #	were  (warning this is BASH code ...)
    grep "|" temp_contig.md | awk -F"|" '{print $1}' | \
        awk '{print $2}' | sort -n -u | while read CHR
do
        grep "[^0-9]${CHR}|" temp_contig.md
done >> seq_contig.md


    # Sanity check, checkYbr was updated to handle the NC_ identifier
    time zcat ../ffa/ncbi_build35.fa.gz | $HOME/bin/i386/checkYbr \
	ncbi_build35.agp stdin seq_contig.md > check.seq_contig
    #	real    2m34.143s
    #	user    2m24.970s
    #	sys     0m8.900s
    #	result should be clean:
    cat check.seq_contig
    #	Read 380 contigs from ncbi_build35.agp
    #	Verifying sequence sizes in stdin
    #	0 problems detected


    # Convert fa files into UCSC style fa files and place in "contigs"
    # directory inside the gs.18/build35 directory 
    #	(a check that can be done here is make a list of the contigs
    #	in this ./contigs directory before and compare it with the
    #	list of distributed contigs created after they have been
    #	disbursed.)
    #	faNcbiToUcsc was fixed to handle the NC_ identifier

    cd /cluster/store5/gs.18/build35
    #	We've been through this often
    mv contigs contigs.0
    time zcat ../ffa/ncbi_build35.fa.gz | $HOME/bin/i386/faNcbiToUcsc \
	-split -ntLast stdin contigs
    #	real    5m10.938s
    #	user    2m20.070s
    #	sys     0m51.020s
    #	If you want to compare anything to previous work, check now, then:
    rm -fr contigs.0

    # Determine the chromosome sizes from agps
    #	Watch carefully how chrY gets constructed.  I'm not sure
    #	this chrom_sizes represents the whole length of chrY with
    #	the PAR added.  We will see about that.
    #	Script updated to handle new chrom names:
    #	my @chroms = (1 .. 22, 'X', 'Y', 'M', '6_hla_hap1', '6_hla_hap2');

    cd /cluster/store5/gs.18/build35
    /cluster/bin/scripts/getChromSizes ../agp
    #	Create chrom.lst list for use in foreach() loops
    awk '{print $1}' chrom_sizes | sed -e "s/chr//" > chrom.lst

    # Create lift files (this will create chromosome directory structure) and
    #	inserts file
  
    /cluster/bin/scripts/createNcbiLifts -s chrom_sizes seq_contig.md .

    # Create contig agp files (will create contig directory structure)
	
    /cluster/bin/scripts/createNcbiCtgAgp seq_contig.md ncbi_build35.agp .

    # Create chromsome random agp files.

    /cluster/bin/scripts/createNcbiChrAgp -randomonly .

    # Copy the original chrN.agp files from the gs.18/agp directory 
    #    into each of the chromosome directories since they contain better 
    #    gap information. Delete the comments at top from these.
    cd /cluster/store5/gs.18/build35
    foreach c ( `cat chrom.lst` )
	sed -e "/^#.*/d" ../agp/chr${c}.agp > ./${c}/chr${c}.agp
    end
    #	chrM needs a name fixup
    sed -e "s#NC_001807#chrM#" ../agp/chrM.agp > M/chrM.agp

    # Distribute contig .fa to appropriate directory (assumes all files
    # are in "contigs" directory).

    # Create inserts file from agp and lift files (new - added by Terry, 2004-07-12)
    /cluster/bin/scripts/createInserts /cluster/data/hg17 > /cluster/data/hg17/inserts

    # create global data link for everyone.  No more home directory
    # links required.
    ln -s /cluster/store5/gs.18/build35 /cluster/data/hg17
    cd /cluster/data/hg17
    /cluster/bin/scripts/distNcbiCtgFa contigs .
    #	Verify that everything was moved properly, the contigs directory
    #	should be empty:
    ls contigs
    #	Nothing there, then remove it
    rmdir  contigs

    #	Make a list of the contigs for use later
    rm contig.lst
    touch contig.lst
    foreach chrom ( `cat chrom.lst` )
	foreach c ( $chrom/N{C,G,T}_?????? )
	    set contig = $c:t
	    echo "${chrom}/${contig}/${contig}.fa" >> contig.lst
	end
    end
    #   For later comparisons, this is how many contigs we have:
    wc -l contig.lst
    #	380

    #	Note 2004-06-30 - there are some clone numbers left in some of
    #	the NCBI files that are incorrect.  Due to version number
    #	changes, more than one version is listed.  Namely for accession
    #	numbers: AC004491 AC004921 AC004983 AC005088 AC006014 AC099654
    #	The AGP files are correct, the sequence.inf file lists these
    #	twice: AC004491.1 AC004491.2
    #	AC004921.1 AC004921.2 AC004983.2 AC004983.3
    #	AC005088.2 AC005088.3 AC006014.2 AC006014.3
    #	AC099654.4 AC099654.5 

    # FILES ARE NOW READY FOR REPEAT MASKING - start that process as
    #	other steps here can proceed in parallel.

    #	Previous practice used to copy everything over for jkStuff from a
    #	previous build.  Rather than do that, pick up whatever is needed
    #	at the time it is needed and verify that it is going to do what
    #	you expect.

    cd /cluster/data/hg17
    mkdir jkStuff

    # Create the contig.gl files - XXX - NCBI doesn't deliver
    # contig_overlaps.agp - 2004-06-18 - this is beginning to come
    # together and there is now a contig_overlaps.agp file

    #	This is properly done below with a combination of psLayout
    #	alignments to create the contig_overlaps.agp file
    # /cluster/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md
    # Create chromosome gl files
    # jkStuff/liftGl.csh contig.gl

# CREATING DATABASE  (DONE - 2004-05-20 - Hiram)
    #	RE-DONE for new NIBS - 2004-06-03
    ssh hgwdev
    # Make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#	Filesystem            Size  Used Avail Use% Mounted on
#	/dev/sdc1             1.8T  303G  1.4T  19% /var/lib/mysql

    # Create the database.
    hgsql -e 'create database hg17' mysql
    # Copy over grp table (for track grouping) from another database:
    hgsql -e "create table grp (PRIMARY KEY(NAME)) select * from hg16.grp" hg17

# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS
#	(DONE - 2004-05-21 - Hiram)
    #	RE-DONE with new NIBS - 2004-06-03
    # Make nib/, unmasked until RepeatMasker and TRF steps are done.
    # Do this now so that the chromInfo table will exist and thus the
    #	trackDb tables can be built in the next step.
    #	These unmasked nibs will be replaced by the masked nibs after
    #	repeat mask and trf are done.
    ssh eieio
    cd /cluster/data/hg17
    # Make chr*.fa from contig .fa
    #  Copied chrFa.sh from hg16/jkStuff, renamed it to chrFa.csh
    time ./jkStuff/chrFa.csh
    #	real    13m24.710s
    #	user    9m0.360s
    #	sys     1m15.820s

    mkdir nib
    foreach c (`cat chrom.lst`)
      foreach f ($c/chr${c}{,_random}.fa)
        if (-e $f) then
          echo "nibbing $f"
          /cluster/bin/i386/faToNib $f nib/$f:t:r.nib
        endif
      end
    end

    # Make symbolic links from /gbdb/hg17/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/hg17/nib
    ln -s /cluster/data/hg17/nib/chr*.nib /gbdb/hg17/nib
    # Load /gbdb/hg17/nib paths into database and save size info.
    cd /cluster/data/hg17
    hgsql hg17  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib hg17 /gbdb/hg17/nib */chr*.fa
    hgsql -N -e "select chrom,size from chromInfo order by chrom" hg17 \
	> chrom.sizes
    # You can compare this chrom.sizes with the previously created
    # chrom_sizes.  Should be no difference
    sort chrom_sizes > s0
    sort chrom.sizes | grep -v random > s1
    diff s0 s1
    rm s0 s1

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE - 2004-05-21 - Hiram)
    #	dbDb orderKey updated 2004-06-08 - Hiram
    ssh hgwdev
    #	reset dbDb orderKey - these have never been ordered properly
    #	before, this will get them on the program.
    hgsql -e 'update dbDb set orderKey=11 where name = "hg16";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=12 where name = "hg15";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=13 where name = "hg13";' \
	-h genome-testdb hgcentraltest

    # Enter hg17 into hgcentraltest.dbDb so test browser knows about it:
    hgsql -e 'INSERT INTO dbDb (name, description, nibPath, organism, \
	defaultPos, active, orderKey, genome, scientificName, \
	htmlPath, hgNearOk) \
	VALUES("hg17", "May 2004", "/gbdb/hg17/nib", "Human", \
	"chr4:56214201-56291736", 1, 10, "Human", "Homo sapiens", \
	"/gbdb/hg17/html/description.html", 0);' \
	-h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~kent/src/hg/makeDb/trackDb
    cvs up -d -P .
    # Edit the makefile to add hg17 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE LIFTALL.LFT, NCBI.LFT (DONE - 2004-05-21 - Hiram)
    #	Re-DONE with new randoms - 2004-06-03 - Hiram)
    cd /cluster/data/hg17
    mkdir -p jkStuff
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft
    # Create jkStuff/ncbi.lft for lifting stuff built with the NCBI assembly.
    # Note: this ncbi.lift will not lift floating contigs to chr_random coords,
    # but it will show the strand orientation of the floating contigs 
    # (grep for '|').
    #   mdToNcbiLift seq_contig.md jkStuff/ncbi.lft 
    #	XXXX - appears to be unused, not done - Hiram

# REPEAT MASKING (DONE - 2004-05-24 - Hiram)
    #	The randoms were rearranged after this was first done,
    #	they are re-made below 2004-06-02)

    # Split contigs, run RepeatMasker, lift results

    #	This split takes about 8 minutes
    ssh eieio
    cd /cluster/data/hg17
    foreach chrom ( `cat chrom.lst` )
	foreach c ( $chrom/N{C,G,T}_?????? )
	    set contig = $c:t
	    echo "splitting ${chrom}/${contig}/${contig}.fa"
	    faSplit size ${chrom}/${contig}/$contig.fa 500000 \
		${chrom}/${contig}/${contig}_ \
		-lift=${chrom}/${contig}/$contig.lft -maxN=500000
	end
    end

    #- Make the run directory and job list:
    cd /cluster/data/hg17
    mkdir -p jkStuff
    #  According to RepeatMasker help file, no arguments are required to
    #	specify species because its default is set for primate (human)
    #  This run script saves the .tbl file to be sent to Arian.  He uses
    # those for his analysis.  Sometimes he needs the .cat and .align files for
    # checking problems.  Krish needs the .align files, they are large.

    cat << '_EOF_' > jkStuff/RMHuman
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/hg17/$2
/bin/cp $2 /tmp/hg17/$2/
cd /tmp/hg17/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s $2
popd
/bin/cp /tmp/hg17/$2/$2.out ./
 if (-e /tmp/hg17/$2/$2.align) /bin/cp /tmp/hg17/$2/$2.align ./
if (-e /tmp/hg17/$2/$2.tbl) /bin/cp /tmp/hg17/$2/$2.tbl ./
# if (-e /tmp/hg17/$2/$2.cat) /bin/cp /tmp/hg17/$2/$2.cat ./
/bin/rm -fr /tmp/hg17/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg17/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg17
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMHuman

    ssh eieio
    cd /cluster/data/hg17
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
    foreach d ( `cat chrom.lst` )
     foreach c ( ${d}/N{C,G,T}_*/N{C,G,T}_*_*.fa )
        set f = $c:t
        set cc = $c:h
        set contig = $cc:t
        echo /cluster/store5/gs.18/build35/jkStuff/RMHuman \
   		/cluster/store5/gs.18/build35/${d}/${contig} $f \
   '{'check out line+ /cluster/store5/gs.18/build35/${d}/${contig}/$f.out'}' \
          >> RMRun/RMJobs
      end
    end

    # We have 5971 jobs in RMJobs:
    wc RMRun/RMJobs
    #	5970   41790 1105804 RMRun/RMJobs

    #- Do the run
    ssh kk
    cd /cluster/data/hg17/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...

    #- While that is running, you can run TRF (simpleRepeat) on the small
    # cluster.  See SIMPLE REPEAT section below
# Completed: 5970 of 5970 jobs
# CPU time in finished jobs:   45189516s  753158.60m 12552.64h  523.03d  1.433 y
# IO & Wait Time:                141333s    2355.55m    39.26h    1.64d  0.004 y
# Average job time:                7593s     126.55m     2.11h    0.09d
# Longest job:                    10268s     171.13m     2.85h    0.12d
# Submission to last job:         81484s    1358.07m    22.63h    0.94d

    #	Lift up the split-contig .out's to contig-level .out's
    #
    #	If a mistake is made in the following it would be possible to
    #	destroy all the RM output.  So, just to be paranoid, save all
    #	the RM output in bluearc for the time being:
    ssh eieio

    cd /cluster/data/hg17
    mkdir /cluster/bluearc/hg17/RMOutput
    foreach c ( `cat chrom.lst` )
     foreach d ( ${c}/N{C,G,T}_* )
	set T = /cluster/bluearc/hg17/RMOutput/${d}
	mkdir -p ${T}
        cd ${d}
        set contig = $d:t
        cp -p ${contig}_?{,?,??}.fa.out ${T}
        cd ../..
	echo "${d} done"
     end
    end
    #	Make sure we got them all:
    #	(this doesn't work later since there are more *.fa.out files
    #	after the lifting.  More explicitly to find just these:
    #		find . -name "N?_*_*.fa.out" -print | wc -l
    find . -name "*.fa.out" -print | wc -l
    #	5970
    find /cluster/bluearc/hg17/RMOutput -type f | wc -l
    #	5970
    #	same count

    #	OK, now you can try this operation, do it in a script like this
    #	and save the output of the script for a record of what happened.

    cat << '_EOF_' > jkStuff/liftRM.csh
#!/bin/csh -fe
foreach c ( `cat chrom.lst` )
 foreach d ( ${c}/N{C,G,T}_* )
    cd $d
    set contig = $d:t
    liftUp $contig.fa.out $contig.lft warn ${contig}_?{,?,??}.fa.out 
    cd ../..
 end
end
'_EOF_'
    chmod +x jkStuff/liftRM.csh
    mkdir scriptsOutput
    time jkStuff/liftRM.csh > scriptsOutput/liftRM.1 2>&1
    #	real    4m37.572s
    #	user    1m19.130s
    #	sys     0m32.950s
    #	Check that they all were done:
    grep "fa.out" scriptsOutput/liftRM.1 | wc -l
    #	5959
    #	same count as above

    #- Lift up RepeatMask .out files to chromosome coordinates via
    # picked up jkStuff/liftOut2.sh from the hg16 build.  Renamed to
    # liftOut2.csh, changed the line that does the chrom listing

    time ./jkStuff/liftOut2.csh > scriptsOutput/liftOut2 2>&1
    #	real    9m46.780s
    #	user    1m18.900s
    #	sys     7m33.990s

    #- By this point, the database should have been created (above):
    ssh hgwdev
    cd /cluster/data/hg17
    time hgLoadOut hg17 ?/*.fa.out ??/*.fa.out 6_hla_hap?/*.fa.out > \
	scriptsOutput/hgLoadOut 2>&1
    #	real    5m59.137s
    #	user    1m47.550s
    #	sys     0m15.410s

    # errors during this load:  (there are always a couple of these)
    #	Strange perc. field -6.1 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -6.1 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -0.2 line 30322 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30324 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30326 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30328 of 17/chr17.fa.out
    #	Strange perc. field -18.6 line 77034 of 19/chr19.fa.out

    #	Verify we have similar results to previous assembly:
    #	featureBits hg17 rmsk
    #	1391378842 bases of 2867328468 (48.525%) in intersection
    #	featureBits hg16 rmsk
    #	1388770568 bases of 2865248791 (48.469%) in intersection
    #	Now proceed to MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
    #	following the SIMPLE REPEAT sections below

# Re-Running REPEAT_MASKER on the new Randoms (DONE - 2004-06-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17
    grep "|" seq_contig.md | awk '{print $2}' | sed -e "s#|#/#" > randoms.lst

    mkdir /cluster/data/hg17/RMRandoms
    foreach r ( `cat randoms.lst` )
	set d = $r:h
	set contig = $r:t
	foreach c ( ${r}/N{C,G,T}_*_*.fa )
	    set f = $c:t
	    echo /cluster/store5/gs.18/build35/jkStuff/RMHuman \
   		/cluster/store5/gs.18/build35/${d}/${contig} $f \
   '{'check out line+ /cluster/store5/gs.18/build35/${d}/${contig}/$f.out'}' \
          >> RMRandoms/RMJobs
	end
    end

    ssh kk
    cd /cluster/data/hg17/RMRandoms
    para create RMJobs
    para try, para check, para check, para push, para check,...
# Completed: 94 of 94 jobs
# CPU time in finished jobs:     221454s    3690.91m    61.52h    2.56d  0.007 y
# IO & Wait Time:                   866s      14.43m     0.24h    0.01d  0.000 y
# Average job time:                2365s      39.42m     0.66h    0.03d
# Longest job:                     9062s     151.03m     2.52h    0.10d
# Submission to last job:          9106s     151.77m     2.53h    0.11d

    #	Continuing with the paranoia theme, let's backup all the RM output
    #
    ssh eieio

    cd /cluster/data/hg17
    mkdir /cluster/bluearc/hg17/RMRandoms
    foreach c ( `cat chrom.lst` )
     foreach d ( ${c}/N{C,G,T}_* )
	set T = /cluster/bluearc/hg17/RMRandoms/${d}
	mkdir -p ${T}
        cd ${d}
        set contig = $d:t
        cp -p ${contig}_?{,?,??}.fa.out ${T}
        cd ../..
	echo "${d} done"
     end
    end
    #	Make sure we got them all:
    find . -name "N?_*_*.fa.out" -print | wc -l
    #	5959
    find /cluster/bluearc/hg17/RMRandoms -type f | wc -l
    #	5959
    #	same count


    time jkStuff/liftRM.csh > scriptsOutput/liftRM2.1 2>&1
    #	real    4m46.302s
    #	user    1m18.260s
    #	sys     0m18.000s
    #	Check that they all were done:
    grep "fa.out" scriptsOutput/liftRM2.1 | wc -l
    #	5959
    #	same count as above

    #- Lift up RepeatMask .out files to chromosome coordinates via
    # picked up jkStuff/liftOut2.sh from the hg16 build.  Renamed to
    # liftOut2.csh, changed the line that does the chrom listing

    time ./jkStuff/liftOut2.csh > scriptsOutput/liftOut2.1 2>&1
    #	real    2m46.347s
    #	user    1m18.650s
    #	sys     0m15.990s

    #- By this point, the database should have been created (above):
    ssh hgwdev
    cd /cluster/data/hg17
    time hgLoadOut hg17 ?/*.fa.out ??/*.fa.out 6_hla_hap?/*.fa.out > \
	scriptsOutput/hgLoadOut 2>&1
    #	real    5m59.137s
    #	user    1m47.550s
    #	sys     0m15.410s

    # errors during this load:  (there are always a couple of these)
    #	Strange perc. field -6.1 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243543 of 2/chr2.fa.out
    #	Strange perc. field -6.1 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -5.6 line 243545 of 2/chr2.fa.out
    #	Strange perc. field -0.2 line 30322 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30324 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30326 of 17/chr17.fa.out
    #	Strange perc. field -0.2 line 30328 of 17/chr17.fa.out
    #	Strange perc. field -18.6 line 77034 of 19/chr19.fa.out

    #	Verify we have similar results to previous assembly:
    #	featureBits hg17 rmsk
    #	1390952984 bases of 2866216770 (48.529%) in intersection
    #	featureBits hg17 rmsk  #with previous randoms:
    #	1391378842 bases of 2867328468 (48.525%) in intersection
    #	featureBits hg16 rmsk
    #	1388770568 bases of 2865248791 (48.469%) in intersection
    #	Now proceed to MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
    #	following the SIMPLE REPEAT sections below

# SIMPLE REPEAT [TRF] TRACK (DONE - 2004-05-21 - Hiram)
    #	Re-done with new randoms, 2004-06-02 - Hiram
    #	Copy the contigs, first to the bluearc, then to /iscratch/i
    ssh eieio
    mkdir /cluster/bluearc/hg17
    mkdir /cluster/bluearc/hg17/contigs

    cd /cluster/data/hg17
    foreach ctg ( `cat contig.lst` )
	set c = $ctg:t
 	echo "$ctg > /cluster/bluearc/hg17/contigs/$c"
	cp -p $ctg /cluster/bluearc/hg17/contigs/$c
    end
    #	Check how much is there:
    #	du -hsc /cluster/bluearc/hg17/contigs
    #	2.8G    /cluster/bluearc/hg17/contigs

    # Distribute contigs to /iscratch/i
    ssh kkr1u00
    mkdir /iscratch/i/gs.18/build35/unmaskedContigs
    cd /iscratch/i/gs.18/build35/unmaskedContigs
    cp -p /cluster/bluearc/hg17/contigs/* .

    # Verify same amount made it there:
    #	du -hsc /iscratch/i/gs.18/build35/unmaskedContigs
    #	2.8G    /iscratch/i/gs.18/build35/unmaskedContigs
    #	Then send them to the other 7 Iservers
    /cluster/bin/iSync

    #	Go to the small cluster for this business:
    ssh kki

    mkdir -p /cluster/data/hg17/bed/simpleRepeat
    cd /cluster/data/hg17/bed/simpleRepeat
    mkdir trf
    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    ls -1S /iscratch/i/gs.18/build35/unmaskedContigs/*.fa > genome.lst
    gensub2 genome.lst single gsub jobList
    para create jobList
    para try
    para check
    para push
    para check
# Completed: 380 of 380 jobs
# CPU time in finished jobs:      13230s     220.49m     3.67h    0.15d  0.000 y
# IO & Wait Time:                  2078s      34.64m     0.58h    0.02d  0.000 y
# Average job time:                  40s       0.67m     0.01h    0.00d
# Longest job:                     1590s      26.50m     0.44h    0.02d
# Submission to last job:          2504s      41.73m     0.70h    0.03d

    liftUp simpleRepeat.bed /cluster/data/hg17/jkStuff/liftAll.lft \
	warn trf/*.bed  > lu.out 2>&1

    # Load into the database:
    ssh hgwdev
    cd /cluster/data/hg17/bed/simpleRepeat
    /cluster/bin/i386/hgLoadBed hg17 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
    #	Loaded 629076 elements of size 16
    #	Compare with previous assembly
    featureBits hg17 simpleRepeat
    #	54952425 bases of 2866216770 (1.917%) in intersection

    #	with previous randoms
    featureBits hg17 simpleRepeat
    #	54964044 bases of 3096628158 (1.775%) in intersection
    featureBits hg16 simpleRepeat
    #	54320136 bases of 2865248791 (1.896%) in intersection
    #	GAPS weren't in hg17 yet at this point, after gaps added:
    #	featureBits hg17 simpleRepeat
    #	54964044 bases of 2867328468 (1.917%) in intersection
    #	featureBits -countGaps hg17 simpleRepeat
    #	54964044 bases of 3096628158 (1.775%) in intersection


# PROCESS SIMPLE REPEATS INTO MASK (DONE - 2004-05-21 - Hiram)
    #	re-done with new randoms - 2004-06-03 - Hiram
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd /cluster/data/hg17/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

    #	EXPERIMENT, at a filter of <= 12, we have coverage:
    #	20904399 bases of 2867328468 (0.729%) in intersection
    #	at a filter of <= 9, we have coverage:
    #	19271270 bases of 2867328468 (0.672%) in intersection


    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/hg17
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c ( `cat chrom.lst` )
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end

# MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE - 2004-05-25)
#							 -Hiram
    #	re-done with new randoms - 2004-06-03 - Hiram
    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above,
    #	and after Repeat Masker is complete.
    ssh eieio
    cd /cluster/data/hg17

    # copied these scripts from hg16 - reset the lines that make
    # the chrom list to work on, reset the wild cards that find all the
    # contig .fa's

    # Make chr*.fa from contig .fa
    #  Copied chrFa.sh from hg16/jkStuff, renamed it to chrFa.csh
    time ./jkStuff/chrFa.csh > scriptsOutput/chrFa.out 2>&1 &
    #	real    13m18.512s
    #	user    9m1.670s
    #	sys     1m7.290s

    #- Soft-mask (lower-case) the contig and chr .fa's
    time ./jkStuff/makeFaMasked.csh > scriptsOutput/maFaMasked.out 2>&1
    #	real    29m31.623s
    #	user    13m49.700s
    #	sys     5m58.750s
    #- Make hard-masked .fa.masked files as well:
    time ./jkStuff/makeHardMasked.csh > scriptsOutput/maHardMasked.out 2>&1

    #- Create the bothMasksNib/ directory
    time ./jkStuff/makeNib.csh > scriptsOutput/maNib.out 2>&1
    #	real    14m41.694s
    #	user    6m28.000s
    #	sys     1m42.500s

    # Make symbolic links from /gbdb/hg17/nib to the real nibs.
    ssh hgwdev
    mv nib nib.raw
    mv bothMasksNib nib
    rm /gbdb/hg17/nib/*.nib
    ln -s `pwd`/nib/* /gbdb/hg17/nib

    # Load /gbdb/hg17/nib paths into database and save size info.
    hgsql hg17  < ~/kent/src/hg/lib/chromInfo.sql
    cd /cluster/data/hg17
    hgNibSeq -preMadeNib hg17 /gbdb/hg17/nib */chr*.fa
    #	3096628158 total bases

    #	Should be the same size as before
    hgsql -N -e "select chrom,size from chromInfo order by chrom" hg17 \
	> chrom.sizes.masked
    diff chrom.sizes chrom.sizes.masked
    #	should be no output at all, thus:
    rm chrom.sizes.masked

    # Copy the masked contig fa to /scratch and /iscratch
    #	And everything else we will need for blastz runs, etc ...
    #	Best to do this sequence first to /cluster/bluearc/scratch,
    #	which is going to be the source for the /scratch copy.
    #	And then from there to the /iscratch
    #	Make sure you are on the fileserver for the original source:
    ssh eieio
    mkdir -p /cluster/bluearc/scratch/hg/gs.18/build35
    cd /cluster/bluearc/scratch/hg/gs.18/build35

    #	these copies take less than 2 minutes each
    mkdir bothMaskedNibs
    cp -p /cluster/data/hg17/nib/*.nib ./bothMaskedNibs
    mkdir maskedContigs
    foreach chrom ( `cat /cluster/data/hg17/chrom.lst` )
	cp -p /cluster/data/hg17/${chrom}/N{C,G,T}_*/N{C,G,T}_??????.fa \
		./maskedContigs
	echo "done ${chrom}"
    end
    #	make sure you have them all:
    ls maskedContigs | wc -l
    #	380
    wc -l /cluster/data/hg17/contig.lst
    #	380
    mkdir rmsk
    foreach chrom ( `cat /cluster/data/hg17/chrom.lst` )
	cp -p /cluster/data/hg17/${chrom}/*.out ./rmsk
	echo "done ${chrom}"
    end

    #	Now, go to the destination for /iscratch and copy from the
    #	bluearc
    ssh kkr1u00
    mkdir -p /iscratch/i/gs.18/build35
    cd /iscratch/i/gs.18/build35
    #	This takes about 5 minutes
    rsync -arlv /cluster/bluearc/scratch/hg/gs.18/build35/ .

    time /cluster/bin/iSync
    #	real    7m27.649s

    # request rsync of /cluster/bluearc/scratch to the KiloKluster /scratch

# LOAD ctgPos table - Contig position track (DONE - 2004-06-08 - Hiram)
    #	After fixing up hgCtgPos to accept the -chromLst argument, simply:
    cd /cluster/data/hg17
    hgCtgPos -chromLst=chrom.lst hg17 .

# GOLD AND GAP TRACKS (DONE - 2004-05-21 - Hiram)
    #	RE-DONE with new randoms - 2004-06-03 - Hiram
    ssh hgwdev
    cd /cluster/data/hg17
    hgGoldGapGl -noGl -chromLst=chrom.lst hg17 /cluster/data/hg17 .
    #	Disappointing to see this create so many tables ...
    #	_gap and _gold for each chrom

    # Create the contig.gl files - XXX - NCBI doesn't deliver
    # contig_overlaps.agp - 2004-06-18 - this is beginning to come
    # together and there is now a contig_overlaps.agp file
    cd /cluster/store5/gs.18/build35
    #	combine the various psLayout attempts on different sections of
    #	clones
    ./combineContigOverlaps.sh
    #	Turn contig_overlaps.agp into gl files
    ~hiram/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md
    # Create chromosome gl files  (had to fix liftUp to do the NC_ properly)
    jkStuff/liftGl.csh contig.gl
    #
    #	Need to remove these PAR clone names from chrY.gl
    rm -f /tmp/chrY.gl
    sed -e "/^AL954722.18/d; /^BX537334.4/d; /^BX000483.7/d; \
	/^BX908402.3/d; /^BX649635.3/d; /^BX119919.5/d; \
	/^AC079176.15/d; /^AC097314.27/d; /^AC006209.25/d; \
	/^AJ271735.1/d; /^AJ271736.1/d" Y/chrY.gl > /tmp/chrY.gl
    rm -f Y/chrY.gl
    mv /tmp/chrY.gl Y/chrY.gl

#  After contig.gl files have been made from contig_overlaps.agp
#	The sed fixes the Celera clones that are marked phase W
#	Call that phase 3 instead,
#	Delete the Celera AACC clones, they are not in this assembly,
#	And fix the line of AC018743 to add it to the assembly, it was a
#	last minute addition by Terry that didn't get carried into the
#	NCBI sequence.inf file.  And remove the older versions of five
#	clones that got left in by mistake at NCBI
    #	AC004491.1=AC004491.2 AC004921.1=AC004921.2 AC004983.2=AC004983.3
    #	AC005088.2=AC005088.3 AC006014.2=AC006014.3 AC099654.4=AC099654.5 
#	And finally the grep selects only those things for_assembly
    cd /cluster/data/hg17
    egrep "for_assembly|AC018743" /cluster/store5/gs.18/ncbi/sequence.inf | \
    sed -e "s/\tW\t/\t3\t/; /^AACC010000.*/d; /^AC004491.1.*/d; \
	/^AC004921.1.*/d; /^AC004983.2.*/d; /^AC005088.2.*/d; \
	/^AC006014.2.*/d; /^AC099654.4.*/d; \
	s/AC018743.27\t31791062\t466818\t1\tD\tUn\t-\tBCM\tRP11-289M22\tSIZE:2big/AC018743.27\t31791062\t466818\t1\t-\t(12)\t-\tBCM\tRP11-289M22\tfor_assembly/" \
	> sequence.inf
    cd /cluster/data/hg17
    hgGoldGapGl -chromLst=chrom.lst hg17 /cluster/store5/gs.18 build35
    $HOME/bin/i386/hgClonePos -chromLst=chrom.lst hg17 \
	/cluster/data/hg17 ./sequence.inf /cluster/store5/gs.18 -maxErr=3 \
	-maxWarn=2000 2> clone.pos.errors
    #	Extract all the PAR clones for chrX from clonePos, change the X
    #	to Y, fixup the coordinates on the last three, and load this
    #	data in on the clonePos table in addition to what is there
    #	already.
    cat << '_EOF_' > chrY.par.clonePos
BX640545.2      34821   3       chrY    0       34250   F
AL954722.18     37771   3       chrY    84821   122592  F
BX537334.4      36872   3       chrY    120592  157464  F
BX000483.7      15918   3       chrY    155466  171384  F
AL954664.17     39200   3       chrY    251384  290307  F
BX000476.5      33340   3       chrY    282188  315528  F
AL732314.18     218723  3       chrY    313528  532251  F
BX004827.18     119555  3       chrY    479050  600112  F
AL683871.15     175765  3       chrY    598112  773877  F
AL672311.26     115998  3       chrY    771877  887875  F
AL672277.20     131682  3       chrY    885875  1017557 F
BX908402.3      36556   3       chrY    1067557 1104113 F
BX649635.3      43709   3       chrY    1154113 1197822 F
BX649553.5      90286   3       chrY    1347822 1438108 F
BX296563.3      21008   3       chrY    1488108 1509117 F
BX119906.16     35666   3       chrY    1507116 1542782 F
AL683870.15     162377  3       chrY    1541782 1704175 F
AL691415.17     45085   3       chrY    1702175 1747265 F
AL683807.22     189825  3       chrY    1745260 1935086 F
AL672040.10     117297  3       chrY    1933086 2050383 F
BX004859.8      63432   3       chrY    2048380 2111815 F
BX119919.5      55442   3       chrY    2261815 2317257 F
AC079176.15     186278  3       chrY    2311674 2497952 F
AC097314.27     80501   3       chrY    2495948 2576449 F
AC006209.25     141759  3       chrY    2551122 2692881 F
AJ271735.1      240000  3       chrY    57302979        57543030        F
AJ271736.1      158661  3       chrY    57543030        57701691        F
'_EOF_'

hgsql -e 'load data local infile "chrY.par.clonePos" into table clonePos;' hg17

    #	We have the following errors
# Processing /cluster/data/hg17/Y/chrY.gl
# Clone BX640545 is on chromosomes chrX and chrY.  Ignoring chrY
# Clone AL954722 is on chromosomes chrX and chrY.  Ignoring chrY
# ... etc for all the PAR clones
# ... And there are an unknown number of these:
# AB000359 is in ./sequence.inf but not in ooDir/*/*.gl
# AB000360 is in ./sequence.inf but not in ooDir/*/*.gl

#  gc5Base wiggle TRACK (DONE - 2004-05-22 - Hiram)
    #	This previously was a script that ran through each nib
    #	Recently transformed into a mini cluster run.
    #	Re-DONE with the new randoms - 2004-06-04
    ssh kki
    mkdir /cluster/data/hg17/bed/gc5Base
    cd /cluster/data/hg17/bed/gc5Base

    mkdir wigData5 dataLimits5 wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRun.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 hg17 \
        /iscratch/i/gs.18/build35/bothMaskedNibs | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigAsciiToBinary -dataSpan=5 -chrom=${chr} \
        -wibFile=wigData5/gc5Base_${chrom} \
            -name=${chrom} stdin 2> dataLimits5/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRun.sh

    ls /iscratch/i/gs.18/build35/bothMaskedNibs > nibList
    cat << '_EOF_' > gsub
#LOOP
./kkRun.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsub jobList
    para create jobList
    para try, check, ... etc
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       5251s      87.51m     1.46h    0.06d  0.000 y
# IO & Wait Time:                   130s       2.17m     0.04h    0.00d  0.000 y
# Average job time:                 117s       1.95m     0.03h    0.00d
# Longest job:                      413s       6.88m     0.11h    0.00d
# Submission to last job:           475s       7.92m     0.13h    0.01d

    # load the .wig files back on hgwdev:
    ssh hgwdev
    cd /cluster/data/hg17/bed/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/hg17/wib/gc5Base hg17 gc5Base wigData5/*.wig
    # and symlink the .wib files into /gbdb
    mkdir /gbdb/hg17/wib/gc5Base
    ln -s `pwd`/wigData5/*.wib /gbdb/hg17/wib/gc5Base

    #	And then the zoomed data view
    ssh kki
    cd /cluster/data/hg17/bed/gc5Base
    mkdir wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRunZoom.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 hg17 \
        /iscratch/i/gs.18/build35/bothMaskedNibs | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigZoom -dataSpan=1000 stdin | wigAsciiToBinary -dataSpan=1000 \
	-chrom=${chr} -wibFile=wigData5_1K/gc5Base_${chrom}_1K \
            -name=${chrom} stdin 2> dataLimits5_1K/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRunZoom.sh

    cat << '_EOF_' > gsubZoom
#LOOP
./kkRunZoom.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsubZoom jobListZoom
    para create jobListZoom
    para try ... check ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       5216s      86.93m     1.45h    0.06d  0.000 y
# IO & Wait Time:                    34s       0.57m     0.01h    0.00d  0.000 y
# Average job time:                 114s       1.90m     0.03h    0.00d
# Longest job:                      415s       6.92m     0.12h    0.00d
# Submission to last job:           469s       7.82m     0.13h    0.01d

    #	Then load these .wig files into the same database as above
    ssh hgwdev
    hgLoadWiggle -pathPrefix=/gbdb/hg17/wib/gc5Base \
	-oldTable hg17 gc5Base wigData5_1K/*.wig
    # and symlink these .wib files into /gbdb
    mkdir -p /gbdb/hg17/wib/gc5Base
    ln -s `pwd`/wigData5_1K/*.wib /gbdb/hg17/wib/gc5Base

# AUTO UPDATE GENBANK MRNA RUN  (DONE - 2004-06-08 - Hiram)
    ssh eieio
    cd /cluster/data/genbank
    # This is a new organism, edit the etc/genbank.conf file and add:
	# hg17
	hg17.genome = /scratch/hg/gs.18/build35/bothMaskedNibs/chr*.nib
	hg17.lift = /cluster/store5/gs.18/build35/jkStuff/liftAll.lft
	hg17.genbank.est.xeno.load = yes
	hg17.mgcTables.default = full
	hg17.mgcTables.mgc = all
	hg17.downloadDir = hg17

    #	Do the refseq's first, they are the quick ones
    ssh eieio
    cd /cluster/data/genbank
    nice bin/gbAlignStep -srcDb=refseq -type=mrna -verbose=1 -initial hg17
    #	 logFile: var/build/logs/2004.05.25-13:41:07.hg17.initalign.log
    #	checking that log, or watching the batch on kk, you can find
    #	where the batch is running and after it is done get the time:
    cd /cluster/store6/genbank/work/initial.hg17/align
    para time > time
    cat time
# Completed: 9500 of 9500 jobs
# CPU time in finished jobs:      62241s    1037.35m    17.29h    0.72d  0.002 y
# IO & Wait Time:                 33719s     561.98m     9.37h    0.39d  0.001 y
# Average job time:                  10s       0.17m     0.00h    0.00d
# Longest job:                     1062s      17.70m     0.29h    0.01d
# Submission to last job:          1063s      17.72m     0.30h    0.01d

    # Load the results from the above
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg17

#	To get the genbank started, the above results need to be
#	moved out of the way.  These things can be removed if there are
#	no problems to debug
    ssh eieio
    cd /cluster/data/genbank/work
    mv initial.hg17 initial.hg17.refseq.mrna

    cd /cluster/data/genbank
    nice bin/gbAlignStep -srcDb=genbank -type=mrna -verbose=1 -initial hg17
    #	logFile: var/build/logs/2004.06.04-10:47:21.hg17.initalign.log
    #	One job was hung up, after killing it on its node, the batch
    #	finished in a few minutes.
# Completed: 35720 of 35720 jobs
# CPU time in finished jobs:    5161424s   86023.74m  1433.73h   59.74d  0.164 y
# IO & Wait Time:                144149s    2402.48m    40.04h    1.67d  0.005 y
# Average job time:                 149s       2.48m     0.04h    0.00d
# Longest job:                    18306s     305.10m     5.08h    0.21d
# Submission to last job:         35061s     584.35m     9.74h    0.41d

    ssh hgwdev
    cd /cluster/data/genbank
    #	some kind of error happened here, had to remove a lock file to
    #	get this to proceed  (this same thing happened again the second
    #	time around)
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg17

    ssh eieio
    cd /cluster/data/genbank/work
    mv initial.hg17 initial.hg17.genbank.mrna
    cd /cluster/data/genbank
    nice bin/gbAlignStep -srcDb=genbank -type=est -verbose=1 -initial hg17
# Completed: 189240 of 189240 jobs
# CPU time in finished jobs:   97172120s 1619535.33m 26992.26h 1124.68d  3.081 y
# IO & Wait Time:               1507789s   25129.82m   418.83h   17.45d  0.048 y
# Average job time:                 521s       8.69m     0.14h    0.01d
# Longest job:                    33165s     552.75m     9.21h    0.38d
# Submission to last job:        126988s    2116.47m    35.27h    1.47d

    ssh hgwdev
    cd /cluster/data/genbank
    time nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg17
    #	real    440m42.750s
    #	user    69m7.810s
    #	sys     23m18.640s
    #	This is ~7.5 hours

    #	If the above is all OK, ask Mark to put this assembly on
    #	the daily updates.

# CPGISLANDS (DONE - 2004-05-25 - Hiram)
    #	Re-DONE with new randoms - 2004-06-04 - Hiram
    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/cpgIsland
    cd /cluster/data/hg17/bed/cpgIsland

    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    #	gcc readseq.c cpg_lh.c -o cpglh.exe
    mv cpglh.exe /cluster/data/hg17/bed/cpgIsland/
    
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    ssh eieio
    cd /cluster/data/hg17/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpglh.exe $f > $fout
    end
    #	the warnings:
    # Bad char 0x52 = 'R' at line 2046, base 102229, sequence chr16_random
    # Bad char 0x4d = 'M' at line 1216113, base 60805573, sequence chr3
    # Bad char 0x52 = 'R' at line 1216118, base 60805801, sequence chr3
    # Bad char 0x52 = 'R' at line 1216118, base 60805801, sequence chr3
    #	real    21m47.823s
    #	user    18m30.810s
    #	sys     1m13.420s

    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    ssh hgwdev
    cd /cluster/data/hg17/bed/cpgIsland
    hgLoadBed hg17 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed
    #	Reading cpgIsland.bed
    #	Loaded 27801 elements of size 10
    #	Sorted
    #	Saving bed.tab
    #	Loading hg17

# MAKE HGCENTRALTEST BLATSERVERS ENTRY (DONE - 2004-05-25 - Heather)
    ssh hgwdev
    hgsql -e 'INSERT INTO blatServers (db, host, port, isTrans) \
	VALUES("hg17", "blat12", "17778", "1"); \
	INSERT INTo blatServers (db, host, port, isTrans) \
	VALUES("hg17", "blat12", "17779", "0");' \
	-h genome-testdb hgcentraltest

# PREPARE CLUSTER FOR BLASTZ RUNS (DONE - 2004-05-26 - Hiram)
    #	Re-DONE with new randoms - 2004-06-03 - Hiram

    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/rmsk.spec
    cd /cluster/bluearc/scratch/hg/gs.18/build35/rmsk.spec
    ln -s ../rmsk/*.out .
    #	This takes 40 minutes run as a script, to hurry it up it has
    #	been converted to a mini cluster run
    cat << '_EOF_' > runArian.sh
#!/bin/sh
for FN in *.out
do
    echo /cluster/bluearc/RepeatMasker030619/DateRepsinRMoutput.pl \
	${FN} -query human -comp rat -comp mouse
done
'_EOF_'
    chmod +x runArian.sh
    ssh kki
    cd /cluster/bluearc/scratch/hg/gs.18/build35/rmsk.spec
    ./runArian.sh > jobList
    para create jobList
    para try, ... check ... push ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:        668s      11.14m     0.19h    0.01d  0.000 y
# IO & Wait Time:                   514s       8.56m     0.14h    0.01d  0.000 y
# Average job time:                  26s       0.43m     0.01h    0.00d
# Longest job:                       86s       1.43m     0.02h    0.00d
# Submission to last job:           108s       1.80m     0.03h    0.00d

    #	Now extract each one, 1 = Rat, 2 = Mouse
    ssh eieio
    cd /cluster/bluearc/scratch/hg/gs.18/build35

    mkdir linSpecRep.notInRat linSpecRep.notInMouse
    foreach f (rmsk.spec/*.out_rat_mus)
        set base = $f:t:r:r
        echo "$f -> $base.out.spec"
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInRat/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    #	There is actually no difference at all between these two results.
    #	copy to iscratch
    ssh kkr1u00
    cd /iscratch/i/gs.18/build35
    rsync -arlv /cluster/bluearc/scratch/hg/gs.18/build35/ .
    /cluster/bin/iSync
    # request rsync of /cluster/bluearc/scratch to the KiloKluster /scratch

# COPY DATA TO GOLDEN PATH LOCATIONS (DONE - 2004-06-04 - Hiram)
    ssh hgwdev
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/chromosomes
    cd /cluster/data/hg17
    #	Beware, this backgrounding of the gzips can be hard on hgwdev.
    #	You could wait until after the copy then run one gzip to do them all
    foreach chrom ( `cat chrom.lst` )
	cp -p ${chrom}/*.fa /usr/local/apache/htdocs/goldenPath/hg17/chromosomes
	gzip \
	/usr/local/apache/htdocs/goldenPath/hg17/chromosomes/chr${chrom}*.fa &
	echo "done ${chrom}"
    end
    cd /usr/local/apache/htdocs/goldenPath/hg17/chromosomes
    gzip *.fa


# FOSMID END PAIRS TRACK (2004-06-09 kate)
# Corrected upper size limit to 50Kbp, reran pslPairs, 
# and reloaded (2004-07-15 kate)

    # Use latest fosmid ends data prepared by Terry Furey.
    # He says there is no on-going work on fosmid ends, so this
    # should suffice indefinitely ?  Move/link this stuff into
    # central data area.
    ssh eieio
    cd /cluster/data/ncbi
    mkdir -p fosends/human
    ln -s /cluster/store1/fosends.3 fosends/human
    cd fosends/human/fosends.3
    faSize fosEnds.fa
       # 579735181 bases (369769 N's 579365412 real) in 1087670 sequences 
       # 580M bases in 1M sequences
    # create link in /gbdb/ncbi/fosends/human ?

    # use pre-split fosend files, and associated list for cluster run
    # Sequences are in /cluster/bluearc/hg/fosEnds
    cp /cluster/bluearc/booch/fosends/fosEnds.lst /cluster/bluearc/hg/fosEnds
    
    # run on rack9 since kilokluster is busy
    ssh kk9
    cd /cluster/data/hg17
    mkdir -p bed/fosends
    cd bed/fosends
    mkdir -p run
    cd run
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa \
                > contigs.lst
    cp /cluster/bluearc/hg/fosEnds/fosEnds.lst fosEnds.lst
        # 380 contigs vs 97 fosEnd files -> 40K jobs
    # send output to kksilo, as it can better handle the NFS load
    mkdir -p /cluster/store7/kate/hg17/fosends/out
    ln -s /cluster/store7/kate/hg17/fosends/out ../out
cat > gsub << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -ooc=/scratch/hg/h/11.ooc {check out line+ /cluster/data/hg17/bed/fosends/out/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst fosEnds.lst gsub jobList
    foreach f (`cat fosEnds.lst`)
        set d = $f:r:t
        echo $d
        mkdir -p /cluster/data/hg17/bed/fosends/out/$d
    end

    para create jobList
        # 36860 jobs
    para try
    para check
    para push
# CPU time in finished jobs:    1655943s   27599.05m   459.98h   19.17d  0.053 y
# IO & Wait Time:                101145s    1685.75m    28.10h    1.17d  0.003 y
# Average job time:                  48s       0.79m     0.01h    0.00d
# Longest job:                     1294s      21.57m     0.36h    0.01d
# Submission to last job:         19269s     321.15m     5.35h    0.22d

    # sort, filter, and lift alignments
    ssh eieio
    cd /cluster/data/hg17/bed/fosends
    pslSort dirs raw.psl temp out/fosEnds*
    pslReps  -nearTop=0.01 -minCover=0.70 -minAli=0.85 -noIntrons raw.psl \
                        fosEnds.psl /dev/null
        # Processed 84096767 alignments

    rm -r temp
    rm raw.psl

    mkdir lifted
    liftUp lifted/fosEnds.lifted.psl \
                /cluster/data/hg17/jkStuff/liftAll.lft warn fosEnds.psl
    pslSort dirs fosEnds.sorted.psl temp lifted
    rmdir temp
    wc -l *.sorted.psl
        # 1693693 fosEnds.sorted.psl
 
    set ncbiDir = /cluster/data/ncbi/fosends/human/fosends.3
    ~/bin/i386/pslPairs -tInsert=5000 -minId=0.94 -noBin -min=30000 -max=50000 -slop -short -long -orphan -mismatch -verbose fosEnds.sorted.psl $ncbiDir/fosEnds.pairs all_fosends fosEnds

    # create header required by "rdb" tools
    # TODO: replace w/ awk & sort
    echo 'chr\tstart\tend\tclone\tscore\tstrand\tall\tfeatures\tstarts\tsizes' > header
    echo '10\t10N\t10N\t10\t10N\t10\t10\t10N\t10\t10' >> header
    cat header fosEnds.pairs | row score ge 300 | sorttbl chr start | headchg -del > fosEndPairs.bed
    cat header fosEnds.slop fosEnds.short fosEnds.long fosEnds.mismatch \
         fosEnds.orphan \
    | row score ge 300 | sorttbl chr start | headchg -del > fosEndPairsBad.bed

    extractPslLoad -noBin fosEnds.sorted.psl fosEndPairs.bed \
                fosEndPairsBad.bed | \
                        sorttbl tname tstart | headchg -del > fosEnds.load.psl

    # load into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/fosends
    hgLoadBed hg17 fosEndPairs fosEndPairs.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/fosEndPairs.sql 
        # Loaded 384558 elements

    # note - this track isn't pushed to RR, just used for assembly QA
    hgLoadBed hg17 fosEndPairsBad fosEndPairsBad.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/fosEndPairsBad.sql
        # Loaded  30830 elements

    #hgLoadPsl hg17 -nobin -table=all_fosends fosEnds.load.psl
    # NOTE: truncates file to 0 if -nobin is used
    hgLoadPsl hg17 -table=all_fosends fosEnds.load.psl
        # load of all_fosends did not go as planned: 1526991 record(s), 0 row(s) skipped, 156 warning(s) loading psl.tab

    # load sequences
    mkdir -p /gbdb/hg17/fosends
    ln -s /cluster/data/ncbi/fosends/human/fosends.3/fosEnds.fa \
                                /gbdb/hg17/fosends/fosEnds.fa
    hgLoadSeq hg17 /gbdb/hg17/fosends/fosEnds.fa
        # 1087670 sequences
       # NOTE: extFile ID is 832625 (shouldn't be so large ??) 
       # may want to reset this.


# BAC END PAIRS TRACK (DONE - 2004-06-09 kate)

    # Use latest BAC ends data from NCBI
    # Checked  ftp.ncbi.nih.gov/genomes/BACENDS/homo_sapiens,
    #  and files were unchanged from Terry's last download
    #  (to /cluster/store1/bacends.4)
    # Link this stuff into central data area.
    ssh eieio
    cd /cluster/data/ncbi
    mkdir -p bacends/human
    ln -s /cluster/store1/bacends.4 bacends/human
    cd bacends/human/bacends.4
    faSize BACends.fa
        # 400230494 bases (2743171 N's 397487323 real) in 832614 sequences
        # 400M bases in 800K sequences

    # use pre-split bacends files, and associated list for cluster run
    ssh kk
    cd /cluster/data/hg17
    mkdir -p bed/bacends
    cd bed/bacends
    mkdir run
    cd run
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/hg/bacEnds/hs/*.fa > bacends.lst
        # 380 contigs vs 98 bacends files -> 40K jobs

    # send output to kksilo, as it can better handle the NFS load
    # (these are quick jobs)
    mkdir -p /cluster/store7/kate/hg17/bacends/out
    ln -s /cluster/store7/kate/hg17/bacends/out ../out
cat > gsub << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -ooc=/scratch/hg/h/11.ooc {check out line+ /cluster/data/hg17/bed/bacends/out/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst bacends.lst gsub jobList
    foreach f (`cat bacends.lst`)
        set d = $f:r:t
        echo $d
        mkdir -p /cluster/data/hg17/bed/bacends/out/$d
    end

    para create jobList
        # 37240 jobs written to batch
    para try
    para check
    para push
# CPU time in finished jobs:    1573932s   26232.19m   437.20h   18.22d  0.050 y
# IO & Wait Time:                122751s    2045.86m    34.10h    1.42d  0.004 y
# Average job time:                  46s       0.76m     0.01h    0.00d
# Longest job:                     3312s      55.20m     0.92h    0.04d
# Submission to last job:          7148s     119.13m     1.99h    0.08d

    cd ../out/BACends000
    pslCheck *.psl
#Error: invalid PSL: AZ519021:1-575 NT_004559:1306426-1608347 - NT_004559.BACends000.psl:1101
#AZ519021 query block 3 start 283 < previous block end 575
    # NOTE: inquired with JK regarding these results

    # lift alignments
    ssh eieio
    cd /cluster/data/hg17/bed/bacends
    pslSort dirs raw.psl temp out/BACends*
    # takes hours ?

        # 37240 files in 98 dirs
        # Got 37240 files 193 files per mid file
    pslReps -nearTop=0.02 -minCover=0.60 -minAli=0.85 -noIntrons \
                raw.psl  bacEnds.psl /dev/null
        # Processed 52291246 alignments
    mkdir lifted
    liftUp lifted/bacEnds.lifted.psl \
                /cluster/data/hg17/jkStuff/liftAll.lft warn bacEnds.psl
    pslSort dirs bacEnds.sorted.psl temp lifted
    rmdir temp
    wc -l *.sorted.psl
        # 2497227 bacEnds.sorted.psl

    set ncbiDir = /cluster/data/ncbi/bacends/human/bacends.4
    ~/bin/i386/pslPairs -tInsert=10000 -minId=0.91 -noBin -min=25000 -max=350000 -slopval=10000 -hardMax=500000 -slop -short -long -orphan -mismatch -verbose bacEnds.sorted.psl $ncbiDir/bacEndPairs.txt all_bacends bacEnds

    # create header required by "rdb" tools
    # TODO: replace w/ awk & sort
    echo 'chr\tstart\tend\tclone\tscore\tstrand\tall\tfeatures\tstarts\tsizes' > header
    echo '10\t10N\t10N\t10\t10N\t10\t10\t10N\t10\t10' >> header
    cat header bacEnds.pairs | row score ge 300 | sorttbl chr start | headchg -del > bacEndPairs.bed
    cat header  bacEnds.slop bacEnds.short bacEnds.long bacEnds.mismatch bacEnds.orphan \
        | row score ge 300 | sorttbl chr start | headchg -del > bacEndPairsBad.bed

    extractPslLoad -noBin bacEnds.sorted.psl bacEndPairs.bed \
                bacEndPairsBad.bed | \
                        sorttbl tname tstart | headchg -del > bacEnds.load.psl

    # load into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/bacends
    hgLoadBed hg17 bacEndPairs bacEndPairs.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/bacEndPairs.sql 
        # Loaded 201380  
    # note - this track isn't pushed to RR, just used for assembly QA
    hgLoadBed hg17 bacEndPairsBad bacEndPairsBad.bed \
                 -sqlTable=/cluster/home/kate/kent/src/hg/lib/bacEndPairsBad.sql
        # Loaded 81773
    #hgLoadPsl hg17 -nobin -table=all_bacends bacEnds.load.psl
    # NOTE: truncates file to 0 if -nobin is used
    hgLoadPsl hg17 -table=all_bacends bacEnds.load.psl
        #load of all_bacends did not go as planned: 441072 record(s), 0 row(s) skipped, 30 warning(s) loading psl.tab
    # load BAC end sequences

    mkdir -p /gbdb/hg17/bacends
    ln -s /cluster/data/ncbi/bacends/human/bacends.4/BACends.fa \
                                /gbdb/hg17/bacends/BACends.fa
    hgLoadSeq hg17 /gbdb/hg17/bacends/BACends.fa
        # 158588 sequences

# PLACE ASSEMBLY CLONES - misc instructions, only somewhat relevant
#	See PLACE ASSEMBLY CLONES ON CONTIGS AND SEQUENCE below

######	 A second attempt at clone alignment###
    #	Split the clones into 3K pieces into about 1000 fa files

    #	Example:
zcat Z99916.1.fa.gz Z99774.1.fa.gz Z99756.7.fa.gz | faSplit size stdin 3000 /tmp/name.fa -lift=/tmp/name.lft -oneFile

    #	Trying this idea in unPlacedBatch
    ssh kk0
    mkdir /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    cd /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    ls -1S /scratch/hg/gs.18/build35/bothMaskedNibs > nibList
    ls -1S /cluster/data/hg17/bed/contig_overlaps/blatClones > cloneList
cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -fastMap -ooc=/scratch/hg/h/11.ooc -q=dna -t=dna {check in exists /scratch/hg/gs.18/build35/bothMaskedNibs/$(path1)} {check in exists+ /cluster/data/hg17/bed/contig_overlaps/blatClones/$(path2)} {check out line+ psl/$(root1)/$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    mkdir psl
    cat nibList | sed -e "s/.nib//" | while read D
do
mkdir psl/$D
done

    gensub2 nibList cloneList gsub jobList
    para create jobList

# PLACE ASSEMBLY CLONES ON CONTIGS AND SEQUENCE (DONE - 2004-07-12 - Hiram)
    ssh eieio
    mkdir /cluster/data/hg17/bed/contig_overlaps
    cd /cluster/data/hg17/bed/contig_overlaps
    #	find all the clones that were used in the assembly
    sed -e "/^#.*/d" /cluster/data/hg17/ncbi_build35.agp | \
        awk '{if (!match($5,"N")) {print $6}}' | \
        sort -u > placed_in_assembly.list
    wc -l placed_in_assembly.list
    #	26872 placed_in_assembly.list
    #	These may be available from the phases files at:
    #	ftp://ftp.ncbi.nih.gov/genbank/genomes/H_sapiens
    #	Which are easily fetched with wget.  However I took a look
    #	at those and could not find all the clones in them.  There may
    #	be a versioning problem because these phases files are often
    #	updated.
    #	Fetch them from Genbank with the following three PERL scripts:
    #	[hiram@hgwdev /cluster/data/hg17/bed/contig_overlaps] ls -og *.pl
    #	-rwxrwxr-x    1     3047 May 24 18:43 bioPerlFetch.pl
    #	-rwxrwxr-x    1     2370 Jun  4 15:21 fetchGenbank.pl
    #	-rwxrwxr-x    1      700 May 24 21:47 foldEm.pl

    #	Which takes about 4 days ...
    #	Example, 
    cat << '_EOF_' > terrys.list
AC011841.7
AC018692.9
AC018743.27
AC037482.14
AL163540.11
'_EOF_'
    # << this line makes emacs coloring happy
    #	only works on hgwdev
    ssh hgwdev
    cd /cluster/data/hg17/bed/contig_overlaps
    mkdir fasta
    time ./fetchGenbank.pl terrys.list > fetchResult.out 2>&1

    #	There is a bit of behind the scenes hocus pocus going on here.
    #	This is a tedious task of comparing various lists with each
    #	other and making sure everything matches.  Manual fixups are
    #	done for the newly named 6_hla_hap* items, copies of the PAR
    #	business were duplicated so that X and Y both have the same set
    #	of clones for that.  The end result should be a directory hierarchy
    #	here with a directory for each chrom, each random, the 6_hla_hap?
    #	items and each directory contains the clones that belong to that
    #	chromosome.  The leftovers are the unplaced clones which end up
    #	in the directory called: unPlaced.  The instructions here are
    #	merely a guideline of possibilities.  Care should be taken to
    #	make sure all listings are correct and everything gets in the
    #	right place.
    ssh eieio
    #	And then make a list of all clones considered for assembly:
    sed -e "/^#.*/d" /cluster/store5/gs.18/ncbi/sequence.inf | \
	grep for_assembly | awk '{print $1}' | sort -u > sequence.list
    wc -l sequence.list
    #	46733 sequence.list
    #	Verify overlaps are correct:
    comm -12 placed_in_assembly.list sequence.list > inBoth
    comm -23 placed_in_assembly.list sequence.list > inAssemblyNotSequence
    comm -13 placed_in_assembly.list sequence.list > inSequenceNotAssembly
    wc in*
    #	    1       1      12 inAssemblyNotSequence
    #	26871   26871  301709 inBoth
    #	19862   19862  219050 inSequenceNotAssembly
    #	46734   46734  520771 total
    #	This stray one is from Terry's five additions in the final fixup
    #	phase with Greg:
    cat inAssemblyNotSequence
    #	AC018743.27
    #	Terry added: AC011841.7 AC018692.9 AC018743.27 AC037482.14 AL163540.11
    #
    #	Generate a listing that relates clones to their contigs
    sed -e "/^#.*/d" /cluster/store5/gs.18/build35/ncbi_build35.agp | \
	./contigAcc.pl > disburseEm.list
    #
    #	Using that list, sort the downloaded clones into their
    #	respective chrom directories:
    ./disburse.sh

    #	Check the number of sequences obtained:
    find ./? ./?? ./*_random ./6_hla* -type f | wc -l
    #	26872
    #	So, why is this number one more than the inBoth list ?
    #	Because, the official NCBI sequence.inf file is missing one of
    #	the clones that Terry added: AC018743.27
    #	And it shows up in our check list above as inAssemblyNotSequence
    #	It isn't exactly missing, it just isn't marked "for_assembly"

    #	OK, with everything in place, we are ready to try and find
    #	all these items in the assembly.  To run a Kluster job on one of
    #	the chroms, matching the items that are supposed to be included
    #	in that chrom.  We need to get things set up on the Iservers,
    #	psLayout is heavy into disk I/O and it brings everything down if
    #	allowed to work on any NFS filesystems for input.

    #	It appears that psLayout wants an ooc file of tile size 10
    #	I tried making one for the whole assembly but it seemed to
    #	include too much for some contigs and it caused a lot of
    #	alignments to be missed.  Thus, create an ooc file for each
    #	contig

    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/contigOoc10
    cd /cluster/bluearc/scratch/hg/gs.18/build35/contigOoc10
    ls ../maskedContigs | sed -e "s/.fa//" | while read CONTIG
    do
	blat -repMatch=256 -makeOoc=${CONTIG}.10.ooc -tileSize=10 \
	    ../maskedContigs/${CONTIG}.fa \
	    ../maskedContigs/${CONTIG}.fa /dev/null
	echo "done: ${CONTIG}"
    done

    #	Copy that result to the Iservers:
    ssh kkr1u00
    mkdir /iscratch/i/gs.18/build35/contigOoc10
    cd /iscratch/i/gs.18/build35/contigOoc10
    rsync -arlv /cluster/bluearc/scratch/hg/gs.18/build35/contigOoc10/ .
    #	And, copy the clone sequences:
    mkdir /iscratch/i/gs.18/build35/clones
    cd /cluster/store5/gs.18/build35/bed/contig_overlaps
    for D in ? ?? *_random 6_hla_hap?
    do
	rsync -arlv `pwd`/${D} /iscratch/i/gs.18/build35/clones
    done
    
    /cluster/bin/iSync

    ssh kk
    cd /cluster/data/hg17/bed/contig_overlaps
    mkdir psl
    cat << '_EOF_' > runPsLayout.sh
#!/bin/sh
#       kkiPsLayout.sh <chrom> <clone> <contig>
#       where <chrom> is the chrom this contig is on
#       <clone> is one of the .fa.gz files in
#               /cluster/data/hg17/bed/contig_overlaps/*/<clone>.fa.gz
#               without the .fa.gz extension
#               This stuff has been mirrored to:
#               /iscratch/i/gs.18/clones/*/<clone>.fa.gz
#       <contig> is one of the contigs found in:
#               /cluster/store5/gs.18/build35/<chrom>/<contig>/<contig>.fa
#
CHROM=$1
CLONE=$2
CONTIG=$3
TARGET=/iscratch/i/gs.18/build35/maskedContigs/${CONTIG}.fa
FAZ=/iscratch/i/gs.18/build35/clones/${CHROM}/${CLONE}.fa.gz
OOC=/iscratch/i/gs.18/build35/contigOoc10/${CONTIG}.10.ooc
mkdir -p psl/${CONTIG}
if [ ! -s ${FAZ} ]; then
        echo "Can not find: ${FAZ}"
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}"
        exit 255
fi
if [ ! -s ${OOC} ]; then
        echo "Can not find: ${OOC}"
        exit 255
fi
zcat ${FAZ} > /tmp/${CLONE}.fa
$HOME/bin/i386/psLayout ${TARGET} \
        /tmp/${CLONE}.fa genomic ${OOC} psl/${CONTIG}/${CLONE}.psl
RET=$?
rm -f /tmp/${CLONE}.fa
exit ${RET}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runPsLayout.sh

    #	make up a listing of chrom, clone, contig from:
    grep -v "^#" disburseEm.list | sed -e "s/.fa.gz//" > chr.clone.contig.list
    wc -l chr.clone.contig.list
    #	26872 chr.clone.contig.list
    awk '{
printf "./runPsLayout.sh %s %s %s {check out line+ psl/%s/%s.psl}\n",
        $1, $2, $3, $3, $2
}' chr.clone.contig.list > jobList
    # << this line makes emacs coloring happy
    #	To do a quick test, run just chr22:
    grep -v "^22" chr.clone.contig.list | awk '{
printf "./runPsLayout.sh %s %s %s {check out line+ psl/%s/%s.psl}\n",
        $1, $2, $3, $3, $2
}' > jobList
    para create jobList
    para try ... check ... etc ...
    #	One run on chr22 took:
# Completed: 561 of 561 jobs
# CPU time in finished jobs:     927068s   15451.14m   257.52h   10.73d  0.029 y
# IO & Wait Time:                  6295s     104.91m     1.75h    0.07d  0.000 y
# Average job time:                1664s      27.73m     0.46h    0.02d
# Longest job:                    69745s    1162.42m    19.37h    0.81d
# Submission to last job:         69780s    1163.00m    19.38h    0.81d


    #	put the results together, filter, lift and load:
    cd /cluster/data/hg17/bed/contig_overlaps/psl
    pslSort dirs raw.psl tmp N*
    pslReps -singleHit raw.psl repsSingle.psl /dev/null
    liftUp chr22.psl /cluster/data/hg17/jkStuff/liftAll.lft \
	warn repsSingle.psl
    hgLoadPsl -table=cloneTest hg17 chr22.psl

    #	There are a number of clones listed in the sequence.inf file
    #	as status W with names beginning AACC AADB AADC AADD
    #	These are the Whole shotgun assemblies for the Celera genome.
    #	A few of them were used in the assembly of the NCBI genome, namely:
./11/AADB01066164.1.fa.gz
./11/AADC01095577.1.fa.gz
./11/AADD01116830.1.fa.gz
./11/AADD01118406.1.fa.gz
./11/AADD01116787.1.fa.gz
./11/AADD01112371.1.fa.gz
./11/AADD01116788.1.fa.gz
./11/AADD01115518.1.fa.gz
./11/AADD01118410.1.fa.gz
./11/AADD01117999.1.fa.gz
./21/AADD01172789.1.fa.gz
./21/AADD01172788.1.fa.gz
./21/AADD01209098.1.fa.gz
./21/AADD01172902.1.fa.gz
    #	And these have been distributed properly in their corresponding
    #	chromosome.  The rest of them, 26, all with names starting AACC are in
    #	the directory here: celeraOnly

    #	To run the unPlaced alignments.
    #	Prepare scratch and iscratch
    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/clones/unPlaced
    rsync -arlv /cluster/data/hg17/bed/contig_overlaps/unPlaced/ \
	/cluster/bluearc/scratch/hg/gs.18/build35/clones/unPlaced
    #	request scratch sync to cluster admins

    ssh kkr1u00
    mkdir /iscratch/i/gs.18/build35/clones/unPlaced
    rsync -arlv /cluster/data/hg17/bed/contig_overlaps/unPlaced/ \
	/iscratch/i/gs.18/build35/clones/unPlaced
    /cluster/bin/iSync

    ssh hgwdev
    cd /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    #	There are too many to try them all, obtain guildelines from hg16
    #	of clone to contig mapping:
    hgsql -N -e "select name,chrom from clonePos;" hg16 > hg16.clone.chrom
    hgsql -N -e "select contig,chrom from ctgPos;" hg16 > hg16.contig.chrom

    ssh kk
    mkdir /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    cd /cluster/data/hg17/bed/contig_overlaps/unPlacedBatch
    ls ../unPlaced | sed -e "s/.fa.gz//" > unPlaced.clone.list
    wc -l unPlaced.clone.list
    #	19836 unPlaced.clone.list
    ls -1S /scratch/hg/gs.18/build35/maskedContigs > contig.list
    wc -l contig.list
    #	380 contig.list

    cat << '_EOF_' > runPsLayout.sh
#!/bin/sh
#       kkiPsLayout.sh <clone> <contig>
#       <clone> is one of the .fa.gz files in
#               /scratch/hg/gs.18/build35/clones/unPlaced
#               without the .fa.gz extension
#       <contig> is one of the contigs found in:
#               /iscratch/i/gs.18/build35/maskedContigs
#
CLONE=$1
CONTIG=$2
TARGET=/iscratch/i/gs.18/build35/maskedContigs/${CONTIG}.fa
FAZ=/scratch/hg/gs.18/build35/clones/unPlaced/${CLONE}.fa.gz
OOC=/iscratch/i/gs.18/build35/contigOoc10/${CONTIG}.10.ooc
mkdir -p psl/${CONTIG}
if [ ! -s ${FAZ} ]; then
        echo "Can not find: ${FAZ}"
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}"
        exit 255
fi
if [ ! -s ${OOC} ]; then
        echo "Can not find: ${OOC}"
        exit 255
fi
zcat ${FAZ} > /tmp/${CLONE}.fa
$HOME/bin/i386/psLayout ${TARGET} \
        /tmp/${CLONE}.fa genomic ${OOC} psl/${CONTIG}/${CLONE}.psl
RET=$?
rm -f /tmp/${CLONE}.fa
exit ${RET}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runPsLayout.sh

    cat << '_EOF_' > gsub
#LOOP
./runPsLayout.sh $(path1) $(path2) {check out line+ psl/$(path2)/$(path1).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 unPlaced.clone.list contig.list gsub jobList

   # XXXX - some time later ... 2004-07-12
    # Bringing this sequence to a close.  Difficulties encountered:
    #	Placed clones that did not survive the psLayout filter:
    #	AC006040.3 AC006328.5 AC007039.6 AC007241.3 AC007965.3
    #	AC009947.2 AC010682.2 AC012005.4 AC016707.2 AC016728.4
    #	AC016752.2 AC017005.7 AC025226.4 AC025246.6 AC055713.29
    #	AC068541.7 AC068601.8 AC068704.4 AC073649.3 AC073962.5
    #	AC091175.11 AC095381.1 AC104597.3 AC130223.2 AC130814.3
    #	AC133883.6 AC139103.3 AF003627.3 AF135405.3 AL021878.2
    #	AL137064.6 AL356803.2 AL390801.4 AL591480.8 AL901608.1
    #	AP005814.2 BX322790.2 Z84489.1 Z84814.1
    #	And placed clones that broken into two pieces during their
    #	psLayout alignment:
    #	AC006982.3 AC007742.4 AC023342.3 AC024183.4 AC025735.4
    #	AC095380.1 AL646104.4 BX293536.4
    #	For the above clones, their assignments in ref_placed.agp were
    #	used instead of trying to adjust the psLayout process.

    #	The PAR clones are a problem.  They were placed properly, but
    #	during their load with hgClonePos there was a warning issued
    #	about their dual existance.  hgClonePos said they were only
    #	going to be placed on chrX and not on chrY.  However in the
    #	browser when chrY is viewed it issues errors about these not
    #	having proper coordinates in the clonePos table.  These were
    #	removed from the coverage track to eliminate that error.
    #	AL954722.18 BX537334.4 BX000483.7 BX908402.3 BX649635.3 BX119919.5
    #	AC079176.15 AC097314.27 AC006209.25 AJ271735.1 AJ271736.1
    #
    #	And finally, after many different types of alignment attempts,
    #	there remain 1489 un-placed clones that could not be located.

    #	While trying to figure out which contigs many clones belonged
    #	to, the following cluster run script was used to take a survey
    #	using blat:
#!/bin/sh
#       runBlat.sh <clone> <contig>
#       <clone> is one of the .fa.gz files in
#               /scratch/hg/gs.18/build35/clones/
#               without the .fa.gz extension
#       <contig> is one of the contigs found in:
#               /iscratch/i/gs.18/build35/maskedContigs
#   
# ./runBlat.sh unPlaced/AB000876.1.fa.gz NT_005612.fa {check out line+
# psl/NT_005612.fa/unPlaced/AB000876.1.fa.gz.psl}
#
HERE=`pwd`
CLONE=$1 
CLONEDIR=`dirname ${CLONE}`
CLONENAME=`basename ${CLONE}`
CLONESRC=/iscratch/i/gs.18/build35/clones/${CLONE}.fa.gz
CONTIG=$2
CONTIGBASE=${CONTIG/.fa/}
TARGET=/iscratch/i/gs.18/build35/maskedContigs/${CONTIG}
if [ ! -s ${CLONESRC} ]; then
        echo "Can not find: ${CLONESRC}" 1>/dev/stderr
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}" 1>/dev/stderr
        exit 255
fi
mkdir -p /tmp/${CLONEDIR}/${CLONENAME}
zcat ${CLONESRC} > /tmp/${CLONEDIR}/${CLONENAME}/${CLONENAME}.fa
cd /tmp/${CLONEDIR}
/cluster/data/hg17/bed/contig_overlaps/FfaSplit/faToFfa ${CLONENAME}
ECOUNT=`cat error.convert | wc -l`
if [ "${ECOUNT}" -ne 0 ]; then
        echo "Error during faToFfa, error.convert not empty" 1>/dev/stderr
        exit 255
fi
rm -f error.convert
B=${CLONENAME/\.*/}
cd /tmp/${CLONEDIR}/${CLONENAME}
faSplit byname ${CLONENAME}.fa .
RET=0
export RET
for F in ${CLONENAME}_*.fa
do
    FA=${F/_*.fa/}
    A=${FA/.[0-9]*/}
    P=${F/.fa/}
    N=${P##*_}
    rm -f t.fa
    mv ${F} t.fa
    cat t.fa | faSplit -oneFile size stdin 3000 ${A}_${N}
    rm -f t.fa
    blat ${TARGET} ${A}_${N}.fa -ooc=/scratch/hg/h/11.ooc ${A}_${N}.psl \
        -t=dna -q=dna -fastMap -noHead
    RET=$?
    if [ "$RET" -ne 0 ]; then
        echo "Error during blat ${TARGET} ${A}_${N}.fa" 1>/dev/stderr
        break
    fi
done
rm -f ${CLONENAME}.fa
rm -f ${B}_*.fa
cd ${HERE}
mkdir -p psl/${CONTIGBASE}
sed -e "s/${A}/${CLONENAME}/" /tmp/${CLONEDIR}/${CLONENAME}/*.psl > \
        psl/${CONTIGBASE}/${CLONENAME}.psl
rm -f /tmp/${CLONEDIR}/${CLONENAME}/*.psl
rmdir --ignore-fail-on-non-empty /tmp/${CLONEDIR}/${CLONENAME}
rmdir --ignore-fail-on-non-empty /tmp/${CLONEDIR}
exit ${RET}

    #	The alignment with psLayout were done with the following cluster
    #	run script:

#!/bin/sh
#       kkiPsLayout.sh <clone> <contig>
#       <clone> is one of the .fa.gz files in
#               /scratch/hg/gs.18/build35/clones/unPlaced
#               without the .fa.gz extension
#       <contig> is one of the contigs found in:
#               /iscratch/i/gs.18/build35/maskedContigs
#
# ./runPsLayout.sh unPlaced/AP001966.2 NT_016354 {check out exists
# psl/NT_016354/AP001966.2.psl}
#
HERE=`pwd`
CLONE=$1
CONTIG=$2
CLONEDIR=`dirname ${CLONE}`
CLONENAME=`basename ${CLONE}`
RESULT=psl/${CONTIG}/${CLONENAME}.psl
CLONESRC=/iscratch/i/gs.18/build35/clones/${CLONE}.fa.gz
TARGET=/iscratch/i/gs.18/build35/maskedContigs/${CONTIG}.fa
OOC=/iscratch/i/gs.18/build35/contigOoc10/${CONTIG}.10.ooc
if [ ! -s ${CLONESRC} ]; then
        echo "Can not find: ${CLONESRC}" 1>/dev/stderr
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}" 1>/dev/stderr
        exit 255
fi
if [ ! -s ${OOC} ]; then
        echo "Can not find: ${OOC}" 1>/dev/stderr
        exit 255
fi
mkdir -p /tmp/${CONTIG}/${CLONEDIR}/${CLONENAME}
zcat ${CLONESRC} > /tmp/${CONTIG}/${CLONEDIR}/${CLONENAME}.fa
cd /tmp/${CONTIG}
/cluster/data/hg17/bed/contig_overlaps/FfaSplit/faToFfa ${CLONEDIR}
cd ${HERE}
mkdir -p psl/${CONTIG}
$HOME/bin/i386/psLayout ${TARGET} /tmp/${CONTIG}/${CLONEDIR}/${CLONENAME}.fa genomic ${OOC} ${RESULT}
RET=$?
rm -f /tmp/${CONTIG}/${CLONEDIR}/${CLONENAME}.fa /tmp/${CONTIG}/error.convert
rmdir --ignore-fail-on-non-empty /tmp/${CONTIG}/${CLONEDIR}/${CLONENAME}
rmdir --ignore-fail-on-non-empty /tmp/${CONTIG}/${CLONEDIR}/
rmdir --ignore-fail-on-non-empty /tmp/${CONTIG}
exit ${RET}

# BUILD KNOWN GENES TABLES (DONE 6/8/04 Fan)

  Build sp040515 and proteins040515 DBs first.
  
  hgsql hg17 -e "create database kgHg17"
  
  cd /cluster/store6/kgDB/bed
  mkdir kgHg17
  cd /cluster/store6/kgDB/bed/kgHg17

  ~/src/hg/protein/KGprocess.sh kgHg17 hg17 040515
  
  The script was run successfully with the last message:

  	Tue Jun  8 15:36:52 PDT 2004 DONE 

  After initial inspection of tables in kgHg17, do the following
  from mySql prompt:

  alter table kgHg17.cgapAlias rename as hg17.cgapAlias;
  alter table kgHg17.cgapBiocDesc rename as hg17.cgapBiocDesc;
  alter table kgHg17.cgapBiocPathway rename as hg17.cgapBiocPathway;
  alter table kgHg17.dupSpMrna rename as hg17.dupSpMrna;
  alter table kgHg17.keggMapDesc rename as hg17.keggMapDesc;
  alter table kgHg17.keggPathway rename as hg17.keggPathway;
  alter table kgHg17.kgAlias rename as hg17.kgAlias;
  alter table kgHg17.kgProtAlias rename as hg17.kgProtAlias;
  alter table kgHg17.kgXref rename as hg17.kgXref;
  alter table kgHg17.knownGene rename as hg17.knownGene;
  alter table kgHg17.knownGeneLink rename as hg17.knownGeneLink;
  alter table kgHg17.knownGeneMrna rename as hg17.knownGeneMrna;
  alter table kgHg17.knownGenePep rename as hg17.knownGenePep;
  alter table kgHg17.mrnaRefseq rename as hg17.mrnaRefseq;
  alter table kgHg17.spMrna rename as hg17.spMrna;

  hg17.knownGene has 43,401 entries and hg16.knownGene has 43,232 entries.
  and running featireBits shows:
  
   	featureBits hg17 knownGene
   	63983072 bases of 2866216770 (2.232%) in intersection
   
   	featureBits hg16 knownGene
   	63781799 bases of 2865248791 (2.226%) in intersection
  
  Connect to genome-testdb and use hgcentraltest DB.
  Add a new entry in gdbPdb table:
 
        insert into gdbPdb values('hg17', 'proteins040515');


# CREATE LINEAGE-SPECIFIC REPEATS FOR BLASTZ WITH ZEBRAFISH
# (DONE, 2004-06-08, hartera)
    # Treat all repeats as lineage-specific
    mkdir /iscratch/i/gs.18/build35/linSpecRep.notInZebrafish
    foreach f (/iscratch/i/gs.18/build35/rmsk/chr*.fa.out)
 cp -p $f /iscratch/i/gs.18/build35/linSpecRep.notInZebrafish/$f:t:r:r.out.spec
    end
    iSync
  

# PREP FOR LIFTOVER CHAINS TO hg17 (2004-06-10 kate)

    # split into 3K chunks
    ssh eieio
    set liftDir = /cluster/data/hg17/bed/liftOver/liftSplit
    mkdir -p $liftDir
    cd $liftDir
cat > split.csh << 'EOF'
    set splitDir = /iscratch/i/hg17/liftOver/split
    mkdir -p $splitDir
    set liftDir = /cluster/data/hg17/bed/liftOver/liftSplit
    foreach n (`ls /cluster/data/hg17/nib`)
        set c = $n:r
        echo $c
        faSplit -lift=$liftDir/$c.lft size \
            /cluster/data/hg17/$d/$c.fa -oneFile 3000 $splitDir/$c
    end
'EOF'
# << for emacs
    csh split.csh >&! split.log &
    tail -100f split.log

    ssh kkr1u00
    iSync


# STS MARKERS (WORKING 2004-07-13 kate)
    # Terry's sts.9 dir is in /cluster/store5/sts.2004-07.old
    # remove this after verifying the newer version

   # update from NCBI (booch)
    ssh eieio
    # use store5 for space
    mkdir -p /cluster/store5/sts.2004-07
    ln -s /cluster/store5/sts.2004-07 /cluster/data/ncbi
    ln -s /cluster/data/ncbi/sts.2004-07 sts.9
    cd /cluster/data/ncbi/sts.2004-07
    wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.sts
    wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.aliases
    wget ftp://ftp.ncbi.nih.gov/blast/db/FASTA/sts.gz
    gunzip sts.gz
    mv sts dbSTS.fa

    # incremental update from previous build
    # NOTE: could mysql dump this, unless hand-updated (like hg16)
    # First - copy from Terry's dir
    ssh eieio
    ln -s /cluster/store1/sts.8 /cluster/data/ncbi
    cd /cluster/data/ncbi/sts.9

    # this time, snag from Terry's dir
    cd /cluster/data/ncbi/sts.9
    cp -p ~booch/tracks/update/all.STS.fa.prev .
    cp -p ~booch/tracks/update/stsInfo2.bed stsInfo2.bed.prev

    # Convert dbSTS.fa file to easier reading format, and get accessions
    /cluster/bin/scripts/convertGbFaFile dbSTS.fa > dbSTS.convert.fa
    grep ">" dbSTS.convert.fa | cut -f 2 -d ">" > dbSTS.acc

    # NOTE: updateStsInfo creates new stsInfo2.bed, all.primers, 
    #   all.STS.fa, stsAlias.bed files 
    updateStsInfo -verbose=1 -gb=dbSTS.acc stsInfo2.bed.prev all.STS.fa.prev \
                    dbSTS.sts dbSTS.aliases dbSTS.convert.fa new
    # 129991  SWXD2599        99622   (0) not in dbSTS anymore
    # 166473  D3S3812 154523  (0) not in dbSTS anymore
    # 185776  RH83562 209614  (0) not in dbSTS anymore

    mv new.info stsInfo2.bed
    mv new.primers all.primers
    mv new.alias stsAlias.bed
    mv new.fa all.STS.fa

    # get list of all STS id's in the fasta file
    sed -n 's/^>\([0-9][0-9]*\) .*/\1/p' all.STS.fa | sort -n >  all.STS.id
    wc -l all.STS.id
        # 92674 total sequences
    /cluster/bin/scripts/convertPrimerToFA all.primers > all.primers.fa

    # Copy stsInfo2.bed and stsAlias.bed to data directory becuase
    # these will be loaded into the database later
    mkdir -p /cluster/data/hg17/bed/sts
    cp stsInfo2.bed /cluster/data/hg17/bed/sts/
    cp stsAlias.bed /cluster/data/hg17/bed/sts/

    # Create sts sequence alignments
    mkdir -p /cluster/bluearc/sts.9/sts.split
    faSplit sequence all.STS.fa 50 /cluster/bluearc/sts.9/sts.split/sts
    cp /cluster/data/ncbi/sts.9/all.STS.fa /cluster/bluearc/sts.9

    # create small ooc file to use with alignments (if not existing)
    # NOTE: these were just used for experimenting; weren't used in
    # final runs
    ssh kolossus
    cd /cluster/data/hg17/bed/sts
    ls /cluster/bluearc/hg17/bothMaskedNibs/chr*.nib > nib.lst
    blat nib.lst /dev/null /dev/null \
        -tileSize=11 -makeOoc=/cluster/bluearc/hg/h/11.4096.ooc -repMatch=4096
    blat nib.lst /dev/null /dev/null \
        -tileSize=11 -makeOoc=/cluster/bluearc/hg/h/11.16384.ooc -repMatch=16384

    ssh kk
    cd /cluster/data/hg17/bed/sts
    mkdir run
    cd run
    ls -1S /scratch/hg/hg17/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/sts.9/sts.split/sts*.fa > sts.lst
    mkdir -p /cluster/bluearc/hg17/sts/sts/out
    foreach f (`cat sts.lst`)
        set d = $f:t:r
        mkdir /cluster/bluearc/hg17/sts/sts/out/$d
    end

    # create alignments
cat > template << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -ooc=/cluster/bluearc/hg/h/11.ooc -stepSize=5 {check out line+ /cluster/bluearc/hg17/sts/sts/out/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
# << for emacs

    gensub2 contigs.lst sts.lst template jobList
    para create jobList
        # 17860 jobs
    para try
    para check
    para push
# CPU time in finished jobs:     216985s    3616.41m    60.27h    2.51d  0.007 y
# IO & Wait Time:                 48790s     813.17m    13.55h    0.56d  0.002 y
# Average job time:                  15s       0.25m     0.00h    0.00d
# Longest job:                      267s       4.45m     0.07h    0.00d
# Submission to last job:          2228s      37.13m     0.62h    0.03d

    # Compile sts sequence results
    ssh kolossus
    cd /cluster/bluearc/hg17/sts/sts
    pslSort dirs raw.psl temp out/*
    rm -rf temp
    pslReps -nearTop=0.0001 -minCover=0.6 -minAli=0.8 -noIntrons raw.psl \
	stsMarkers.psl /dev/null
            # Processed 7121016 alignments
    #cp stsMarkers.psl /cluster/data/hg17/bed/sts/run

    # Lift them and get them ready to combine with primer alignments
    #cd  /cluster/data/hg17/bed/sts/run
    #liftUp -nohead /cluster/data/hg17/bed/sts/run/stsMarkers.lifted.psl \
    liftUp -nohead stsMarkers.lifted.psl \
        /cluster/data/hg17/jkStuff/liftAll.lft warn stsMarkers.psl

    # missing some utilities for kolossus, so switch to fileserver
    # NOTE: probably no longer true -- try on kolossus next time
    ssh kksilo
    cd /cluster/bluearc/hg17/sts/sts
    /cluster/bin/scripts/extractPslInfo stsMarkers.lifted.psl
        # creates <file>.initial
    /cluster/bin/scripts/findAccession -agp stsMarkers.lifted.psl.initial \
	/cluster/data/hg17
            # "Could not open /cluster/data/hg17/Y/chrY_random.agp" etc.
            # Looks like it trys all _randoms (even one's that don't
            # exist/aren't needed
            # creates <file>.acc
    #rm stsMarkers.lifted.psl.initial
    sort -k 4n stsMarkers.lifted.psl.initial.acc > stsMarkers.final
    #rm stsMarkers.lifted.psl.initial.acc
    #cp stsMarkers.final stsMarkers.lifted.psl.initial /cluster/data/hg17/bed/sts
    # determine found markers (4th field in file)
    cut -f 4 stsMarkers.final | sort -n -u > stsMarkers.found
    wc -l stsMarkers.found
        #   89532 stsMarkers.found
        # out of 92674 total sequences

    # extract sequences for markers not yet found, and
    # blat w/o ooc to try to place more
    comm -1 -3  stsMarkers.found /cluster/data/ncbi/sts.9/all.STS.id \
                > stsMarkers.notFound
    wc -l stsMarkers.notFound
        # 3142 stsMarkers.notFound
    faSomeRecords /cluster/data/ncbi/sts.9/all.STS.fa stsMarkers.notFound \
                notFound.STS.fa
    mkdir /cluster/bluearc/sts.9/sts.splitNotFound
    faSplit sequence notFound.STS.fa 20 \
                /cluster/bluearc/sts.9/sts.splitNotFound/sts

    # blat with 11.ooc misses alignments, so reblat w/o the
    # sequences that aren't found
    # NOTE: filtering produces yield of only 149 markers placed (out of 3142).
    # not enough to justify this step next time
    ssh kk
    cd /cluster/data/hg17/bed/sts
    mkdir run.noOoc
    cd run.noOoc
    ls -1S /scratch/hg/hg17/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/sts.9/sts.splitNotFound/sts*.fa > sts.lst
    mkdir -p /cluster/bluearc/hg17/sts/sts/out.noOoc

    foreach f (`cat sts.lst`)
        set d = $f:t:r
        mkdir /cluster/bluearc/hg17/sts/sts/out.noOoc/$d
    end

cat > template << 'EOF'
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -stepSize=5 {check out line+ /cluster/bluearc/hg17/sts/sts/out.noOoc/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'EOF'
# << for emacs

    gensub2 contigs.lst sts.lst template jobList
    para create jobList
        # 7220 jobs written to batch
    para try
    para check

    # process this set of alignments
    ssh kolossus
    cd /cluster/bluearc/hg17/sts/sts
    pslSort dirs raw.noOoc.psl temp out.noOoc/*

    rm -rf temp
    pslReps -nearTop=0.0001 -minCover=0.6 -minAli=0.8 -noIntrons \
        raw.noOoc.psl stsMarkers.noOoc.psl /dev/null
            # Processed 4254094 alignments
    #cp stsMarkers.psl /cluster/data/hg17/bed/sts/run

    # Lift them and get them ready to combine with primer alignments
    liftUp -nohead stsMarkers.noOoc.lifted.psl \
        /cluster/data/hg17/jkStuff/liftAll.lft warn stsMarkers.noOoc.psl

    /cluster/bin/scripts/extractPslInfo stsMarkers.noOoc.lifted.psl
        # creates <file>.initial
    /cluster/bin/scripts/findAccession -agp \
        stsMarkers.noOoc.lifted.psl.initial /cluster/data/hg17
            # "Could not open /cluster/data/hg17/Y/chrY_random.agp" etc.
            # Looks like it trys all _randoms (even one's that don't
            # exist/aren't needed
            # creates <file>.acc
    #rm stsMarkers.lifted.psl.initial
    mv stsMarkers.final stsMarkers.ooc.final
    sort -k 4n stsMarkers.noOoc.lifted.psl.initial.acc > stsMarkers.extra
    sort -k 4n stsMarkers.lifted.psl.initial.acc \
                stsMarkers.noOoc.lifted.psl.initial.acc > stsMarkers.final

    # determine found markers (4th field in file)
    cut -f 4 stsMarkers.final | sort -n -u > stsMarkers.found
    wc -l stsMarkers.found
        #  89681 stsMarkers.found
    cut -f 4 stsMarkers.extra | sort -n -u > stsMarkers.extra.found
    wc -l stsMarkers.extra.found
        #   149 out of 3142 attempted
        # out of 92674 total sequences
    cp stsMarkers.final stsMarkers.*lifted.psl.initial* stsMarkers.found \
                /cluster/data/hg17/bed/sts

    # primers
    ssh eieio
    cd /cluster/data/ncbi/sts.9
    # strip out N's and wobbles (KS) from primers, as isPcr
    # can't currently handle them
    # strip out primers < 10 as isPcr can't handle them
    #awk '$0 !~ /[^ACGT0-9\t]/ && (length($2) > 10) && (length($3) > 10) {printf "dbSTS_%s\t%s\t%s\n", $1,$2,$3}' \
    awk '$0 !~ /[^ACGT0-9\-\t]/ && (length($2) > 10) && (length($3) > 10) {printf "dbSTS_%s\t%s\t%s\n", $1,$2,$3}' \
                all.primers > all.primers.ispcr
    mkdir -p /cluster/bluearc/sts.9/primers
    cd /cluster/bluearc/sts.9/primers
    split -l 2000 /cluster/data/ncbi/sts.9/all.primers.ispcr primers_

    ssh kk
    cd /cluster/data/hg17/bed/sts
    mkdir primers
    cd primers
    mkdir run
    cd run
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > contigs.lst
    ls -1S /cluster/bluearc/sts.9/primers/primers_* > primers.lst
    mkdir -p /cluster/bluearc/hg17/sts/primers/out

cat > template << 'EOF'
#LOOP
/cluster/home/kate/bin/i386/isPcr -out=psl -minPerfect=2 -maxSize=5000 -tileSize=10 -ooc=/scratch/hg/h/10.ooc  -stepSize=5 $(path1) $(path2) {check out line /cluster/bluearc/hg17/sts/primers/out/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'
    gensub2 contigs.lst primers.lst template jobList
    para create jobList
	# 26980 jobs
    para try
    para check
    para push

    #Completed: 26953 of 26980 jobs
    #Crashed: 27 jobs
    #CPU time in finished jobs:    1130353s   18839.22m   313.99h   13.08d  0.036 y
    #IO & Wait Time:                 86067s    1434.44m    23.91h    1.00d  0.003 y
    #Average job time:                  45s       0.75m     0.01h    0.00d
    #Longest job:                     1255s      20.92m     0.35h    0.01d
    #Submission to last job:          2762s      46.03m     0.77h    0.03d

    # 27 jobs seg faulted due to -minPerfect=2.
    # Looks like a bug in isPcr -- till it's fixed,
    # we'll rerun with -minPerfect=5 (Terry determined they
    # all complete with this (he used 3, 4, or 5, tuned individually
    # for each job, but just using 5 should be adequate and 
    # less labor-intensive).
    # NOTE: isPcr bug is fixed -- this shouldn't be necessary for
    # next run

    para crashed | grep isPcr | sed 's/minPerfect=2/minPerfect=5/' \
        > jobList.minPerfect5
    para create jobList.minPerfect5
        # 28 jobs
    # repeat with increasing minPerfect, till all complete succesfully

    # Filter output file quickly based on simple parameters
    ssh kolossus
    cd /cluster/bluearc/hg17/sts/primers/
    mkdir -p filter
    pslQuickFilter -minMatch=26 -maxMismatch=5 -maxTinsert=5000 -verbose out/ filter/
	# Note: there will be many messages saying files are empty - this is OK
    pslSort dirs primers.psl.unlifted temp filter

    # filter primer alignments and create not found primer file for ePCR run (booch)
    pslFilterPrimers /cluster/bluearc/hg17/sts/primers/primers.psl.unlifted  \
	/cluster/data/ncbi/sts.9/all.primers primers.filter.unlifted.psl
        # creates $3.notfound.primers
    wc -l primers.filter.unlifted.psl.notfound.primers                   
    # 21919  primers.filter.unlifted.psl.notfound.primers

    # use Greg Schuler's ePCR to attempt alignment of primers missed
    # by isPcr
    mkdir -p /cluster/data/hg17/bed/sts/primers/run.epcr
    mkdir -p /cluster/bluearc/hg17/sts/primers/epcr
    cd /cluster/bluearc/hg17/sts/primers/epcr
    split -l 2500 /cluster/data/hg17/bed/sts/primers/primers.filter.unlifted.psl.notfound.primers  primers_
    cd /cluster/data/hg17/bed/sts/primers/run.epcr
    ls -1S /cluster/bluearc/hg17/sts/primers/epcr/primers_* > primers.lst
    # create contig.lst based on split in build dir
    # NOTE: should probably replace this with something more standard
    # and faster.  Also, this appears to cause load spikes on fileservers.
    # Should get contigs from bluearc, iservers, or cluster local disk
    # At least it's over pretty quick!
    ssh eieio
    cd /cluster/data/hg17/bed/sts/primers/run.epcr
    /cluster/bin/scripts/splitContigList -ncbi /cluster/data/hg17 1
    # next time... ls -1S /cluster/bluearc/hg17/contigs/* > contig.lst (?)
    mkdir -p /cluster/bluearc/hg17/sts/primers/epcr/out

    ssh kk
    cd /cluster/data/hg17/bed/sts/primers/run.epcr

cat > template << 'EOF'
#LOOP
/cluster/bin/scripts/runEpcr $(path1) $(path2) {check out line /cluster/bluearc/hg17/sts/primers/epcr/out/$(root1).$(root2).epcr}
#ENDLOOP
'EOF'
# << for emacs
    gensub2 primers.lst contig.lst template jobList
    para create jobList
	# 3420 jobs
    para try
    para check
    para push

# CPU time in finished jobs:      78897s    1314.95m    21.92h    0.91d  0.003 y
# IO & Wait Time:                254582s    4243.03m    70.72h    2.95d  0.008 y
# Average job time:                  98s       1.63m     0.03h    0.00d
# Longest job:                      647s      10.78m     0.18h    0.01d
# Submission to last job:          1112s      18.53m     0.31h    0.01d

    # merge output
    ssh eieio
    cd /cluster/bluearc/hg17/sts/primers/epcr
    cat out/*.epcr > all.epcr
    wc -l all.epcr
    # 3573 

    # use all.epcr file to re-filter alignemnts and determine which
    # ePCR records to keep
    cp all.epcr /cluster/data/hg17/bed/sts/primers
    cd /cluster/data/hg17/bed/sts/primers
    pslFilterPrimers -epcr=all.epcr -verbose=1 \
        /cluster/bluearc/hg17/sts/primers/primers.psl.unlifted \
	/cluster/data/ncbi/sts.9/all.primers primers.unlifted.epcr.psl

    # convert to PSL and combine with other psl file (this takes a couple hours)
    /cluster/bin/scripts/epcrToHgPsl epcr.not.found \
        /cluster/data/ncbi/sts.9/all.primers /cluster/data/hg17
    cat primers.unlifted.epcr.psl epcr.not.found.psl \
                | sort -k 10n > primers.final.unlifted.psl

    # Fix the query gap lengths so that they match the all.primers.fa 
    #   file lengths
    /cluster/bin/scripts/fixPrimersQueryGaps \
        /cluster/data/ncbi/sts.9/all.primers primers.final.unlifted.psl \
                > primers.final.unlifted.fix.psl

    # lift results from contigs to chrom coordinates, and create final file
    liftUp -nohead /cluster/data/hg17/bed/sts/primers/primers.psl \
            /cluster/data/hg17/jkStuff/liftAll.lft warn \
            primers.final.unlifted.fix.psl
    # Extract relevant info, make alignments unique, and create final file to be merged
    # with full sequence alignments
    /cluster/bin/scripts/extractPslInfo primers.psl
    /cluster/bin/scripts/findAccession -agp primers.psl.initial \
                /cluster/data/hg17
    #rm primers.psl.initial

    /cluster/bin/scripts/getStsId /cluster/data/ncbi/sts.9/stsInfo2.bed \
	primers.psl.initial.acc \
        | sort -k 4n > primers.final
    #rm primers.psl.initial.acc
    wc -l primers.final
    # 314713 primers.final


    # Merge primer and sequence files to create final bed file
    # Merge (combineSeqPrimerPos) takes about an hour to run
    ssh kolossus
    cd /cluster/data/hg17/bed/sts
    /cluster/bin/scripts/combineSeqPrimerPos stsMarkers.final primers/primers.final
        # creates *_pos.rdb
    /cluster/bin/scripts/createSTSbed /cluster/data/ncbi/sts.9/stsInfo2.bed \
                stsMarkers_pos.rdb > stsMap.bed

# GOT HERE

    # Set up sequence files
    ssh hgwdev
    mkdir -p /gbdb/hg17/sts.9/
    ln -s /cluster/data/ncbi/sts.9/all.STS.fa /gbdb/hg17/sts.9/all.STS.fa
    # TODO: relink this (it's currently linked to sts.terry
    ln -s /cluster/data/ncbi/sts.9/all.primers.fa /gbdb/hg17/sts.9/all.primers.fa

    # Load all files
    cd /cluster/data/hg17/bed/sts
    hgLoadSeq hg17 /gbdb/hg17/sts.9/all.STS.fa /gbdb/hg17/sts.9/all.primers.fa
    hgsql hg17 < ~kent/src/hg/lib/stsInfo2.sql
    hgsql hg17 < ~kent/src/hg/lib/stsAlias.sql
    hgsql hg17
    mysql> load data local infile 'stsInfo2.bed' into table stsInfo2;
    mysql> load data local infile 'stsAlias.bed' into table stsAlias;
    hgLoadBed -noBin -tab -sqlTable=/cluster/home/kent/src/hg/lib/stsMap.sql \
	hg17 stsMap stsMap.bed
    hgLoadPsl -nobin -table=all_sts_primer hg17 primers/primers.psl
    hgLoadPsl -nobin -table=all_sts_seq hg17 run/stsMarkers.lifted.psl

    
# RECOMBINATION RATES (2004-07-13 Terry)
#                       (2004-07-21 kate)

# The STS MArkers track must be completed prior to creating this track

    ssh eieio
    cd /cluster/data/hg17/bed
    mv recombRate recombRate.terry
    mkdir -p recombRate
	cd recombRate

# Copy other necessary files here (in future, can take from previous version)
    cp /projects/hg2/booch/psl/info/decode_all .
    cp /projects/hg2/booch/psl/info/marshfield_all .
    cp /projects/hg2/booch/psl/info/genethon_all .
	
# Determine maximum concordant set of markers for each of the maps
    /cluster/bin/scripts/assignGPsts -full -maxcon \
        /cluster/data/ncbi/sts.9/stsAlias.bed \
        /cluster/data/hg17/bed/sts/stsMarkers_pos.rdb \
        decode_all > decode.marker.rdb
    /cluster/bin/scripts/assignGPsts -full -maxcon \
        /cluster/data/ncbi/sts.9/stsAlias.bed \
        /cluster/data/hg17/bed/sts/stsMarkers_pos.rdb \
        marshfield_all > marshfield.marker.rdb
    /cluster/bin/scripts/assignGPsts -full -maxcon \
        /cluster/data/ncbi/sts.9/stsAlias.bed \
        /cluster/data/hg17/bed/sts/stsMarkers_pos.rdb \
        genethon_all > genethon.marker.rdb

# Determine the rates for each of the maps
    /cluster/bin/scripts/markers_to_recomb_rate.terry.pl decode.marker.rdb \
            /cluster/data/hg17/chrom.sizes 1000000 1000000 \
                > decode_1mb_slide_1mb
    /cluster/bin/scripts/markers_to_recomb_rate.terry.pl genethon.marker.rdb \
            /cluster/data/hg17/chrom.sizes 1000000 1000000 \
                > genethon_1mb_slide_1mb
        # Marker number 2 at position 120005974 on chr9 is out of genetic distance order. DISCARDING
    /cluster/bin/scripts/markers_to_recomb_rate.terry.pl marshfield.marker.rdb \
            /cluster/data/hg17/chrom.sizes 1000000 1000000 \
                > marshfield_1mb_slide_1mb
        # Marker number 1 at position 124276104 on chr9 is out of genetic distance order. DISCARDING

# Convert files to proper format
    /cluster/bin/scripts/convertRecombRate decode_1mb_slide_1mb \
        /cluster/data/hg17/inserts \
        /cluster/data/hg17 1000 > decode_1mb_slide_1mb_conv
    /cluster/bin/scripts/convertRecombRate marshfield_1mb_slide_1mb \
        /cluster/data/hg17/inserts \
         /cluster/data/hg17 1000 > marshfield_1mb_slide_1mb_conv
    /cluster/bin/scripts/convertRecombRate genethon_1mb_slide_1mb \
        /cluster/data/hg17/inserts \
	    /cluster/data/hg17 1000 > genethon_1mb_slide_1mb_conv

# Create bed file and load
    /cluster/bin/scripts/createRRbed decode_1mb_slide_1mb_conv \
        marshfield_1mb_slide_1mb_conv genethon_1mb_slide_1mb_conv \
                > recombRate.bed

        # GOT HERE
    hgLoadBed -noBin -tab \
        -sqlTable=/cluster/home/kent/src/hg/lib/recombRate.sql \
	    hg17 recombRate recombRate.bed
	   

# FISH CLONES (2004-07-13 Terry)

# The STS Marker, Coverage, and BAC End Pairs tracks must be completed prior to 
# creating this track

    ssh eieio
    mkdir -p /cluster/data/ncbi/fishClones/fishClones.2004-07/
    cd /cluster/data/ncbi/fishClones/fishClones.2004-07/

# Download information from NCBI
        # point browser at http://www.ncbi.nlm.nih.gov/genome/cyto/cytobac.cgi?CHR=all&VERBOSE=ctg
        # change "Show details on sequence-tag" to "yes"
        # change "Download or Display" to "Download table for UNIX"
        # press Submit - save as /cluster/data/ncbi/fishClones/fishClones.2004-07/hbrc.txt
    chmod 664 /cluster/data/ncbi/fishClones/fishClones.2004-07/hbrc.txt

# Get current clone/accession information
    wget http://www.ncbi.nlm.nih.gov/genome/clone/DATA/clac.out

# Create initial Fish Clones bed file
    mkdir -p /cluster/data/hg17/bed/fishClones
    cd /cluster/data/hg17/bed/fishClones

# Copy previous sts info from fhcrc (take from previous build in future)
    cp ~booch/tracks/fish/fhcrc.sts .
    fishClones -verbose=1 -fhcrc=fhcrc.sts -noBin hg17 \
         /cluster/data/ncbi/fishClones/fishClones.2004-07/hbrc.txt \
         /cluster/data/ncbi/fishClones/fishClones.2004-07/clac.out \
         /cluster/data/ncbi/bacends/human/bacends.4/cl_acc_gi_len \
         /cluster/data/hg17/bed/bacends/lifted/bacEnds.lifted.psl \
            fishClones_initial
	     
# Get sequences for accessions not in genome
    ssh kolossus
    mkdir -p /cluster/bluearc/hg17/fishClones/
    cd /cluster/bluearc/hg17/fishClones/
# GOT HERE
	# goto http://www.ncbi.nlm.nih.gov/entrez/batchentrez.cgi?db=Nucleotide
	# select file "/cluster/data/hg17/bed/fishClones/fishClones_initial.acc"
	# change output to FASTA format
	# download results to "/cluster/bluearc/hg17/fishClones/notFound.fa"

# Align these using blat
    cp ~booch/tracks/gs.17/build34/fish/convert.pl .
    cp ~booch/tracks/gs.17/build34/fish/blatAll.pl .
    convert.pl  < notFound.fa > notFound.convert.fa
    mkdir out
    blatAll.pl /cluster/data/hg17 notFound.convert.fa out

# Make final fishClones file with this new clone placement info
    cd /cluster/data/hg17/bed/fishClones
    fishClones -verbose=1 -fhcrc=fhcrc.sts -noBin \
         -psl=/cluster/bluearc/hg17/fishClones/notFound.psl hg17 \
         /cluster/data/ncbi/fishClones/fishClones.2004-07/hbrc.txt \
         /cluster/data/ncbi/fishClones/fishClones.2004-07/clac.out \
         /cluster/data/ncbi/bacends/human/bacends.4/cl_acc_gi_len \
         /cluster/data/hg17/bed/bacends/lifted/bacEnds.lifted.psl fishClones

# Load the track
    hgLoadBed -noBin -tab \
        -sqlTable=/cluster/home/kent/src/hg/lib/fishClones.sql \
	hg17 fishClones fishClones.bed


# CHROMOSOME BANDS TRACK (2004-07-13 Terry)

# This must wait until the Fish Clones tracks is done
    mkdir -p /cluster/data/hg17/bed/cytoband
    cd /cluster/data/hg17/bed/cytoband

# Copy in some necessary files (usually from previous version)
    cp /projects/hg2/booch/psl/cytobands/pctSetBands.txt .
    cp /projects/hg2/booch/psl/cytobands/ISCN800.txt .

# Create some preliminary information files
    /cluster/bin/scripts/createSetBands pctSetBands.txt \
	/cluster/data/hg17/inserts /cluster/data/hg17  100 > setBands.txt
    /cluster/bin/scripts/makeBands ISCN800.txt /cluster/data/hg17 > cytobands.pct.bed
    /cluster/bin/scripts/makeBandRanges cytobands.pct.bed > cytobands.pct.ranges

# Reformat fishClones file
    /cluster/bin/scripts/createBanderMarkers \
	/cluster/data/hg17/bed/fishClones/fishClones.bed > fishClones.txt

# Create bed file
    /cluster/bin/scripts/runBander fishClones.txt \
	ISCN800.txt setBands.txt /cluster/data/hg17

    # Should be 862 bands
    wc cytobands.bed
    # 862    4310   30748 cytobands.bed

# Load track
    hgLoadBed -noBin -tab -sqlTable=/cluster/home/kent/src/hg/lib/cytoBand.sql \
	hg17 cytoBand cytobands.bed
	    
# Load ideogram table
    hgLoadBed -noBin -tab -sqlTable=/cluster/home/booch/src/hg/lib/cytoBandIdeo.sql \
	hg17 cytoBandIdeo cytobands.bed


# LOAD AFFYRATIO (DONE - 2004-07-14 - Hiram)
#	Copied from Hg16 doc
    # Set up cluster job to align consenesus/exemplars to hg17
    ssh eieio
    mkdir /cluster/bluearc/hg17/affyGnf
    cp -p /projects/compbio/data/microarray/affyGnf/sequences/HG-U95/HG-U95Av2_all.fa /cluster/bluearc/hg17/affyGnf

    ssh kkr1u00
    mkdir -p /iscratch/i/affyGnf
    cp -p /cluster/bluearc/hg17/affyGnf/* /iscratch/i/affyGnf
    /cluster/bin/iSync

    ssh kki
    mkdir /cluster/data/hg17/bed/affyGnf.2004-06-09
    cd /cluster/data/hg17/bed/affyGnf.2004-06-09
    ls -1 /iscratch/i/affyGnf/* > affy.lst
    ls -1 /iscratch/i/gs.18/build35/maskedContigs/* > allctg.lst
    cat << '_EOF_' > template.sub
#LOOP
/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/iscratch/i/gs.18/build35/hg17.11.ooc  $(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 allctg.lst affy.lst template.sub jobList
    mkdir psl
    para create jobList
# Completed: 380 of 380 jobs
# CPU time in finished jobs:       2922s      48.70m     0.81h    0.03d  0.000 y
# IO & Wait Time:                  1146s      19.10m     0.32h    0.01d  0.000 y
# Average job time:                  11s       0.18m     0.00h    0.00d
# Longest job:                       80s       1.33m     0.02h    0.00d
# Submission to last job:           333s       5.55m     0.09h    0.00d

    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create affyU95.psl
    ssh eieio
    cd /cluster/data/hg17/bed/affyGnf.2004-06-09
    pslSort dirs raw.psl tmp psl

    # change filter parameters for these sequences. only use alignments that
    # cover 30% of sequence and have at least 95% identity in aligned
    # region. 
    # minAli = 0.97 too high. low minCover as a lot of n's in these
    # sequences
    pslReps -minCover=0.3 -sizeMatters -minAli=0.95 -nearTop=0.005 \
	raw.psl contig.psl /dev/null
    liftUp affyU95.psl ../../jkStuff/liftAll.lft warn contig.psl
    #   Eliminate the long names
    sed -e "s/U95Av2://" affyU95.psl | sed -e "s/;//" > affyU95shortQname.psl

    # Merge with spot data and load into database. added -chip flag to 
    # affyPslAndAtlasToBed to allow correct parsing
    ssh hgwdev
    cd /cluster/data/hg17/bed/affyGnf.2004-06-09
    
    /cluster/home/sugnet/bin/i386/affyPslAndAtlasToBed -chip=U95Av2 \
	affyU95shortQname.psl \
	/projects/compbiodata/microarray/affyGnf/human_atlas_U95_gnf.noquotes.txt \
	affyRatio.bed affyRatio.exr > affyPslAndAtlasToBed.log 2>&1

    hgLoadBed -sqlTable=$HOME/src/hg/lib/affyRatio.sql hg17 \
	affyRatio affyRatio.bed
    #	Loaded 12740 elements of size 15

    mkdir affyU95
    hgLoadPsl hg17 -table=affyU95 affyU95shortQname.psl

# Load AFFYUCLANORM, extended version of affyUcla track. Hopefully
# final freeze of data set.		(DONE - 2004-07-14 - Hiram)
    ssh kk
    mkdir /cluster/data/hg17/bed/affyUclaNorm
    cd /cluster/data/hg17/bed/affyUclaNorm

    cp /projects/compbio/data/microarray/affyUcla/sequences/HG-U133AB_all.fa .
    ls -1 /scratch/hg/gs.18/build35/maskedContigs/* > contig.lst

    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc  $(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

    mkdir psl
    ls HG-U133AB_all.fa > affy.lst
    gensub2 contig.lst affy.lst gsub jobList
    para create jobList
    para try
    para check
    para push ... etc
# Completed: 380 of 380 jobs
# CPU time in finished jobs:      20070s     334.51m     5.58h    0.23d  0.001 y
# IO & Wait Time:                162784s    2713.06m    45.22h    1.88d  0.005 y
# Average job time:                 481s       8.02m     0.13h    0.01d
# Longest job:                      735s      12.25m     0.20h    0.01d
# Submission to last job:           771s      12.85m     0.21h    0.01d

    ssh eieio
    cd /cluster/data/hg17/bed/affyUclaNorm
    pslSort dirs hg17.affyU133AB_all.psl tmp psl
    wc hg17.affyU133AB_all.psl
    #	61022 1281401 12934919 hg17.affyU133AB_all.psl
    liftUp hg17.affyU133AB_all.lifted.psl \
	/cluster/data/hg17/jkStuff/liftAll.lft warn hg17.affyU133AB_all.psl 
    pslReps -minCover=0.5 -sizeMatters -minAli=0.97 \
	-nearTop=0.005  hg17.affyU133AB_all.lifted.psl \
	hg17.affyU133AB_all.lifted.pslReps.psl out.psr
    #	Processed 61017 alignments
    affyUclaMergePslData -pslFile=hg17.affyU133AB_all.lifted.pslReps.psl \
	-affyFile=/projects/compbio/data/microarray/affyUcla/data/feature_biomaterial_chip_logratios_formatForTrack.txt \
	-bedOut=hg17.affyUcla.bed \
	-expRecordOut=hg17.affyUcla.expRecords \
	-expFile=/projects/compbio/data/microarray/affyUcla/data/expNames.sorted.txt

    ~/kent/src/hg/affyGnf/addUclaAnnotations.pl hg17.affyUcla.expRecords \
	/projects/compbio/data/microarray/affyUcla/data/normal_tissue_database_annotations2.txt > hg17.affyUcla.annotations.expRecords

    # Load the databases
    ssh hgwdev
    cd /cluster/data/hg17/bed/affyUclaNorm
    sed -e 's/affyRatio/affyUclaNorm/' ~/kent/src/hg/lib/affyRatio.sql \
	> affyUclaNorm.sql
    hgLoadBed hg17 affyUclaNorm hg17.affyUcla.bed -sqlTable=affyUclaNorm.sql

# MAKE AFFY U133 - made after above affyUclaNorm (DONE - 2004-07-15 - Hiram)
    #	Someday the names can be fixed.
    ssh hgwdev
    mkdir /cluster/data/hg17/bed/affyU133
    cd /cluster/data/hg17/bed/affyU133
    ln -s ../affyUclaNorm/hg17.affyU133AB_all.lifted.pslReps.psl affyU133.psl
    hgLoadPsl hg17 affyU133.psl
    #	hgsql -e "select count(*) from affyU133;" hg17
    #	row count in hg16: 45693, in hg17: 44620
    hgLoadSeq hg17 /gbdb/hgFixed/affyProbes/HG-U133AB_all.fa
    #	44792 sequences

# MAKE LINEAGE-SPECIFIC REPEATS FOR CHICKEN & FUGU (DONE 2004-06-10 kate)
    # In an email 2/13/04 to Angie, Arian said we could treat all 
    # human repeats as 
    # lineage-specific for human-chicken blastz.  
    # and Angie did the same for fugu.
    # Lacking input from Arian, and using blastzSelf as a model,
    # I'm also using all human repeats for the human/chimp blastz.
    # Scripts expect *.out.spec filenames.
    ssh kkr1u00
    cd /cluster/data/hg17
    mkdir /iscratch/i/hg17/linSpecRep.chicken
    foreach f (/iscratch/i/hg17/rmsk/chr*.fa.out)
      cp -p $f /iscratch/i/hg17/linSpecRep.chicken/$f:t:r:r.out.spec
    end
    ln -s /iscratch/i/hg17/linSpecRep.chicken \
          /iscratch/i/hg17/linSpecRep.fugu
    ln -s /iscratch/i/hg17/linSpecRep.chicken \
          /iscratch/i/hg17/linSpecRep.chimp
    iSync


# BLASTZ FUGU (FR1) (DONE 2004-06-24 kate)
    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.fr1.2004-06-10
    ln -s /cluster/data/hg17/bed/blastz.fr1.2004-06-10 \
            /cluster/data/hg17/bed/blastz.fr1
    cd /cluster/data/hg17/bed/blastz.fr1
    # Set L=6000 (more relaxed than chicken) and abridge repeats.
    # Treat all repeats as lineage-specific (reuse linSpecRep.Chicken).
    cat << '_EOF_' > DEF
# human vs. fugu
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Reuse parameters from human-chicken.
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human
SEQ1_DIR=/iscratch/i/hg17/bothMaskedNibs
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/hg17/linSpecRep.fugu
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Fugu
SEQ2_DIR=/iscratch/i/fr1/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/iscratch/i/fr1/linSpecRep
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.fr1

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    bash # if a csh/tcsh user
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    # GOT HERE
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
        # 11935 jobs
    para try
    para check
    para push
# Completed: 11935 of 11935 jobs
# CPU time in finished jobs:    4673316s   77888.60m  1298.14h   54.09d  0.148 y
# IO & Wait Time:                329249s    5487.48m    91.46h    3.81d  0.010 y
# Average job time:                 419s       6.99m     0.12h    0.00d
# Longest job:                      714s      11.90m     0.20h    0.01d
# Submission to last job:          5575s      92.92m     1.55h    0.06d

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    cd /cluster/data/hg17/bed/blastz.fr1
    bash # if a csh/tcsh user
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
        # 341 jobs
    para try
    para check 
    para push
# CPU time in finished jobs:        315s       5.26m     0.09h    0.00d  0.000 y
# IO & Wait Time:                  4451s      74.18m     1.24h    0.05d  0.000 y
# Average job time:                  14s       0.23m     0.00h    0.00d
# Longest job:                      107s       1.78m     0.03h    0.00d
# Submission to last job:           368s       6.13m     0.10h    0.00d

    # third run: lav -> axt
    ssh kki
    cd /cluster/data/hg17/bed/blastz.fr1
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << 'EOF' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| lavToAxt stdin \
        /iscratch/i/hg17/bothMaskedNibs /iscratch/i/fr1/nib stdout \
| axtSort stdin ../../axtChrom/$chr.axt 
axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
        ../../pslChrom/$chr.psl
'EOF'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
        # 41 jobs
    para try
    para check
    para push


# CHAIN FUGU BLASTZ (2004-06-11 kate)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/hg17/bed/blastz.fr1
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/hg17/bed/blastz.fr1/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    # Reuse gap penalties from chicken run.
    cat << '_EOF_' > temp.gap
tablesize	11
smallSize	111
position	1	2	3	11	111	2111	12111	32111	72111	152111	252111
qGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
tGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
bothGap	625	660	700	750	900	1400	4000	8000	16000	32000	57000
'_EOF_'
    # << this line makes emacs coloring happy
    sed 's/  */\t/g' temp.gap > ../../fuguHumanTuned.gap
    rm -f temp.gap

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
                      -linearGap=../../fuguHumanTuned.gap \
                      -minScore=5000 $1 \
    /iscratch/i/hg17/bothMaskedNibs \
    /iscratch/i/fr1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
        # 46 jobs
    para try
    para check
    para push
        # 1 crashed job -- chr6_hla_hap1.chain is empty
# CPU time in finished jobs:        610s      10.16m     0.17h    0.01d  0.000 y
# IO & Wait Time:                  1644s      27.40m     0.46h    0.02d  0.000 y
# Average job time:                  50s       0.83m     0.01h    0.00d
# Longest job:                      233s       3.88m     0.06h    0.00d
# Submission to last job:           339s       5.65m     0.09h    0.00d

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain hg17 ${c}_chainFr1 $i
    end
    featureBits hg16 chainFr1Link
        # 50709290 bases of 2865248791 (1.770%) in intersection


# ANCIENT REPEAT TABLE (2004-06-11 kate)

    # The netClass operations requires an "ancientRepeat" table in one 
    # of the databases.
    # This is a hand curated table obtained from Arian.

    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/ancientRepeat
    cd /cluster/data/hg17/bed/ancientRepeat
    # mysqldump needs write permission to this directory
    chmod 777 .
    hgsqldump --all --tab=. hg15 ancientRepeat
    chmod 775 .
    hgsql hg17 < ancientRepeat.sql
    echo "LOAD DATA LOCAL INFILE 'ancientRepeat.txt' into table ancientRepeat"\
                | hgsql hg17


# NET FUGU BLASTZ (2004-06-11 kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    netClass noClass.net hg17 fr1 human.net

    # Make a 'syntenic' subset:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netFr1 stdin
    #netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 netSyntenyFr1 stdin


# EXTRACT AXT'S AND MAF'S FROM THE NET (kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.fr1/axtChain
    netSplit human.net humanNet
    mkdir -p ../axtNet ../mafNet
cat > makeMaf.csh << 'EOF'
    foreach f (humanNet/chr*.net)
        set c = $f:t:r
        echo "axtNet on $c"
        netToAxt humanNet/$c.net chain/$c.chain /cluster/data/hg17/nib /cluster/data/fr1/nib stdout | axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/fr1/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=fr1.
    end
'EOF'
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

# PRODUCE FUGU BLAT ALIGNMENT (DONE - 2004-07-07 - Hiram)

    # Use masked scaffolds from fr1 assembly (same sequence as
    # previous BlatFugu, however it's repeat and TRF-masked).

    ssh kk
    mkdir /cluster/data/hg17/bed/blatFr1
    cd /cluster/data/hg17/bed/blatFr1
    mkdir psl 
    # next time, use N?_?????? (to pick up NG_ contigs)
    foreach f ( `cat /cluster/data/hg17/contig.lst` )
      set c=$f:t:r
      echo $c
      mkdir psl/$c
    end

    # create cluster job
    mkdir run
    cd run
    ls -1S /iscratch/i/fugu/trfFa/*.fa > fugu.lst
    ls -1S /scratch/hg/gs.18/build35/maskedContigs/*.fa > human.lst
cat << 'EOF' > gsub
#LOOP
/cluster/bin/i386/blat -mask=lower -qMask=lower -q=dnax -t=dnax {check in line+ $(path1)} {check in line+ $(path2)} {check out line+ /cluster/data/hg17/bed/blatFr1/psl/$(root1)/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'
    # << keep emacs happy
    gensub2 human.lst fugu.lst gsub jobList
    para create spec
       # 219640 jobs  
    para try
    para check
    para push -maxQueue=300000 -maxPush=220000
    para check
# Completed: 219640 of 219640 jobs
# CPU time in finished jobs:    5206945s   86782.41m  1446.37h   60.27d  0.165 y
# IO & Wait Time:                797791s   13296.52m   221.61h    9.23d  0.025 y
# Average job time:                  27s       0.46m     0.01h    0.00d
# Longest job:                      951s      15.85m     0.26h    0.01d
# Submission to last job:          7553s     125.88m     2.10h    0.09d
        # cd psl
        # count files with aligments
        # find . -not -size 427c | wc -l
        # 44558
        # count files with no aligments
        # find . -size 427c | wc -l
        # 175463

   # When cluster run is done, sort alignments
   # into chrom directory
    ssh eieio
    cd /cluster/data/hg17/bed/blatFr1
    pslCat -dir psl/N?_?????? | \
      liftUp -type=.psl stdout \
        /cluster/data/hg17/jkStuff/liftAll.lft warn stdin | \
      pslSortAcc nohead chrom temp stdin
        # 65 minutes ?
        # Processed 216595 lines into 1 temp files

    # Rename to correspond with tables and load into database:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blatFr1/chrom
    foreach i (chr*.psl)
        set r = $i:r
        echo mv $i ${r}_blatFr1.psl
        mv $i ${r}_blatFr1.psl
    end

    # lift fugu scaffolds to Fugu browser chrUn,
    # so you can link to other browser.  And don't need to load sequence
    cd /cluster/data/hg17/bed/blatFr1
    liftUp -pslQ all.psl /cluster/data/fr1/fugu_v3.masked.lft warn chrom/*.psl

    hgLoadPsl -table=blatFr1 hg17 all.psl
    #	load of blatFr1 did not go as planned: 216595 record(s),
    #	0 row(s) skipped, 3 warning(s) loading psl.tab
    #	featureBits hg17 blatFr1 refGene:CDS
    #	13476002 bases of 2866216770 (0.470%) in intersectio
    #	featureBits hg16 blatFr1 refGene:CDS
    #	13547219 bases of 2865248791 (0.473%) in intersection
    #	featureBits hg15 blatFugu refGene:CDS
    #	12427544 bases of 2866466359 (0.434%) in intersection

#  BLASTZ RAT RN3 (DONE - 2004-06-14 - Hiram)

    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.rn3.2004-06-11
    cd /cluster/data/hg17/bed
    ln -s  blastz.rn3.2004-06-11 blastz.rn3
    cd blastz.rn3

    cat << '_EOF_' > DEF
# rat vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Rat
SEQ2_DIR=/iscratch/i/rn3/bothMaskedNibs
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/store5/gs.18/build35/bed/blastz.rn3

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.rn3
    source DEF
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run0.sh
    #	it is a generic script and works for any assembly
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
Completed: 41943 of 41943 jobs
CPU time in finished jobs:   15330421s  255507.02m  4258.45h  177.44d  0.486 y
IO & Wait Time:                673809s   11230.15m   187.17h    7.80d  0.021 y
Average job time:                 382s       6.36m     0.11h    0.00d
Longest job:                     4651s      77.52m     1.29h    0.05d
Submission to last job:        169197s    2819.95m    47.00h    1.96d

    #	Second cluster run to convert the .out's to .lav's
    #	You do NOT want to run this on the big cluster.  It brings
    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.rn3
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run1.sh
    #	fixup machine check, should be kki, not kk
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       1894s      31.56m     0.53h    0.02d  0.000 y
# IO & Wait Time:                  6271s     104.52m     1.74h    0.07d  0.000 y
# Average job time:                  24s       0.40m     0.01h    0.00d
# Longest job:                      131s       2.18m     0.04h    0.00d
# Submission to last job:           590s       9.83m     0.16h    0.01d

    #	Third cluster run to convert lav's to axt's
    cd /cluster/data/hg17/bed/blastz.rn3
    #	The copy of this in mm4 was broken, fixed here
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:        426s       7.09m     0.12h    0.00d  0.000 y
# IO & Wait Time:                  7283s     121.39m     2.02h    0.08d  0.000 y
# Average job time:                 168s       2.79m     0.05h    0.00d
# Longest job:                      642s      10.70m     0.18h    0.01d
# Submission to last job:           642s      10.70m     0.18h    0.01d

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3
    mkdir pslChrom
    set tbl = "blastzRn3"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 30 minutes

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/pslChrom
    for I in *.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done: ${I}"
    done
    # this is a 55 minute job
    #	Check results
    #	featureBits hg16 blastzRn3
    #	1013603401 bases of 2865248791 (35.376%) in intersection
    #	featureBits hg17 blastzRn3
    #	1013003285 bases of 2866216770 (35.343%) in intersection

# CHAIN RN3 BLASTZ (DONE - 2004-06-14 - Hiram)
#  re-worked with no 'axtFilter -notQ_random' on the axtChain step - 2004-06-23
    axtFilter -notQ_random $1 | axtChain stdin \

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kki
    mkdir -p /cluster/data/hg17/bed/blastz.rn3/axtChain/run1
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastz.rn3/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
    axtChain $1 \
	/iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/rn3/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       4645s      77.41m     1.29h    0.05d  0.000 y
# IO & Wait Time:                  6840s     114.00m     1.90h    0.08d  0.000 y
# Average job time:                 250s       4.16m     0.07h    0.00d
# Longest job:                     1539s      25.65m     0.43h    0.02d
# Submission to last job:          3761s      62.68m     1.04h    0.04d


    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    36m42.170s
    #	user    4m55.970s
    #	sys     1m49.840s

    time chainSplit chain all.chain
    #	real    13m54.860s
    #	user    4m50.370s
    #	sys     1m3.260s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg17 ${c}_chainRn3 $i
        echo done $c
    end
    #	featureBits hg17 chainRn3
    #	2827052992 bases of 2866216770 (98.634%) in intersection
    #	(with filter:) 2826192649 bases of 2866216770 (98.604%) in intersection
    #	featureBits hg16 chainRn3
    #	2830563493 bases of 2865248791 (98.789%) in intersection

# NET RN3 (DONE - 2004-06-15 - Hiram)
#	Re-done due to Chain being re-done 2004-06-23

    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg17/chrom.sizes \
                        /cluster/data/rn3/chrom.sizes ../preNet/$i
    end

    cd ..
    mkdir n1
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg17/chrom.sizes \
                            /cluster/data/rn3/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2510467072, utime 19307 s/100, stime 3181

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    time netClass hNoClass.net hg17 rn3 rat.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInRat \
	-qNewR=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman
    #	real    34m29.829s
    #	user    11m30.440s
    #	sys     1m52.730s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn rat.net > ratSyn.net
    #	real    16m25.640s
    #	user    7m41.330s
    #	sys     1m1.150s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    netFilter -minGap=10 rat.net |  hgLoadNet hg17 netRn3 stdin
    netFilter -minGap=10 ratSyn.net | hgLoadNet hg17 syntenyNetRn3 stdin
    #	real    37m0.199s
    #	user    15m13.770s
    #	sys     1m41.540s

    # check results
    # featureBits hg17 netRn3
    # 2817656275 bases of 2866216770 (98.306%) in intersection
    # (with axtFilter) 2816623107 bases of 2866216770 (98.270%) in intersection
    # featureBits hg16 netRn3
    # 2820958389 bases of 2865248791 (98.454%) in intersection

    # featureBits hg17 syntenyNetRn3
    # 2781748096 bases of 2866216770 (97.053%) in intersection
    # (with axtFilter) 2780883450 bases of 2866216770 (97.023%) in intersection
    # featureBits hg16 syntenyNetRn3
    # 2784011730 bases of 2865248791 (97.165%) in intersection

    # Add entries for net and chain to rat/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtChain
    mkdir ratNet
    time netSplit rat.net ratNet
    #	real    12m1.478s
    #	user    8m35.050s
    #	sys     1m7.230s

    # extract axts from net 
    mkdir ../axtNet 
    foreach n (ratNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt ratNet/$c.net chain/$c.chain \
		/cluster/data/hg17/nib \
		/cluster/data/rn3/nib stdout ../axtNet/$c.axt
	echo "Complete: $c.net -> axtNet/$c.axt"
    end
    # sort axt's and convert to maf format
    mkdir ../mafNet
cat << 'EOF' > makeMaf.csh
    foreach f (../axtNet/chr*.axt)
        set c=$f:t:r
        echo $c.axt
        mv ../axtNet/$c.axt ../axtNet/$c.unsorted.axt
        axtSort ../axtNet/$c.unsorted.axt ../axtNet/$c.axt
        rm ../axtNet/$c.unsorted.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/rn3/chrom.sizes \
                ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=rn3.
    end
'EOF'
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/blastz.rn3/axtBest
    cd /cluster/data/hg17/bed/blastz.rn3/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestRn3.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestRn3.psl
	echo "Done: ${c}_blastzBestRn3.psl"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/pslBest
    for I in chr*BestRn3.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits hg17 blastzBestRn3
    #	975533772 bases of 2866216770 (34.036%) in intersection
    # (with axtFilter) 970005525 bases of 2866216770 (33.843%) in intersection
    # featureBits hg16 blastzBestRn3
    #	976121391 bases of 2865248791 (34.068%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg17/axtBest/Rn3
     cd /gbdb/hg17/axtBest/Rn3
     ln -s /cluster/data/hg17/bed/blastz.rn3/axtNet/chr*.axt .
     cd /cluster/data/hg17/bed/blastz.rn3/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/hg17/axtBest/Rn3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('rn3','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
    hgsql hg17 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql hg17 < axtInfoInserts.sql

# MAKING RAT SYNTENY (DONE - 2004-06-30 - Hiram)
#	Re-Done after above done without the axtFilter

ssh hgwdev
mkdir /cluster/data/hg17/bed/syntenyRn3
cd /cluster/data/hg17/bed/syntenyRn3

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyMm3
cp -p /cluster/data/hg16/bed/syntenyMm3/*.pl .
cp -p /cluster/data/hg16/bed/syntenyMm3/*.sh .

./syntenicBest.pl -db=hg17 -table=blastzBestRn3
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg17 -table=blastzBestRn3
./synteny2bed.pl
#	The five commands above
#	real    196m2.565s
#	user    0m21.170s
#	sys     0m4.690s

#	Used to load this in syntenyRn3, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
sed -e 's/ensPhusionBlast/ensRn3MusHom/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRn3MusHom.sql
hgLoadBed hg17 ensRn3MusHom ucsc100k.bed -sqlTable=ensRn3MusHom.sql

    #	featureBits hg17 ensRn3MusHom
    #	2592164486 bases of 2866216770 (90.439%) in intersection
    #	featureBits hg16 syntenyRn3
    #	2595919851 bases of 2865248791 (90.600%) in intersection


# MAKING RAT AXTTIGHT FROM AXTBEST (DONE - 2004-06-15 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3/axtNet
    mkdir -p ../axtTight
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightRn3.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/pslTight
    for I in chr*TightRn3.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly
    #	featureBits hg17 blastzTightRn3
    #	153936720 bases of 2866216770 (5.371%) in intersection
    #	featureBits hg16 blastzTightRn3
    #	153151903 bases of 2865248791 (5.345%) in intersection


    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.rn3/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtTight
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsRn3/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

# BLASTZ RN3 CLEAN UP (DONE - 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.rn3
    nice rm -rf raw &
    nice rm axtChain/run1/chain/* &
    nice rm -fr axtChain/n1 axtChain/hNoClass.net &
    nice gzip axtChrom/* pslChrom/* lav/*/* axtChain/all.chain axtChain/*.net &

# BLASTZ CHICKEN (GALGAL2) (DONE - 2004-06-14 - Fan)

    ssh kk
    mkdir /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    cd /cluster/data/hg17/bed
    ln -s /cluster/data/hg17/bed/blastz.galGal2.2004-06-14 blastz.galGal2
    cd blastz.galGal2
    # Set L=10000 (higher threshold on blastz's outer loop) and abridge 
    # repeats.
    cat << '_EOF_' > DEF
# human vs. chicken
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Specific settings for chicken (per Webb email to Brian Raney)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=10000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human
SEQ1_DIR=/iscratch/i/hg17/bothMaskedNibs
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.chicken
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Chicken
SEQ2_DIR=/iscratch/i/galGal2/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/iscratch/i/galGal2/linSpecRep
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/store5/gs.18/build35/bed/blastz.galGal2

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.galGal2
    bash
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run0.sh
    #	it is a generic script and works for any assembly
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
Completed: 41943 of 41943 jobs
CPU time in finished jobs:   15330421s  255507.02m  4258.45h  177.44d  0.486 y
IO & Wait Time:                673809s   11230.15m   187.17h    7.80d  0.021 y
Average job time:                 382s       6.36m     0.11h    0.00d
Longest job:                     4651s      77.52m     1.29h    0.05d
Submission to last job:        169197s    2819.95m    47.00h    1.96d

    #	Second cluster run to convert the .out's to .lav's
    #	You do NOT want to run this on the big cluster.  It brings
    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.galGal2
    bash
    # script copied over from /cluster/data/mm4/jkStuff/BlastZ_run1.sh
    #	fixup machine check, should be kki, not kk
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       1894s      31.56m     0.53h    0.02d  0.000 y
# IO & Wait Time:                  6271s     104.52m     1.74h    0.07d  0.000 y
# Average job time:                  24s       0.40m     0.01h    0.00d
# Longest job:                      131s       2.18m     0.04h    0.00d
# Submission to last job:           590s       9.83m     0.16h    0.01d

    #	Third cluster run to convert lav's to axt's
    cd /cluster/data/hg17/bed/blastz.galGal2
    #	The copy of this in mm4 was broken, fixed here
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:        426s       7.09m     0.12h    0.00d  0.000 y
# IO & Wait Time:                  7283s     121.39m     2.02h    0.08d  0.000 y
# Average job time:                 168s       2.79m     0.05h    0.00d
# Longest job:                      642s      10.70m     0.18h    0.01d
# Submission to last job:           642s      10.70m     0.18h    0.01d

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2
    mkdir pslChrom
    set tbl = "blastzGalGal2"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 30 minutes

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2/pslChrom
    bash
    for I in *.psl
    do
        /cluster/bin/i386/hgLoadPsl hg17 ${I}
        echo "done: ${I}"
    done   


    # CHIMP ALIGNMENTS (2004-06-15, 2004-06-21 kate)

    # Align with nucleotide blat, unmasked (same method as liftOver chains
    # Use 1K split of panTro1 doc'ed in makePanTro1.doc
    ssh kk
    cd /cluster/data/hg17
    mkdir -p bed/blat.panTro1.2004-06-23
    cd bed/blat.panTro1.2004-06-23
    mkdir run raw
    cd run
cat > gsub << 'EOF'
#LOOP
do.csh $(path1) $(path2) $(root1) $(root2) {check out line+ ../raw/$(root1)/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'
cat > do.csh << 'EOF'
#!/bin/csh -fe
set c = $3
set f = ${c}_${4}.psl
blat $1 $2 /tmp/$f -tileSize=11 -ooc=/cluster/bluearc/hg/h/11.ooc \
                -minScore=100 -minIdentity=93 -fastMap
set ret = $status
mv -f /tmp/$f $5
exit $ret
'EOF'
    chmod +x do.csh
    ls -1S /scratch/hg/hg17/bothMaskedNibs/*.nib > human.lst
    ls -1S /cluster/bluearc/panTro1/blatSplit/splitChrom.3K/*.fa > chimp.lst
    gensub2 human.lst chimp.lst gsub spec
    foreach f (`cat human.lst`)
        set d = $f:t:r
        echo $d
        mkdir ../raw/$d
    end
    para create spec
        # 2438 jobs
    para try 
    para check
    para push

    ssh kksilo
    cd /cluster/data/hg17
    cd bed/blat.panTro1/raw

    # lift results to chrom coordinates
    # takes about an hour -- might want to
    # run this on the minicluster
    ssh eieio
    cd /cluster/bluearc/panTro1/blatSplit/liftChrom.3K
    cat chr*.lft > all.lft
    cd /cluster/data/hg17
    cd bed/blat.panTro1.2004-06-23/raw
    mkdir -p ../psl
cat << 'EOF' > liftup.csh
    foreach c (chr*)
        echo $c
        pslCat $c/*.psl | \
            liftUp -pslQ ../psl/$c.psl \
                /cluster/bluearc/panTro1/blatSplit/liftChrom.3K/all.lft warn stdin
    end
'EOF'
    csh liftup.csh >&! liftup.log &
    tail -100f liftup.log
    rm -r raw

# GNF ATLAS 2 (DONE - 2004-07-14 - Hiram
    # Align probes from GNF1H chip.
    ssh kk
    cd /cluster/data/hg17/bed
    mkdir -p geneAtlas2/run/psl
    cd geneAtlas2/run
    #	This bluearc/geneAtlas2 directory already exists
    # mkdir -p /cluster/bluearc/geneAtlas2
    # cp /projects/compbio/data/microarray/geneAtlas2/human/gnf1h.fa /cluster/bluearc/geneAtlas2
    ls -1 /scratch/hg/gs.18/build35/maskedContigs > genome.lst
    ls -1 /cluster/bluearc/geneAtlas2/gnf1h.fa > mrna.lst
    cat << '_EOF_' > gsub
#LOOP
blat -fine -ooc=/scratch/hg/h/11.ooc  /scratch/hg/gs.18/build35/maskedContigs/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 genome.lst mrna.lst gsub jobList
    para create jobList
    para try
    para check
    para push
    para time
# Completed: 380 of 380 jobs
# CPU time in finished jobs:      10599s     176.65m     2.94h    0.12d  0.000 y
# IO & Wait Time:                  3893s      64.88m     1.08h    0.05d  0.000 y
# Average job time:                  38s       0.64m     0.01h    0.00d
# Longest job:                      649s      10.82m     0.18h    0.01d
# Submission to last job:           663s      11.05m     0.18h    0.01d

    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create gnf1h.psl.
    pslSort dirs raw.psl tmp psl
    pslReps -minCover=0.3 -minAli=0.95 -nearTop=0.005 raw.psl \
	contig.psl /dev/null
    #	Processed 80818 alignments
    liftUp ../affyGnf1h.psl ../../../jkStuff/liftAll.lft warn contig.psl
    rm -r contig.psl raw.psl psl

    # Load probes and alignments from GNF1H into database.
    ssh hgwdev
    cd /cluster/data/hg17/bed/geneAtlas2
    #	Already symlinked
    # ln -s /projects/compbio/data/microarray/geneAtlas2/human/gnf1h.fa \
    #	/gbdb/hgFixed/affyProbes
    hgLoadPsl hg17 affyGnf1h.psl
    hgLoadSeq hg17 /gbdb/hgFixed/affyProbes/gnf1h.fa

    grep -v U133B ../affyUclaNorm/hg17.affyU133AB_all.lifted.pslReps.psl \
	| sed -e "s/exemplar://; s/consensus://; s/U133A://" \
	| sed -e "s/;//" > affyU133A.psl

    hgMapMicroarray gnfAtlas2.bed hgFixed.gnfHumanAtlas2MedianRatio \
    	affyU133A.psl  /cluster/data/hg17/bed/geneAtlas2/affyGnf1h.psl

# Loaded 44696 rows of expression data from hgFixed.gnfHumanAtlas2MedianRatio
# Mapped 32857,  multiply-mapped 1462, missed 49, unmapped 11839

    hgLoadBed hg17 gnfAtlas2 gnfAtlas2.bed
    #	Loaded 34319 elements of size 15

# LOAD SNPS (TO BE DONE)
    # SNP processing has been condensed into a single script,
    # which makes snpNih, snpTsc, and snpMap
    #   ${HOME}/kent/src/hg/snp/locations/processSnpLocations.csh

    #	take a look at the directory:
    #	ftp://ftp.ncbi.nlm.nih.gov/snp/human/genome_reports/
    #	To see what snpBuild is available and if available for this
    #	human build 35 - as of 2004-07-15 - do not see anything for b35

    # snpBuild = 119
    # Run from directory $oo/bed/snp/build$snpBuild/snpMap
    mkdir -p $oo/bed/snp/build$snpBuild/snpMap
    cd       $oo/bed/snp/build$snpBuild/snpMap
    processSnpLocations.csh hg16 human 34_2 119 >& log &

    # check data:
    # wc -l snpTsc.bed; hgsql -e "select count(*) from snpTsc;" hg17
    # wc -l snpNih.bed; hgsql -e "select count(*) from snpNih;" hg17
    # wc -l snpMap.bed; hgsql -e "select count(*) from snpMap;" hg17
    # select * from snpNih limit 5; desc snpNih; show indexes from
    # snpNih"
    # select * from snpTsc limit 5; desc snpTsc; show indexes from
    # snpTsc"
    # select * from snpMap limit 5; desc snpMap; show indexes from
    # snpMap"

    # remove temp files
    # rm human* *bed.gz

# GENE SORTER (AKA: FAMILY BROWSER) (DONE - 2004-06-16 - Hiram)
#	to be done after knownGene tables are complete from known gene
#	process.
#
# Cluster together various alt-splicing isoforms.
#	Creates the knownIsoforms and knownCanonical tables
ssh hgwdev
mkdir /cluster/data/hg17/bed/geneSorter.2004-06-15
ln -s /cluster/data/hg17/bed/geneSorter.2004-06-15 \
	/cluster/data/hg17/bed/geneSorter
cd /cluster/data/hg17/bed/geneSorter
hgClusterGenes hg17 knownGene knownIsoforms knownCanonical

# Extract peptides from knownGenes into fasta file
# and create a blast database out of them.
mkdir /cluster/data/hg17/bed/geneSorter/blastp
cd /cluster/data/hg17/bed/geneSorter/blastp
pepPredToFa hg17 knownGenePep known.faa
#	You may need to build this binary in src/hg/near/pepPredToFa
/scratch/blast/formatdb -i known.faa -t known -n known
#	This command is in /projects/compbio/bin/$MACH/formatdb

# Copy over database to bluearc
rm -fr /cluster/bluearc/hg17/blastp
mkdir -p /cluster/bluearc/hg17/blastp
cp -p /cluster/data/hg17/bed/geneSorter/blastp/known.* \
	/cluster/bluearc/hg17/blastp

#	Had to pick up a new blastall binary (2004-06-15)
#	Our old one would no longer run on our systems that have
#	updated Linux versions
mkdir /cluster/bluearc/blast229
cd /cluster/bluearc/blast229
wget --timestamping \
    ftp://ftp.ncbi.nlm.nih.gov/blast/executables/release/2.2.9/blast-2.2.9-ia32-linux.tar.gz
wget --timestamping \
    ftp://ftp.ncbi.nlm.nih.gov/blast/executables/release/2.2.9/ChangeLog.txt
wget --timestamping \
    ftp://ftp.ncbi.nlm.nih.gov/blast/executables/release/2.2.9/ReleaseNotes.txt
tar xvzf blast-2.2.9-ia32-linux.tar.gz


# Split up fasta file into bite sized chunks for cluster
cd /cluster/data/hg17/bed/geneSorter/blastp
mkdir split
faSplit sequence known.faa 8000 split/kg

# Make parasol run directory
ssh kk
mkdir /cluster/data/hg17/bed/geneSorter/blastp/self
cd /cluster/data/hg17/bed/geneSorter/blastp/self
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/hg17/blastp/known -i $1 -o $2 \
	-e 0.01 -m 8 -b 1000
'_EOF_'
    # << keep emacs happy
chmod +x blastSome

# Make gensub2 file
cat  << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
#	'ls ../../split/*.fa' is too much, hence the echo
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push
# This should finish in ~15 minutes if the cluster is free.
Completed: 7749 of 7749 jobs
CPU time in finished jobs:     182148s    3035.81m    50.60h    2.11d  0.006 y
IO & Wait Time:                 22954s     382.56m     6.38h    0.27d  0.001 y
Average job time:                  26s       0.44m     0.01h    0.00d
Longest job:                      372s       6.20m     0.10h    0.00d
Submission to last job:           871s      14.52m     0.24h    0.01d

# Load into database.  This takes about 30 minutes
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/self/run/out
time hgLoadBlastTab hg17 knownBlastTab *.tab
# Scanning through 7749 files
# Loading database with 11799667 rows
#	Hg16 was:       11376875 rows
# real    30m10.761s
# user    5m25.490s
# sys     1m0.630s

cd /cluster/data/hg17/bed/geneSorter
# Create table that maps between known genes and RefSeq
hgMapToGene hg17 refGene knownGene knownToRefSeq
#	may need to build this command in src/hg/near/hgMapToGene
#	hgsql -e "select count(*) from knownToRefSeq;" hg17
#	row count changed from 36078 in Hg16 to 36082

# Create table that maps between known genes and LocusLink
hgsql --skip-column-names -e "select mrnaAcc,locusLinkId from refLink" hg17 \
	> refToLl.txt
hgMapToGene hg17 refGene knownGene knownToLocusLink -lookup=refToLl.txt
#	hgsql -e "select count(*) from knownToLocusLink;" hg17
#	row count went from 36078 in Hg16 to 36082

# Create table that maps between known genes and Pfam domains
hgMapViaSwissProt hg17 knownGene name proteinID Pfam knownToPfam
#	hgsql -e "select count(*) from knownToPfam;" hg17
#	row count dropped from 30467 in Hg16 to 29725


# Create table to map between known genes and GNF Atlas2
# expression data.
    hgMapToGene hg17 gnfAtlas2 knownGene knownToGnfAtlas2 '-type=bed 12'
#	hgsql -e "select count(*) from knownToGnfAtlas2;" hg17
#	row count droppted from 35817 in Hg16 to 35739

# Create expression distance table - takes about an hour
    hgExpDistance hg17 hgFixed.gnfHumanAtlas2MedianRatio \
    	hgFixed.gnfHumanAtlas2MedianExps gnfAtlas2Distance \
	-lookup=knownToGnfAtlas2
# Got 35739 unique elements in hgFixed.gnfHumanAtlas2MedianRatio
    #	hgsql -e "select count(*) from gnfAtlas2Distance;" hg17
    #	row count went from 35,817,000 in Hg16 to 35,739,000
    #	real    108m1.671s
    #	user    89m30.680s
    #	sys     3m6.800s

# Create a table that maps between known genes and 
# the nice affy expression data.
hgMapToGene "-type=bed 12" hg17 affyUclaNorm knownGene knownToU133
    #	hgsql -e "select count(*) from knownToU133;" hg17
    #	row count went from 37,634 in Hg16 to 36,795

# Create expression distance table.  This will take about 2.5 hours
cd /tmp
cp -p ~/kent/src/hg/near/hgExpDistance/affyUcla.weight .
time hgExpDistance hg17 affyUclaNorm affyUclaExp knownExpDistance \
	-weights=affyUcla.weight -lookup=knownToU133
    #	211 genes, 42 weights, 26.500000 total wieght
    #	Got 36795 unique elements in affyUclaNorm
    #	real    154m1.058s
    #	user    134m45.000s
    #	sys     3m1.990s

# Create table that maps between known genes and 
# the GNF data.
cd /tmp
hgMapToGene hg17 affyU95 knownGene knownToU95
    #	row count went from 18780 in Hg16 to 18796
    #	hgFixed.gnfHumanU95Exps argument is unused, no need to exist
hgExpDistance hg17 hgFixed.gnfHumanU95MedianRatio \
	hgFixed.gnfHumanU95Exps gnfU95Distance  -lookup=knownToU95
    #	row count went from 17711000 in Hg16 to 17710000
    #	real    21m37.703s
    #	user    13m35.110s
    #	sys     0m28.470s

# Make sure that GO database is up to date.
See README in /cluster/store1/geneOntology.
#	I update this GO database very carefully, checking that all
#	structures in it remain the same from release to release and
#	backing up the current go DB in a backup database.  In this case
#	the backup is go040107 - when it was loaded for Mm4, and the new
#	go database is based on data from Dec 17th 2003 and Feb 2004 according
#	to the time stamp on the fetched data.  This build was done in
#	/cluster/store1/geneOntology/20040217

cd /cluster/data/hg17/bed/geneSorter

XXX - DO NOT YET HAVE ensGene table - must wait on Ensembl to release that
XXX - have not created the knownToEnsembl table yet - 2004-07-15 - Hiram
# Create knownToEnsembl column
hgMapToGene hg17 ensGene knownGene knownToEnsembl
#	table row count went from previous version: 36068 to 38251

XXX - DO NOT YET HAVE snp tables - not at NCBI yet - 2004-07-15 - Hiram
# Make knownToCdsSnp column.  This is a little complicated by
# having to merge data form the snpTsc and the snpNih tracks.
hgMapToGene hg17 snpTsc knownGene knownToCdsSnp -createOnly -all -cds
hgMapToGene hg17 snpTsc knownGene snp1 -noLoad -all -cds
hgMapToGene hg17 snpNih knownGene snp2 -noLoad -all -cds
sort snp1.tab snp2.tab > knownToCdsSnp.tab
rm snp1.tab snp2.tab
hgsql \
    -e 'load data local infile "knownToCdsSnp.tab" into table knownToCdsSnp;' \
	hg17
#	row count went from 87273 to 106199

# Make C. elegans ortholog column using blastp on wormpep.
# First make C. elegans protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/ce1/blastp should have data

#	The blast jobs below can be run on the kk or kk9 clusters
# Create the ceBlastTab
ssh kk9
mkdir /cluster/data/hg17/bed/geneSorter/blastp/ce1
cd /cluster/data/hg17/bed/geneSorter/blastp/ce1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/ce1/blastp/wormPep \
	-i $1 -o $2 -e 0.01 -m 8 -b 1
'_EOF_'
    # << keep emacs happy
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
para check
para push ... etc ...
#	Only takes 10 minutes on an idle cluster
# Completed: 7749 of 7749 jobs
# CPU time in finished jobs:      32023s     533.72m     8.90h    0.37d  0.001 y
# IO & Wait Time:                 20643s     344.05m     5.73h    0.24d  0.001 y
# Average job time:                   7s       0.11m     0.00h    0.00d
# Longest job:                      110s       1.83m     0.03h    0.00d
# Submission to last job:          1911s      31.85m     0.53h    0.02d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/ce1/run/out
hgLoadBlastTab hg17 ceBlastTab -maxPer=1 *.tab
#	row count went from 27620 to 27616

# Make mouse ortholog column using blastp on mouse known genes.
# First make mouse protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This already exists.  See makeMm5.doc for procedure
#	the directory: /cluster/bluearc/scratch/mus/mm5/blastp should have data

# Make parasol run directory 
ssh kk
mkdir /cluster/data/hg17/bed/geneSorter/blastp/mm5
cd /cluster/data/hg17/bed/geneSorter/blastp/mm5
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/scratch/mus/mm5/blastp/known \
	-i $1 -o $2 -e 0.001 -m 8 -b 1
'_EOF_'
    # << keep emacs happy
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
#	this echo trick is used because otherwise the command line is
#	too long and you can not do a simple ls
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
para check
para push ... etc ...
# Completed: 7749 of 7749 jobs
# CPU time in finished jobs:     139041s    2317.34m    38.62h    1.61d  0.004 y
# IO & Wait Time:                 21227s     353.79m     5.90h    0.25d  0.001 y
# Average job time:                  21s       0.34m     0.01h    0.00d
# Longest job:                      260s       4.33m     0.07h    0.00d
# Submission to last job:          1137s      18.95m     0.32h    0.01d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/mm5/run/out
hgLoadBlastTab hg17 mmBlastTab -maxPer=1 *.tab
# Scanning through 7748 files
#	row count went from 36471 to 36638

# Make Danio rerio (zebrafish) ortholog column using blastp on Ensembl.
# First make protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/dr1/blastp should have data

# Make parasol run directory 
ssh kk
mkdir /cluster/data/hg17/bed/geneSorter/blastp/dr1
cd /cluster/data/hg17/bed/geneSorter/blastp/dr1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/dr1/blastp/ensembl \
	-i $1 -o $2 -e 0.005 -m 8 -b 1
'_EOF_'
    # << keep emacs happy
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
para check
para push ... etc ...
# Completed: 7749 of 7749 jobs
# CPU time in finished jobs:     100217s    1670.28m    27.84h    1.16d  0.003 y
# IO & Wait Time:                 23697s     394.95m     6.58h    0.27d  0.001 y
# Average job time:                  16s       0.27m     0.00h    0.00d
# Longest job:                      233s       3.88m     0.06h    0.00d
# Submission to last job:          1667s      27.78m     0.46h    0.02d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/dr1/run/out
hgLoadBlastTab hg17 drBlastTab -maxPer=1 *.tab
#	row count went from 32971 to 33023

# Make Saccharomyces cerevisiae (yeast) ortholog column using blastp on RefSeq.
# First make protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/sc1/blastp should have data

# Make parasol run directory 
ssh kk
mkdir /cluster/data/hg17/bed/geneSorter/blastp/sc1
cd /cluster/data/hg17/bed/geneSorter/blastp/sc1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/sc1/blastp/sgd \
	-i $1 -o $2 -e 0.01 -m 8 -b 1
'_EOF_'
    # << keep emacs happy
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
para check
para push ... etc ...
# Completed: 7749 of 7749 jobs
# CPU time in finished jobs:      20738s     345.64m     5.76h    0.24d  0.001 y
# IO & Wait Time:                 22018s     366.96m     6.12h    0.25d  0.001 y
# Average job time:                   6s       0.09m     0.00h    0.00d
# Longest job:                       39s       0.65m     0.01h    0.00d
# Submission to last job:           572s       9.53m     0.16h    0.01d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/sc1/run/out
hgLoadBlastTab hg17 scBlastTab -maxPer=1 *.tab
#	row count went from 18286 to 18265

# Make Drosophila melanagaster ortholog column using blastp on FlyBase.
# First make SwissProt protein database and copy it to cluster/bluearc
# if it doesn't exist already
#	This is already done, see makeMm3.doc for procedure
#	the directory: /cluster/bluearc/dm1/blastp should have data

# Make parasol run directory 
ssh kk
mkdir /cluster/data/hg17/bed/geneSorter/blastp/dm1
cd /cluster/data/hg17/bed/geneSorter/blastp/dm1
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/dm1/blastp/flyBase \
	-i $1 -o $2 -e 0.01 -m 8 -b 1
'_EOF_'
    # << keep emacs happy
chmod a+x blastSome

# Make gensub2 file
cat << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
para check
para push ... etc ...
# Completed: 7749 of 7749 jobs
# CPU time in finished jobs:      82022s    1367.03m    22.78h    0.95d  0.003 y
# IO & Wait Time:                 21982s     366.37m     6.11h    0.25d  0.001 y
# Average job time:                  13s       0.22m     0.00h    0.00d
# Longest job:                      174s       2.90m     0.05h    0.00d
# Submission to last job:          1439s      23.98m     0.40h    0.02d

# Load into database.  
ssh hgwdev
cd /cluster/data/hg17/bed/geneSorter/blastp/dm1/run/out
hgLoadBlastTab hg17 dmBlastTab -maxPer=1 *.tab
#	row count went from 29322 to 29341

####  Blat knownGene proteins to determine exons (braney 2004-06-20)
    ssh hgwdev
    cd /cluster/data/hg17/bed
    mkdir blat.hg17KG.2004-06-20
    rm blat.hg17KG
    ln -s  blat.hg17KG.2004-06-20 blat.hg17KG
    cd blat.hg17KG
    pepPredToFa hg17 knownGenePep known.fa
    grep ">" known.fa | sed "s/>//" > kgName.lst
    kgName hg17 kgName.lst kg.mapNames
    ssh kk
    cd /cluster/data/hg17/bed/blat.hg17KG
    cat << '_EOF_' > blatSome
#!/bin/csh -fe
/cluster/bin/i386/blat -t=dnax -q=prot -out=pslx $1 $2 $3
'_EOF_'
    # << keep emacs happy
    chmod +x blatSome
    ls -1S /scratch/hg/gs.18/build35/bothMaskedNibs/*.nib > human.lst
    mkdir kgfa
    cd kgfa
    faSplit sequence ../known.fa 3000 kg
    cd ..
    ls -1S kgfa/*.fa > kg.lst
    cat << '_EOF_' > blatGsub
#LOOP
blatSome $(path1) {check in line $(path2)} {check out line psl/$(root1)/$(root2).psl}
#ENDLOOP
'_EOF_'
    # << keep emacs happy
    gensub2 human.lst kg.lst blatGsub blatSpec
    mkdir psl
    cd psl
    foreach i (`cat ../human.lst`)
	mkdir `basename $i .nib`
    end
    cd ..
    para create blatSpec
    para push

# Completed: 133676 of 133676 jobs
# CPU time in finished jobs:   29661130s  494352.16m  8239.20h  343.30d  0.941 y
# IO & Wait Time:               2181179s   36352.99m   605.88h   25.25d  0.069 y
# Average job time:                 238s       3.97m     0.07h    0.00d
# Longest job:                   105972s    1766.20m    29.44h    1.23d

    ssh eieio
    cd /cluster/data/hg17/bed/blat.hg17KG
    pslSort dirs raw.psl /tmp psl/*
    pslReps -nohead -minCover=0.9 -minAli=0.9 raw.psl cooked.psl /dev/null
    pslUniq cooked.psl hg17KG.psl
    pslxToFa hg17KG.psl hg17KG_ex.fa -liftTarget=genome.lft -liftQuery=protein.lft

# BLASTZ MM4 (DONE - 2004-06-22 - Hiram)
    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.mm4.2004-06-21
    cd /cluster/data/hg17/bed
    ln -s  blastz.mm4.2004-06-21 blastz.mm4
    cd blastz.mm4

    cat << '_EOF_' > DEF
# human vs. mouse
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/scratch/mus/mm4/softNib
# RMSK not currently used
SEQ2_RMSK=/scratch/mus/mm4/rmsk
# FLAG not currently used
SEQ2_FLAG=-rodent
SEQ2_SMSK=/scratch/mus/mm4/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.mm4

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm4
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
# Completed: 43648 of 43648 jobs
# CPU time in finished jobs:   16448001s  274133.36m  4568.89h  190.37d  0.522 y
# IO & Wait Time:                751666s   12527.76m   208.80h    8.70d  0.024 y
# Average job time:                 394s       6.57m     0.11h    0.00d
# Longest job:                     8323s     138.72m     2.31h    0.10d
# Submission to last job:         44244s     737.40m    12.29h    0.51d

    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.mm4
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       3925s      65.42m     1.09h    0.05d  0.000 y
# IO & Wait Time:                  6208s     103.46m     1.72h    0.07d  0.000 y
# Average job time:                  30s       0.50m     0.01h    0.00d
# Longest job:                      289s       4.82m     0.08h    0.00d
# Submission to last job:          2800s      46.67m     0.78h    0.03d

    #	Third cluster run to convert lav's to axt's
    #	Does not work on kki since /scratch on the iservers is not the
    #	same as /scratch on the other clusters.
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm4
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 45 of 46 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       2389s      39.82m     0.66h    0.03d  0.000 y
# IO & Wait Time:                 13374s     222.90m     3.71h    0.15d  0.000 y
# Average job time:                 350s       5.84m     0.10h    0.00d
# Longest job:                     1426s      23.77m     0.40h    0.02d
# Submission to last job:          1440s      24.00m     0.40h    0.02d

    #	chr19 failing due to out of memory.  Run this job individually
    #	on kolossus, adjusting the location of the nib directories:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.mm4
    sed -e "s/i386/x86_64/g" /cluster/bin/scripts/blastz-chromlav2axt > \
	x86_64-chromlav2axt
    chmod +x x86_64-chromlav2axt
    time ./x86_64-chromlav2axt \
	/cluster/data/hg17/bed/blastz.mm4/lav/chr19 \
	/cluster/data/hg17/bed/blastz.mm4/axtChrom/chr19.axt \
	/cluster/bluearc/scratch/hg/gs.18/build35/bothMaskedNibs \
	/cluster/bluearc/scratch/mus/mm4/softNib
    #	real    24m28.955s
    #	user    6m40.990s
    #	sys     1m16.500s

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4
    mkdir -p pslChrom
    set tbl = "blastzMm4"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	This takes more than an hour.  You can shorten this by changing
    #	that command to a simple echo, put the results into a file,
    #	split the file into four parts and run the four files as shell
    #	scripts on eieio to have four processes running at the same
    #	time.  Load on eieio gets up to about 20 which is reasonable.

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/pslChrom
    bash
    for F in chr*_blastzMm4.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${F}
	echo "${F} done"
    done
    # this is a 55 minute job
    # exit bash if you are tcsh

    # featureBits on blastzMm3 or 4 will not work on hgwdev, runs out of
    # memory.  But if you reset your ~/.hg.conf to use the read-only
    #	user and contact the hgwdev host, then use the x86_64 featureBits
    # featureBits hg16 blastzMm4
    # 1056761609 bases of 2865248791 (36.882%) in intersection
    # featureBits hg17 blastzMm4
    # 1056201417 bases of 2866216770 (36.850%) in intersection

# CHAIN MM4 BLASTZ (DONE - 2004-06-29 - Hiram)
# redone with the 'axtFilter -notQ_random' removed - 2004-06-23

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kk9
    mkdir -p /cluster/data/hg17/bed/blastz.mm4/axtChain/run1
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastz.mm4/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#  May need -minScore=5000 for all chroms if chr19 won't finish on kolossus

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 /iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/mm4/softNib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 45 of 46 jobs
# CPU time in finished jobs:       6575s     109.58m     1.83h    0.08d  0.000 y
# IO & Wait Time:                  9274s     154.57m     2.58h    0.11d  0.000 y
# Average job time:                 352s       5.87m     0.10h    0.00d
# Longest job:                     3121s      52.02m     0.87h    0.04d
# Submission to last job:          3121s      52.02m     0.87h    0.04d
    #	one job wouldn't finish due to memory usage
    #	run the chr19 job on kolossus, takes an hour, gets up to 4 Gb
    #	memory usage

    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    17m17.639s
    #	user    9m54.240s
    #	sys     1m31.210s
    #	(1.9 Gb result file !)

    time chainSplit chain all.chain
    #	real    27m32.278s
    #	user    9m46.970s
    #	sys     2m45.960s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg17 ${c}_chainMm4 $i
        echo done $c
    end

    #	featureBits hg17 chainMm4
    #	2829135227 bases of 2866216770 (98.706%) in intersection
    #	featureBits hg16 chainMm4
    #	2828363353 bases of 2865248791 (98.713%) in intersection

# NET MM4 (DONE - 2004-06-29 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg17/chrom.sizes \
                        /cluster/data/mm4/chrom.sizes ../preNet/$i
    end

    cd ..
    mkdir n1
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg17/chrom.sizes \
	/cluster/data/mm4/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2504171520, utime 19373 s/100, stime 5906

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    time netClass hNoClass.net hg17 mm4 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/scratch/mus/mm4/linSpecRep.notInHuman
    #	real    19m33.421s
    #	user    10m37.130s
    #	sys     1m45.630s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn mouse.net > mouseSyn.net
    #	real    13m24.885s
    #	user    7m37.100s
    #	sys     1m5.760s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg17 netMm4 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg17 syntenyNetMm4 stdin
    #	real    44m20.735s
    #	user    15m58.620s
    #	sys     1m58.720s
    # check results
    # featureBits hg17 netMm4
    #	2824272033 bases of 2866216770 (98.537%) in intersection
    # featureBits hg16 netMm4
    #	2823565051 bases of 2865248791 (98.545%) in intersection

    # featureBits hg17 syntenyNetMm4
    #	2785830955 bases of 2866216770 (97.195%) in intersection
    # featureBits hg16 syntenyNetMm4
    #	2786960572 bases of 2865248791 (97.268%) in intersection

    # Add entries for net and chain to mouse/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    mkdir mouseNet
    time netSplit mouse.net mouseNet
    #	real    12m1.478s
    #	user    8m35.050s
    #	sys     1m7.230s

    #	extract axt's from net, and convert to maf's (DONE - Kate - 2004-06-24)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtChain
    mkdir ../axtNet ../mafNet
cat > makeMaf.csh << '_EOF_'
    foreach f (mouseNet/chr*.net)
        set c = $f:t:r
        echo "netToAxt: $c.net -> $c.axt"
        rm -f ../axtNet/$c.axt
        netToAxt mouseNet/$c.net chain/$c.chain \
	    /cluster/data/hg17/nib /cluster/data/mm4/nib stdout | \
	    axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/mm4/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=mm4.
	echo "Complete: $c.net -> axtNet/$c.axt -> mafNet/$c.maf"
    end
'_EOF_'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/blastz.mm4/axtBest
    cd /cluster/data/hg17/bed/blastz.mm4/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestMm4.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestMm4.psl
	echo "Done: ${c}_blastzBestMm4.psl"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/pslBest
    for I in chr*BestMm4.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits hg17 blastzBestMm4
    #	1017319919 bases of 2866216770 (35.493%) in intersection
    # featureBits hg16 blastzBestMm4
    #	996722004 bases of 2865248791 (34.787%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg17/axtBest/Mm4
     cd /gbdb/hg17/axtBest/Mm4
     ln -s /cluster/data/hg17/bed/blastz.mm4/axtNet/chr*.axt .
     cd /cluster/data/hg17/bed/blastz.mm4/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/hg17/axtBest/Mm4/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('mm4','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
    hgsql hg17 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql hg17 < axtInfoInserts.sql

# MAKING MOUSE SYNTENY (DONE - 2004-06-29 - Hiram)

ssh hgwdev
mkdir /cluster/data/hg17/bed/syntenyMm4
cd /cluster/data/hg17/bed/syntenyMm4

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyMm3
cp -p /cluster/data/hg17/bed/syntenyRn3/*.pl .

./syntenicBest.pl -db=hg17 -table=blastzBestMm4
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg17 -table=blastzBestMm4
./synteny2bed.pl
#	The five commands above
#	real    220m16.227s
#	user    0m22.940s
#	sys     0m3.960s

#	Used to load this in syntenyMm4, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
#	Need a new name here for the Mm4 to not conflict with Rn3
sed -e 's/ensPhusionBlast/ensRatMm4Hom/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRatMm4Hom.sql
hgLoadBed hg17 ensRatMm4Hom ucsc100k.bed -sqlTable=ensRatMm4Hom.sql
    #	featureBits hg17 ensRatMm4Hom
    #	2549307611 bases of 2866216770 (88.943%) in intersection
    #	featureBits hg16 syntenyMm4
    #	2560252977 bases of 2865248791 (89.355%) in intersection

# MAKING MOUSE AXTTIGHT FROM AXTBEST (DONE - 2004-06-29 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4/axtNet
    mkdir -p ../axtTight
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMm4.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/pslTight
    for I in chr*TightMm4.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly:
    #	featureBits hg17 blastzTightMm4
    #	166569246 bases of 2866216770 (5.811%) in intersection
    #	featureBits hg16 blastzTightMm4
    #	162641577 bases of 2865248791 (5.676%) in intersection

    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm4/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtTight
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm4/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

# BLASTZ MM4 CLEAN UP (DONE - 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm4
    nice rm -rf raw &
    nice rm axtChain/run1/chain/* &
    nice rm -fr axtChain/n1 axtChain/hNoClass.net &
    nice gzip axtChrom/* pslChrom/* lav/*/* axtChain/all.chain axtChain/*.net &


# BLASTZ CHIMP panTro1 (2004-06-21 kate)
# NOTE: Ran with abridge repeats=0, although SMSK was set
# Looked better than running with abridge=1, which had very
# chopped-up alignments

    ssh kk
    cd /cluster/data/hg17/bed
    mkdir -p blastz.panTro1.2004-06-22
    rm -f blastz.panTro1
    cd blastz.panTro1.2004-06-22

    cat << 'EOF' > DEF
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# Specific settings for chimp
BLASTZ_Y=3400
BLASTZ_T=2
BLASTZ_K=4500
BLASTZ_Q=/cluster/data/penn/human_chimp.q

# TARGET: Human
SEQ1_DIR=/scratch/hg/gs.18/build35/bothMaskedNibs
# not used 
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/hg17/linSpecRep.chimp
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Chimp
SEQ2_DIR=/scratch/chimp/panTro1/nib
# not currently used
SEQ2_RMSK=/iscratch/i/chimp/panTro1/linSpecRep.human
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.panTro1.2004-06-22

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'EOF'
    # << this line keeps emacs coloring happy

    # first cluster run: raw blastz alignments
    ssh kk
    bash # if a csh/tcsh user
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
        # 160270 jobs written to batc
    para try, check, push, check, ....

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    bash # if a csh/tcsh user
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
        # 341 jobs
    para try, check, push, etc ...
# CPU time in finished jobs:       3458s      57.63m     0.96h    0.04d  0.000 y
# IO & Wait Time:                 57996s     966.60m    16.11h    0.67d  0.002 y
# Average job time:                 180s       3.00m     0.05h    0.00d
# Longest job:                      483s       8.05m     0.13h    0.01d
# Submission to last job:          1498s      24.97m     0.42h    0.02d

    # third run: lav -> axt -> psl
    ssh kki
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| /cluster/bin/x86_64/lavToAxt stdin \
    /iscratch/i/hg17/bothMaskedNibs /iscratch/i/chimp/panTro1/nib stdout \
| /cluster/bin/x86_64/axtSort stdin ../../axtChrom/$chr.axt 
/cluster/bin/x86_64/axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
  ../../pslChrom/$chr.psl
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    for d in ../lav/chr*; do
      echo "do.csh $d" >> jobList
    done
    para create jobList
        # 46 jobs
    para try, check, push, check
#Completed: 42 of 42 jobs
#Average job time:                  38s       0.64m     0.01h    0.00d
#Longest job:                      147s       2.45m     0.04h    0.00d
#Submission to last job:           147s       2.45m     0.04h    0.00d

    # Load database tables (takes an hour or so)
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/pslChrom
cat > load.csh << 'EOF'
    foreach f (chr*.psl)
	set table = $f:r_blastzPanTro1
	echo "loading ${table}"
	/cluster/bin/i386/hgLoadPsl hg17 -table=$f:r_${table} $f
    end
'EOF'
# << for emacs
    csh load.csh >&! load.log & 
    tail -100f load.log


# CHAIN CHIMP BLASTZ (6/23/04 kate)
    # Run axtChain on little cluster
    # first copy input to bluearc, as eieo bogs down if even mini-cluster
    # gets input from it !?
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    cp -rp axtChrom /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom

    ssh kki
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -fe
set c = $1:r:t
axtChain $1 -scoreScheme=/cluster/data/blastz/human_chimp.q \
        /iscratch/i/hg17/bothMaskedNibs \
        /iscratch/i/chimp/panTro1/nib /tmp/$c.chain.$$ > /tmp/$c.out.$$
set ret = $status
mv -f /tmp/$c.chain.$$ $2
mv -f /tmp/$c.out.$$ $3
exit $status
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # TODO
    rm -fr /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom
    echo "remove after 7/1/04" > /cluster/bluearc/hg17/blastz.panTro1.2004-06-22/axtChrom/README

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    # TODO
    rm run1/chain/*.chain
    echo "remove after 7/1/04" > run1/chain/README

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain hg17 ${c}_chainPanTro1 $i
    end
    # TODO
    featureBits hg16 chainPanTro1Link
        #2627280557 bases of 2865248791 (91.695%) in intersection
    featureBits hg17 chainPanTro1Link
        # 2633869032 bases of 2866216770 (91.894%) in intersection


# NET CHIMP (DONE 2004-6-24 kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    #chainPreNet all.chain ../S1.len ../S2.len stdout \
    #| chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    #| netSyntenic stdin noClass.net

    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=10 ../S1.len ../S2.len human.net chimp.net
    netSyntenic human.net noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    netClass noClass.net hg17 panTro1 human.net

    # Make a 'syntenic' subset:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    # TODO
    #rm noClass.net
    # Make a 'syntenic' subset of these with
    # NOTE: we used -chimpSyn filtering for the reciprocal best nets
    # on hg16 -- perhaps should use for nets here as well
    netFilter -chimpSyn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netPanTro1 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 netSyntenyPanTro1 stdin
    # Add entries for chainPanTro1, netPanTro1, syntenyPanTro1 to 
    # human/hg17 trackDb


# GENERATE CHIMP MAF FOR MULTIZ FROM NET (IN PROGRESS 2004-06-24 kate)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    netSplit human.net net

    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.panTro1.2004-06-22/axtChain
    mkdir axtNet mafNet
cat > makeMaf.csh << 'EOF'
foreach f (axtChain/net/*.net)
    set c = $f:t:r
    netToAxt $f axtChain/chain/$c.chain /cluster/data/hg17/nib \
        /cluster/data/panTro1/nib stdout | axtSort stdin axtNet/$c.axt
    axtToMaf axtNet/$c.axt  \
        /cluster/data/hg17/chrom.sizes /cluster/data/panTro1/chrom.sizes \
        mafNet/$c.maf -tPrefix=hg17. -qPrefix=panTro1.
    end
'EOF'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log
    # TODO


# RESCORE CHICKEN BLASTZ (DONE 6/23/04 angie)
    # Webb noticed low scores when using non-default BLASTZ_Q scoring matrix 
    # and repeats abridged --
    # PSU's restore_rpts program rescored alignments with default matrix 
    # instead of BLASTZ_Q matrix.  Rescore them here so the chainer sees 
    # the higher scores:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    mkdir axtChrom.rescore
    foreach f (axtChrom/chr*.axt)
      axtRescore -scoreScheme=/cluster/data/blastz/HoxD55.q \
        $f axtChrom.rescore/$f:t
    end
    mv axtChrom axtChrom.preRescore
    mv axtChrom.rescore axtChrom


# CHAIN CHICKEN BLASTZ (DONE 6/23/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -minScore=5000 $1 \
    /iscratch/i/hg17/bothMaskedNibs \
    /iscratch/i/galGal2/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # axtChrom/chr18_random.axt is empty, so the {out line +} check failed:
#Completed: 45 of 46 jobs
#Crashed: 1 jobs
#Average job time:                  46s       0.76m     0.01h    0.00d
#Longest job:                      273s       4.55m     0.08h    0.00d
#Submission to last job:           519s       8.65m     0.14h    0.01d

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain hg17 ${c}_chainGalGal2 $i
    end


# NET CHICKEN BLASTZ (DONE 6/23/04 angie)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    netClass noClass.net hg17 galGal2 human.net

    # Make a 'syntenic' subset:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netGalGal2 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 netSyntenyGalGal2 stdin
    # Add entries for chainGalGal2, netGalGal2, syntenyGalGal2 to 
    # human/hg17 trackDb


# GENERATE GALGAL2 MAF FOR MULTIZ FROM NET (DONE 6/23/04 angie)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    netSplit human.net net
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/hg17/nib \
        /cluster/data/galGal2/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.hg.maf
      axtToMaf $f \
            /cluster/data/hg17/chrom.sizes /cluster/data/galGal2/chrom.sizes \
            $maf -tPrefix=hg17. -qPrefix=galGal2.
    end


# MAKE VSGALGAL2 DOWNLOADABLES (DONE 6/23/04 angie)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.galGal2.2004-06-14/axtChain
    ln all.chain chicken.chain
    zip /cluster/data/hg17/zip/chicken.chain.zip chicken.chain
    rm chicken.chain
    ln human.net chicken.net
    zip /cluster/data/hg17/zip/chicken.net.zip chicken.net
    rm chicken.net
    ln humanSyn.net chickenSyn.net
    zip /cluster/data/hg17/zip/chickenSyn.net.zip chickenSyn.net
    rm chickenSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/hg17/vsGalGal2
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsGalGal2
    mv /cluster/data/hg17/zip/chicken*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# 8-WAY MULTIZ MULTIPLE ALIGNMENT WITH MM5 (WORKING 2004-07-13 kate)
    ssh eieio
    set multizDir = multiz.2004-07-13
    set workingDir = /cluster/bluearc/hg17/$multizDir
    ln -s $workingDir /cluster/bluearc/hg17/multiz8way.mm5
    mkdir -p $workingDir
    mkdir -p /cluster/data/hg17/bed/$multizDir
    cd /cluster/data/hg17/bed/$multizDir

# wrapper script for multiz
    # NOTE: first arg is pairwise, 2nd arg is multiple (to add to) 
    # NOTE: next time, modify script so it only needs one arg -- saves the
    # multiple dirname in a file for use by the next run
    cat << 'EOF' > doMultiz.csh
#!/bin/csh -fe
mkdir -p $3:h
/cluster/bin/penn/multiz $1 $2 - > $3
'EOF'
# << for emacs
    cat << 'EOF' > gsub
#LOOP
../doMultiz.csh {check in line /cluster/bluearc/hg17/multiz.2004-07-13/$(dir1)/$(root2).maf} {check in line /cluster/bluearc/hg17/multiz.2004-07-13/$(root1)/$(root2).maf} {check out line+ /cluster/bluearc/hg17/multiz.2004-07-13/$(root1)$(dir1)/$(root2).maf}
#ENDLOOP
'EOF'
# << for emacs
    chmod +x doMultiz.csh

    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-07-13

    # copy mafs to bluearc -- chimp
    mkdir $workingDir/panTro1
    cp /cluster/data/hg17/bed/blastz.panTro1/mafNet/*.maf \
                $workingDir/panTro1
    ls $workingDir/panTro1/*.maf > chrom.lst

    # mouse
    mkdir $workingDir/mm5
    cp /cluster/data/hg17/bed/blastz.mm5/mafNet/chr*.maf $workingDir/mm5

    # rat
    mkdir $workingDir/rn3
    cp /cluster/data/hg17/bed/blastz.rn3/mafNet/chr*.maf $workingDir/rn3

    # dog
    mkdir $workingDir/canFam1
    foreach f (/cluster/data/hg17/bed/blastz.canFam1.2004-07-08/mafNet/chr*.maf)
        set c = $f:r:r:t
        echo $c
        cp $f $workingDir/canFam1/$c.maf
    end

    # chicken
    mkdir $workingDir/galGal2
    foreach f (/cluster/data/hg17/bed/blastz.galGal2/mafNet/chr*.maf)
        set c = $f:r:r:t
        cp $f $workingDir/galGal2/$c.maf
    end

    # fugu
    mkdir $workingDir/fr1
    cp /cluster/data/hg17/bed/blastz.fr1/mafNet/chr*.maf $workingDir/fr1

    # zebrafish
    mkdir $workingDir/danRer1
    cp /cluster/data/hg17/bed/blastz.danRer1.swap/mafNet/chr*.maf \
                        $workingDir/danRer1

    # first multiz - add in mm5 mouse to human/chimp
    # 
    ssh kki
    set multizDir = multiz.2004-07-13
    set workingDir = /cluster/bluearc/hg17/$multizDir
    cd /cluster/data/hg17/bed/$multizDir
    mkdir run.mm5
    cd run.mm5
    echo "mm5/panTro1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
# CPU time in finished jobs:       6620s     110.33m     1.84h    0.08d  0.000 y
# IO & Wait Time:                  3685s      61.42m     1.02h    0.04d  0.000 y
# Average job time:                 224s       3.73m     0.06h    0.00d
# Longest job:                      819s      13.65m     0.23h    0.01d
# Submission to last job:          1474s      24.57m     0.41h    0.02d
    cd ..

    # rat
    mkdir run.rn3
    cd run.rn3
    echo "rn3/panTro1mm5" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # dog
    mkdir run.canFam1
    cd run.canFam1
    echo "canFam1/panTro1mm5rn3" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ../

    # chicken
    mkdir run.galGal2
    cd run.galGal2
    echo "galGal2/panTro1mm5rn3canFam1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # no alignment file for chr18_random -- create one so we can create jobList
    touch $workingDir/galGal2/chr18_random.maf
    para create jobList
        # 46 jobs
    para try, check, push, check
    # 1 crashed job for empty file chr18_random
    cd ..

    # fugu
    mkdir run.fr1
    cd run.fr1
    echo "fr1/panTro1mm5rn3canFam1galGal2" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    touch /cluster/bluearc/hg17/multiz.2004-07-13/fr1/chr6_hla_hap1.maf
    para create jobList
        # 46 jobs
    para try, check, push, check
    # 1 crashed job for empty file chr6_hla_hap1
    cd ..

    # zebrafish
    mkdir run.danRer1
    cd run.danRer1
    echo "danRer1/panTro1mm5rn3canFam1galGal2fr1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # copy 8-way mafs to build directory
    ssh eieio
    set multizDir = multiz.2004-07-13
    set workingDir = /cluster/bluearc/hg17/$multizDir
    ln -s $workingDir/panTro1mm5rn3canFam1galGal2fr1danRer1 $workingDir/maf
    cd /cluster/data/hg17/bed/multiz.2004-07-13
    mkdir maf
    cp $workingDir/maf/*.maf maf


# PHYLO-HMM CONSERVATION FOR 8-WAY MM5 (WORKING 2004-07-20 kate)

    ssh eieio
    set path = ($path /cluster/bin/phast)
    cd /cluster/data/hg17/bed/multiz.2004-07-13
    mkdir cons
    cd cons


    #break up the genome-wide MAFs into pieces
    mkdir /cluster/bluearc/hg17/chrom
    cd /cluster/data/hg17
    foreach f (`cat chrom.lst`)
        echo $f
        cp $f/*.fa /cluster/bluearc/hg17/chrom
    end

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-07-13/cons
    mkdir run.split
    cd run.split
    set WINDOWS = /cluster/bluearc/hg17/multiz.2004-07-13/cons/WINDOWS
    rm -fr $WINDOWS
    mkdir -p $WINDOWS
    cat << 'EOF' > doSplit.sh
#!/bin/sh

PHAST=/cluster/bin/phast
FA_SRC=/cluster/bluearc/hg17/chrom
WINDOWS=/cluster/bluearc/hg17/multiz.2004-07-13/cons/WINDOWS

maf=$1
c=`basename $maf .maf`
echo $c
mkdir -p /scratch/msa_split
${PHAST}/msa_split $maf -i MAF -M ${FA_SRC}/$c.fa -O hg17,panTro1,mm5,rn3,canFam1,galGal2,fr1,danRer1 -w 1000000,0 -r /scratch/msa_split/$c -o SS -I 1000 -B 5000
[ $? -eq 0 ] || exit 1
echo "Copying..."
cd /scratch/msa_split
for file in $c.*.ss ; do gzip -c $file > ${WINDOWS}/$file.gz ; done
[ $? -eq 0 ] || exit 1
rm -f /scratch/msa_split/$c.*.ss
echo "Done copying"
echo "Done" >> ${WINDOWS}/$c.done
'EOF'
# << for emacs
    chmod +x doSplit.sh
    rm -f jobList
    foreach file (/cluster/bluearc/hg17/multiz.2004-07-13/maf/*.maf) 
        set c = $file:t:r
	echo "doSplit.sh $file {check out line+ $WINDOWS/$c.done}" >> jobList
    end
    
    para create jobList
        # 46 jobs
    para try
    para check
    para push
        # 2 crashed jobs -- due to no alignments in input maf
        # chr18_random, chr6_hla_hap1
    cd ..

    # generate conservation scoring using phastCons
    ssh kk
    cd /cluster/data/hg17/bed/multiz.2004-07-13/cons
    mkdir run.cons
    cd run.cons

    # Model provided by Adam, based on merge of separately generated trees for
    #   mammals (HPMRC), and non-mammals (using substitution rates for
    #   conserved regions only
cat > hg17panTro1mm5rn3canFam1galGal2fr1danRer1.mod << 'EOF'
ALPHABET: A C G T
ORDER: 0
SUBST_MOD: REV
NRATECATS: 10
ALPHA: 4.658942
TRAINING_LNL: -6889216721.159384
BACKGROUND: 0.294633 0.205082 0.205189 0.295097
RATE_MAT:
  -0.865237    0.159990    0.554805    0.150442
   0.229851   -1.194646    0.168269    0.796526
   0.796651    0.168182   -1.194919    0.230086
   0.150205    0.553556    0.159985   -0.863747
   TREE: (((((1:0.006523,2:0.007997):0.103779,(3:0.104867,4:0.078911):0.265676):0.0196,5:0.2051):0.3906,6:0.5293):0.5557,(7:0.9558,8:0.9375):0.5557);
'EOF'
# << for emacs
    
    # set up wrapper for phastCons
    # WARNING: watch load on fileserver -- may need to write output 
    # elsewhere and copy back
    cat << '_EOF_' > doPhastCons.sh
#!/bin/sh

PHAST=/cluster/bin/phast
TMP=/tmp/phastCons

file=$1
root=`basename $file .ss.gz`
chrom=`echo $root | awk -F\. '{print $1}'`

mkdir -p $TMP 
zcat $file | $PHAST/phastCons - hg17panTro1mm5rn3canFam1galGal2fr1danRer1.mod --nrates 40 --suppress-missing --transitions 0.080,0.008 --quiet > $TMP/$root.pp
[ $? -eq 0 ] || exit 1
mkdir -p PHASTCONS/$chrom
gzip -c $TMP/$root.pp > PHASTCONS/$chrom/$root.pp.gz
[ $? -eq 0 ] || exit 1
rm $TMP/$root.pp
'_EOF_'
# << for emacs
    chmod u+x doPhastCons.sh
    rm -fr PHASTCONS

    # the --transitions arguments are approximate maximum likelihood
    # estimates obtained by running the program *without* --cut-params
    # (causes estimation by EM) on five randomly selected 1M bp
    # windows.  All estimates were in the same ballpark (took a rough average)

    # set up cluster job
    rm -f jobList
    foreach f (/cluster/bluearc/hg17/multiz.2004-07-13/cons/WINDOWS/*.ss.gz)
        set b = $f:t:r:r
        set c = $b:r
        echo "doPhastCons.sh $f {check out exists+ /cluster/data/hg17/bed/multiz.2004-07-13/cons/run.cons/PHASTCONS/$c/$b.pp.gz}">> jobList
    end
    para create jobList
        # 2932 jobs
    para try ; para push ... etc.

    # now create tracks
    # load wiggle table
    ssh eieio
    cd /cluster/data/hg17/bed/multiz.2004-07-13/cons
    cd run.cons
    mkdir -p PHASTCONS/wib
    bash
    for dir in PHASTCONS/chr* ; do \
	echo $dir ;\
	chr=`basename $dir` ;\
	zcat `ls $dir/*.pp.gz | sort -t\. -k2,2n` | \
	    wigAsciiToBinary -chrom=$chr \
	    -wibFile=PHASTCONS/wib/${chr}_multiz8wayCons stdin ;\
    done


    # load data for track name "multiz8way"
    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz.2004-07-13/cons
    cd run.cons
    hgLoadWiggle hg17 multiz8wayCons -pathPrefix=/gbdb/hg17/multiz8way/wib \
                PHASTCONS/wib/chr*_phastCons.wig
    mkdir -p /gbdb/hg17/multiz8way/wib
    rm -f /gbdb/hg17multiz8way/wib/chr*phastCons.wib
    ln -s `pwd`/PHASTCONS/wib/*.wib /gbdb/hg17/multiz8way/wib
    chmod 775 . PHASTCONS PHASTCONS/wib
    chmod 664 PHASTCONS/wib/*.wib
# GOT HERE
    
    # load multiz maf tables 
    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz.2004-07-13
    set mafDir = /gbdb/hg17/multiz8way/maf
    set table = multiz8way
    mkdir -p $mafDir/$table
    ln -s `pwd`/maf/*.maf $mafDir/$table
    cd maf
    hgLoadMaf hg17 -warn multiz8way -pathPrefix=$mafDir/$table

    # load blastz maf tables
    # TODO: change mafWiggle to use db names instead of species names
    # in speciesOrder 
    # link files into /gbdb table dir
    ln -s /cluster/data/hg17/bed/blastz.panTro1/mafNet $mafDir/chimp_netBlastz
    ln -s /cluster/data/hg17/bed/blastz.mm5/mafNet $mafDir/mouse_netBlastz
    ln -s /cluster/data/hg17/bed/blastz.rn3/mafNet $mafDir/rat_netBlastz
    ln -s /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/mafNet $mafDir/dog_netBlastz
    ln -s /cluster/data/hg17/bed/blastz.galGal2/mafNet $mafDir/chicken_netBlastz
    ln -s /cluster/data/hg17/bed/blastz.fr1/mafNet $mafDir/fugu_netBlastz
    ln -s /cluster/data/hg17/bed/blastz.danRer1.swap/mafNet $mafDir/zebrafish_netBlastz

    # remove empty file, disliked by hgLoadMaf
    rm chicken/chr18_random.maf
    rm fugu/chr6_hla_hap1.maf

    # load tables
    foreach s (chimp mouse rat dog chicken fugu zebrafish)
        set table = ${s}_netBlastz
        echo "$s $mafDir/$table"
        ~kate/bin/i386/hgLoadMaf hg17 -warn ${s}_netBlastz -pathPrefix=$mafDir/$table
    end

    # trackDb entry:
# track multiz8way
# shortLabel Conservation
# longLabel Chimp/Mouse/Rat/Dog/Chicken/Fugu/Zebrafish Multiz Alignments & PhyloHMM Cons
# group compGeno
# priority 149
# visibility pack
#color 0, 10, 100
# type wigMaf 0.0 1.0
# maxHeightPixels 100:40:11
# wiggle multiz8wayCons
# yLineOnOff Off
# autoScaleDefault Off
# pairwise netBlastz
# speciesOrder chimp mouse rat dog chicken fugu zebrafish


# 8-WAY MULTIZ MULTIPLE ALIGNMENT (WORKING 2004-07-12 kate)
# NOTE: this will be replaced with MM5 8-WAY, above
    ssh eieio
    set multizDir = multiz.2004-07-12
    set workingDir = /cluster/bluearc/hg17/$multizDir
    ln -s $workingDir /cluster/bluearc/hg17/multiz8way
    mkdir -p $workingDir
    mkdir -p /cluster/data/hg17/bed/$multizDir
    cd /cluster/data/hg17/bed/$multizDir

# wrapper script for multiz
    # NOTE: first arg is pairwise, 2nd arg is multiple (to add to) 
    # NOTE: next time, modify script so it only needs one arg -- saves the
    # multiple dirname in a file for use by the next run
    cat << 'EOF' > doMultiz.csh
#!/bin/csh -fe
mkdir -p $3:h
/cluster/bin/penn/multiz $1 $2 - > $3
'EOF'
# << for emacs
    cat << 'EOF' > gsub
#LOOP
../doMultiz.csh {check in line /cluster/bluearc/hg17/multiz.2004-07-12/$(dir1)/$(root2).maf} {check in line /cluster/bluearc/hg17/multiz.2004-07-12/$(root1)/$(root2).maf} {check out line+ /cluster/bluearc/hg17/multiz.2004-07-12/$(root1)$(dir1)/$(root2).maf}
#ENDLOOP
'EOF'
# << for emacs
chmod +x doMultiz.csh
ls /cluster/bluearc/hg17/multiz.2004-07-12/canFam1/*.maf > chrom.lst

    # reuse chimp/mouse/rat alignments from previous (7way) multiz
    ln -s /cluster/bluearc/hg17/multiz.2004-06-24/panTro1mm4rn3 $workingDir

    # add in dog
    mkdir $workingDir/canFam1
    foreach f (/cluster/data/hg17/bed/blastz.canFam1.2004-07-08/mafNet/chr*.maf)
        set c = $f:r:r:t
        echo $c
        cp $f $workingDir/canFam1/$c.maf
    end

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-07-12
    mkdir run.canFam1
    cd run.canFam1
    echo "canFam1/panTro1mm4rn3" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check

    # chicken
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-07-12
    mkdir $workingDir/galGal2
    foreach f (/cluster/data/hg17/bed/blastz.galGal2/mafNet/chr*.maf)
        set c = $f:r:r:t
        cp $f $workingDir/galGal2/$c.maf
    end

    ssh kki
    set workingDir = /cluster/bluearc/hg17/multiz.2004-07-12
    cd /cluster/data/hg17/bed/multiz.2004-07-12
    mkdir run.galGal2
    cd run.galGal2
    echo "galGal2/panTro1mm4rn3canFam1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # no alignment file for chr18_random -- create one so we can create jobList
    touch $workingDir/galGal2/chr18_random.maf
    para create jobList
        # 46 jobs
    para try, check, push, check
    # 1 crashed job for empty file chr18_random
    cd ..

    # fugu
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-07-12
    mkdir $workingDir/fr1
    cp /cluster/data/hg17/bed/blastz.fr1/mafNet/chr*.maf $workingDir/fr1

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-07-12
    mkdir run.fr1
    cd run.fr1
    echo "fr1/panTro1mm4rn3canFam1galGal2" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    touch /cluster/bluearc/hg17/multiz.2004-07-12/fr1/chr6_hla_hap1.maf
    para create jobList
        # 46 jobs
    para try, check, push, check
    # 1 crashed job for empty file chr6_hla_hap1
    cd ..

    # zebrafish
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-07-12
    mkdir $workingDir/danRer1
    cp /cluster/data/hg17/bed/blastz.danRer1.swap/mafNet/chr*.maf $workingDir/danRer1

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-07-12
    mkdir run.danRer1
    cd run.danRer1
    echo "danRer1/panTro1mm4rn3canFam1galGal2fr1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # 8-WAY mafs are now in $workingDir/panTro1mm4rn3canFam1galGal2fr1danRer1


# PHYLO-HMM CONSERVATION FOR 8-WAY (WORKING kate)

    # tree model (acs)
    
    # first estimate a model for the mammals
    ssh eieio
    cd /cluster/bluearc/hg17/multiz.2004-07-13/panTro1mm5rn3canFam1

    # collect sufficient stats (takes maybe an hour)
    for file in *.maf ; do echo $file ; msa_view -i MAF $file -o SS --order hg17,panTro1,rn3,mm5,canFam1 > `basename $file .maf`.ss ; done
    ls *.ss | grep -v chr6_hla_hap2 > files
    msa_view '*files' --aggregate hg17,panTro1,rn3,mm5,canFam1 -i SS -o SS > all.ss

    # estimate model, with rate variation (takes about a minute)
    phyloFit all.ss --nrates 10 --tree "(((hg17,panTro1),(rn3,mm5)),canFam1)" --alpha 4.4 --EM --log log -i SS --out-root hprmc-rev-dg

    cat hprmc-rev-dg.mod
#ALPHABET: A C G T
#ORDER: 0
#SUBST_MOD: REV
#NRATECATS: 10
#ALPHA: 4.658942
#TRAINING_LNL: -6889216721.159384
#BACKGROUND: 0.294633 0.205082 0.205189 0.295097
#RATE_MAT:
#  -0.865237    0.159990    0.554805    0.150442
#   0.229851   -1.194646    0.168269    0.796526
#   0.796651    0.168182   -1.194919    0.230086
#   0.150205    0.553556    0.159985   -0.863747
#TREE: (((1:0.006523,2:0.007997):0.103779,(3:0.104867,4:0.078911):0.265676):0.112364,5:0.112364);

    # now add chicken and fish by hand, as follows

    # obtain branch lengths to chicken, fugu, and zfish from CFTR
    # tree, http://www.cse.ucsc.edu/~acs/cftr25_hybrid.ps

    # Let species 6 be chicken, species 7 be fugu, and species 8 be
    # zfish.  Summing branch lengths as necessary, we get:

#(...):0.3906,6:0.5293):0.5557,(7:0.9558,8:0.9375):0.5557);

    # We also have to root the branch between dog and the
    # primates/rodents.  We'll use the total estimated branch length
    # of 0.112364*2 = 0.2247 (rounded), but we'll use the proportions
    # from the CFTR tree, 0.0193/0.2012.  This gives us a branch of
    # 0.0196 to the primates/rodents and a branch of 0.2051 to dog.

    # putting it all together, we get:

#TREE: (((((1:0.006523,2:0.007997):0.103779,(3:0.104867,4:0.078911):0.265676):0.0196,5:0.2051):0.3906,6:0.5293):0.5557,(7:0.9558,8:0.9375):0.5557);

    # make a copy of the .mod file and replace the TREE line with the
    # one above.  The new one is called
    # hg17panTro1rn3mm5canFam1galGal2fr1danRer1.mod
    
# 7-WAY MULTIZ MULTIPLE ALIGNMENT (2004-06-24 kate)

    ssh eieio
    set multizDir = multiz.2004-06-24
    set workingDir = /cluster/bluearc/hg17/$multizDir
    mkdir -p $workingDir
    mkdir -p /cluster/data/hg17/bed/$multizDir
    cd /cluster/data/hg17/bed/$multizDir

    # wrapper script for multiz
    # NOTE: first arg is pairwise, 2nd arg is multiple (to add to) 
    # NOTE: next time, modify script so it only needs one arg -- saves the
    # multiple dirname in a file for use by the next run
    cat << 'EOF' > doMultiz.csh
#!/bin/csh -fe
mkdir -p $3:h
/cluster/bin/penn/multiz $1 $2 - > $3
'EOF'
# << for emacs
    cat << 'EOF' > gsub
#LOOP
../doMultiz.csh {check in line /cluster/bluearc/hg17/multiz.2004-06-24/$(dir1)/$(root2).maf} {check in line /cluster/bluearc/hg17/multiz.2004-06-24/$(root1)/$(root2).maf} {check out line+ /cluster/bluearc/hg17/multiz.2004-06-24/$(root1)$(dir1)/$(root2).maf}
#ENDLOOP
'EOF'
# << for emacs
    chmod +x doMultiz.csh

    # copy over first mafs
    mkdir $workingDir/panTro1
    cp /cluster/data/hg17/bed/blastz.panTro1/mafNet/*.maf \
                $workingDir/panTro1
    ls /cluster/bluearc/hg17/multiz.2004-06-24/panTro1/*.maf > chrom.lst

    # first multiz - add mouse in to human/chimp
    mkdir $workingDir/mm4
    cp /cluster/data/hg17/bed/blastz.mm4/mafNet/chr*.maf $workingDir/mm4

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.mm4
    cd run.mm4
    echo "mm4/panTro1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       6637s     110.62m     1.84h    0.08d  0.000 y
# IO & Wait Time:                  3788s      63.13m     1.05h    0.04d  0.000 y
# Average job time:                 227s       3.78m     0.06h    0.00d
# Longest job:                      950s      15.83m     0.26h    0.01d
# Submission to last job:          3058s      50.97m     0.85h    0.04d

    # rat
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/rn3
    cp /cluster/data/hg17/bed/blastz.rn3/mafNet/chr*.maf $workingDir/rn3

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.rn3
    cd run.rn3
    echo "rn3/panTro1mm4" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # chicken
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/galGal2
    foreach f (/cluster/data/hg17/bed/blastz.galGal2/mafNet/chr*.maf)
        set c = $f:r:r:t
        cp $f $workingDir/galGal2/$c.maf
    end

    ssh kki
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.galGal2
    cd run.galGal2
    echo "galGal2/panTro1mm4rn3" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # no alignment file for chr18_random -- create one so we can create jobList
    touch $workingDir/galGal2/chr18_random
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # fugu
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/fr1
    cp /cluster/data/hg17/bed/blastz.fr1/mafNet/chr*.maf $workingDir/fr1

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.fr1
    cd run.fr1
    echo "fr1/panTro1mm4rn3galGal2" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    touch /cluster/bluearc/hg17/multiz.2004-06-24/fr1/chr6_hla_hap1.maf
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # zebrafish
    ssh eieio
    set workingDir = /cluster/bluearc/hg17/multiz.2004-06-24
    mkdir $workingDir/danRer1
    cp /cluster/data/hg17/bed/blastz.danRer1.swap/mafNet/chr*.maf $workingDir/danRer1

    ssh kki
    cd /cluster/data/hg17/bed/multiz.2004-06-24
    mkdir run.danRer1
    cd run.danRer1
    echo "danRer1/panTro1mm4rn3galGal2fr1" > species.lst
    gensub2 species.lst ../chrom.lst ../gsub jobList
    # create empty alignment file for missing one (no alignments)
    para create jobList
        # 46 jobs
    para try, check, push, check
    cd ..

    # 7-WAY mafs are now in $workingDir/panTro1mm4rn3galGal2fr1/danRer1


# PHYLO-HMM CONSERVATION FOR 7-WAY (2004-06-25 kate)

    ssh eieio
    set path = ($path /cluster/bin/phast)

    #Create "sufficient statistics" (SS) file from maf
    cd /cluster/data/hg17/bed/multiz
    mkdir cons
    cd cons

    # Model provided by Adam, based on 25-way plus HMR
cat > hg17panTro1mm4rn3galGal2fr1danRer1.mod << 'EOF'
ALPHABET: A C G T 
ORDER: 0
SUBST_MOD: REV
NRATECATS: 10
ALPHA: 4.43
BACKGROUND: 0.286083 0.213573 0.213691 0.286652 
RATE_MAT:
  -0.891523    0.166770    0.574850    0.149902 
   0.223389   -1.146311    0.153784    0.769137 
   0.769591    0.153699   -1.147159    0.223869 
   0.149605    0.573055    0.166888   -0.889548 
TREE: ((((1:0.0056,2:0.0057):0.1043,(3:0.076303,4:0.083043):0.2753):0.4099,5:0.5293):0.5557,(6:0.9558,7:0.9375):0.5557);
'EOF'

    #break up the genome-wide MAFs into pieces
    mkdir /cluster/bluearc/hg17/chrom
    cd /cluster/data/hg17
    foreach f (`cat chrom.lst`)
        echo $f
        cp $f/*.fa /cluster/bluearc/hg17/chrom
    end

    cd /cluster/data/hg17/bed/multiz/cons
    # NOTE: next time, split to WINDOWS dir directly on bluearc
    cat << 'EOF' > doSplit.sh
#!/bin/sh

PHAST=/cluster/bin/phast
# hg17 chrom fasta files
FA_SRC=/cluster/bluearc/hg17/chrom
WINDOWS=/cluster/data/hg17/bed/multiz/cons/WINDOWS

maf=$1
c=`basename $maf .maf`
echo $c
mkdir -p /scratch/msa_split
${PHAST}/msa_split $maf -i MAF -M ${FA_SRC}/$c.fa -O hg17,panTro1,mm4,rn3,galGal2,fr1,danRer1 -w 1000000,0 -r /scratch/msa_split/$c -o SS -I 1000 -B 5000
echo "Copying..."
cd /scratch/msa_split
for file in $c.*.ss ; do gzip -c $file > ${WINDOWS}/$file.gz ; done
rm -f /scratch/msa_split/$c.*.ss
echo "Done copying"
'EOF'
    chmod +x doSplit.sh
    mkdir -p WINDOWS
    rm -f WINDOWS/* jobList
    foreach file (/cluster/bluearc/hg17/multiz/7way/*.maf) 
	echo "./doSplit.sh $file" >> jobList
    end
    
    para create jobList
        # 46 jobs
    para try
    para check
    para push

    # conservation scoring using phastCons
    ssh kk
    cd /cluster/data/hg17/bed/multiz/cons
    mkdir run.cons
    cd run.cons
    
    # set up wrapper for phastCons
    cat << '_EOF_' > doPhastCons
#!/bin/sh

PHAST=/cluster/bin/phast
TMP=/tmp/phastCons

file=$1
root=`basename $file .ss.gz`
chrom=`echo $root | awk -F\. '{print $1}'`

mkdir -p $TMP 
zcat $file | $PHAST/phastCons - hg17panTro1mm4rn3galGal2fr1danRer1.mod --rates-cut 1 --nrates 40 --suppress-missing --cut-params 0.080,0.008 --quiet > $TMP/$root.pp
mkdir -p PHASTCONS/$chrom
gzip -c $TMP/$root.pp > PHASTCONS/$chrom/$root.pp.gz
rm $TMP/$root.pp
'_EOF_'
    chmod u+x doPhastCons

    # the --cut-params arguments are approximate maximum likelihood
    # estimates obtained by running the program *without* --cut-params
    # (causes estimation by EM) on five randomly selected 1M bp
    # windows.  All estimates were in the same ballpark (took a rough average)

    # set up cluster job
    ssh eieio
    cd /cluster/data/hg17/bed/multiz/cons
    mkdir -p /cluster/bluearc/hg17/multiz/cons/WINDOWS
    cp WINDOWS/*.ss.gz /cluster/bluearc/hg17/multiz/cons/WINDOWS
    # TODO cleanup
    rm -fr WINDOWS

    ssh kk
    cd /cluster/data/hg17/bed/multiz/cons
    cd run.cons
    rm -f jobList
    foreach f (/cluster/bluearc/hg17/multiz/cons/WINDOWS/*.ss.gz)
        echo $f
        echo doPhastCons $f >> jobList
    end
    para create jobList
        # 2932 jobs
    para try ; para push ... etc.
    
    # now create tracks
    # load wiggle table
    ssh eieio
    cd /cluster/data/hg17/bed/multiz/cons
    cd run.cons
    mkdir -p PHASTCONS/wib
    bash
    for dir in PHASTCONS/chr* ; do \
	echo $dir ;\
	chr=`basename $dir` ;\
	zcat `ls $dir/*.pp.gz | sort -t\. -k2,2n` | \
	    wigAsciiToBinary -chrom=$chr \
	    -wibFile=PHASTCONS/wib/${chr}_phastCons stdin ;\
    done

    # load data for track name "multiz7way"
    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz/cons
    cd run.cons
    hgLoadWiggle hg17 phastCons -pathPrefix=/gbdb/hg17/multiz7way/wib \
                PHASTCONS/wib/chr*_phastCons.wig
    mkdir -p /gbdb/hg17/multiz7way/wib
    rm -f /gbdb/hg17multiz7way/wib/chr*phastCons.wib
    ln -s `pwd`/PHASTCONS/wib/*.wib /gbdb/hg17/multiz7way/wib
    chmod 775 . PHASTCONS PHASTCONS/wib
    chmod 664 PHASTCONS/wib/*.wib
    
    # load multiz maf tables 
    # TODO: move mafs to /cluster/data (need to free up space on store5)
    ssh hgwdev
    cd /cluster/data/hg17/bed/multiz
    set mafDir = /gbdb/hg17/multiz7way/maf
    set table = multiz7way
    mkdir -p $mafDir/$table
    ln -s /cluster/bluearc/hg17/multiz/7way/*.maf $mafDir/$table
    hgLoadMaf hg17 -warn multiz7way -pathPrefix=$mafDir/$table
        # Indexing and tabulating /gbdb/hg17/multiz7way/maf/chr14.maf
        # 11489 warnings
        # TODO: check this out

    # load blastz maf tables
    # TODO: change mafWiggle to use db names instead of species names
    # in speciesOrder 
    # TODO: move mafs to /cluster/data (need to free up space on store5)
    cd /cluster/bluearc/hg17/multiz
    ln -s panTro1 chimp
    ln -s mm4 mouse
    ln -s rn3 rat
    ln -s galGal2 chicken
    # remove empty file, disliked by hgLoadMaf
    rm chicken/chr18_random.maf
    ln -s fr1 fugu
    rm fugu/chr6_hla_hap1.maf
    ln -s danRer1 zebrafish
    foreach s (chimp mouse rat chicken fugu zebrafish)
        set table = ${s}_netBlastz
        #mkdir -p $mafDir/$table
        #ln -s /cluster/bluearc/hg17/multiz/$s/*.maf $mafDir/$table
        echo $s
        ~kate/bin/i386/hgLoadMaf hg17 -warn \
                ${s}_netBlastz -pathPrefix=$mafDir/$table
    end

    # trackDb entry:
# track multiz7way
# shortLabel Conservation
# longLabel Human/Chimp/Mouse/Rat/Chicken/Fugu/Zebrafish Multiz Alignments & PhyloHMM Cons
# group compGeno
# priority 149
# visibility pack
#color 0, 10, 100
# type wigMaf 0.0 1.0
# maxHeightPixels 100:40:11
# wiggle phastCons
# yLineOnOff Off
# autoScaleDefault Off
# pairwise netBlastz
# speciesOrder chimp mouse rat chicken fugu zebrafish


    # GOT HERE
    # tweak scores and names of predictions
    cat PREDICTIONS/*/*.bed | sed 's/id //' | \
	awk '{printf "%s\t%s\t%s\tlod=%d\t%d\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", \
	    $1, $2, $3, $5, 147.49 * log($5) - 240.34, $6, $7, $8, $9, \
	    $10, $11, $12}' > all.bed
    hgLoadBed hg17 phastConsElements all.bed

    # Scores are transformed as follows, for a reasonable-looking 
    # "spectrum".  Let x_max be the maximum score (here
    # x_max  = 4490) and let x_med be the median score (here x_med =
    # 39).  The  scores are transformed via the function f(x) = a *
    # log x + b, s.t. f(x_med) = 300 and f(x_max) = 1000.  Solving
    # for a and b, you get b = (300 log x_max - 1000 log x_med) /
    # (log x_max - log x_med), a = (1000 - b) / log x_max.  Here a =
    # 147.49, b = -240.34

#track phastCons
#shortLabel phastCons 
#longLabel phastCons Conservation Score, Human/Chimp/Mouse/Rat/Chicken
#group compGeno
#priority 103
#visibility hide
#color 0,10,100
#maxHeightPixels 40
#type wig 0.0 1.0
#autoScaleDefault off

#track phastConsElements
#shortLabel phastConsElements
#longLabel phastCons Conserved Elements, Human/Chimp/Mouse/Rat/Chicken
#group compGeno
#priority 104
#visibility hide
#spectrum on
#color 0,60,120
#altColor 200,220,255
#exonArrows off
#type bed 12 .


# PRODUCING GENSCAN PREDICTIONS (DONE - 2004-07-08 - Hiram)
#	Needed to download a new binary for this run.  Our Linux systems
#  XXX - I thought a new binary was needed.  Turned out it was already
#  here in our hg3rdParty CVS project.  All of this discussed here can
#  be simply fetched from cvs:  cvs co hg3rdParty/genscanlinux
#	have been updated since the last time, the old binary would not
#	run.  Go to: http://genes.mit.edu/GENSCAN.html
#	and then to: http://genes.mit.edu/license.html
#	Fill in the license agreement and you can then pick up the
#	README and the Linux version: genscanlinux.tar.uue.tgz
#	To uudecode that file, go to one of the Solaris home machines
#	and use the uudecode command:
#	uudecode genscanlinux.tar.uue.tgz
#	That produces the file: genscanlinux.tar
#	Which contains the files:
# drwxr-xr-x chris/burgelab    0 2003-02-17 11:48:44 ./
# -rw-r--r-- chris/burgelab 219056 2000-09-07 12:39:26 ./Arabidopsis.smat
# -rw-r--r-- chris/burgelab   6622 2000-09-07 12:39:26 ./HUMRASH
# -rw-r--r-- chris/burgelab    849 2000-09-07 12:39:26 ./HUMRASH.sample
# -rw-r--r-- chris/burgelab 219050 2000-09-07 12:39:26 ./HumanIso.smat
# -rw-r--r-- chris/burgelab 155735 2000-09-07 12:39:26 ./Maize.smat
# -rw-r--r-- chris/burgelab  24465 2000-09-07 12:39:26 ./README
# -rw-r--r-- chris/burgelab   6344 2000-09-07 12:39:27 ./HUMRASH.ps
# -rwxr-xr-x chris/burgelab 126365 2003-02-17 11:48:44 ./genscan
#
#	I placed these currently in: /cluster/home/hiram/GENSCAN/
#	I'll check with Angie where it should properly live ...
#  XXX - it already lives in 'cvs co hg3rdParty/genscanlinux'
#  These instructions should simple check it out right here in
#  bed/genscan and make the gsub command refer to these copies.

    ssh hgwdev
    mkdir /cluster/data/hg17/bed/genscan
    cd /cluster/data/hg17/bed/genscan
    cvs co hg3rdParty/genscanlinux

    ssh eieio
    cd /cluster/data/hg17/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequencable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    bash
    for f in `cat /cluster/data/hg17/contig.lst`
    do
      egrep '[ACGT]' /cluster/data/hg17/$f.masked > /dev/null
	if [ $? = 0 ]; then
	    echo /cluster/data/hg17/$f.masked >> genome.list
	fi
    done
    # exit your bash shell if you are [t]csh ...
    #	This egrep matched all the contigs in hg17.  I guess none of
    #	them are complete Ns* at this point.

    # Log into kki (not kk !).  kki is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kki
    cd /cluster/data/hg17/bed/genscan
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push ... etc ...
# Completed: 379 of 380 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:      79998s    1333.30m    22.22h    0.93d  0.003 y
# IO & Wait Time:                  2989s      49.82m     0.83h    0.03d  0.000 y
# Average job time:                 219s       3.65m     0.06h    0.00d
# Longest job:                     2999s      49.98m     0.83h    0.03d
# Submission to last job:          8324s     138.73m     2.31h    0.10d

    #	Running the single failed job on kolossus with a smaller window:
/cluster/bin/x86_64/gsBig /cluster/data/hg17/5/NT_006576/NT_006576.fa.masked \
        gtf/NT_006576.fa.gtf -trans=pep/NT_006576.fa.pep \
        -subopt=subopt/NT_006576.fa.bed -exe=hg3rdParty/genscanlinux/genscan \
        -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2000000

    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # something lower.  In build33, this was 22/NT_011519
    #  In build34 there were NO failures !

    # Convert these to chromosome level files as so:     
    ssh eieio
    cd /cluster/data/hg17/bed/genscan
    $HOME/bin/i386/liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/N*.gtf
    $HOME/bin/i386/liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft \
	warn subopt/N*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/hg17/bed/genscan
    ldHgGene hg17 genscan genscan.gtf
    #	35 minute job
    #	Read 42807 transcripts in 325994 lines in 1 files
    #	  42807 groups 46 seqs 1 sources 1 feature types

    hgPepPred hg17 generic genscanPep genscan.pep
    #	Processing genscan.pep
    hgLoadBed hg17 genscanSubopt genscanSubopt.bed
    #	Reading genscanSubopt.bed
    #	Loaded 517157 elements of size 6
    #	Sorted
    #	Creating table definition for 
    #	Saving bed.tab
    #	Loading hg17

    #	featureBits hg17 genscan
    #	55323340 bases of 2866216770 (1.930%) in intersection

    #	featureBits hg16 genscan
    #	55333689 bases of 2865248791 (1.931%) in intersection

    #	featureBits hg17 genscanSubopt
    #	55986178 bases of 2866216770 (1.953%) in intersection
    #	featureBits hg16 genscanSubopt
    #	56082952 bases of 2865248791 (1.957%) in intersection

    #	Should be zero intersection with rmsk
    #	featureBits -chrom=chr1 hg17 genscan rmsk
    #	794 bases of 222827847 (0.000%) in intersection


# EXTRACT LINEAGE-SPECIFIC REPEATS FOR DOG (DONE 7/1/04 angie)
    ssh eieio
    cd /cluster/bluearc/scratch/hg/gs.18/build35/rmsk
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Even though we already have the human-mouse linSpecReps,
    # extractLinSpecReps requires two columns of DateRepsinRMoutput.pl
    # additions.  So add mouse, then ignore it.  
    # Dog in extra column 1, Mouse in extra column 2
    foreach outfl ( *.out )
        echo "$outfl"
        /cluster/bluearc/RepeatMasker/DateRepsinRMoutput.pl \
          ${outfl} -query human -comp dog -comp mouse
    end
    # Now extract dog (extra column 1), ignore mouse.
    cd /cluster/bluearc/scratch/hg/gs.18/build35
    mkdir linSpecRep.notInDog
    foreach f (rmsk/*.out_dog_mus)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInDog/$base.out.spec
    end
    # Clean up.
    rm /cluster/bluearc/scratch/hg/gs.18/build35/rmsk/*.out_dog_mus
    # Ask cluster-admin for an rsync.


# BLASTZ DOG (CANFAM1) (DONE 7/8/04 angie)
    ssh kk
    # space is awful tight on store4 -- use store7.  
    mkdir -p /cluster/store7/hg17/bed/blastz.canFam1.2004-07-08
    ln -s /cluster/store7/hg17/bed/blastz.canFam1.2004-07-08 \
      /cluster/data/hg17/bed/
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    # Use default (Human-Mouse) settings for starters.
    cat << '_EOF_' > DEF
# human vs. dog
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Default
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human
SEQ1_DIR=/scratch/hg/gs.18/build35/bothMaskedNibs
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/scratch/hg/gs.18/build35/linSpecRep.notInDog
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Dog
SEQ2_DIR=/scratch/hg/canFam1/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/scratch/hg/canFam1/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.canFam1.2004-07-08

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # first cluster run: raw blastz alignments
    ssh kk
    bash # if a csh/tcsh user
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
    para try, check, push, check, ....
    # Moving the human chr19 jobs up to the top of the jobList probably 
    # would have shaved 4 hours off the total time!  It was almost done 
    # after 6 hours, except for a few chr19 stragglers.
#Completed: 93775 of 93775 jobs
#Average job time:                 202s       3.37m     0.06h    0.00d
#Longest job:                    17806s     296.77m     4.95h    0.21d
#Submission to last job:         35523s     592.05m     9.87h    0.41d

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    bash # if a csh/tcsh user
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
    para try, check, push, etc ...
#Completed: 341 of 341 jobs
#Average job time:                  36s       0.61m     0.01h    0.00d
#Longest job:                      302s       5.03m     0.08h    0.00d
#Submission to last job:          1143s      19.05m     0.32h    0.01d

    # third run: lav -> axt
    # (if non-default BLASTZ_Q is used in the future, put axtRescore in 
    # the pipe after lavToAxt)
    ssh kki
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| $HOME/bin/x86_64/lavToAxt stdin \
    /iscratch/i/gs.18/build35/bothMaskedNibs /iscratch/i/canFam1/nib stdout \
| $HOME/bin/x86_64/axtSort stdin ../../axtChrom/$chr.axt 
$HOME/bin/x86_64/axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
  ../../pslChrom/$chr.psl
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 46 of 46 jobs
#Average job time:                 300s       5.00m     0.08h    0.00d
#Longest job:                     1669s      27.82m     0.46h    0.02d
#Submission to last job:          1689s      28.15m     0.47h    0.02d


# CHAIN DOG BLASTZ (DONE 7/9/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in line+ $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 \
    /iscratch/i/gs.18/build35/bothMaskedNibs \
    /iscratch/i/canFam1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 46 of 46 jobs
#Average job time:                 266s       4.43m     0.07h    0.00d
#Longest job:                     3578s      59.63m     0.99h    0.04d
#Submission to last job:          3578s      59.63m     0.99h    0.04d
    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Lots of chaff with scores in the 3000's.  Many very-high-scoring 
    # chains.  So filter the chain down somewhat...
    mv all.chain all.chain.unfiltered
    chainFilter -minScore=5000 all.chain.unfiltered > all.chain
    rm chain/*
    chainSplit chain all.chain
    gzip all.chain.unfiltered

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg17 ${c}_chainCanFam1 $i
    end
    # Coverage is significantly higher than mouse:
    featureBits hg17 -chrom=chr1 chainCanFam1Link
#123999291 bases of 222827847 (55.648%) in intersection
# before filtering: 124750124 bases of 222827847 (55.985%) in intersection
    featureBits hg17 -chrom=chr1 chainMm5Link
#83773012 bases of 222827847 (37.595%) in intersection


# NET DOG BLASTZ (DONE 7/9/04 angie)
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    netClass noClass.net hg17 canFam1 dog.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn dog.net > dogSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    netFilter -minGap=10 dog.net |  hgLoadNet hg17 netCanFam1 stdin
    netFilter -minGap=10 dogSyn.net | hgLoadNet hg17 syntenyNetCanFam1 stdin
    # Add entries for chainCanFam1, netCanFam1 to human/hg17 trackDb


# MAKE VSCANFAM1 DOWNLOADABLES (TODO 7/9/04 angie)
    ssh kksilo
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    ln all.chain dog.chain
    zip /cluster/data/hg17/zip/dog.chain.zip dog.chain
    rm dog.chain
    zip /cluster/data/hg17/zip/dog.net.zip dog.net
    zip /cluster/data/hg17/zip/dogSyn.net.zip dogSyn.net
    # Mike Zody asked for raw blastz in chain format, so figure out some 
    # way to translate axt or psl to chain and put it out there.  
    # Actually, it's probably just hg16-canFam1 that he wants for now -- ?
    # Ask when we get to this point.

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/hg17/vsCanFam1
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsCanFam1
    mv /cluster/data/hg17/zip/dog*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# GENERATE CANFAM1 MAF FOR MULTIZ FROM NET (DONE 7/9/04 angie)
    ssh kksilo
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08/axtChain
    netSplit dog.net net
    cd /cluster/data/hg17/bed/blastz.canFam1.2004-07-08
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/hg17/nib \
        /cluster/data/canFam1/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.hg.maf
      axtToMaf $f \
            /cluster/data/hg17/chrom.sizes /cluster/data/canFam1/chrom.sizes \
            $maf -tPrefix=hg17. -qPrefix=canFam1.
    end


# BLASTZ MM5 (DONE - 2004-06-22 - Hiram)
    ssh kk
    mkdir -p /cluster/data/hg17/bed/blastz.mm5.2004-07-01
    cd /cluster/data/hg17/bed
    ln -s  blastz.mm5.2004-07-01 blastz.mm5
    cd blastz.mm5

    cat << '_EOF_' > DEF
# human vs. mouse
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/scratch/mus/mm5/softNib
# RMSK not currently used
SEQ2_RMSK=/scratch/mus/mm5/rmsk
# FLAG not currently used
SEQ2_FLAG=-rodent
SEQ2_SMSK=/scratch/mus/mm5/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/hg17/bed/blastz.mm5

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm5
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
# Completed: 44330 of 44330 jobs
# CPU time in finished jobs:   16250628s  270843.80m  4514.06h  188.09d  0.515 y
# IO & Wait Time:                387936s    6465.60m   107.76h    4.49d  0.012 y
# Average job time:                 375s       6.26m     0.10h    0.00d
# Longest job:                     4417s      73.62m     1.23h    0.05d
# Submission to last job:         43754s     729.23m    12.15h    0.51d

    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastz.mm5
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       2189s      36.48m     0.61h    0.03d  0.000 y
# IO & Wait Time:                  7714s     128.57m     2.14h    0.09d  0.000 y
# Average job time:                  29s       0.48m     0.01h    0.00d
# Longest job:                      165s       2.75m     0.05h    0.00d
# Submission to last job:           830s      13.83m     0.23h    0.01d


    #	Third cluster run to convert lav's to axt's
    #	Does not work on kki since /scratch on the iservers is not the
    #	same as /scratch on the other clusters.
    ssh kk
    cd /cluster/data/hg17/bed/blastz.mm5
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 45 of 46 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       1638s      27.30m     0.46h    0.02d  0.000 y
# IO & Wait Time:                 12068s     201.13m     3.35h    0.14d  0.000 y
# Average job time:                 305s       5.08m     0.08h    0.00d
# Longest job:                     1124s      18.73m     0.31h    0.01d
# Submission to last job:          2519s      41.98m     0.70h    0.03d
    #	chr19 takes too long, the axtSort becomes too large and the poor
    #	node ends up swapping forever.  When you are down to that last
    #	job running, stop it and go to kolossus.
    #	Adjusting the location of the nib directories, and fixing the
    #	MACHTYPE on the commands in the blastz script:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.mm5
    sed -e "s/i386/x86_64/g" /cluster/bin/scripts/blastz-chromlav2axt > \
	x86_64-chromlav2axt
    chmod +x x86_64-chromlav2axt
    time ./x86_64-chromlav2axt \
	/cluster/data/hg17/bed/blastz.mm5/lav/chr19 \
	/cluster/data/hg17/bed/blastz.mm5/axtChrom/chr19.axt \
	/cluster/bluearc/scratch/hg/gs.18/build35/bothMaskedNibs \
	/cluster/bluearc/scratch/mus/mm5/softNib
    #	real    7m41.719s
    #	user    2m2.850s
    #	sys     0m23.070s

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5
    mkdir -p pslChrom
    set tbl = "blastzMm5"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	This takes more than an hour.  You can shorten this by changing
    #	that command to a simple echo, put the results into a file,
    #	split the file into four parts and run the four files as shell
    #	scripts on eieio to have four processes running at the same
    #	time.  Load on eieio gets up to about 20 which is reasonable.

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/pslChrom
    bash		#	for tcsh users
    for F in chr*_blastzMm5.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${F}
	echo "${F} done"
    done
    # this is a 40 minute job
    # exit bash if you are tcsh

    # featureBits on blastzMm3 or 4 will not work on hgwdev, runs out of
    # memory.  But if you reset your ~/.hg.conf to use the read-only
    #	user and contact the hgwdev host, then use the x86_64 featureBits
    # featureBits hg16 blastzMm5
    # 1056761609 bases of 2865248791 (36.882%) in intersection
    # featureBits hg17 blastzMm5
    #	1052077141 bases of 2866216770 (36.706%) in intersection
    # featureBits hg17 blastzMm4
    #  1056201417 bases of 2866216770 (36.850%) in intersection

# CHAIN MM5 BLASTZ (DONE - 2004-07-02 - Hiram)

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kki
    mkdir -p /cluster/data/hg17/bed/blastz.mm5/axtChain/run1
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastz.mm5/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#  May need -minScore=5000 for all chroms if chr19 won't finish on kolossus

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 /iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/mus/mm5/softNib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 46 of 46 jobs
# CPU time in finished jobs:       4856s      80.94m     1.35h    0.06d  0.000 y
# IO & Wait Time:                 20083s     334.71m     5.58h    0.23d  0.001 y
# Average job time:                 542s       9.04m     0.15h    0.01d
# Longest job:                     2929s      48.82m     0.81h    0.03d
# Submission to last job:          2929s      48.82m     0.81h    0.03d


    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    8m42.853s
    #	user    5m59.100s
    #	sys     0m40.320s

    time chainSplit chain all.chain
    #	real    10m52.224s
    #	user    5m52.360s
    #	sys     0m34.870s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain/chain
    bash	#	for tcsh users
    for i in *.chain
    do
        c=${i/.chain/}
        hgLoadChain hg17 ${c}_chainMm5 $i
        echo done $c
    done
    # exit bash if you are tcsh
    #	This is a 50 minute job

    #	featureBits hg17 chainMm5
    #	2834490112 bases of 2866216770 (98.893%) in intersection
    #	featureBits hg17 chainMm4
    #	2829135227 bases of 2866216770 (98.706%) in intersection
    #	featureBits hg16 chainMm4
    #	2828363353 bases of 2865248791 (98.713%) in intersection

# NET MM5 (DONE - 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    mkdir preNet
    cd chain
    bash	#	for tcsh users
    for i in *.chain
    do
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg17/chrom.sizes \
                        /cluster/data/mm5/chrom.sizes ../preNet/$i
    done
    # exit bash if you are tcsh
    #	15 minute job

    cd ..
    mkdir n1
    cd preNet
    bash	#	for tcsh users
    for i in *.chain
    do
      n=${i/.chain/}.net
      echo primary netting $i $n
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg17/chrom.sizes \
	/cluster/data/mm5/chrom.sizes ../n1/$n /dev/null
    done
    # exit bash if you are tcsh
    #	9 minute job

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2546110464, utime 16327 s/100, stime 3546

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    time netClass hNoClass.net hg17 mm5 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/scratch/mus/mm5/linSpecRep.notInHuman
    #	real    16m38.098s
    #	user    11m38.490s
    #	sys     1m48.470s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn mouse.net > mouseSyn.net
    #	real    12m3.701s
    #	user    8m44.180s
    #	sys     1m1.610s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg17 netMm5 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg17 syntenyNetMm5 stdin

    # check results
    #	featureBits hg17 netMm5
    #	2830625630 bases of 2866216770 (98.758%) in intersection

    #	featureBits hg17 netMm4
    #	2824272033 bases of 2866216770 (98.537%) in intersection
    # featureBits hg16 netMm5
    #	2823565051 bases of 2865248791 (98.545%) in intersection

    # featureBits hg17 syntenyNetMm5
    #	2799194300 bases of 2866216770 (97.662%) in intersection
    # featureBits hg17 syntenyNetMm4
    #	2785830955 bases of 2866216770 (97.195%) in intersection
    # featureBits hg16 syntenyNetMm5
    #	2786960572 bases of 2865248791 (97.268%) in intersection

    # Add entries for net and chain to mouse/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    mkdir mouseNet
    time netSplit mouse.net mouseNet
    #	real    11m45.243s
    #	user    8m48.490s
    #	sys     1m13.490s

    #	extract axt's from net, and convert to maf's
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtChain
    mkdir ../axtNet ../mafNet
cat > makeMaf.csh << '_EOF_'
#!/bin/csh -ef
    foreach f (mouseNet/chr*.net)
        set c = $f:t:r
        echo "netToAxt: $c.net -> $c.axt"
        rm -f ../axtNet/$c.axt
        netToAxt mouseNet/$c.net chain/$c.chain \
	    /cluster/data/hg17/nib /cluster/data/mm5/nib stdout | \
	    axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/mm5/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=mm5.
	echo "Complete: $c.net -> axtNet/$c.axt -> mafNet/$c.maf"
    end
'_EOF_'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log


    ssh hgwdev
    mkdir /cluster/data/hg17/bed/blastz.mm5/axtBest
    cd /cluster/data/hg17/bed/blastz.mm5/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)
    #	32 minute gzip

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo -n "processing $c.axt -> ${c}_blastzBestMm5.psl ..."
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestMm5.psl
	echo "Done"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/pslBest
    for I in chr*BestMm5.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits hg17 blastzBestMm5
    #	1013348528 bases of 2866216770 (35.355%) in intersection
    # featureBits hg17 blastzBestMm4
    #	1017319919 bases of 2866216770 (35.493%) in intersection
    # featureBits hg16 blastzBestMm5
    #	996722004 bases of 2865248791 (34.787%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg17/axtBest/Mm5
     cd /gbdb/hg17/axtBest/Mm5
     ln -s /cluster/data/hg17/bed/blastz.mm5/axtNet/chr*.axt .
     cd /cluster/data/hg17/bed/blastz.mm5/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/hg17/axtBest/Mm5/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('mm5','Blastz Best in Genome','$chr','$f');" \
         >>! axtInfoInserts.sql
     end
    hgsql hg17 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql hg17 < axtInfoInserts.sql

# SWAP BLASTZ ZEBRAFISH-HUMAN (danRer1-hg17) to HUMAN-ZEBRAFISH (hg17-danRer1)
# USE RESCORED ALIGNMENTS (see makeDanRer1.doc)
# (DONE, 2004-06-22, hartera)

    ssh kolossus
    mkdir /cluster/data/hg17/bed/blastz.danRer1.swap
    cd /cluster/data/hg17/bed/blastz.danRer1.swap
    # use rescored axtChrom from blastzHg17 on danRer1
    set aliDir = /cluster/data/danRer1/bed/blastz.hg17
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSplitByTarget stdin unsorted
    # Sort the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    du -sh $aliDir/axtChrom unsorted axtChrom
# 19G     /cluster/data/danRer1/bed/blastz.hg17/axtChrom
# 19G     unsorted

    rm -r unsorted

# CHAIN ZEBRAFISH (danRer1) BLASTZ (DONE, 2004-06-23, hartera)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/hg17/bed/blastz.danRer1.swap
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/hg17/bed/blastz.danRer1.swap/axtChrom/*.axt \
                    > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'

    # << this line makes emacs coloring happy

# Reuse gap penalties from hg16 vs chicken run.
    cat << '_EOF_' > ../../chickenHumanTuned.gap
tablesize^V     11
smallSize^V     111
position^V      1^V     2^V     3^V     11^V    111^V   2111^V  12111^V 32111^V 72111^V 152111^V        252111
qGap^V  325^V   360^V   400^V   450^V   600^V   1100^V  3600^V  7600^V  15600^V 31600^V 56600
tGap^V  325^V   360^V   400^V   450^V   600^V   1100^V  3600^V  7600^V  15600^V 31600^V 56600
bothGap^V       625^V   660^V   700^V   750^V   900^V   1400^V  4000^V  8000^V  16000^V 32000^V 57000
'_EOF_'
    # << this line makes emacs coloring happy

cat << '_EOF_' > doChain
#!/bin/csh
axtFilter $1 \
| axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
                      -linearGap=../../chickenHumanTuned.gap \
                      -minScore=5000 stdin \
    /iscratch/i/gs.18/build35/bothMaskedNibs \
    /iscratch/i/danRer1/nib $2 > $3
'_EOF_'
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
# para time
# Completed: 45 of 46 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       3559s      59.32m     0.99h    0.04d  0.000 y
# IO & Wait Time:                   934s      15.56m     0.26h    0.01d  0.000 y
# Average job time:                 100s       1.66m     0.03h    0.00d
# Longest job:                      502s       8.37m     0.14h    0.01d
# Submission to last job:          2969s      49.48m     0.82h    0.03d
# chr19.axt crashed - out of memory so try again on kolossus

    ssh kolossus
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain/run1
    # need to use nibs on bluearc as iscratch not accessible to kolossus
cat << '_EOF_' > doChain2
#!/bin/csh
axtFilter $1 \
| axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
                      -linearGap=../../chickenHumanTuned.gap \
                      -minScore=5000 stdin \
    /cluster/bluearc/hg17/bothMaskedNibs \
    /cluster/bluearc/danRer1/nib $2 >& $3
'_EOF_'
    chmod +x doChain2

    doChain2 \
         /cluster/data/hg17/bed/blastz.danRer1.swap/axtChrom/chr19.axt \
         chain/chr19.chain out/chr19.out
    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg17 ${c}_chainDanRer1 $i
        echo done $c
    end
# tried minScore = 1000 and minScore = 10000 for axtChain
# minScore = 5000 was best for reducing low scoring chains but not reducing 
# overlap with refGene CDS too much

# NET ZEBRAFISH (danRer1) BLASTZ (DONE, 2004-06-24, hartera)
# REMAKE NET WITHOUT ANCIENT REPEATS (DONE, 2004-07-07, hartera)
    ssh kksilo
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
       echo preNetting $i
       /cluster/bin/i386/chainPreNet $i ../../S1.len ../../S2.len \
                                     ../preNet/$i
    end

    cd ..
    mkdir n1
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 ../../S1.len ../../S2.len \
                                 ../n1/$n /dev/null
    end

    cd ..
    mkdir n1
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 ../../S1.len ../../S2.len \
                                 ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin noClass.net
    # memory usage 149086208, utime 868 s/100, stime 173                                                                            
    # Add classification info using db tables:
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain
    # netClass looks for ancient repeats in one of the databases
    # hg17 has this table - hand-curated by Arian
    # this is only for human rodent comparisons so use -noAr option
    mkdir -p /cluster/bluearc/danRer1/linSpecRep.notInHuman
    mkdir -p /cluster/bluearc/hg17/linSpecRep.notInZebrafish
    cp /iscratch/i/gs.18/build35/linSpecRep.notInZebrafish/* \
       /cluster/bluearc/hg17/linSpecRep.notInZebrafish
    cp /iscratch/i/danRer1/linSpecRep.notInHuman/* \
       /cluster/bluearc/danRer1/linSpecRep.notInHuman
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain
    # add -noAr option
    # mkdir old
    # mv zebrafish.net ./old/zebrafish.net.old
    time netClass noClass.net hg17 danRer1 zebrafish.net \
        -tNewR=/cluster/bluearc/hg17/linSpecRep.notInZebrafish \
        -qNewR=/cluster/bluearc/danRer1/linSpecRep.notInHuman -noAr
    # 83.410u 43.650s 3:09.94 66.8%   0+0k 0+0io 198pf+0w
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain
    netFilter -minGap=10 zebrafish.net | hgLoadNet hg17 netDanRer1 stdin

# EXTRACT AXT'S AND MAF'S FROM ZEBRAFISH (danRer1) NET 
# (DONE, 2004-06-24, hartera) used net where hg17 ancient Repeat table used
# sorted axts and remade mafs as multiz needs axts to be sorted
# (DONE, 2004-06-25, kate)
    ssh eieio
    # create axts
    cd /cluster/data/hg17/bed/blastz.danRer1.swap/axtChain
    netSplit zebrafish.net zebrafishNet
    mkdir -p ../axtNet
cat > axtNet.csh << 'EOF'
    foreach f (zebrafishNet/chr*.net)
        set c = $f:t:r
        echo "axtNet on $c"
        netToAxt zebrafishNet/$c.net chain/$c.chain \
        /cluster/data/hg17/nib /cluster/data/danRer1/nib ../axtNet/$c.axt
    echo "Complete: $c.net -> $c.axt"
    end
'EOF'

    chmod +x axtNet.csh
    csh axtNet.csh >&! axtNet.log &
    tail -100f axtNet.log

    # sort axts before making mafs - must be sorted for multiz
    #  (DONE, 2004-05-25, kate)
    cd /cluster/data/hg17/bed/blastz.danRer1.swap
    mv axtNet axtNet.unsorted
    mkdir axtNet
    foreach f (axtNet.unsorted/*.axt)
        set c = $f:t:r
        echo "Sorting $c"
        axtSort $c axtNet/$c.axt
    end

    # create maf
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.danRer1.swap
    cd axtNet
    mkdir ../mafNet

cat > makeMaf.csh << 'EOF'
    foreach f (chr*.axt)
      set maf = $f:t:r.danRer1.maf
      echo translating $f to $maf
      axtToMaf $f \
            /cluster/data/hg17/chrom.sizes /cluster/data/danRer1/chrom.sizes \
            ../mafNet/$maf -tPrefix=hg17. -qPrefix=danRer1.
    end
'EOF'
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log

# MAKING MOUSE SYNTENY (DONE - 2004-07-03 - Hiram)

ssh hgwdev
mkdir /cluster/data/hg17/bed/syntenyMm5
cd /cluster/data/hg17/bed/syntenyMm5

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyMm3
cp -p /cluster/data/hg17/bed/syntenyRn3/*.pl .

./syntenicBest.pl -db=hg17 -table=blastzBestMm5
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg17 -table=blastzBestMm5
./synteny2bed.pl
    #	The five commands above
    #	real    209m28.161s
    #	user    0m21.040s
    #	sys     0m4.100s

#	Used to load this in syntenyMm5, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
#	Need a new name here for the Mm5 to not conflict with Rn3
sed -e 's/ensPhusionBlast/ensRatMm5Hom/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRatMm5Hom.sql
hgLoadBed hg17 ensRatMm5Hom ucsc100k.bed -sqlTable=ensRatMm5Hom.sql
    #	featureBits hg17 ensRatMm5Hom
    #	2649530748 bases of 2866216770 (92.440%) in intersection
    #	featureBits hg17 ensRatMm4Hom
    #	2549307611 bases of 2866216770 (88.943%) in intersection
    #	featureBits hg16 syntenyMm5
    #	2560252977 bases of 2865248791 (89.355%) in intersection

# MAKING MOUSE AXTTIGHT FROM AXTBEST (DONE - 2004-07-02 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5/axtNet
    mkdir -p ../axtTight
    bash	#	for tcsh users
    for I in *.axt
    do
      echo $I
      subsetAxt  $I ../axtTight/$I \
	~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    done
    # exit bash if you are tcsh
    #	An 8 minute job

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    bash	#	for tcsh users
    for I in *.axt
    do
      C=${I/.axt/}
      axtToPsl $I ../S1.len ../S2.len ../pslTight/${C}_blastzTightMm5.psl
      echo "Done: $I -> ${C}_blastzTightMm5.psl"
    done
    # exit bash if you are tcsh

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/pslTight
    for I in chr*TightMm5.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly:
    #	featureBits hg17 blastzTightMm5
    #	165862935 bases of 2866216770 (5.787%) in intersection
    #	featureBits hg17 blastzTightMm4
    #	166569246 bases of 2866216770 (5.811%) in intersection
    #	featureBits hg16 blastzTightMm5
    #	162641577 bases of 2865248791 (5.676%) in intersection

    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastz.mm5/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtTight
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsMm5/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)
    #	4 minute gzip

# BLASTZ MM5 CLEAN UP (DONE 2004-07-02 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastz.mm5
    nice rm -rf raw &
    nice rm -fr axtChain/n1 axtChain/hNoClass.net &
    nice rm axtChain/run1/chain/* &
    nice gzip axtChrom/* pslChrom/* lav/*/* axtChain/all.chain axtChain/*.net &

#  MAKING BLASTZ SELF (DONE - 2004-07-14 - Hiram)

    # The procedure for lineage spec business with self is to simply
    # use the actual repeat masker output for this human assembly as
    # the lineage specific repeats for itself.  Thus, merely make
    # symlinks to the repeat masker out files and name them as expected
    # for blastz.  In this case they are called notInHuman but they
    # really mean InHuman.  Yes, it is confusing, but that's just the
    # nature of the game in this case.

    ssh eieio
    mkdir /cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
    cd /cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
    foreach f (../rmsk/*.fa.out)
	set base = $f:t:r:r
	echo $base.out.spec
	ln -s $f $base.out.spec
    end
    #	Same thing done on iscratch
    #	Not worried about pushing this scratch yet, it will get done
    #	sometime later.  Using the actual /cluster/bluearc/scratch/
    #	location below.

    ssh kk
    mkdir /cluster/data/hg17/bed/blastzSelf.2004-07-01
    cd /cluster/data/hg17/bed
    ln -s blastzSelf.2004-07-01 blastzSelf
    cd blastzSelf

    cat << '_EOF_' > DEF
# human vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Human
SEQ2_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/data/hg17/bed/blastzSelf

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/hg17/bed/blastzSelf
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
    #	you need a -maxPush=200000 on this one, it is more than 100000
    #	jobs the default push limit.  Also be aware of maxQueue limits
    #	on the KK, may need something more than the default of 200000 if
    #	the KK is busy.
XXX - running 2004-07-01 11:26


# LIFTOVER (DROP) CHAINS TO HG16 (IN PROGRESS 2004-07-07 kate)

    # run alignment
    # NOTE: split hg16 to /iscratch/i is doc'ed in makeHg16.doc
    ssh kk
    cd /cluster/data/hg17
    makeLoChain-align hg17 /scratch/hg/gs.18/build35/bothMaskedNibs \
                    hg16 /iscratch/i/gs.17/build34/liftOver/split
    # Created parasol job in bed/blat.hg16.2004-07-07/run
    # 1150 jobs
    cd bed/blat.hg16.2004-07-07/run
    para try
    para check
    para push

    # GOT HERE

    # lift results
    ssh eieio
    cd /cluster/data/hg17
    mkdir -p bed/liftOver
    cd bed/liftOver
    # lift directory defined in makeHg17.doc when split was performed
    makeLoChain-lift hg17 hg16 /cluster/bluearc/hg/gs.17/build34/liftOver/lift
                        >&! lift.log &
    tail -100f lift.log
    # GOT HERE -- error messages in lift log

    # chain alignments
    makeLoChain-chain
    ssh kk

    makeLoChain-net
    makeLoChain-load


# Completed: 116281 of 116281 jobs
# CPU time in finished jobs:   21807388s  363456.46m  6057.61h  252.40d  0.692 y
# IO & Wait Time:               2319383s   38656.39m   644.27h   26.84d  0.074 y
# Average job time:                 207s       3.46m     0.06h    0.00d
# Longest job:                    22063s     367.72m     6.13h    0.26d
# Submission to last job:         83402s    1390.03m    23.17h    0.97d


    #	Second cluster run to convert the .out's to .lav's
    #	You do NOT want to run this on the big cluster.  It brings
    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/hg17/bed/blastzSelf
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...

# Completed: 341 of 341 jobs
# CPU time in finished jobs:       6344s     105.73m     1.76h    0.07d  0.000 y
# IO & Wait Time:                  5413s      90.22m     1.50h    0.06d  0.000 y
# Average job time:                  34s       0.57m     0.01h    0.00d
# Longest job:                      505s       8.42m     0.14h    0.01d
# Submission to last job:          4521s      75.35m     1.26h    0.05d

    #	Third cluster run to convert lav's to axt's

    #	These self alignments do not work well as the usual third cluster job.
    #	Instead, a specialized job here that includes a DropSelf
    #	operation, and in individual lav pieces to avoid out of memory
    #	problems during axtSort
    ssh kki
    cd /cluster/data/hg17/bed/blastzSelf
    mkdir axtChrom run.2
    cd run.2
    cat << '_EOF_' > runLavToAxt.sh
#!/bin/sh

BASE=/cluster/data/hg17/bed/blastzSelf
SEQ1_DIR=/cluster/bluearc/scratch/hg/gs.18/build35/bothMaskedNibs
SEQ2_DIR=/cluster/bluearc/scratch/hg/gs.18/build35/bothMaskedNibs

CHR=$1
OUT=axtChrom/$CHR.axt
cd ${BASE}/lav/${CHR}
for D in *.lav
do
    smallout=$D.axt
    lavToAxt  $D $SEQ1_DIR $SEQ2_DIR stdout \
	| axtDropSelf stdin stdout \
	| axtSort stdin $smallout
done
cat `ls -1 *.lav.axt | sort -g` > $BASE/$OUT
'_EOF_'
    # << keep emacs coloring happy
    chmod +x runLavToAxt.sh

    cat << '_EOF_' > gsub
#LOOP
./runLavToAxt.sh $(path1) {check out line ../axtChrom/$(path1).axt}
#ENDLOOP
'_EOF_'
    # << keep emacs coloring happy

    ls ../lav > chrList
    gensub2 chrList single gsub jobList
    para create jobList
    para try
    para push
    #	This is a tough load on eieio.  Managable, but the load should
    #	be monitored to make sure it isn't severe.  I saw about 100 to 150
    #	the chr19 job will not finish, even in parts it takes up too
    #	much memory and the node it runs on ends up swapping endlessly.
    #	Need to go to kolossus to do chr19
    para stop
    para recover jobList chr19JobList
    ssh kolossus
    cd /cluster/data/hg17/bed/blastzSelf/run.2
    time ./runLavToAxt.sh chr19
    #	real    43m14.797s
    #	user    12m56.670s
    #	sys     3m13.590s

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf
    mkdir pslChrom
    set tbl = "blastzSelf"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 70 minutes

    # Load database tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastzSelf/pslChrom
    bash # if a csh/tcsh user
    for I in *.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done: ${I}"
    done
    # exit bash if you are tcsh
    #	This is an 80 minute job

    #	Check results
    #	featureBits hg17 blastzSelf
    #	252256266 bases of 2866216770 (8.801%) in intersection
    #	real    40m49.573s
    #	user    21m14.200s
    #	sys     2m10.420s

    #	featureBits hg16 blastzSelf
    #	254410837 bases of 2865248791 (8.879%) in intersection


# CHAIN SELF BLASTZ (DONE - 2004-07-07 - Hiram)

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kki
    mkdir -p /cluster/data/hg17/bed/blastzSelf/axtChain/run1
    cd /cluster/data/hg17/bed/blastzSelf/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg17/bed/blastzSelf/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#  May need -minScore=5000 for all chroms if chr19 won't finish on kolossus

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 /iscratch/i/gs.18/build35/bothMaskedNibs \
	/iscratch/i/gs.18/build35/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 45 of 46 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       8519s     141.98m     2.37h    0.10d  0.000 y
# IO & Wait Time:                  4795s      79.92m     1.33h    0.06d  0.000 y
# Average job time:                 296s       4.93m     0.08h    0.00d
# Longest job:                     2407s      40.12m     0.67h    0.03d
# Submission to last job:          3540s      59.00m     0.98h    0.04d

    #	chr19 did fail, on kolossus, try:
    ssh kolossus
    cd /cluster/data/hg17/bed/blastzSelf/axtChain/run1
    time axtChain /cluster/data/hg17/bed/blastzSelf/axtChrom/chr19.axt \
	/cluster/data/hg17/nib \
	/cluster/data/hg17/nib \
	chain/chr19.chain > out/chr19.out
    #	80 minute job, 1.5 Gb result:
    #	-rw-rw-r--    1 1588795432 Jul  7 21:54 chr19.chain

    # now on the file server, sort chains
    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    27m38.935s
    #	user    23m18.540s
    #	sys     2m39.300s
    #	A 5 Gb file:
    #	-rw-rw-r--    1 5267202936 Jul  7 22:23 all.chain


    time chainSplit chain all.chain
    #	real    29m27.062s
    #	user    22m48.250s
    #	sys     1m57.910s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastzSelf/axtChain/chain
    bash	#	for tcsh users
    for I in *.chain
    do
        c=${I/.chain/}
        hgLoadChain hg17 ${c}_chainSelf $I
        echo done $c
    done
    # exit bash if you are tcsh
    #	This is almost 3 hours to load

    #	featureBits hg17 chainSelf
    #	682833453 bases of 2866216770 (23.824%) in intersection
    #	featureBits hg16 chainSelf
    #	626345319 bases of 2865248791 (21.860%) in intersection

# NET SELF (DONE - 2004-07-13 - Hiram)

    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf/axtChain
    mkdir preNet
    cd chain
    bash	#	for tcsh users
    for I in *.chain
    do
      echo preNetting $I
      /cluster/bin/i386/chainPreNet $I /cluster/data/hg17/chrom.sizes \
                        /cluster/data/hg17/chrom.sizes ../preNet/$I
    done
    #	23 minutes

    cd ..
    mkdir n1
    cd preNet
    for I in *.chain
    do
      N=${I/.chain/}.net
      echo primary netting $I
      /cluster/bin/i386/chainNet $I -minSpace=10 \
	/cluster/data/hg17/chrom.sizes /cluster/data/hg17/chrom.sizes \
	../n1/$N /dev/null
    done
    # exit bash if you are tcsh
    #	5 minute job

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 206442496, utime 3009 s/100, stime 252
    #	memory usage 2510467072, utime 19307 s/100, stime 3181

    ssh hgwdev
    cd /cluster/data/hg17/bed/blastzSelf/axtChain
    time netClass hNoClass.net hg17 hg17 human.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman \
	-qNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInHuman
    #	real    9m32.951s
    #	user    2m42.840s
    #	sys     1m23.460s

    # If things look good do
    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn human.net > humanSyn.net
    #	real    0m29.851s
    #	user    0m27.200s
    #	sys     0m2.120s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastzSelf/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg17 netSelf stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet hg17 syntenyNetSelf stdin

    # check results
    # featureBits hg17 netSelf
    #	620827374 bases of 2866216770 (21.660%) in intersection
    # featureBits hg16 netSelf
    #	563788850 bases of 2865248791 (19.677%) in intersection
    # featureBits hg15 selfNet
    #	749177799 bases of 2866466359 (26.136%) in intersection


    # featureBits hg17 syntenyNetSelf
    #	404535376 bases of 2866216770 (14.114%) in intersection
    # featureBits hg16 syntenyNetSelf
    #	340871322 bases of 2865248791 (11.897%) in intersection

    # Add entries for net and chain to human/hg17 trackDb

    # make net
    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf/axtChain
    mkdir humanNet
    time netSplit human.net humanNet
    #	real    0m52.106s
    #	user    0m43.350s
    #	sys     0m5.170s

    # extract axts from net  - this should be combined with the sort and
    # maf conversion below
    mkdir ../axtNet 
    foreach n (humanNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt humanNet/$c.net chain/$c.chain \
		/cluster/data/hg17/nib \
		/cluster/data/hg17/nib stdout > ../axtNet/$c.axt
	echo "Complete: $c.net -> axtNet/$c.axt"
    end

    # sort axt's and convert to maf format
    mkdir ../mafNet
    foreach f (../axtNet/chr*.axt)
        set c=$f:t:r
        echo $c.axt
        mv ../axtNet/$c.axt ../axtNet/$c.unsorted.axt
        axtSort ../axtNet/$c.unsorted.axt ../axtNet/$c.axt
        rm ../axtNet/$c.unsorted.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/hg17/chrom.sizes /cluster/data/hg17/chrom.sizes \
                ../mafNet/$c.maf -tPrefix=hg17. -qPrefix=hg17.
    end
    # a 3 minute job

    XXXX - ! ! !   WE DO NOT NEED the Best and Tight tracks for Self ! ! !
    ssh hgwdev
    mkdir -p /cluster/data/hg17/bed/blastzSelf/axtBest
    cd /cluster/data/hg17/bed/blastzSelf/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area - XXX Do we need this for Self ?
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastzSelf/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg17/vsSelf/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/hg17/vsSelf/axtNet
    cd /usr/local/apache/htdocs/goldenPath/hg17/vsSelf/axtNet
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestSelf.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestSelf.psl
	echo "Done: ${c}_blastzBestSelf.psl"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/hg17/bed/blastzSelf/pslBest
    bash # if a csh/tcsh user
    for I in chr*BestSelf.psl
    do
	/cluster/bin/i386/hgLoadPsl hg17 ${I}
	echo "done ${I}"
    done
    # exit bash if you are tcsh

    #	check results
    #	featureBits hg17 blastzBestSelf
    #	233978156 bases of 2866216770 (8.163%) in intersection
    #	featureBits hg16 blastzBestSelf
    #	225819219 bases of 2865248791 (7.881%) in intersection

# MAKING HUMAN AXTTIGHT FROM AXTBEST (NOT TO BE DONE - 2004-07-13 - Hiram)
    #	XXXX - ! ! !  DO NOT NEED axtBest for Self alignments
    #	Been done anyway, Robert and Gill like to see it.

# BLASTZ SELF CLEAN UP (DONE - 2004-07-15 - Hiram)
    ssh eieio
    cd /cluster/data/hg17/bed/blastzSelf
    nice rm -rf raw &
    nice rm axtChain/run1/chain/* &
    nice rm -fr axtChain/n1 axtChain/hNoClass.net &
    nice gzip axtChrom/* pslChrom/* lav/*/* axtChain/all.chain axtChain/*.net &

