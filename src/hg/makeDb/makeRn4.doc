#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on the Rattus 
# Norvegicus genome, November 2004 update (Rnor3.4) from Baylor.

# CREATE BUILD DIRECTORY (DONE 1/27/06 angie)
    # df -h /cluster/store*, choose the one with the most space...
    ssh kkstore01
    mkdir /cluster/store9/rn4
    ln -s /cluster/store9/rn4 /cluster/data/rn4


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 1/27/06 angie)
    mkdir /cluster/data/rn4/M
    cd /cluster/data/rn4/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "Rattus norvegicus mitochondrion complete genome".  
    # There are more than one of those... I picked NC_001665 whose gi # is
    # 5835177
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=5835177&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Rattus norvegicus mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# DOWNLOAD SEQUENCE (DONE 1/27/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    mkdir downloads
    cd downloads
    wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/README
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}.fa.gz
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}.fa.qual.gz
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}-random.fa.gz
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}-random.fa.qual.gz
      echo ""
    end
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/contigs/chr{$c}.agp
    end

    mkdir bacs
    cd bacs
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/contigs/chr${c}.contig_bacs.fa.gz
    end
    cd ..

    # Distribute into chrom dirs.
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      mkdir ../$c
      zcat Rnor3.4chr${c}.fa.gz \
      | sed -e 's/^>gnl[|].*[|]/>/' > ../$c/chr${c}.fa
      zcat Rnor3.4chr${c}-random.fa.gz \
      | sed -e 's/^>gnl[|].*[|]/>/' > ../$c/chr${c}_random.fa
      mv chr${c}.agp ../$c/
    end
#mv: cannot stat `chrUn.agp': No such file or directory
    # No agp for Un, nor *_random.... guess we'll have to use hgFakeAgp 
    # to at least get gaps for those.

    # checkAgpAndFa prints out way too much info -- keep the end/stderr only:
    foreach agp (*/chr*.agp)
      set fa = $agp:r.fa
      echo checking consistency of $agp and $fa
      checkAgpAndFa $agp $fa | tail -1
    end
    faSize */chr*.fa
#2834127293 bases (267832528 N's 2566294765 real 2566294765 upper 0 lower) in 45 sequences in 45 files
#Total size: mean 62980606.5 sd 75162894.7 min 16300 (chrM) max 267910886 (chr1) median 6862066
#N count: mean 5951834.0 sd 6940811.4
#U count: mean 57028772.6 sd 68565220.7
#L count: mean 0.0 sd 0.0


# MAKE FAKE AGP WHERE NECESSARY (DONE 1/27/06 angie)
    # In the chromosomal AGP, all gaps are marked "fragment" *except* for 
    # gaps of exactly 50000 which are "clone".  There are gaps of >>50000
    # marked "fragment"!  However, in the chr*_random and chrUn here,
    # that just seems wrong... chrUn has a gap of 2602000, how could that 
    # possibly be bridged?  (Why are they wasting that kind of space?)
    # So just count >= 50000 as "clone no", even though that is not what 
    # they do in their AGP for the chroms.
    ssh kkstore01
    cd /cluster/data/rn4
    foreach f (?{,?}/chr*.fa)
      set agp = $f:r.agp
      if (! -e $agp) then
        echo Faking missing AGP $agp
        hgFakeAgp -minContigGap=50 -minScaffoldGap=50000 $f stdout \
        | sed -e 's/contig/fragment/; s/scaffold/clone/' \
          > $agp
      endif
    end


# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT CONTIGS/GAPS (DONE 1/27/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    foreach agp (*/chr*.agp)
      set fa = $agp:r.fa
      echo splitting $agp and $fa
      cp -p $agp $agp.bak
      cp -p $fa $fa.bak
      splitFaIntoContigs $agp $fa . -nSize=5000000
    end
    # splitFaIntoContigs makes new dirs for _randoms.  Move their contents 
    # back into the main chrom dirs and get rid of the _random dirs.
    foreach d (*_random)
      set base = `echo $d | sed -e 's/_random$//'`
      mv $d/lift/oOut.lst $base/lift/rOut.lst
      mv $d/lift/ordered.lft $base/lift/random.lft
      mv $d/lift/ordered.lst $base/lift/random.lst
      rmdir $d/lift
      mv $d/* $base
      rmdir $d
    end
    # checkAgpAndFa again to get a warm-fuzzy
    foreach agp (*/chr*.agp)
      set fa = $agp:r.fa
      echo checking consistency of $agp and $fa
      checkAgpAndFa $agp $fa | tail -1
    end
    # Make a "pseudo-contig" for processing chrM too:
    mkdir M/chrM_1
    sed -e 's/chrM/chrM_1/' M/chrM.fa > M/chrM_1/chrM_1.fa
    mkdir M/lift
    set mSize=`faSize M/chrM.fa | awk '{print $1;}'`
    echo "chrM_1/chrM_1.fa.out" > M/lift/oOut.lst
    echo "chrM_1" > M/lift/ordered.lst
    echo "0	M/chrM_1	"$mSize"	chrM	"$mSize"" > M/lift/ordered.lft


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 1/27/06 angie)
    # This used to hold scripts -- better to keep them inline here so 
    # they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/rn4/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/rn4/bed


# REPEAT MASKING (DONE 1/30/06 angie)
    # Record RM version used:
    ls -l /cluster/bluearc/RepeatMasker
#lrwxrwxrwx    1 hiram    protein        18 Jan 20 13:13 /cluster/bluearc/RepeatMasker -> RepeatMasker060120/
    cat /cluster/bluearc/RepeatMasker/Libraries/version
#RM database version 20060120
    # Run RepeatMasker on a dummy input, just to make it initialize its 
    # rat libraries once before the cluster run:
    /cluster/bluearc/RepeatMasker/RepeatMasker -spec rat /dev/null
#Building species libraries in: /cluster/bluearc/RepeatMasker060120/Libraries/20060120/rattus

    #- Split contigs into 500kb chunks, at gaps if possible:
    ssh kkstore01
    cd /cluster/data/rn4
    foreach c (?{,?})
      foreach d ($c/chr${c}*_?{,?})
        cd $d
        echo "splitting $d"
        set contig = $d:t
        faSplit gap $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -minGapSize=100
        cd ../..
      end
    end

    #- Make the run directory and job list:
    cd /cluster/data/rn4
    cat << '_EOF_' > jkStuff/RMRat
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/rn4/$2
/bin/cp $2 /tmp/rn4/$2/
cd /tmp/rn4/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -s -spec rat $2
popd
/bin/cp /tmp/rn4/$2/$2.out ./
if (-e /tmp/rn4/$2/$2.tbl) /bin/cp /tmp/rn4/$2/$2.tbl ./
if (-e /tmp/rn4/$2/$2.cat) /bin/cp /tmp/rn4/$2/$2.cat ./
/bin/rm -fr /tmp/rn4/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn4/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn4
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMRat
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach c (?{,?})
      foreach d ($c/chr${c}{,_random}_?{,?})
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/data/rn4/jkStuff/RMRat \
                 /cluster/data/rn4/$d $f \
               '{'check out line+ /cluster/data/rn4/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
      end
    end

    #- Do the run
    ssh kk
    cd /cluster/data/rn4/RMRun
    para create RMJobs
    para make RMJobs; para time | mail -s 'RM cluster run finished' $USER
#Completed: 6487 of 6488 jobs
#Crashed: 1 jobs
#CPU time in finished jobs:   46404794s  773413.24m 12890.22h  537.09d  1.471 y
#IO & Wait Time:                229486s    3824.76m    63.75h    2.66d  0.007 y
#Average job time:                7189s     119.81m     2.00h    0.08d
#Longest finished job:           10699s     178.32m     2.97h    0.12d
#Submission to last job:         86450s    1440.83m    24.01h    1.00d
    # The one crash was due to a divide-by-zero error in ProcessRepeats,
    # on chr1_24_04.fa.  RepeatMasker made chr1_24_04.fa.cat OK, but then 
    # ProcessRepeats died on that when trying to create the .out.  
    # The 050112 version of ProcessRepeats ran OK on the .cat, but the 
    # 050305 and later versions get the divide-by-zero error.  
    # I sent a test case to Robert Hubley on Sunday 1/29 but as of 2pm Mon.
    # I haven't heard back from him yet.  

    # I made what I think is a straightforward fix to get around the 
    # divide-by-0 (there already was a case to handle another denominator
    # term being 0; I just hooked into that), and re-ran ProcessRepeats 
    # like this:
    ssh kolossus
    cd /tmp
    cp /cluster/data/rn4/1/chr1_24/chr1_24_04.out .
    /cluster/bluearc/RepeatMasker/RepeatMasker chr1_24_04.fa
    ~/cb/hg3rdParty/RepeatMasker/ProcessRepeats chr1_24_04.fa.cat
    mv chr1_24_04.fa.out /cluster/data/rn4/1/chr1_24/
    # That is risky -- Robert might provide a fix that has a slightly 
    # different effect, in which case I'll have to redo everything at least 
    # for chr1.  But I'd like to make some progress at least....

    # Update 2/7/06 -- Robert sent a patch for ProcessRepeats (and for 
    # DateRepeats, see below).  Although the patch was not identical to 
    # my patch, the results of ProcessRepeats run on the .cat were identical.
    # So I don't have to redo subsequent steps, whew!

    #- Lift up the 500KB chunk .out's to 5MB ("pseudo-contig") level
    ssh kkstore01
    cd /cluster/data/rn4
    foreach d (*/chr*_?{,?})
      set contig = $d:t
      echo $contig
      liftUp $d/$contig.fa.out $d/$contig.lft warn $d/${contig}_*.fa.out \
        > /dev/null
    end

    #- Lift pseudo-contigs to chromosome level
    foreach c (?{,?})
      echo lifting $c
      cd $c
      if (-e lift/ordered.lft && ! -z lift/ordered.lft) then
        liftUp chr$c.fa.out lift/ordered.lft warn `cat lift/oOut.lst` \
        > /dev/null
      endif
      if (-e lift/random.lft && ! -z lift/random.lft) then
        liftUp chr${c}_random.fa.out lift/random.lft warn `cat lift/rOut.lst` \
        > /dev/null
      endif
      cd ..
    end

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/rn4
    hgLoadOut rn4 */chr*.fa.out
    # Many warnings like this one:
#Strange perc. field -7282.5 line 384881 of 1/chr1.fa.out
#Strange perc. field -143.1 line 384881 of 1/chr1.fa.out
    # That's from chr1_49, not chr1_24 so it is independent of 
    # my tweak to ProcessRepeats above.
    # There was also this warning at the end:
#note: 4 records dropped due to repStart > repEnd
#      run with -verbose=2 for details
    # Ran with -verbose=2 on kolossus... these are the warnings:
#bad rep range [152, 128] line 108428 of 17/chr17.fa.out 
#bad rep range [58, -69] line 86997 of 5/chr5.fa.out 
#bad rep range [69, 7] line 30310 of 8/chr8.fa.out 
#bad rep range [1303, 1228] line 94319 of X/chrX.fa.out 
#TODO: send those on to Robert too.


# CREATING DATABASE (DONE 1/27/06 angie)
    ssh hgwdev
    hgsql '' -e 'create database rn4'
    # Use df to make sure there is at least 75G free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  1.6T   88G  95% /var/lib/mysql
    # Wow... we sure have filled that sucker up.


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 1/27/06 angie)
    ssh hgwdev
    hgsql rn4 -e "create table grp (PRIMARY KEY(NAME)) select * from rn3.grp"


# VERIFY REPEATMASKER RESULTS (TODO 1/30/06 angie)
    # Eyeball some repeat annotations in the browser, compare to lib seqs.
    # Run featureBits on rn4 and on previous genome build, and compare:
    ssh hgwdev
    nice featureBits rn4 rmsk
# Hmmmm... seems wrong for this to decrease...
#1106283290 bases of 2571531505 (43.020%) in intersection
    nice featureBits rn3 rmsk
#1117483165 bases of 2571104688 (43.463%) in intersection


# MAKE LIFTALL.LFT (DONE 1/27/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft


# GOLD AND GAP TRACKS (DONE 1/27/06 angie)
    ssh hgwdev
    cd /cluster/data/rn4
    hgGoldGapGl -noGl rn4 /cluster/data/rn4 .
    # Wow, tons of warnings like this:
#unexpected coords (6960, 6960) for frag chrX_random_2 in chrom chrX_random
    # -- There really are little single non-N bases between large blocks 
    # of N in the random fasta!  Sheesh, what a mess.  But randoms are 
    # the dregs...


# SIMPLE REPEATS (TRF) (DONE 1/30/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/bed/simpleRepeat
    cd /cluster/data/rn4/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach d (/cluster/data/rn4/*/chr*_?{,?})
      set ctg = $d:t
      foreach f ($d/${ctg}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
      end
    end
    csh -ef jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
#591
    endsInLf trf/*
#trf/chrM_1.bed zero length
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/rn4/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load into the database:
    ssh hgwdev
    hgLoadBed rn4 simpleRepeat \
      /cluster/data/rn4/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
    nice featureBits rn4 simpleRepeat
#72859247 bases of 2571531505 (2.833%) in intersection
    # Compare to rn3:
    nice featureBits rn3 simpleRepeat
#70073656 bases of 2571104688 (2.725%) in intersection


# SET UP DB ON KOLOSSUS (DONE 1/30/06 angie)
    # to spare hgwdev, make an rn4 on kolossus so that we have the 
    # option of loading there and pushing to hgwdev.  It will need the 
    # gap tables and also chromInfo (added below) so that we can run 
    # featureBits on it.
    hgsql '' -e 'create database rn4'
    cd /cluster/data/rn4
    hgGoldGapGl -noGl rn4 /cluster/data/rn4 .


# CYTOBAND (DONE 1/30/06 angie)
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/cytoBand
    cd /cluster/data/rn4/bed/cytoBand
    wget ftp://ftp.ncbi.nih.gov/genomes/R_norvegicus/mapview/ideogram.gz
    zcat ideogram.gz | sort -k1,1 -k6n,6n > ideogram.sorted
    /cluster/bin/scripts/createNcbiCytoBand ideogram.sorted
    # Load the bed file into both cytoBand and cytoBandIdeo:
    hgLoadBed -noBin -sqlTable=$HOME/kent/src/hg/lib/cytoBand.sql \
      rn4 cytoBand cytoBand.bed
    hgLoadBed -noBin -sqlTable=$HOME/kent/src/hg/lib/cytoBandIdeo.sql \
      rn4 cytoBandIdeo cytoBand.bed
    # Doh, the file does not have stain information!  All of the bands 
    # are the same as in rn3, so grab stain info from there.
    hgsql rn4 -e '\
      create table bandToStain select name,gieStain from rn3.cytoBand; \
      update cytoBand,bandToStain \
        set cytoBand.gieStain = bandToStain.gieStain \
        where cytoBand.name = bandToStain.name; \
      update cytoBandIdeo,bandToStain \
        set cytoBandIdeo.gieStain = bandToStain.gieStain \
        where cytoBandIdeo.name = bandToStain.name; \
      drop table bandToStain;'


# PROCESS SIMPLE REPEATS INTO MASK (DONE 1/30/06 angie)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kkstore01
    cd /cluster/data/rn4/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/rn4
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # Here's the coverage for the filtered TRF:
    ssh kolossus
    cat /cluster/data/rn4/bed/simpleRepeat/trfMaskChrom/*.bed \
      > /tmp/filtTrf.bed
    featureBits rn4 /tmp/filtTrf.bed
#50551402 bases of 2571531505 (1.966%) in intersection


# MASK SEQUENCE WITH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 1/30/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    # Soft-mask (lower-case) the contig and chr .fa's, 
    # then make hard-masked versions from the soft-masked.  
    set trfCtg=bed/simpleRepeat/trfMask
    set trfChr=bed/simpleRepeat/trfMaskChrom
    foreach f (*/chr*.fa)
      echo "repeat- and trf-masking $f"
      maskOutFa -soft $f $f.out $f
      set chr = $f:t:r
      maskOutFa -softAdd $f $trfChr/$chr.bed $f
      echo "hard-masking $f"
      maskOutFa $f hard $f.masked
    end
    foreach c (?{,?})
      echo "repeat- and trf-masking contigs of chr$c, chr${c}_random"
      foreach d ($c/chr*_?{,?})
        set ctg=$d:t
        set f=$d/$ctg.fa
        maskOutFa -soft $f $f.out $f
        maskOutFa -softAdd $f $trfCtg/$ctg.bed $f
        maskOutFa $f hard $f.masked
      end
    end
    # Make 2bit (for hgBlat, browser):
    faToTwoBit */chr*.fa rn4.2bit
    # Make nib (for blastz w/linSpecRep, OK for genbank too):
    mkdir nib
    foreach f (?{,?}/chr*.fa)
      echo $f:t:r
      faToNib -softMask $f nib/$f:t:r.nib
    end


# PUT NIBS ON /SCRATCH (DONE 1/30/06 angie)
    ssh kkstore01
    mkdir /cluster/bluearc/scratch/hg/rn4
    rsync -av /cluster/data/rn4/nib/* /cluster/bluearc/scratch/hg/rn4/nib/
    # Ask cluster-admin to distribute to /scratch on big & small cluster


# MAKE CHROMINFO TABLE WITH 2BIT (DONE 1/30/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    mkdir bed/chromInfo
    twoBitInfo rn4.2bit stdout \
    | awk '{print $1 "\t" $2 "\t/gbdb/rn4/rn4.2bit";}' \
      > bed/chromInfo/chromInfo.tab

    # Link to 2bit from /gbdb/rn4/:
    ssh hgwdev
    mkdir /gbdb/rn4
    ln -s /cluster/data/rn4/rn4.2bit /gbdb/rn4/
    # Load /gbdb/rn4/rn4.2bit paths into database and save size info.
    hgsql rn4  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgsql rn4 -e 'load data local infile \
      "/cluster/data/rn4/bed/chromInfo/chromInfo.tab" \
      into table chromInfo;'
    echo "select chrom,size from chromInfo" | hgsql -N rn4 > chrom.sizes
    # take a look at chrom.sizes size
    wc chrom.sizes
#     45      90     789 chrom.sizes
    # Load chromInfo on kolossus too (required for featureBits):
    ssh kolossus
    hgsql rn4  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgsql rn4 -e 'load data local infile \
      "/cluster/data/rn4/bed/chromInfo/chromInfo.tab" \
      into table chromInfo;'


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE 1/30/06 angie)
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvsup

    # Add trackDb directories and a description.html
    mkdir rat/rn4
    cvs add rat/rn4
    cvs add rat/rn4/description.html
    cvs ci rat/rn4
    # Edit that makefile to add rn4 in all the right places and do
    make update DBS=rn4

    mkdir /gbdb/rn4/html
    cvs ci makefile
    # Go public on genome-test.  In a clean tree (no mods, up-to-date):
    cvs up makefile
    make alpha
    # Note: hgcentral*.genome values must correspond
    # with defaultDb.genome values
    hgsql -h genome-testdb hgcentraltest \
      -e 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome, scientificName, \
                htmlPath, hgNearOk, hgPbOk, sourceName) values \
        ("rn4", "Nov. 2004", "/gbdb/rn4/rn4.2bit", "Rat", \
               "chr2:22845558-23004134", 1, 30, "Rat", \
                "Rattus norvegicus", "/gbdb/rn4/html/description.html", \
                0, 0, "Baylor HGSC v. 3.4");'


# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 1/30/06 angie)
    ssh kolossus
    cd /cluster/data/rn4
    #- Build the .tar.gz files -- no genbank for now.
    cat << '_EOF_' > jkStuff/zipAll.csh
rm -rf bigZips
mkdir bigZips
tar cvzf bigZips/chromAgp.tar.gz ?{,?}/chr*.agp
tar cvzf bigZips/chromOut.tar.gz ?{,?}/chr*.fa.out
tar cvzf bigZips/chromFa.tar.gz ?{,?}/chr*.fa
tar cvzf bigZips/chromFaMasked.tar.gz ?{,?}/chr*.fa.masked
cd bed/simpleRepeat
tar cvzf ../../bigZips/chromTrf.tar.gz trfMaskChrom/chr*.bed
cd ../..
'_EOF_'
    # << this line makes emacs coloring happy
    csh -ef ./jkStuff/zipAll.csh >& zipAll.log &
    tail -f zipAll.log
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    cd bigZips
    md5sum *.gz > md5sum.txt
    # Make a README.txt
    cd ..
    mkdir chromGz
    foreach f ( ?{,?}/chr*.fa )
      echo $f:t:r
      gzip -c $f > chromGz/$f:t.gz
    end
    cd chromGz
    md5sum *.gz > md5sum.txt
    # Make a README.txt

    #- Link the .gz and .txt files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    set gp = /usr/local/apache/htdocs/goldenPath/rn4
    mkdir -p $gp/bigZips
    ln -s /cluster/data/rn4/bigZips/{chrom*.tar.gz,*.txt} $gp/bigZips
    mkdir -p $gp/chromosomes
    ln -s /cluster/data/rn4/chromGz/{chr*.gz,*.txt} $gp/chromosomes
    # Take a look at bigZips/* and chromosomes/*
    # Can't make refGene upstream sequence files - no refSeq for yakuba.
    mkdir $gp/database
    # Create README.txt files in database/ to explain the files.


# MAKE 11.OOC (DONE 2/10/06 angie)
    ssh kolossus
    cd /cluster/data/rn4
    mkdir /cluster/bluearc/rn4
    blat rn4.2bit /dev/null /dev/null \
      -tileSize=11 -makeOoc=/cluster/bluearc/rn4/11.ooc -repMatch=1024
#Wrote 25608 overused 11-mers to /cluster/bluearc/rn4/11.ooc


# GENBANK AUTO UPDATE (DONE 2/10/06 angie)
    # align with revised genbank process. drop xeno ESTs.
    cd ~/kent/src/makeDb/genbank
    cvsup
    # edit etc/genbank.conf to add rn4

# rn4
rn4.serverGenome = /cluster/data/rn4/rn4.2bit
rn4.clusterGenome = /iscratch/i/rn4/rn4.2bit
rn4.ooc = /cluster/bluearc/rn4/11.ooc
rn4.align.unplacedChroms = chrUn,chr*_random
rn4.lift = /cluster/data/rn4/jkStuff/liftAll.lft
rn4.refseq.mrna.native.pslCDnaFilter  = ${ordered.refseq.mrna.native.pslCDnaFilter}
rn4.refseq.mrna.xeno.pslCDnaFilter    = ${ordered.refseq.mrna.xeno.pslCDnaFilter}
rn4.genbank.mrna.native.pslCDnaFilter = ${ordered.genbank.mrna.native.pslCDnaFilter}
rn4.genbank.mrna.xeno.pslCDnaFilter   = ${ordered.genbank.mrna.xeno.pslCDnaFilter}
rn4.genbank.est.native.pslCDnaFilter  = ${ordered.genbank.est.native.pslCDnaFilter}
rn4.downloadDir = rn4
rn4.refseq.mrna.xeno.load  = yes
rn4.refseq.mrna.xeno.loadDesc = yes
rn4.mgcTables.default = full
rn4.mgcTables.mgc = all

    cvs ci etc/genbank.conf
    # update /cluster/data/genbank/
    make etc-update

    ssh kkstore02
    cd /cluster/data/genbank
    nice bin/gbAlignStep -initial rn4 &
    # load database when finished
    ssh hgwdev
    cd /cluster/data/genbank
    nice ./bin/gbDbLoadStep -drop -initialLoad rn4 &

    # enable daily alignment and update of hgwdev
    cd ~/kent/src/makeDb/genbank
    cvsup
    # add rn4 to:
        etc/align.dbs
        etc/hgwdev.dbs 
    cvs commit
    make etc-update


# PRODUCING GENSCAN PREDICTIONS (DONE 1/31/06 angie)
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/genscan
    cd /cluster/data/rn4/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Run on small cluster (more mem than big cluster).
    ssh kki
    cd /cluster/data/rn4/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    cp /dev/null genome.list
    foreach f ( `ls -1S /cluster/data/rn4/*/chr*_*/chr*_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    wc -l genome.list
#591 genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para make jobList
    para time
#Completed: 589 of 591 jobs
#Crashed: 2 jobs
#CPU time in finished jobs:     110813s    1846.88m    30.78h    1.28d  0.004 y
#IO & Wait Time:                  8627s     143.79m     2.40h    0.10d  0.000 y
#Average job time:                 203s       3.38m     0.06h    0.00d
#Longest finished job:            4230s      70.50m     1.18h    0.05d
#Submission to last job:         11260s     187.67m     3.13h    0.13d
    # If there are crashes, diagnose with "para problems" / "para crashed".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    ssh kkr5u00
    cd /cluster/data/rn4/bed/genscan
    /cluster/bin/x86_64/gsBig /cluster/data/rn4/10/chr10_3/chr10_3.fa.masked gtf/chr10_3.fa.gtf -trans=pep/chr10_3.fa.pep -subopt=subopt/chr10_3.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/x86_64/gsBig /cluster/data/rn4/9/chr9_21/chr9_21.fa.masked gtf/chr9_21.fa.gtf -trans=pep/chr9_21.fa.pep -subopt=subopt/chr9_21.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000

    # Convert these to chromosome level files as so:
    ssh kkstore01
    cd /cluster/data/rn4/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/rn4/bed/genscan
    ldHgGene rn4 genscan genscan.gtf
    hgPepPred rn4 generic genscanPep genscan.pep
    hgLoadBed rn4 genscanSubopt genscanSubopt.bed


# MAKE GCPERCENT (DONE 1/30/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/bed/gc5Base
    cd /cluster/data/rn4/bed/gc5Base
    hgGcPercent -wigOut -doGaps -file=stdout -win=5 -verbose=2 rn4 \
       /cluster/data/rn4 \
    | wigEncode stdin gc5Base.wig gc5Base.wib
    ssh hgwdev
    mkdir /gbdb/rn4/wib
    cd /cluster/data/rn4/bed/gc5Base
    ln -s `pwd`/gc5Base.wib /gbdb/rn4/wib
    hgLoadWiggle -pathPrefix=/gbdb/rn4/wib rn4 gc5Base gc5Base.wig


# ENSEMBL GENES (DONE 1/30/06 angie)
    mkdir /cluster/data/rn4/bed/ensembl
    cd /cluster/data/rn4/bed/ensembl
    # Get the ensembl gene data from 
    # http://www.ensembl.org/Rattus_norvegicus/martview
    # Follow this sequence through the pages:
    # Page 1) Make sure that the Rattus_norvegicus choice is selected. Hit next.
    # Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
    # Page 3) Choose the "Structures" box. 
    # Page 4) Choose GTF as the ouput.  choose gzip compression.  hit export.
    # Save as ensembl.gff.gz
    # Add "chr" to front of each line in the gene data gtf file to make 
    # it compatible with our software.
    gunzip -c ensembl.gff.gz \
    | perl -wpe 's/^([0-9]+|X|Y|M|Un(_random)?)/chr$1/ \
                 || die "Line $. doesnt start with rat chrom:\n$_"' \
    > ensGene.gtf
    ssh hgwdev
    ldHgGene -gtf -genePredExt rn4 ensGene \
      /cluster/data/rn4/bed/ensembl/ensGene.gtf

    # ensGtp associates geneId/transcriptId/proteinId for hgPepPred and 
    # hgKnownToSuper.  Use ensMart to create it as above, except:
    # Page 3) Choose the "Features" box. In "Ensembl Attributes", check 
    # Ensembl Gene ID, Ensembl Transcript ID, Ensembl Peptide ID.  
    # Choose Text, tab-separated as the output format.  Result name ensGtp.
    # Save file as ensGtp.txt.gz
    gunzip ensGtp.txt.gz
    hgsql rn4 < ~/kent/src/hg/lib/ensGtp.sql
    hgsql rn4 -e 'load data local infile "ensGtp.txt" into table ensGtp'

    # Load Ensembl peptides:
    # Get them from ensembl as above in the gene section except for
    # Page 3) Choose the "Sequences" box. 
    # Page 4) Transcripts/Proteins.  Peptide.  Format = FASTA.
    # Save file as ensemblPep.fa.gz
    gunzip -c ensemblPep.fa.gz \
    | perl -wpe 's/^>.*\|(ENSRNOT\d+\.\d+).*/>$1/' \
    > ensPep.fa
    hgPepPred rn4 generic ensPep ensPep.fa


# CPGISSLANDS (WUSTL) (DONE 1/30/06 angie)
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/cpgIsland
    cd /cluster/data/rn4/bed/cpgIsland
    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    mv cpglh.exe /cluster/data/rn4/bed/cpgIsland/
    
    ssh kolossus
    cd /cluster/data/rn4/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      nice ./cpglh.exe $f > $fout
    end
    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd /cluster/data/rn4/bed/cpgIsland
    hgLoadBed rn4 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed


# CPGISLANDS (ANDY LAW) (DONE 1/30/06 angie)
    # See notes in makeGalGal2.doc
    ssh kolossus
    mkdir /cluster/data/rn4/bed/cpgIslandGgfAndy
    cd /cluster/data/rn4/bed/cpgIslandGgfAndy
    #	Build the preProcGgfAndy program in
    #	kent/src/oneShot/preProcGgfAndy into your ~/bin/$MACHTYPE
    # Use masked sequence since this is a mammal...
    cp /dev/null cpgIslandGgfAndyMasked.bed
    foreach f (../../*/chr*.fa.masked)
      set chr = $f:t:r:r
      echo preproc and run on masked $chr
      ~/bin/x86_64/preProcGgfAndy $f \
      | /cluster/home/angie/ggf-andy-cpg-island.pl \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyMasked.bed
    end
    # load into database:
    ssh hgwdev
    cd /cluster/data/rn4/bed/cpgIslandGgfAndy
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyMasked/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > cpgIslandGgfAndyMasked.sql
    hgLoadBed rn4 cpgIslandGgfAndyMasked -tab -noBin \
      -sqlTable=cpgIslandGgfAndyMasked.sql cpgIslandGgfAndyMasked.bed
#Loaded 91097 elements of size 10
    featureBits rn4 cpgIslandExt
#9629809 bases of 2571531505 (0.374%) in intersection
    featureBits rn4 cpgIslandGgfAndyMasked
#43899646 bases of 2571531505 (1.707%) in intersection
    wc -l ../cpgIsland/cpgIsland.bed *bed
#  15809 ../cpgIsland/cpgIsland.bed
#  91097 cpgIslandGgfAndyMasked.bed


# LIFTOVER RGD (DONE 2/9/06 angie)
    # ftp://rgd.mcw.edu/pub/RGD_genome_annotations/ still has 3.1 (rn3) not 
    # 3.4 (rn4).  Jim said these are interesting enough that we should lift 
    # over at least the QTLs.
    ssh kolossus
    mkdir /cluster/data/rn4/bed/rgdLiftover
    cd /cluster/data/rn4/bed/rgdLiftover
    wget ftp://rgd.mcw.edu/pub/RGD_genome_annotations/V3.1/GFF_files/rgd_rat_qtl_12052005.gff
    awk '{print $1"\t"$4-1"\t"$5"\t"$10}' rgd_rat_qtl_12052005.gff \
    | sed -e 's/Chr/chr/g; s/"//g; s/RGD://g; s/;//g' \
      > rgdQtl_rn3.bed
    awk '{printf "%s\t%s\t", $12, $10; \
          for (i = 14;i <= NF; ++i ) {printf "%s ", $i} printf "\n"} ' \
      rgd_rat_qtl_12052005.gff \
    | sed -e 's/"//g; s/RGD://g; s/;\t/\t/g' \
      > rgdQtlLink.tab
    # liftOver rgdQtl_rn3.bed \
    #   /cluster/data/rn3/bed/blat.rn4.2006-02-07/rn3ToRn4.over.chain.gz \
    #   rgdQtl.bed rgdQtl.unmapped
    # liftOver of rgdQtl_rn3.bed did not go well -- out of 903 qtls,
    # only 95 were successfully mapped.  772 got "Partially split in new."
    # Since these are enormous, presumably fuzzy-edged regions, just lift 
    # start and end.  If the start and end of each feature seems to be 
    # liftOver'd coherently, "chain" those back up into big regions in rn4.
    perl -we 'while (<>) { \
                chomp;  ($chr, $start, $end, $name) = split; \
                print "$chr\t$start\t" . ($start+100) . "\tstart_$name\n"; \
                print "$chr\t" . ($end-100) . "\t$end\tend_$name\n"; \
              }' \
      rgdQtl_rn3.bed > rgdQtl_rn3_endpoints.bed
    liftOver rgdQtl_rn3_endpoints.bed \
      /cluster/data/rn3/bed/blat.rn4.2006-02-07/rn3ToRn4.over.chain.gz \
      rgdQtl_endpoints.bed rgdQtl_endpoints.unmapped
    # Now 1706 out of 1806 survive... but 100 are deleted in new?!
    # I manually checked 10 of them and they all are either in a gap 
    # or off the end of a chrom.  Makes me wonder if these really are 
    # rn3 coords...  oh well, I guess we can load them up and ask 
    # RGD about them in the meantime.  I submitted a question using their 
    # online form -- my message ID is 439 and I can email rgd@rgd.mcw.edu 
    # with that ID if I don't hear from them in 3 biz days.
    perl -we 'while (<>) { \
                chomp;  ($chr, $start, $end, $name) = split; \
                if ($name =~ /^start_(\S+)/) { \
                  $starts{$1} = [$chr, $start]; \
                } elsif ($name =~ /^end_(\S+)/) { \
                  $ends{$1} = [$chr, $end]; \
                } else { die "parse error line $.: name $name\n"; } \
              } \
              foreach my $name (keys %starts) { \
                if (defined $ends{$name}) { \
                  my ($sChr, $start) = @{$starts{$name}}; \
                  my ($eChr, $end)   = @{$ends{$name}}; \
                  if (($sChr eq $eChr) && $end > $start) { \
                    print "$sChr\t$start\t$end\t$name\n"; \
                  } else { \
                    print STDERR "reject: [$sChr, $start] / [$eChr, $end] / $name\n"; \
                  } \
                } \
              }' \
      rgdQtl_endpoints.bed \
      | sort -k 1,1 -k 2n,2n > rgdQtl.bed
    wc -l rgdQtl.bed
#806 rgdQtl.bed
    ssh hgwdev
    cd /cluster/data/rn4/bed/rgdLiftover
    hgLoadBed rn4 rgdQtl rgdQtl.bed
    hgsql rn4 < ~/kent/src/hg/lib/rgdQtlLink.sql
    hgsql rn4 -e \
      'load data local infile "rgdQtlLink.tab" into table rn4.rgdQtlLink;'
 

# MAKE LINEAGE-SPECIFIC REPEATS VS. HUMAN, MOUSE (DONE 2/8/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/rmsk
    cd /cluster/data/rn4/rmsk
    ln -s ../?{,?}/chr*.fa.out .
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Human in extra column 1, Mouse in extra column 2
    foreach outfl ( *.out )
        echo "$outfl"
        nice /cluster/bluearc/RepeatMasker/DateRepeats \
          ${outfl} -query rat -comp human -comp mouse
    end
    # Now extract human (extra column 1), mouse (extra column).
    cd ..
    mkdir linSpecRep.notInHuman
    mkdir linSpecRep.notInMouse
    foreach f (rmsk/*.out_homo-sapiens_mus-musculus)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInHuman/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    wc -l rmsk/*.out
#  4417757 total
    wc -l linSpecRep.notInHuman/*
#  2676056 total
    wc -l linSpecRep.notInMouse/*
#  471417 total
    # Clean up.
    rm -r rmsk
    # Distribute linSpecRep.* for cluster run
    ssh kkstore01
    mkdir /san/sanvol1/scratch/rn4
    rsync -av /cluster/data/rn4/linSpecRep.notInHuman/* \
      /san/sanvol1/scratch/rn4/linSpecRep.notInHuman/
    rsync -av /cluster/data/rn4/linSpecRep.notInMouse/* \
      /san/sanvol1/scratch/rn4/linSpecRep.notInMouse/


# SWAP/CHAIN/NET HG17 (DONE 2/10/06 angie)
    mkdir /cluster/data/rn4/bed/blastz.hg17.swap
    cd /cluster/data/rn4/bed/blastz.hg17.swap
    doBlastzChainNet.pl -swap /cluster/data/hg17/bed/blastz.rn4/DEF \
      -workhorse=kkr5u00 >& do.log & tail -f do.log
    ln -s blastz.hg17.swap /cluster/data/rn4/bed/blastz.hg177


# MAKE LINEAGE-SPECIFIC REPEATS FOR NON-MAMMALS (DONE 2/13/06 angie)
    # In an email 2/13/04 to Angie, Arian said we could treat all 
    # human repeats as lineage-specific for human-chicken blastz.  
    # Extrapolate to any mammal vs. anything at least as distant as chicken.
    ssh kkr1u00
    mkdir /iscratch/i/rn4/linSpecRep.notInNonMammal
    foreach f (/cluster/data/rn4/*/chr*.fa.out)
      cp -p $f /iscratch/i/rn4/linSpecRep.notInNonMammal/$f:t:r:r.out.spec
    end
    iSync


# BLASTZ CHICKEN (GALGAL2) (DONE 2/14/06 angie)
    ssh kk
    mkdir /cluster/data/rn4/bed/blastz.galGal2.2006-02-13
    cd /cluster/data/rn4/bed/blastz.galGal2.2006-02-13
    # Set L=10000 (higher threshold on blastz's outer loop) and abridge 
    # repeats.
    cat << '_EOF_' > DEF
#rat vs. chicken

# Specific settings for chicken (per Webb email to Brian Raney)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=10000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Rat
SEQ1_DIR=/scratch/hg/rn4/nib
SEQ1_SMSK=/iscratch/i/rn4/linSpecRep.notInNonMammal
SEQ1_CHUNK=10000000
SEQ1_LAP=10000
SEQ1_LEN=/cluster/data/rn4/chrom.sizes

# QUERY: Chicken
SEQ2_DIR=/iscratch/i/galGal2/nib
SEQ2_SMSK=/iscratch/i/galGal2/linSpecRep
SEQ2_CHUNK=10000000
SEQ2_LAP=0
SEQ2_LEN=/cluster/data/galGal2/chrom.sizes

BASE=/cluster/data/rn4/bed/blastz.galGal2.2006-02-13
'_EOF_'
    # << this line keeps emacs coloring happy
    doBlastzChainNet.pl DEF \
      -blastzOutRoot=/cluster/bluearc/blastzRn4GalGal2Out \
      > do.log & tail -f do.log
    cd /cluster/data/rn4/bed
    ln -s /cluster/data/rn4/bed/blastz.galGal2.2006-02-13 blastz.galGal2


##########################################################################
# BACEND PAIRS TRACK

# DOWNLOAD CLONEENDS (BACENDS) FROM NCBI (DONE 2/23/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    # Plenty of room at the moment:
    df -h .
#                      1.3T 1009G  234G  82% /cluster/store9
    mkdir -p bed/cloneend/ncbi
    cd bed/cloneend/ncbi
    wget --timestamping \
	ftp://ftp.ncbi.nih.gov/genomes/CLONEEND/rattus_norvegicus/\*
    cd ..
    # Extract unversioned accessions from headers and combine into one 
    # uncompressed file which we will link to from /gbdb/:
    zcat ncbi/*ends*.mfa.gz \
    | perl -wpe 'if (/^>/) { \
       s/^>.*\|(gb|dbj)\|(\w+)\.\d+\|.*/>$2/ || die "parse line $.:$_\n"; }' \
      > cloneEnds.fa
    # Make sure the sequences are intact after the header-munging:
    faSize ncbi/*.mfa.gz
#188448559 bases (4451 N's 188444108 real 102020307 upper 86423801 lower) in 307557 sequences in 18 files
#Total size: mean 612.7 sd 198.9 min 83 (gi|30387889|gb|CC181697.1|) max 1158 (gi|24002262|gb|BZ277934.1|) median 634
    faSize cloneEnds.fa
#188448559 bases (4451 N's 188444108 real 102020307 upper 86423801 lower) in 307557 sequences in 1 files
#Total size: mean 612.7 sd 198.9 min 83 (CC181697) max 1158 (BZ277934) median 634

    # Extract pairings from info files:
    zcat ncbi/*info*.txt.gz \
    | /cluster/bin/scripts/convertCloneEndInfo stdin
#134351 pairs and 38410 singles

    # split for cluster run
    mkdir /cluster/bluearc/rn4/cloneEnds
    faSplit sequence cloneEnds.fa 100 /cluster/bluearc/rn4/cloneEnds/cloneEnds
    #	Check to ensure no breakage:
    faSize /cluster/bluearc/rn4/cloneEnds/*.fa
#188448559 bases (4451 N's 188444108 real 102020307 upper 86423801 lower) in 307557 sequences in 98 files
#Total size: mean 612.7 sd 198.9 min 83 (CC181697) max 1158 (BZ277934) median 634
    #	same numbers as before

    # load sequences
    ssh hgwdev
    mkdir /gbdb/rn4/cloneend
    ln -s /cluster/data/rn4/bed/cloneend/cloneEnds.fa /gbdb/rn4/cloneend/
    cd /tmp
    hgLoadSeq rn4 /gbdb/rn4/cloneend/cloneEnds.fa
#307557 sequences


# BACEND SEQUENCE ALIGNMENTS (DONE 2/23/06 angie)
    ssh kkstore01
    # Make unmasked fasta.
    cd /cluster/data/rn4
    mkdir /cluster/bluearc/rn4/noMask
    foreach f (?{,?}/chr*.fa)
      echo $f:t:r
      perl -wpe 'tr/a-z/A-Z/ if (! /^>/);' $f \
        > /cluster/bluearc/rn4/noMask/$f:t
    end

    # kluster run
    ssh pk
    mkdir /cluster/data/rn4/bed/bacends
    cd /cluster/data/rn4/bed/bacends
    mkdir out
    # allow blat to run politely in /tmp while it writes output, then
    # copy results to results file:
    cat << '_EOF_' > runBlat.csh
#!/bin/csh -ef
set root1 = $1
set root2 = $2
set result = $3
rm -fr /scratch/tmp/${root1}_${root2}
mkdir /scratch/tmp/${root1}_${root2}
pushd /scratch/tmp/${root1}_${root2}
/cluster/bin/x86_64/blat /cluster/bluearc/rn4/noMask/${root1}.fa \
  /cluster/bluearc/rn4/cloneEnds/${root2}.fa \
  -ooc=/cluster/bluearc/rn4/11.ooc ${root1}.${root2}.psl
popd
mkdir -p out/${root2}
rm -f ${result}
mv /scratch/tmp/${root1}_${root2}/${root1}.${root2}.psl ${result}
rm -fr /scratch/tmp/${root1}_${root2}
'_EOF_'
    #	<< happy emacs
    chmod +x runBlat.csh

    cat << '_EOF_' > template
#LOOP
./runBlat.csh $(root1) $(root2) {check out line+ out/$(root2)/$(root1).$(root2).psl}
#ENDLOOP
'_EOF_'
    # << emacs happy
    ls -1S /cluster/bluearc/rn4/cloneEnds/cloneEnds???.fa > bacEnds.lst
    ls -1S /cluster/bluearc/rn4/noMask/chr*.fa > contig.lst
    gensub2 contig.lst bacEnds.lst template jobList
    para make jobList
#Completed: 4410 of 4410 jobs
#CPU time in finished jobs:     450309s    7505.15m   125.09h    5.21d  0.014 y
#IO & Wait Time:                812287s   13538.12m   225.64h    9.40d  0.026 y
#Average job time:                 286s       4.77m     0.08h    0.00d
#Longest finished job:            1834s      30.57m     0.51h    0.02d
#Submission to last job:          6982s     116.37m     1.94h    0.08d

    ssh kkstore01
    cd /cluster/data/rn4/bed/bacends
    mkdir temp
    time pslSort dirs raw.psl temp out/*
#538.065u 55.510s 14:46.80 66.9%       0+0k 0+0io 3pf+0w
    time pslReps -nearTop=0.01 -minCover=0.7 -minAli=0.8 -noIntrons \
      raw.psl bacEnds.psl /dev/null
#203.262u 8.877s 3:57.34 89.3%   0+0k 0+0io 2pf+0w


# BACEND PAIRS TRACK (DONE 2/23/06 angie)
    ssh kolossus
    cd /cluster/data/rn4/bed/bacends
    time /cluster/bin/x86_64/pslPairs -tInsert=10000 \
      -minId=0.91 -noBin -min=25000 \
      -max=350000 -slopval=10000 -hardMax=500000 -slop -short -long -orphan \
      -mismatch -verbose bacEnds.psl \
        ../cloneend/cloneEndPairs.txt all_bacends bacEnds
#19.229u 4.720s 0:26.34 90.8%    0+0k 0+0io 0pf+0w

    # Filter by score and sort by {chrom,chromStart}:
    awk '$5 >= 300 {print;}' bacEnds.pairs | sort -k1,2n > bacEndPairs.bed
    cat bacEnds.{slop,short,long,mismatch,orphan} \
    | awk '$5 >= 300 {print;}' | sort -k1,2n > bacEndPairsBad.bed

    #	CHECK bacEndPairs.bed ID's to make sure they have no blanks in them
    awk '{print $5}' bacEndPairs.bed | sort -u

    /cluster/bin/scripts/extractPslLoad -noBin bacEnds.psl bacEndPairs.bed \
      bacEndPairsBad.bed \
    | sorttbl tname tstart | headchg -del \
    > bacEnds.load.psl
    wc -l bacEnds.*
#   5590477 bacEnds.psl
#   4462768 bacEnds.load.psl
#    109315 bacEnds.pairs
#       705 bacEnds.long
#        98 bacEnds.lst
#      3925 bacEnds.mismatch
#     88292 bacEnds.orphan
#       558 bacEnds.short
#       687 bacEnds.slop

    # load into database
    ssh hgwdev
    cd /cluster/data/rn4/bed/bacends
    hgLoadBed -strict -notItemRgb rn4 bacEndPairs bacEndPairs.bed \
        -sqlTable=$HOME/kent/src/hg/lib/bacEndPairs.sql
#Loaded 109139 elements of size 11
    # note - the "Bad" track isn't pushed to RR, just used for assembly QA.
    hgLoadBed -strict -notItemRgb rn4 bacEndPairsBad bacEndPairsBad.bed \
      -sqlTable=$HOME/kent/src/hg/lib/bacEndPairsBad.sql
#Loaded 38981 elements of size 11
    time hgLoadPsl rn4 -table=all_bacends bacEnds.load.psl
#load of all_bacends did not go as planned: 4462768 record(s), 0 row(s) skipped, 1 warning(s) loading psl.tab
#165.730u 24.690s 10:57.43 28.9% 0+0k 0+0io 258pf+0w

    # To diagnose:
    echo select \* from all_bacends | hgsql -N rn4 > psl.tab.loaded
    diff psl.tab* 
#1491015c1491015
#< 120   908     82      0       0       3       -124    6       278579  -       BZ232973        866     0       866     chr17   97296363        49307517   49587086 8       21,5,71,86,327,250,116,114,     0,21,27,98,184,382,632,752,     49307517,49307539,49307544,49335694,49336333,49470455,49586851,49586972,
#---
#> 120   908     82      0       0       3       0       6       278579  -       BZ232973        866     0       866     chr17   97296363        49307517   49587086 8       21,5,71,86,327,250,116,114,     0,21,27,98,184,382,632,752,     49307517,49307539,49307544,49335694,49336333,49470455,49586851,49586972,
    # Q gap bases was -124 in... clipped to 0 in the db.  
    # Identify and save the out/*.psl file that contains the -124:
    grep '^>BZ232973' /cluster/bluearc/rn4/cloneEnds/*.fa
#/cluster/bluearc/rn4/cloneEnds/cloneEnds079.fa:>BZ232973
    grep BZ232973 out/cloneEnds079/*.psl | grep .-124
#out/cloneEnds079/chr17.cloneEnds079.psl:908     82      0       0       3       -124    6       278579  -       BZ232973        866     0       866     chr17       97296363        49307517        49587086        8       21,5,71,86,327,250,116,114,     0,21,27,98,184,382,632,752,     49307517,49307539,49307544,49335694,49336333,49470455,49586851,49586972,
    cp -p out/cloneEnds079/chr17.cloneEnds079.psl .

    featureBits rn4 all_bacends
#241203668 bases of 2571531505 (9.380%) in intersection
    featureBits rn3 all_bacends
#232313031 bases of 2571104688 (9.036%) in intersection
    featureBits rn4 bacEndPairs
#2687958438 bases of 2571531505 (104.528%) in intersection
    featureBits rn3 bacEndPairs
#2717444119 bases of 2571104688 (105.692%) in intersection
    featureBits rn4 bacEndPairsBad
#664080718 bases of 2571531505 (25.824%) in intersection
    featureBits rn3 bacEndPairsBad
#table bacEndPairsBad not found for any chroms

    # Clean up - this recovers >10G!
    rm psl.tab psl.tab.loaded raw.psl bed.tab
    rm -r out
    rmdir temp

# end BACEND PAIRS TRACK
##########################################################################


# SWAP/CHAIN/NET MM7 (DONE 2/24/06 angie)
    mkdir /cluster/data/rn4/bed/blastz.mm7.swap
    cd /cluster/data/rn4/bed/blastz.mm7.swap
    doBlastzChainNet.pl -swap /cluster/data/mm7/bed/blastz.rn4/DEF \
      >& do.log & tail -f do.log
    ln -s blastz.mm7.swap /cluster/data/rn4/bed/blastz.mm7


# SWAP/CHAIN/NET HG18 (DONE 2/24/06 angie)
    mkdir /cluster/data/rn4/bed/blastz.hg18.swap
    cd /cluster/data/rn4/bed/blastz.hg18.swap
    doBlastzChainNet.pl -swap /cluster/data/hg18/bed/blastz.rn4/DEF \
      >& do.log & tail -f do.log
    ln -s blastz.hg18.swap /cluster/data/rn4/bed/blastz.hg18


# MAKE LINEAGE-SPECIFIC REPEATS VS. DOG, COW, RABBIT (DONE 2/24/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/rmsk
    cd /cluster/data/rn4/rmsk
    ln -s ../?{,?}/chr*.fa.out .
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Dog in extra column 1, mouse in 2, rabbit in 3
    foreach outfl ( *.out )
        echo "$outfl"
        nice /cluster/bluearc/RepeatMasker/DateRepeats \
          ${outfl} -query rat -comp dog -comp cow -comp rabbit
    end
    # Now extract human (extra column 1), mouse (extra column).
    cd ..
    mkdir linSpecRep.notIn{Dog,Cow,Rabbit}
    foreach f (rmsk/*.out_*)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractRepeats 1 $f > \
                        linSpecRep.notInDog/$base.out.spec
        /cluster/bin/scripts/extractRepeats 2 $f > \
                        linSpecRep.notInCow/$base.out.spec
        /cluster/bin/scripts/extractRepeats 3 $f > \
                        linSpecRep.notInRabbit/$base.out.spec
    end
    wc -l rmsk/*.out
#  4417757 total
    wc -l linSpecRep.notInDog/*
#  2676056 total
    wc -l linSpecRep.notInCow/*
#  2676056 total
    wc -l linSpecRep.notInRabbit/*
#  2676056 total
    # These all look identical to each other (and to human except for header):
    foreach f (linSpecRep.notInDog/*)
      cmp $f linSpecRep.notInCow/$f:t
      cmp $f linSpecRep.notInRabbit/$f:t
    end
    # Consolidate to save space (probably could have done this for human too):
    mv linSpecRep.notInDog linSpecRep.notInNonRodentMammal
    # Clean up.
    rm -r rmsk linSpecRep.notInCow linSpecRep.notInRabbit
    # Distribute linSpecRep.* for cluster run
    ssh kkstore01
    rsync -av /cluster/data/rn4/linSpecRep.notInNonRodentMammal/* \
      /cluster/bluearc/rn4/linSpecRep.notInNonRodentMammal/


# BLASTZ/CHAIN/NET CANFAM2 (DONE 2/24/06 angie)
    ssh kkstore01
    mkdir /cluster/data/rn4/bed/blastz.canFam2.2006-02-24
    cd /cluster/data/rn4/bed/blastz.canFam2.2006-02-24
    cat << '_EOF_' > DEF
# rat vs. dog

BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Rat
SEQ1_DIR=/scratch/hg/rn4/nib
SEQ1_SMSK=/cluster/bluearc/rn4/linSpecRep.notInNonRodentMammal
SEQ1_LEN=/cluster/data/rn4/chrom.sizes
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Dog
SEQ2_DIR=/scratch/hg/canFam2/nib
SEQ2_SMSK=/cluster/bluearc/canFam2/linSpecRep.notInRat
SEQ2_LEN=/cluster/data/canFam2/chrom.sizes
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/rn4/bed/blastz.canFam2.2006-02-24
'_EOF_'
    # << for emacs
    doBlastzChainNet.pl DEF -bigClusterHub=pk \
      -blastzOutRoot /san/sanvol1/scratch/blastzRn4CanFam2Out >& do.log &
    tail -f do.log
    ln -s blastz.canFam2.2006-02-24 /cluster/data/rn4/bed/blastz.canFam2 


##########################################################################
# STS MARKERS
# NOTE: Instead of using UniSTS_rat.sts as usual, I made a local version 
# which uses the name given in UniSTS.sts if none is given in UniSTS_rat.sts 
# and "UniSTS:$id" if no name is given in UniSTS.sts.  Some inconsistencies 
# between UniSTS.sts and UniSTS_rat.sts reported 2/21/06; haven't heard 
# back from them yet so I'll just forge ahead with latest UniSTS files.

# MAKE STSINFORAT (DONE 3/6/06 angie)
    # This method was developed by Yontao.  ytlu/script is under CVS control
    # so I'm using ~/ytlu/script/perl/script/match but have copied several 
    # other scripts from /cluster/store4/ratMarker/code into 
    # kent/src/hg/stsMarkers/ to get them in CVS too.
    ssh kkstore01
    mkdir /cluster/data/rn4/bed/stsMarkers
    mkdir /cluster/data/rn4/bed/stsMarkers/info
    cd /cluster/data/rn4/bed/stsMarkers/info
    wget --timestamping ftp://ftp.ncbi.nih.gov/repository/UniSTS/UniSTS_MapReports/Rattus_norvegicus/10116.FHH_x_ACI.7.txt
    wget --timestamping ftp://ftp.ncbi.nih.gov/repository/UniSTS/UniSTS_MapReports/Rattus_norvegicus/10116.RH_map.3.4.txt
    wget --timestamping ftp://ftp.ncbi.nih.gov/repository/UniSTS/UniSTS_MapReports/Rattus_norvegicus/10116.SHRSP_x_BN.7.txt
    wget --timestamping ftp://ftp.ncbi.nih.gov/repository/UniSTS/UniSTS_rat.sts
    wget --timestamping ftp://ftp.ncbi.nih.gov/repository/UniSTS/UniSTS.aliases
    wget --timestamping ftp://rgd.mcw.edu/pub/rhmap/3.4/RHv3_4_MapData.txt
    wget --timestamping ftp://rgd.mcw.edu/pub/rhmap/3.4/RAW_MARKER_SEQINFO.txt

    # UniSTS_rat.sts is missing a lot of names that can be found in UniSTS.sts
    # so load that up and make a fixed-up UniSTS_rat.rat_extracted.sts:
    wget --timestamping ftp://ftp.ncbi.nih.gov/repository/UniSTS/UniSTS.sts
    awk -F"\t" '$5 != "-" {print $1 "\t" $5 "\t" $8;}' UniSTS.sts \
      > UniSTS.names
    cat > extractRat.pl <<'_EOF_'
#!/usr/bin/perl -w

use strict;

open(NAMES, "<UniSTS.names") || die "Can't open UniSTS.names: $!\n";
print STDERR "Hashing UniSTS.names...\n";
my %id2name;
while (<NAMES>) {
  chomp;
  my @words = split("\t");
  $id2name{$words[0]} = $words[1];
}

print STDERR "Extracting rat and adding in names...\n";
while (<>) {
  chomp;
  my @words = split("\t");
  next if ($words[7] ne "Rattus norvegicus");
  if ($words[4] eq '-') {
    $words[4] = $id2name{$words[0]};
    $words[4] = "UniSTS:$words[0]" if (! defined $words[4]);
  } elsif ((defined $id2name{$words[0]}) &&
           ($words[4] ne $id2name{$words[0]})) {
    print STDERR "Disagreement: name of $words[0] given as " .
                  $id2name{$words[0]} . " and as $words[4]\n";
  }
  print join("\t", @words) . "\n";
}
'_EOF_'
    # << emacs
    chmod a+x extractRat.pl
    ./extractRat.pl UniSTS_rat.sts > UniSTS_rat.rat_extracted.sts
    # Many warnings about different name given in UniSTS_rat.sts vs. 
    # UniSTS.sts -- reported to NCBI.
    # Make UniSTS_rat.alias by joining the first columns of
    # UniSTS_rat.rat_extracted.sts and UniSTS.aliases so we get just the 
    # aliases of items in UniSTS_rat.rat_extracted.sts:
    /cluster/home/ytlu/ytlu/script/perl/script/match \
      UniSTS_rat.rat_extracted.sts 1 UniSTS.aliases 1 \
      > UniSTS_rat.alias
    # Extract these columns from RHv3_4_MapData.txt:
    # RGD_Sym TEMPL_SEQ FORWARD_PRIMER REVERSE_PRIMER EXP_SIZE
    awk '{print $2,$1,$17,$8,$9,$10}' RHv3_4_MapData.txt | sed s/" "/"\t"/g \
      > inMapData.txt 
    # Find entries not in RAW_MARKER_SEQINFO.txt but in inMapData.txt, 
    /cluster/home/ytlu/ytlu/script/perl/script/match -M \
      RAW_MARKER_SEQINFO.txt 1 inMapData.txt 1 > inMapDataOnly.txt
    cat inMapDataOnly.txt RAW_MARKER_SEQINFO.txt > marker_seqinfo.txt
    # Combine sources into a "draft" stsInfoRat.tab file:
    ~/kent/src/hg/stsMarkers/createStsInfoRat \
      UniSTS_rat.rat_extracted.sts marker_seqinfo.txt UniSTS_rat.alias \
      10116.RH_map.3.4.txt 10116.FHH_x_ACI.7.txt 10116.SHRSP_x_BN.7.txt \
      > stsInfoRat-draft
    # clean some redundant and conflicting entries --> final stsInfoRat.tab:
    ~/kent/src/hg/stsMarkers/cleanInfo.pl -rat stsInfoRat-draft \
      > ../stsInfoRat.tab
    # Create the primer.fa, cloneseq.fa, and primerinfo files for alignment:
    cd ..
    ~/kent/src/hg/stsMarkers/luConvertPrimerToFa stsInfoRat.tab \
      ratPrimer.fa ratSeq.fa ratPrimer.info -a 200


# BLAT CLONE SEQUENCES (DONE 3/8/06 angie)
    # Based on what was done for hg17, I think the thing to do is not use 
    # ooc, but filter out the results with tGapSize > 1000.
    ssh kkstore01
    cd /cluster/data/rn4
    mkdir -p /cluster/bluearc/rn4/ctgFa
    foreach d (*/chr*_?{,?})
      cp -p $d/$d:t.fa /cluster/bluearc/rn4/ctgFa/
    end
    cp -p /cluster/data/rn4/bed/stsMarkers/ratSeq.fa \
      /cluster/bluearc/rn4/
    ssh pk
    mkdir /cluster/data/rn4/bed/stsMarkers/clone
    cd /cluster/data/rn4/bed/stsMarkers/clone
    # A run with ooc, and then a run without ooc only on the unaligned seqs,
    # would probably save time next time around...
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/blat {check in line+ $(path1)} {check in line+ /cluster/bluearc/rn4/ratSeq.fa} -stepSize=5 {check out line+ clone.out/$(root1).psl}
#ENDLOOP
'_EOF_'
    # << emacs
    mkdir clone.out
    ls -1S /cluster/bluearc/rn4/ctgFa/chr*.fa > ctg.lst
    gensub2 ctg.lst single gsub jobList
    para make jobList
    para time
#Completed: 591 of 591 jobs
#CPU time in finished jobs:    1628303s   27138.38m   452.31h   18.85d  0.052 y
#IO & Wait Time:                 26091s     434.85m     7.25h    0.30d  0.001 y
#Average job time:                2799s      46.66m     0.78h    0.03d
#Longest finished job:            6138s     102.30m     1.71h    0.07d
#Submission to last job:          8714s     145.23m     2.42h    0.10d
    ssh kolossus
    cd /cluster/data/rn4/bed/stsMarkers/clone
    #	filter alignments for (qEnd-qStart) vs. (tEnd-tStart)
    #	should not be more than 100 bases different.
    pslSort dirs stdout temp clone.out \
    | pslReps -nearTop=0.0001 -minCover=0.6 -minAli=0.8 -noIntrons stdin \
        clones.unlifted.tmp.psl /dev/null
    awk '($8 < 1000) {print;}' clones.unlifted.tmp.psl > clones.unlifted.psl
    wc -l clones.un*
#  19097 clones.unlifted.psl
#  22275 clones.unlifted.tmp.psl
    rmdir temp
    rm /cluster/bluearc/rn4/ratSeq.fa


# BLAT.2 STS PRIMERS (DONE 3/7/06 angie)
    cp -p /cluster/data/rn4/bed/stsMarkers/ratPrimer.fa \
      /cluster/bluearc/rn4/
    ssh kk
    mkdir /cluster/data/rn4/bed/stsMarkers/primer
    cd /cluster/data/rn4/bed/stsMarkers/primer
    # PLEASE NOTE /cluster/bin/i386/blat.2 SPECIFICALLY IS USED HERE. 
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat.2 {check in line+ $(path1)} {check in line+ /cluster/bluearc/rn4/ratPrimer.fa} -ooc=/cluster/bluearc/rn4/11.ooc  -minMatch=1 -minScore=0 -minIdentity=80 -oneOff {check out line+ primers.out/$(root1).psl}
#ENDLOOP
'_EOF_'
    # << emacs
    mkdir primers.out
    ls -1S /cluster/bluearc/rn4/ctgFa/chr*.fa > ctg.lst
    gensub2 ctg.lst single gsub jobList
    para make jobList
    para time
#Completed: 591 of 591 jobs
#CPU time in finished jobs:     466140s    7769.00m   129.48h    5.40d  0.015 y
#IO & Wait Time:                 63525s    1058.75m    17.65h    0.74d  0.002 y
#Average job time:                 896s      14.94m     0.25h    0.01d
#Longest finished job:            1756s      29.27m     0.49h    0.02d
#Submission to last job:          5330s      88.83m     1.48h    0.06d

    ssh kkstore01
    cd /cluster/data/rn4/bed/stsMarkers/primer
    #	filter alignments for (qEnd-qStart) vs. (tEnd-tStart)
    #	should not be more than 100 bases different.
    pslSort dirs stdout temp primers.out \
    | awk -F"\t" ' \
      { if (((($13 - $12) - ($17 - $16)) > -100) && \
            ((($13 - $12) - ($17 - $16)) < 100)) {print} \
      }' \
      > primers.psl.100.unlifted
    rmdir temp
    rm /cluster/bluearc/rn4/ratPrimer.fa
    # Would be very nice to compare wc output with rn3 run, but I cannot
    # find the rn3 run.
    wc primers.psl.100.unlifted
#  8050086 169051724 799770587 primers.psl.100.unlifted


# E-PCR STS PRIMERS (DONE 3/7/06 angie)
    ssh kkstore01
    cp -p /cluster/data/rn4/bed/stsMarkers/ratPrimer.info \
      /cluster/bluearc/rn4/
    ssh kk
    mkdir /cluster/data/rn4/bed/stsMarkers/ePCR
    cd /cluster/data/rn4/bed/stsMarkers/ePCR
    ls -1S /cluster/bluearc/rn4/ctgFa/chr*.fa > ctg.lst
    # Hiram built latest e-PCR into /cluster/bin/{i386,x86_64}/e-PCR,
    # see notes in makeMm7.doc.
    mkdir epcr.out
    cat << '_EOF_' > runPCR.csh
#!/bin/csh -fe
/cluster/bin/$MACHTYPE/e-PCR $1 $2 N=1 M=50 W=5 > $3
'_EOF_'
    chmod +x runPCR.csh

    cat << '_EOF_' > gsub
#LOOP
./runPCR.csh {check in line+ /cluster/bluearc/rn4/ratPrimer.info} {check in line+ $(path1)} {check out line+ epcr.out/$(num1).epcr}
#ENDLOOP
'_EOF_'
    gensub2 ctg.lst single gsub jobList
    para make jobList
    para time
    # Actually ran on pk -- kk is swamped at the moment.
#Completed: 591 of 591 jobs
#CPU time in finished jobs:     103485s    1724.75m    28.75h    1.20d  0.003 y
#IO & Wait Time:                 29018s     483.63m     8.06h    0.34d  0.001 y
#Average job time:                 224s       3.74m     0.06h    0.00d
#Longest finished job:             341s       5.68m     0.09h    0.00d
#Submission to last job:           482s       8.03m     0.13h    0.01d

    ssh kkstore01
    cd /cluster/data/rn4/bed/stsMarkers/ePCR
    cat epcr.out/*.epcr > all.epcr
    rm /cluster/bluearc/rn4/ratPrimer.info
    rm -r /cluster/bluearc/rn4/ctgFa
    # Would compare to rn3 if I could find it...
    wc all.epcr
#  73885  295540 3915703 all.epcr


# COMBINE AND FILTER BLAT.2 AND E-PCR RESULTS (DONE 3/8/06 angie)
    ssh kolossus
    cd /cluster/data/rn4/bed/stsMarkers/primer
    # create accession_info.rdb: AGP info.
    /cluster/bin/scripts/compileAccInfo -rat /cluster/data/rn4 /dev/null
#0 processed
    # "0 processed" sounds a little scary but it's 0 because we didn't pass 
    # in a -pre rdb.
    mv accession_info.rdb accession_info.rdb.tmp
    /cluster/bin/scripts/sorttbl Chr Ord Start < accession_info.rdb.tmp \
      > accession_info.rdb
    # some lines have "chrN_random_M" in the Contig column but "chrN" 
    # (not chrN_random) in the chrom column.... looks weird, but reading 
    # compileAccInfo it seems intentional to lump ordered and random.
    rm accession_info.rdb.tmp
    # Would compare to rn3 if I could find it...
    wc accession_info.rdb
# 138571 1524285 9921966 accession_info.rdb

    # filterSTSPrimers combines blat.2 and epcr results.  
    # For human there is a program pslFilterPrimers that combines isPcr and 
    # epcr results... might be interesting to try that next time around.
    /cluster/bin/scripts/filterSTSPrimers -rat \
      ../stsInfoRat.tab primers.psl.100.unlifted \
      ../ratPrimer.info ../ePCR/all.epcr \
    | liftUp -nohead -type=.psl primers.psl.filter.blat \
        ../../../jkStuff/liftAll.lft warn stdin
    # Would compare to rn3 if I could find it...
    wc primers.psl.100.unlifted
#  8050086 169051724 799770587 primers.psl.100.unlifted
    wc primers.psl.filter.blat
#  38707  812847 4100619 primers.psl.filter.blat

    # filterSTSPrimers creates epcr.not.found which actually contains 
    # items that *were* found by epcr but not by blat.  Translate to PSL:
    /cluster/bin/scripts/epcrToPsl -rat epcr.not.found ../ratPrimer.info \
      accession_info.rdb /cluster/data/rn4
    # epcrToPsl creates epcr.not.found.nomatch and epcr.not.found.psl
    # Would compare to rn3 if I could find it...
    wc epcr*
#  748  2992 27112 epcr.not.found
#    0     0     0 epcr.not.found.nomatch
#  748 15708 72452 epcr.not.found.psl
    # Lift the PSL:
    mv epcr.not.found.psl epcr.not.found.unlifted.psl
    liftUp -nohead epcr.not.found.psl \
      ../../../jkStuff/liftAll.lft warn epcr.not.found.unlifted.psl
    wc epcr.not.found.psl
#  748 15708 80899 epcr.not.found.psl

    cat primers.psl.filter.blat epcr.not.found.psl > primers.psl.filter

    # create primers.psl.filter.lifted.initial
    /cluster/bin/scripts/extractPslInfo primers.psl.filter
    # Would compare to rn3 if I could find it...
    wc primers.psl.filter.initial
#  39451  236706 2071215 primers.psl.filter.initial

    # create primers.psl.filter.lifted.initial.acc
    /cluster/bin/scripts/findAccession -agp \
      -rat primers.psl.filter.initial /cluster/data/rn4
    # it warns about missing AGP for M_random -- OK.
    # Would compare to rn3 if I could find it...
    wc primers.psl.filter.initial.acc
#  39451  276157 2579345 primers.psl.filter.initial.acc

    /cluster/bin/scripts/getStsId -rat \
      ../stsInfoRat.tab  primers.psl.filter.initial.acc \
    | sort -k 4n primers.initial.acc.trans > primers.final
    # Would compare to rn3 if I could find it...
    wc primers.final
#  39451  276157 2232848 primers.final

    # Lift clone sequence alignments
    cd /cluster/data/rn4/bed/stsMarkers/clone
    liftUp -nohead clones.psl \
      ../../../jkStuff/liftAll.lft warn clones.unlifted.psl
    /cluster/bin/scripts/extractPslInfo clones.psl
    # extractPslInfo creates clones.psl.initial
    /cluster/bin/scripts/findAccession -agp \
      -rat clones.psl.initial /cluster/data/rn4
    # findAccession creates clones.psl.initial.acc
    sort -k 4n clones.psl.initial.acc > clones.final

    # Combine clone sequence alignments with primer alignments
    cd /cluster/data/rn4/bed/stsMarkers
    /cluster/bin/scripts/combineSeqPrimerPos \
      clone/clones.final primer/primers.final 
    # creates stsMarkers_pos.rdb
    # Would compare to rn3 if I could find it...
    wc stsMarkers_pos.rdb
#  39291  275037 1893500 stsMarkers_pos.rdb

    ~/kent/src/hg/stsMarkers/createStsMapRat \
      stsInfoRat.tab  stsMarkers_pos.rdb > stsMapRat.bed
    # Would compare to rn3 if I could find it...
    wc stsMapRat.bed
#  38802  582030 3297166 stsMapRat.bed

    ~/kent/src/hg/stsMarkers/createStsAlias stsInfoRat.tab \
    | sort -u > stsAlias.tab
    # Warnings about missing aliases... probably OK.
    # Would compare to rn3 if I could find it...
    wc stsAlias.tab
# 115872  347616 2809404 stsAlias.tab

    #	compare old and new name lists:
    ssh -x hgwdev 'hgsql -N rn3 -e "select name from stsMapRat" | sort -u' \
    > rn3.nameList
    awk '{print $4}' stsMapRat.bed | sort -u > rn4.nameList
    comm -12 rn?.nameList | wc
#  32693   32693  290774 [in common]
    comm -23 rn3.nameList rn4.nameList | wc
#   1208    1208   10659 [in rn3 only]
    comm -13 rn3.nameList rn4.nameList | wc
#   5234    5234   48832 [in rn4 only]


# LOAD STS MARKER TABLES (DONE 3/8/06 angie)
    ssh hgwdev
    cd /cluster/data/rn4/bed/stsMarkers
    # Add primer sequences to /gbdb and load:
    mkdir /gbdb/rn4/stsMarker
    ln -s /cluster/data/rn4/bed/stsMarkers/ratPrimer.fa \
      /gbdb/rn4/stsMarker/ratPrimer.fa
    # PLEASE NOTE: if re-running hgLoadSeq, you MUST add
    #	-replace
    #	hgLoadSeq -replace rn4 /gbdb/rn4/stsMarker/ratPrimer.fa
    # otherwise there will be a problem that the seq and extFile tables 
    # will be out of sync. 
    hgLoadSeq rn4 /gbdb/rn4/stsMarker/ratPrimer.fa
    hgLoadSqlTab rn4 stsAlias \
      ~/kent/src/hg/lib/stsAlias.sql stsAlias.tab
    hgLoadSqlTab rn4 stsInfoRat \
      ~/kent/src/hg/lib/stsInfoRat.sql stsInfoRat.tab

    # After some work on the stsInfoRat creation process which should help 
    # next time around (do not do this part next time, just for the record):
    hgLoadSqlTab rn4 stsInfoRat \
      ~/kent/src/hg/lib/stsInfoRat.sql stsInfoRat.tab.new
#Warning: load of stsInfoRat did not go as planned: 48048 record(s), 0 row(s) skipped, 5 warning(s) loading stsInfoRat.tab
    echo 'select * from stsInfoRat' | hgsql -N rn4 > /tmp/tmp
    # compare /tmp/tmp and stsInfoRat.tmp -- looks like 5 alias fields are 
    # truncated at 255 chars, not so terrible because we have stsAlias.
    # -- But since the IDs are off-by-one for a large stretch of that due 
    # -- to getting rid of a garbage line, I reloaded and manually deleted 
    # -- the unused and often truncated clone sequence values:
    hgLoadSqlTab rn4 stsInfoRat \
      ~/kent/src/hg/lib/stsInfoRat.sql stsInfoRat.tab
#Warning: load of stsInfoRat did not go as planned: 48049 record(s), 0 row(s) skipped, 396095 warning(s) loading stsInfoRat.tab
    hgsql rn4 -e 'update stsInfoRat set clone = "";'
    # Again, next time around the above should not be necessary.

    cat primer/primers.psl.filter clone/clones.psl \
    | hgLoadPsl -table=all_sts_primer rn4 stdin
    hgLoadBed rn4 stsMapRat -tab \
      -sqlTable=$HOME/kent/src/hg/lib/stsMapRat.sql stsMapRat.bed
#Loaded 38802 elements of size 15

    nice featureBits rn4 all_sts_primer
#10103096 bases of 2571531505 (0.393%) in intersection
    nice featureBits rn3 all_sts_primer
#9722909 bases of 2571104688 (0.378%) in intersection
    nice featureBits rn4 stsMapRat
#11755453 bases of 2571531505 (0.457%) in intersection
    nice featureBits rn3 stsMapRat
#10119869 bases of 2571104688 (0.394%) in intersection

# end STS MARKERS 
##########################################################################


###############################################################################
# BUILD KNOWN GENES TABLES (DONE 3/2/06 angie)

# Use protein databases built by Fan: sp060115 and proteins060115
# See makeProteins060115.doc for details.
# Ask cluster-admin to rync sp060115 and proteins060115 to kolossus 
# so that database work can be done there; then final results will be 
# rsync'd back to hgwdev.

    # Create working subdirectories and temporary databases (kgRn4A)
    ssh kolossus
    mkdir /cluster/data/rn4/bed/kgRn4A
    ln -s /cluster/data/rn4/bed/kgRn4A /cluster/store6/kgDB/bed/kgRn4A
    ln -s /cluster/data/rn4/bed/kgRn4A /cluster/store11/kg/kgRn4A

    hgsql rn4 -e "create database kgRn4A"   
    hgsql rn4 -e "create database kgRn4ATemp"

    mkdir /cluster/bluearc/kgDB/kgRn4A
    mkdir /cluster/bluearc/kgDB/kgRn4A/protBlat
    ln -s /cluster/bluearc/kgDB/kgRn4A/protBlat \
      /cluster/data/rn4/bed/kgRn4A/protBlat

    # Save a copy of several genbank tables so that we can produce consistent 
    # results if we need to add more tables later.  First, ask cluster-admin 
    # to rsync the tables from hgwdev rn4 --> kolossus.  Save files too:
    mkdir /cluster/data/rn4/bed/kgRn4A/genbankBackup
    cd /cluster/data/rn4/bed/kgRn4A/genbankBackup
    chmod 777 .
    foreach t (all_mrna cds gbCdnaInfo gbExtFile gbLoaded gbSeq gbStatus \
               mgcGenes \
               refFlat refGene refLink refSeqAli refSeqStatus refSeqSummary \
               xenoMrna xenoRefFlat xenoRefGene xenoRefSeqAli)
      echo $t
      hgsqldump --tab=. rn4 $t
    end
    gzip *.txt
    chmod 775 .

    # Get all rat protein sequences
    cd /cluster/data/rn4/bed/kgRn4A/protBlat
    hgsql -N sp060115 -e \
    'select p.acc, p.val from protein p, accToTaxon x \
      where x.taxon=10116 and p.acc=x.acc'\
    | awk '{print ">" $1; print $2;}' \
      > ratProt.fa
    hgsql -N sp060115 -e \
    'select v.varAcc, p.val from varAcc v, protein p, accToTaxon x \
      where v.parAcc = p.acc and x.taxon=10116   and v.parAcc=x.acc'\
    | awk '{print ">" $1; print $2;}' \
      >> ratProt.fa

    # Prepare and perform cluster run for protein/genome alignment
    ssh kolossus
    cd /cluster/bluearc/kgDB/kgRn4A/protBlat
    mkdir prot
    faSplit sequence ratProt.fa 2000 prot/prot
    ls /cluster/bluearc/kgDB/kgRn4A/protBlat/prot/* > prot.lis
    hgsql rn4 -N -e 'select chrom from chromInfo' > chrom.lis

    ssh pk
    cd /cluster/bluearc/kgDB/kgRn4A/protBlat
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/blat -t=dnax -q=prot /scratch/hg/rn4/nib/$(path1).nib $(path2) {check out line+ /cluster/bluearc/kgDB/kgRn4A/protBlat/result/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
     # << emacs
    mkdir result
    gensub2 chrom.lis prot.lis gsub jobList
    para make jobList
#Completed: 89100 of 89100 jobs
#CPU time in finished jobs:    4215176s   70252.93m  1170.88h   48.79d  0.134 y
#IO & Wait Time:                230997s    3849.96m    64.17h    2.67d  0.007 y
#Average job time:                  50s       0.83m     0.01h    0.00d
#Longest finished job:            5794s      96.57m     1.61h    0.07d
#Submission to last job:         16257s     270.95m     4.52h    0.19d

    # collect BLAT results
    ssh kolossus
    cd /cluster/bluearc/kgDB/kgRn4A/protBlat
    pslSort -nohead dirs raw.psl temp result
    pslReps -nohead -minCover=0.80 -minAli=0.80 -nearTop=0.002 raw.psl \
      protBlat.psl /dev/null
    hgLoadPsl -fastLoad rn4 protBlat.psl
#load of protBlat did not go as planned: 14768 record(s), 0 row(s) skipped, 48 warning(s) loading psl.tab
# Some of the lines had negative qGapSizes.  ask Jim...

    # create all_mrna.psl and tight_mrna.psl
    zcat /cluster/data/rn4/bed/kgRn4A/genbankBackup/all_mrna.txt.gz \
    | cut -f 2-22 > all_mrna.psl
    pslReps -minCover=0.40 -minAli=0.97 -nearTop=0.002 all_mrna.psl \
      tight_mrna.psl /dev/null

    # Use overlapSelect to get protein and mRNA alignment overlaps   
    overlapSelect  -statsOutput  -dropped=protOut.psl -overlapThreshold=0.90 \
      -selectFmt=psl -inFmt=psl tight_mrna.psl  protBlat.psl protMrna.stat
    overlapSelect  -mergeOutput  -dropped=protOut.psl -overlapThreshold=0.90 \
      -selectFmt=psl -inFmt=psl tight_mrna.psl  protBlat.psl protMrna.out

    # Create protein/mRNA pair and protein lists
    cut -f 10,31 protMrna.out | sort -u > spMrna.tab
    cut -f 10    protMrna.out | sort -u > protein.lis

    # Load spMrna.tab into spMrna table in temp DB.
    hgLoadSqlTab -notOnServer kgRn4ATemp spMrna ~/kent/src/hg/lib/spMrna.sql \
      spMrna.tab
    hgsql kgRn4ATemp -e 'create index mrnaID on spMrna(mrnaID)'

# Prepare and perform cluster run of protein/mRNA alignment
    # Get mRNA fa file.
    cd /cluster/data/rn4/bed/kgRn4A
    /cluster/data/genbank/bin/i386/gbGetSeqs -native -db=rn4 \
      -gbRoot=/cluster/data/genbank genbank mrna mrna.fa
    # Create mrnaSeq table in kgRn4ATemp DB.
    hgPepPred kgRn4ATemp generic mrnaSeq mrna.fa
    # Prepare files for cluster run
    cd /cluster/bluearc/kgDB/kgRn4A
    ~/kent/src/hg/protein/KG2.sh kgRn4A rn4 060115
    # Perform cluster run of protein/mRNA alignment
    ~/kent/src/hg/protein/KG3.sh kgRn4A rn4 060115
    # Collect cluster run results
    cd kgBestMrna
    cp /dev/null protMrnaRaw.psl
    foreach d (out/*)
      echo $d
      cat $d/*.out >> protMrnaRaw.psl
    end
    # Filter out low quality alignments
    pslReps -nohead -singleHit -minAli=0.9 protMrnaRaw.psl \
      protMrnaBlat.psl /dev/null
#Processed 33623 alignments
    cut -f 10,14 protMrnaBlat.psl | sort -u > protMrna.lis
    wc protMrna.lis
# 21430  42860 334656 protMrna.lis

    # Load BLAT results into temp DB.
    ssh kolossus
    cd /cluster/data/rn4/bed/kgRn4A/kgBestMrna
    hgsql kgRn4ATemp -e 'create table chromInfo select * from rn4.chromInfo'
    hgLoadPsl -fastLoad kgRn4ATemp protMrnaBlat.psl
#load of protMrnaBlat did not go as planned: 21432 record(s), 0 row(s) skipped, 97 warning(s) loading psl.tab
#-- tGapBases (tGapInsert) this time -- ask Jim
    # Create CDS files from protein/mRNA alignment results.
    hgsql kgRn4ATemp -N -e \
    'select qName,"_",tName,tStart+1,":",tEnd+3 from protMrnaBlat \
      order by qName,tName,tEnd-tStart desc'\
    | sed 's/\t_\t/_/g; s/\t:\t/../g' > protMrna.cds

    # Create protMrna.psl with proteinID_mrnaID as query ID.
    cut -f 22-30 ../protBlat/protMrna.out > j1.tmp
    cut -f 32-42 ../protBlat/protMrna.out > j2.tmp
    cut -f 10,31 ../protBlat/protMrna.out | sed -e 's/\t/_/g' > j3.tmp
    paste j1.tmp j3.tmp j2.tmp > protMrna.psl
    rm j1.tmp j2.tmp j3.tmp

    # Run mrnaToGene to create protMrna.gp
    bash
    mrnaToGene -cdsFile=protMrna.cds protMrna.psl protMrna.gp \
      2>protMrna.err >protMrna.log
    exit

    # No need to move kgBestMrna anywhere else for now:
    du -sh
#240M    .
    df -h .
#kkstore01-10:/export/cluster/store9
#                      1.3T  1.1T  199G  84% /cluster/store9

    # Prepare refGene and all_mrna gp files.
    cd ..
    zcat genbankBackup/refGene.txt.gz > ref.gp
    hgsql rn4 -N -e \
    'select gbCdnaInfo.acc,cds.name from gbCdnaInfo,cds,all_mrna \
     where all_mrna.qName=gbCdnaInfo.acc and gbCdnaInfo.cds=cds.id' \
    | sort -u > all_mrna.cds
    bash
    mrnaToGene -cdsFile=all_mrna.cds \
      /cluster/bluearc/kgDB/kgRn4A/protBlat/all_mrna.psl all_mrna.gp \
      2>all_mrna.err > all_mrna.log
    exit

    # Align proteins to RefSeq.
    overlapSelect -inCds -statsOutput -overlapThreshold=0.90 -selectFmt=psl \
      -inFmt=genePred protBlat/protBlat.psl ref.gp ref.stat
    overlapSelect -inCds -dropped=refOut1.gp -overlapThreshold=0.90 \
      -selectFmt=psl -inFmt=genePred protBlat/protBlat.psl ref.gp protRef.gp
    overlapSelect -mergeOutput -selectCds -dropped=protOut1.psl \
      -overlapThreshold=0.80 -inFmt=psl \
      -selectFmt=genePred ref.gp protBlat/protBlat.psl protRef.out

    cut -f 10,22 protRef.out | sort -u >spRef.tab
    cut -f 10 protRef.out    | sort -u >protRef.lis

    hgLoadSqlTab kgRn4ATemp spRef ~/kent/src/hg/lib/spRef.sql spRef.tab

    # Prepare and perform cluster runs for protein/RefSeq alignments
    ~/kent/src/hg/protein/KGRef2.sh kgRn4A rn4 060115
    ~/kent/src/hg/protein/KGRef3.sh kgRn4A rn4 060115

    cd kgBestRef
    cp /dev/null protRefRaw.psl
    foreach d (out/*)
      echo $d
      cat $d/*.out >> protRefRaw.psl
    end
    # Filter out low quality alignments.
    pslReps -nohead -singleHit -minAli=0.9 protRefRaw.psl \
      protRefBlat.psl /dev/null
#Processed 15266 alignments
    cut -f 10,14 protRefBlat.psl | sort -u > protRef.lis
    wc protRef.lis
# 11957  23914 216980 protRef.lis

    hgLoadPsl -fastLoad kgRn4ATemp protRefBlat.psl
#load of protRefBlat did not go as planned: 11958 record(s), 0 row(s) skipped, 45 warning(s) loading psl.tab
    # Negative tGapSizes again.

    # Run gene-check to filter out invalid gp entries
    cd /cluster/data/rn4/bed/kgRn4A
    cat ref.gp kgBestMrna/protMrna.gp all_mrna.gp >kgCandidate0.gp
    /cluster/bin/i386/gene-check  -incl-ok -ok-genepred-out \
      kgCandidate0.passed.gp \
      -nib-dir /cluster/data/rn4/nib kgCandidate0.gp kgCandidate0.check

    ldHgGene -predTab kgRn4ATemp kgCandidate0 kgCandidate0.gp
    tail +3 kgCandidate0.check > geneCheck.tab
    hgLoadSqlTab kgRn4ATemp geneCheck ~/kent/src/hg/lib/geneCheck.sql \
      geneCheck.tab

    # Run kgCheck to get all KG candidates that pass the KG gene check criteria
    kgCheck kgRn4ATemp rn4 kgCandidate0 geneCheck kgCandidate.tab
    hgLoadSqlTab  kgRn4ATemp kgCandidate ~/kent/src/hg/lib/kgCandidate.sql \
      kgCandidate.tab
    hgsql kgRn4ATemp -e 'create index alignID on kgCandidate(alignID)'

    # Construct the kgCandidateX table that has alignID in the name field. 
    cut -f 2-10 kgCandidate.tab > j2.tmp
    cut -f 11 kgCandidate.tab > j1.tmp
    paste j1.tmp j2.tmp > kgCandidateX.tab
    ldHgGene -predTab kgRn4ATemp kgCandidateX kgCandidateX.tab

    # Score protein/mRna and protein/RefSeq alignments
    ln -s /cluster/bluearc/kgDB/kgRn4A/protBlat/protein.lis .
    kgResultBestMrna2 060115 kgRn4ATemp rn4 protMrnaBlat | sort -u \
      > protMrnaBlatScore.tab
    kgResultBestRef2  060115 kgRn4ATemp rn4 protRefBlat | sort -u \
      > protRefScore.tab

    # Combine scoring results and load them into temp DB.
    cat protMrnaBlatScore.tab protRefScore.tab > protMrnaScore.tab
    hgLoadSqlTab kgRn4ATemp protMrnaScore ~/kent/src/hg/lib/protMrnaScore.sql \
      protMrnaScore.tab
    hgsql kgRn4ATemp -e 'create index mrnaAcc on protMrnaScore(mrnaAcc)'

    # Run kgGetCds to get CDS structure of each gene
    kgGetCds kgRn4ATemp 060115 kgCandidateX stdout \
    | sort -u > kgCandidateY.tab
    hgLoadSqlTab kgRn4ATemp kgCandidateY ~/kent/src/hg/lib/kgCandidateY.sql \
      kgCandidateY.tab

    # Run kgPickPrep to replace long cds structure string with cdsId.
    kgPickPrep kgRn4ATemp kgCandidateZ.tab
    hgLoadSqlTab kgRn4ATemp kgCandidateZ ~/kent/src/hg/lib/kgCandidateZ.sql \
      kgCandidateZ.tab
    hgsql kgRn4ATemp -e 'create index cdsId on kgCandidateZ(cdsId)'

    # Run kgPick to pick the representative a mrna/protein pair for each 
    # unique CDS structure.
    kgPick kgRn4ATemp rn4 sp060115 kg3.tmp stdout \
    | sort -u > dupSpMrna.tab

    # Create put back list
    /cluster/data/genbank/bin/i386/gbGetSeqs \
      -gbRoot=/cluster/data/genbank db=rn4 -get=ra -native RefSeq mrna stdout \
    | perl -wpe 's/^(\w+) (.*)/$1\t$2/ || next; $acc = $2 if ($1 eq "acc"); \
                 s/^/$acc\t/;' \
    | sort -u | tail +2 > refRa.tab
    hgLoadSqlTab rn4 refRa ~/kent/src/hg/lib/refRa.sql refRa.tab

     hgsql rn4 -N -e \
     'select r.acc, r.attr, r.val from refRa r, refRa r2, refRa r3 \
      where r.attr="selenocysteine" and r.acc=r2.acc and r2.attr="rss" and \
        r2.val="rev" and r3.acc=r.acc and r3.attr="org" and \
        r3.val="Rattus norvegicus"' \
     > kgPutBack2.tab
     hgsql rn4 -N -e \
     'select r.acc, r.attr, r.val from refRa r, refRa r2, refRa r3 \
      where r.attr="cno" and r.val like "%ribosomal frameshift%" and \
        r.acc=r2.acc and r2.attr="rss" and r2.val="rev" and r2.val="rev" and \
        r3.acc=r.acc and r3.attr="org" and r3.val="Rattus norvegicus"' \
     >> kgPutBack2.tab
     hgsql rn4 -N -e \
     'select r.acc, r.attr, r.val from refRa r, refRa r2, refRa r3 \
      where r.attr="cno" and r.val like "%non-AUG%" and r.acc=r2.acc and \
        r2.attr="rss" and r2.val="rev" and r2.val="rev" and r3.acc=r.acc and \
        r3.attr="org" and r3.val="Rattus norvegicus"' \
     >> kgPutBack2.tab
     hgsql rn4 -N -e \
     'select r.acc, r.attr, r.val from refRa r, refRa r2, refRa r3 \
      where r.attr="translExcept" and r.acc=r2.acc and r2.attr="rss" and \
        r2.val="rev" and r2.val="rev" and r3.acc=r.acc and r3.attr="org" and \
        r3.val="Rattus norvegicus"' \
     >> kgPutBack2.tab 
     hgsql rn4 -N -e \
     'select r.acc, r.attr, r.val from refRa r, refRa r2, refRa r3 \
      where r.attr="exception" and r.acc=r2.acc and r2.attr="rss" and \
        r2.val="rev" and r2.val="rev" and r3.acc=r.acc and r3.attr="org" and \
        r3.val="Rattus norvegicus"' \
     >> kgPutBack2.tab
     wc -l kgPutBack2.tab
#10 kgPutBack2.tab

    hgLoadSqlTab kgRn4ATemp kgPutBack2 ~/kent/src/hg/lib/kgPutBack2.sql \
      kgPutBack2.tab
    kgPutBack kgRn4ATemp rn4 sp060115 kgPutBack2 kgPutBack2.gp

    # Sort KG genes to make the kg4.gp table file.
    cat kgPutBack2.gp kg3.tmp > kg4.tmp
    ~/kent/src/hg/protein/sortKg.pl kg4.tmp \
    | cut -f 1-12 > knownGene.tab
    # Load data into knownGene table in both kgRn4ATemp and rn4.
    hgLoadSqlTab kgRn4ATemp knownGene ~/kent/src/hg/lib/knownGene.sql \
      knownGene.tab
    hgLoadSqlTab rn4 knownGene ~/kent/src/hg/lib/knownGene.sql \
      knownGene.tab

    # Load dupSpMrna table after knownGene table is loaded so that \
    # joinerCheck does not complain.
    hgLoadSqlTab rn4 dupSpMrna ~/kent/src/hg/lib/dupSpMrna.sql dupSpMrna.tab

    # Perform analysis on KG
    nice featureBits rn4 -enrichment refGene knownGene
#refGene 0.722%, knownGene 0.582%, both 0.539%, cover 74.72%, enrich 128.33x
    nice featureBits rn4 -enrichment refGene:cds knownGene:cds
#refGene:cds 0.500%, knownGene:cds 0.377%, both 0.352%, cover 70.41%, enrich 186.83x

    nice featureBits rn3 -enrichment refGene knownGene
#refGene 0.721%, knownGene 0.523%, both 0.411%, cover 56.96%, enrich 108.94x
    nice featureBits rn3 -enrichment refGene:cds knownGene:cds
#refGene:cds 0.500%, knownGene:cds 0.392%, both 0.294%, cover 58.91%, enrich 150.16x

    # Build knownGeneMrna and knownGenePep tables.
    kgPepMrna kgRn4ATemp rn4 060115
    hgPepPred rn4 tab knownGeneMrna knownGeneMrna.tab
    hgPepPred rn4 tab knownGenePep knownGeneMrna.tab

    # Use hgwdev's entrez database (loaded by Fan, see makeHg18.doc) 
    # to buid the mrnaRefseq table.
    ssh hgwdev
    hgsql entrez -N -e \
    'select mrna, refseq from entrezRefseq, entrezMrna \
     where entrezRefseq.geneID=entrezMrna.geneID' \
      > /cluster/data/rn4/bed/kgRn4A/mrnaRefseq.tmp
    hgsql rn4 -N -e 'select name, name from refGene' \
     >> /cluster/data/rn4/bed/kgRn4A/mrnaRefseq.tmp
    ssh kolossus
    cd /cluster/data/rn4/bed/kgRn4A
    sort -u mrnaRefseq.tmp > mrnaRefseq.tab
    hgLoadSqlTab rn4 mrnaRefseq ~/kent/src/hg/lib/mrnaRefseq.sql mrnaRefseq.tab

    # Build kgXref table
    kgXref2 kgRn4ATemp 060115 rn4
    hgLoadSqlTab rn4 kgXref ~/kent/src/hg/lib/kgXref.sql kgXref.tab

    # Build spMrna table
    hgsql rn4 -N -e 'select name, proteinID from knownGene' > kgSpMrna.tab
    hgLoadSqlTab rn4 spMrna ~/kent/src/hg/lib/spMrna.sql kgSpMrna.tab

    # Build kgProtMap table
    ln -s /cluster/bluearc/kgDB/kgRn4A/protBlat/tight_mrna.psl .
    ~/kent/src/hg/protein/kgProtMap2.sh kgRn4A rn4 060115

#####################################
# Build alias tables.		

    kgAliasM rn4 proteins060115
    kgAliasKgXref rn4
    kgAliasRefseq rn4

    hgsql sp060115 -N -e \
    'select name,gene.val from rn4.knownGene,displayId,gene \
     where displayId.val=proteinID and displayId.acc=gene.acc' \
    | sort -u  > kgAliasP.tab

    hgsql rn4 -N -e 'select name, name from knownGene' > kgAliasDup.tab
    hgsql rn4 -N -e 'select mrnaID, dupMrnaID from dupSpMrna' >> kgAliasDup.tab

    sort -u kgAliasM.tab kgAliasRefseq.tab kgAliasKgXref.tab kgAliasP.tab \
      kgAliasDup.tab > kgAlias.tab

    hgLoadSqlTab rn4 kgAlias ~/kent/src/hg/lib/kgAlias.sql kgAlias.tab
    kgProtAlias rn4 060115

    hgsql rn4 -N -e \
    'select kgID, spDisplayID, protAcc from kgXref where protAcc != ""' \
    | sort -u > kgProtAliasNCBI.tab

    # include variant splice protein IDs
    hgsql rn4 -N -e \
    'select name, proteinID, parAcc from knownGene,sp060115.varAcc \
     where varAcc=proteinID' \
    | sort -u > kgProtAliasDup.tab
    # include duplicate protein IDs from dupSpMrna table
    hgsql rn4 -N -e \
    'select name, knownGene.proteinID, dupProteinID from knownGene, dupSpMrna \
     where name=mrnaID' \
    | sort -u >> kgProtAliasDup.tab
    # catch parent acc from dupProteinID too
    hgsql rn4 -N -e\
    'select name, knownGene.proteinID, parAcc \
     from knownGene,dupSpMrna,sp060115.varAcc \
     where name=mrnaID and dupProteinID=varAcc.varAcc' \
    | sort -u >> kgProtAliasDup.tab
    sort -u kgProtAliasNCBI.tab kgProtAlias.tab kgProtAliasDup.tab \
    > kgProtAliasAll.tab

    hgLoadSqlTab rn4 kgProtAlias ~/kent/src/hg/lib/kgProtAlias.sql \
      kgProtAliasAll.tab

    # Build kgSpAlias table
    hgsql rn4 -e \
    'select kgXref.kgID, spID, alias from kgXref, kgAlias \
     where kgXref.kgID=kgAlias.kgID' > j.tmp
    hgsql rn4 -e \
    'select kgXref.kgID, spID, alias from kgXref, kgProtAlias \
     where kgXref.kgID=kgProtAlias.kgID' >> j.tmp
    sort -u j.tmp | grep -v 'kgID' > rn4.kgSpAlias.tab
    rm j.tmp

    hgLoadSqlTab rn4 kgSpAlias ~/kent/src/hg/lib/kgSpAlias.sql \
      rn4.kgSpAlias.tab

    # Ask cluster-admin to rsync the following tables from kolossus rn4 
    # back to hgwdev rn4:
    dupSpMrna
    kgAlias
    kgProtAlias
    kgProtMap
    kgSpAlias
    kgXref
    knownGene
    knownGeneMrna
    knownGenePep
    mrnaRefseq
    protBlat
    refRa
    spMrna

    # Copy history comments from kolossus to hgwdev's rn4.history table.
    hgsqldump rn4 history \
    | egrep 'dupSpMrna|kgAlias|kgProtAlias|kgProtMap|kgSpAlias|kgXref|knownGene|knownGeneMrna|knownGenePep|mrnaRefseq|protBlat|refRa|spMrna' \
    | perl -wpe 's/\([0-9]+,/(NULL,/' \
      > kgHistory.sql
    ssh hgwdev
    hgsql rn4 < /cluster/data/rn4/bed/kgRn4A/kgHistory.sql


# CREATE FULL TEXT INDEX FOR KNOWN GENES (DONE 3/6/06 angie)
    # This depends on the go and uniProt databases as well as 
    # the kgAlias and kgProAlias tables.
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/kgRn4A/index
    cd /cluster/data/rn4/bed/kgRn4A/index
    hgKgGetText rn4 knownGene.text
    ixIxx knownGene.text knownGene.ix knownGene.ixx
    ln -s /cluster/data/rn4/bed/kgRn4A/index/knownGene.ix /gbdb/rn4/
    ln -s /cluster/data/rn4/bed/kgRn4A/index/knownGene.ixx /gbdb/rn4/

# end KNOWN GENES
###############################################################################


# BLASTZ/CHAIN/NET DANRER3 - NO LINSPECREP (DONE 3/2/06 angie)
    ssh kkstore01
    mkdir /cluster/data/rn4/bed/blastz.danRer3.2006-03-02
    cd /cluster/data/rn4/bed/blastz.danRer3.2006-03-02
    cat << '_EOF_' > DEF
# rat vs zebrafish
BLASTZ=blastz.v7.x86_64

# Reuse parameters from hg16-fr1, danRer-hg17 and mm5-danRer
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_M=50
BLASTZ_Q=/cluster/data/blastz/HoxD55.q

# TARGET: Rat Rn4
SEQ1_DIR=/scratch/hg/rn4/nib
SEQ1_LEN=/cluster/data/rn4/chrom.sizes
SEQ1_CHUNK=20000000
SEQ1_LAP=10000

# QUERY: Zebrafish (danRer3)
#  large enough chunk to do complete chroms at once
SEQ2_DIR=/san/sanvol1/scratch/danRer3/chromNib
SEQ2_LEN=/san/sanvol1/scratch/danRer3/chromNib.sizes
SEQ2_CHUNK=100000000
SEQ2_LAP=0

BASE=/cluster/data/rn4/bed/blastz.danRer3.2006-03-02
'_EOF_'
    # << for emacs
    doBlastzChainNet.pl DEF -bigClusterHub=pk \
      -blastzOutRoot /san/sanvol1/scratch/blastzRn4DanRer3Out >& do.log &
    tail -f do.log
    ln -s blastz.danRer3.2006-03-02 /cluster/data/rn4/bed/blastz.danRer3 


# BLASTZ/CHAIN/NET DANRER3 - WITH LINSPECREP (DONE 3/3/06 angie)
    ssh kkstore01
    # Set up rn4/linSpecRep.notInNonMammal
    mkdir /cluster/bluearc/rn4/linSpecRep.notInNonMammal
    cd /cluster/data/rn4
    foreach f (?{,?}/chr*.fa.out)
      echo $f:t:r:r
      cp -p $f /cluster/bluearc/rn4/linSpecRep.notInNonMammal/$f:t:r:r.out.spec
    end

    # Rename tables from previous run; remove download dir
    ssh hgwdev
    foreach t (netDanRer3 \
               `hgsql rn4 -N -e 'show tables like "%chainDanRer3%"'`)
      set newT = `echo $t | sed -e 's/Rer3/Rer3NoLSR/'`
      hgsql rn4 -e 'rename table '$t' to '$newT
    end
    rm -r /usr/local/apache/htdocs/goldenPath/rn4/vsDanRer3

    ssh pk
    mkdir /cluster/data/rn4/bed/blastz.danRer3.2006-03-03
    cd /cluster/data/rn4/bed/blastz.danRer3.2006-03-03
    cat << '_EOF_' > DEF
# rat vs zebrafish
BLASTZ=blastz.v7.x86_64

BLASTZ_ABRIDGE_REPEATS=1

# Reuse parameters from hg16-fr1, danRer-hg17 and mm5-danRer
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_M=50
BLASTZ_Q=/cluster/data/blastz/HoxD55.q

# TARGET: Rat Rn4
SEQ1_DIR=/scratch/hg/rn4/nib
SEQ1_SMSK=/cluster/bluearc/rn4/linSpecRep.notInNonMammal
SEQ1_LEN=/cluster/data/rn4/chrom.sizes
SEQ1_CHUNK=20000000
SEQ1_LAP=10000

# QUERY: Zebrafish (danRer3)
#  large enough chunk to do complete chroms at once
SEQ2_DIR=/san/sanvol1/scratch/danRer3/chromNib
SEQ2_SMSK=/san/sanvol1/scratch/danRer3/linSpecRep.notInOthers
SEQ2_LEN=/san/sanvol1/scratch/danRer3/chromNib.sizes
SEQ2_CHUNK=100000000
SEQ2_LAP=0

BASE=/cluster/data/rn4/bed/blastz.danRer3.2006-03-03
'_EOF_'
    # << for emacs
    doBlastzChainNet.pl DEF -bigClusterHub=pk \
      -blastzOutRoot /san/sanvol1/scratch/blastzRn4DanRer3Out >& do.log &
    tail -f do.log
    ln -s blastz.danRer3.2006-03-03 /cluster/data/rn4/bed/blastz.danRer3 


#TODO: compare the two danRer3 runs... netstat?  coverage?  eyeball?

#TODO: other pairwise: cow, rabbit, opossum, frog, elephant? armadillo?

# MULTIZ
# PHASTCONS

# AFFY CHIPS

# MGI?
# SNPS?

############################################################################
##  BLASTZ swap from mm8 alignments (DONE - 2006-02-18 - Hiram)
    ssh kk
    cd /cluster/data/mm8/bed/blastzRn4.2006-02-16
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
        -swap -bigClusterHub=kk -chainMinScore=3000 -chainLinearGap=medium \
        `pwd`/DEF > swap.out 2>&1 &

    time nice -n +19 featureBits rn4 chainMm8Link
    #   1791093685 bases of 2571531505 (69.651%) in intersection


