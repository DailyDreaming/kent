#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on the Rattus 
# Norvegicus genome, November 2004 update (Rnor3.4) from Baylor.

# CREATE BUILD DIRECTORY (DONE 1/27/06 angie)
    # df -h /cluster/store*, choose the one with the most space...
    ssh kkstore01
    mkdir /cluster/store9/rn4
    ln -s /cluster/store9/rn4 /cluster/data/rn4


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 1/27/06 angie)
    mkdir /cluster/data/rn4/M
    cd /cluster/data/rn4/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "Rattus norvegicus mitochondrion complete genome".  
    # There are more than one of those... I picked NC_001665 whose gi # is
    # 5835177
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=5835177&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Rattus norvegicus mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# DOWNLOAD SEQUENCE (DONE 1/27/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    mkdir downloads
    cd downloads
    wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/README
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}.fa.gz
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}.fa.qual.gz
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}-random.fa.gz
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/chromosomes/Rnor3.4chr${c}-random.fa.qual.gz
      echo ""
    end
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/contigs/chr{$c}.agp
    end

    mkdir bacs
    cd bacs
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rnorvegicus/Rnor3.4/contigs/chr${c}.contig_bacs.fa.gz
    end
    cd ..

    # Distribute into chrom dirs.
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Un X)
      echo chr$c
      mkdir ../$c
      zcat Rnor3.4chr${c}.fa.gz \
      | sed -e 's/^>gnl[|].*[|]/>/' > ../$c/chr${c}.fa
      zcat Rnor3.4chr${c}-random.fa.gz \
      | sed -e 's/^>gnl[|].*[|]/>/' > ../$c/chr${c}_random.fa
      mv chr${c}.agp ../$c/
    end
#mv: cannot stat `chrUn.agp': No such file or directory
    # No agp for Un, nor *_random.... guess we'll have to use hgFakeAgp 
    # to at least get gaps for those.

    # checkAgpAndFa prints out way too much info -- keep the end/stderr only:
    foreach agp (*/chr*.agp)
      set fa = $agp:r.fa
      echo checking consistency of $agp and $fa
      checkAgpAndFa $agp $fa | tail -1
    end
    faSize */chr*.fa
#2834127293 bases (267832528 N's 2566294765 real 2566294765 upper 0 lower) in 45 sequences in 45 files
#Total size: mean 62980606.5 sd 75162894.7 min 16300 (chrM) max 267910886 (chr1) median 6862066
#N count: mean 5951834.0 sd 6940811.4
#U count: mean 57028772.6 sd 68565220.7
#L count: mean 0.0 sd 0.0


# MAKE FAKE AGP WHERE NECESSARY (DONE 1/27/06 angie)
    # In the chromosomal AGP, all gaps are marked "fragment" *except* for 
    # gaps of exactly 50000 which are "clone".  There are gaps of >>50000
    # marked "fragment"!  However, in the chr*_random and chrUn here,
    # that just seems wrong... chrUn has a gap of 2602000, how could that 
    # possibly be bridged?  (Why are they wasting that kind of space?)
    # So just count >= 50000 as "clone no", even though that is not what 
    # they do in their AGP for the chroms.
    ssh kkstore01
    cd /cluster/data/rn4
    foreach f (?{,?}/chr*.fa)
      set agp = $f:r.agp
      if (! -e $agp) then
        echo Faking missing AGP $agp
        hgFakeAgp -minContigGap=50 -minScaffoldGap=50000 $f stdout \
        | sed -e 's/contig/fragment/; s/scaffold/clone/' \
          > $agp
      endif
    end


# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT CONTIGS/GAPS (DONE 1/27/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    foreach agp (*/chr*.agp)
      set fa = $agp:r.fa
      echo splitting $agp and $fa
      cp -p $agp $agp.bak
      cp -p $fa $fa.bak
      splitFaIntoContigs $agp $fa . -nSize=5000000
    end
    # splitFaIntoContigs makes new dirs for _randoms.  Move their contents 
    # back into the main chrom dirs and get rid of the _random dirs.
    foreach d (*_random)
      set base = `echo $d | sed -e 's/_random$//'`
      mv $d/lift/oOut.lst $base/lift/rOut.lst
      mv $d/lift/ordered.lft $base/lift/random.lft
      mv $d/lift/ordered.lst $base/lift/random.lst
      rmdir $d/lift
      mv $d/* $base
      rmdir $d
    end
    # checkAgpAndFa again to get a warm-fuzzy
    foreach agp (*/chr*.agp)
      set fa = $agp:r.fa
      echo checking consistency of $agp and $fa
      checkAgpAndFa $agp $fa | tail -1
    end
    # Make a "pseudo-contig" for processing chrM too:
    mkdir M/chrM_1
    sed -e 's/chrM/chrM_1/' M/chrM.fa > M/chrM_1/chrM_1.fa
    mkdir M/lift
    set mSize=`faSize M/chrM.fa | awk '{print $1;}'`
    echo "chrM_1/chrM_1.fa.out" > M/lift/oOut.lst
    echo "chrM_1" > M/lift/ordered.lst
    echo "0	M/chrM_1	"$mSize"	chrM	"$mSize"" > M/lift/ordered.lft


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 1/27/06 angie)
    # This used to hold scripts -- better to keep them inline here so 
    # they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/rn4/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/rn4/bed


# REPEAT MASKING (DONE 1/30/06 angie)
    # Record RM version used:
    ls -l /cluster/bluearc/RepeatMasker
#lrwxrwxrwx    1 hiram    protein        18 Jan 20 13:13 /cluster/bluearc/RepeatMasker -> RepeatMasker060120/
    cat /cluster/bluearc/RepeatMasker/Libraries/version
#RM database version 20060120
    # Run RepeatMasker on a dummy input, just to make it initialize its 
    # rat libraries once before the cluster run:
    /cluster/bluearc/RepeatMasker/RepeatMasker -spec rat /dev/null
#Building species libraries in: /cluster/bluearc/RepeatMasker060120/Libraries/20060120/rattus

    #- Split contigs into 500kb chunks, at gaps if possible:
    ssh kkstore01
    cd /cluster/data/rn4
    foreach c (?{,?})
      foreach d ($c/chr${c}*_?{,?})
        cd $d
        echo "splitting $d"
        set contig = $d:t
        faSplit gap $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -minGapSize=100
        cd ../..
      end
    end

    #- Make the run directory and job list:
    cd /cluster/data/rn4
    cat << '_EOF_' > jkStuff/RMRat
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/rn4/$2
/bin/cp $2 /tmp/rn4/$2/
cd /tmp/rn4/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -s -spec rat $2
popd
/bin/cp /tmp/rn4/$2/$2.out ./
if (-e /tmp/rn4/$2/$2.tbl) /bin/cp /tmp/rn4/$2/$2.tbl ./
if (-e /tmp/rn4/$2/$2.cat) /bin/cp /tmp/rn4/$2/$2.cat ./
/bin/rm -fr /tmp/rn4/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn4/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/rn4
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMRat
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach c (?{,?})
      foreach d ($c/chr${c}{,_random}_?{,?})
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/data/rn4/jkStuff/RMRat \
                 /cluster/data/rn4/$d $f \
               '{'check out line+ /cluster/data/rn4/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
      end
    end

    #- Do the run
    ssh kk
    cd /cluster/data/rn4/RMRun
    para create RMJobs
    para make RMJobs; para time | mail -s 'RM cluster run finished' $USER
#Completed: 6487 of 6488 jobs
#Crashed: 1 jobs
#CPU time in finished jobs:   46404794s  773413.24m 12890.22h  537.09d  1.471 y
#IO & Wait Time:                229486s    3824.76m    63.75h    2.66d  0.007 y
#Average job time:                7189s     119.81m     2.00h    0.08d
#Longest finished job:           10699s     178.32m     2.97h    0.12d
#Submission to last job:         86450s    1440.83m    24.01h    1.00d
    # The one crash was due to a divide-by-zero error in ProcessRepeats,
    # on chr1_24_04.fa.  RepeatMasker made chr1_24_04.fa.cat OK, but then 
    # ProcessRepeats died on that when trying to create the .out.  
    # The 050112 version of ProcessRepeats ran OK on the .cat, but the 
    # 050305 and later versions get the divide-by-zero error.  
    # I sent a test case to Robert Hubley on Sunday 1/29 but as of 2pm Mon.
    # I haven't heard back from him yet.  

    # I made what I think is a straightforward fix to get around the 
    # divide-by-0 (there already was a case to handle another denominator
    # term being 0; I just hooked into that), and re-ran ProcessRepeats 
    # like this:
    ssh kolossus
    cd /tmp
    cp /cluster/data/rn4/1/chr1_24/chr1_24_04.out .
    /cluster/bluearc/RepeatMasker/RepeatMasker chr1_24_04.fa
    ~/cb/hg3rdParty/RepeatMasker/ProcessRepeats chr1_24_04.fa.cat
    mv chr1_24_04.fa.out /cluster/data/rn4/1/chr1_24/
    # That is risky -- Robert might provide a fix that has a slightly 
    # different effect, in which case I'll have to redo everything at least 
    # for chr1.  But I'd like to make some progress at least....

    # Update 2/7/06 -- Robert sent a patch for ProcessRepeats (and for 
    # DateRepeats, see below).  Although the patch was not identical to 
    # my patch, the results of ProcessRepeats run on the .cat were identical.
    # So I don't have to redo subsequent steps, whew!

    #- Lift up the 500KB chunk .out's to 5MB ("pseudo-contig") level
    ssh kkstore01
    cd /cluster/data/rn4
    foreach d (*/chr*_?{,?})
      set contig = $d:t
      echo $contig
      liftUp $d/$contig.fa.out $d/$contig.lft warn $d/${contig}_*.fa.out \
        > /dev/null
    end

    #- Lift pseudo-contigs to chromosome level
    foreach c (?{,?})
      echo lifting $c
      cd $c
      if (-e lift/ordered.lft && ! -z lift/ordered.lft) then
        liftUp chr$c.fa.out lift/ordered.lft warn `cat lift/oOut.lst` \
        > /dev/null
      endif
      if (-e lift/random.lft && ! -z lift/random.lft) then
        liftUp chr${c}_random.fa.out lift/random.lft warn `cat lift/rOut.lst` \
        > /dev/null
      endif
      cd ..
    end

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/rn4
    hgLoadOut rn4 */chr*.fa.out
    # Many warnings like this one:
#Strange perc. field -7282.5 line 384881 of 1/chr1.fa.out
#Strange perc. field -143.1 line 384881 of 1/chr1.fa.out
    # That's from chr1_49, not chr1_24 so it is independent of 
    # my tweak to ProcessRepeats above.
    # There was also this warning at the end:
#note: 4 records dropped due to repStart > repEnd
#      run with -verbose=2 for details
    # Ran with -verbose=2 on kolossus... these are the warnings:
#bad rep range [152, 128] line 108428 of 17/chr17.fa.out 
#bad rep range [58, -69] line 86997 of 5/chr5.fa.out 
#bad rep range [69, 7] line 30310 of 8/chr8.fa.out 
#bad rep range [1303, 1228] line 94319 of X/chrX.fa.out 
#TODO: send those on to Robert too.


# CREATING DATABASE (DONE 1/27/06 angie)
    ssh hgwdev
    hgsql '' -e 'create database rn4'
    # Use df to make sure there is at least 75G free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  1.6T   88G  95% /var/lib/mysql
    # Wow... we sure have filled that sucker up.


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 1/27/06 angie)
    ssh hgwdev
    hgsql rn4 -e "create table grp (PRIMARY KEY(NAME)) select * from rn3.grp"


# VERIFY REPEATMASKER RESULTS (TODO 1/30/06 angie)
    # Eyeball some repeat annotations in the browser, compare to lib seqs.
    # Run featureBits on rn4 and on previous genome build, and compare:
    ssh hgwdev
    nice featureBits rn4 rmsk
# Hmmmm... seems wrong for this to decrease...
#1106283290 bases of 2571531505 (43.020%) in intersection
    nice featureBits rn3 rmsk
#1117483165 bases of 2571104688 (43.463%) in intersection


# MAKE LIFTALL.LFT (DONE 1/27/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft


# GOLD AND GAP TRACKS (DONE 1/27/06 angie)
    ssh hgwdev
    cd /cluster/data/rn4
    hgGoldGapGl -noGl rn4 /cluster/data/rn4 .
    # Wow, tons of warnings like this:
#unexpected coords (6960, 6960) for frag chrX_random_2 in chrom chrX_random
    # -- There really are little single non-N bases between large blocks 
    # of N in the random fasta!  Sheesh, what a mess.  But randoms are 
    # the dregs...


# SIMPLE REPEATS (TRF) (DONE 1/30/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/bed/simpleRepeat
    cd /cluster/data/rn4/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach d (/cluster/data/rn4/*/chr*_?{,?})
      set ctg = $d:t
      foreach f ($d/${ctg}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
      end
    end
    csh -ef jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
#591
    endsInLf trf/*
#trf/chrM_1.bed zero length
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/rn4/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load into the database:
    ssh hgwdev
    hgLoadBed rn4 simpleRepeat \
      /cluster/data/rn4/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
    nice featureBits rn4 simpleRepeat
#72859247 bases of 2571531505 (2.833%) in intersection
    # Compare to rn3:
    nice featureBits rn3 simpleRepeat
#70073656 bases of 2571104688 (2.725%) in intersection


# SET UP DB ON KOLOSSUS (DONE 1/30/06 angie)
    # to spare hgwdev, make an rn4 on kolossus so that we have the 
    # option of loading there and pushing to hgwdev.  It will need the 
    # gap tables and also chromInfo (added below) so that we can run 
    # featureBits on it.
    hgsql '' -e 'create database rn4'
    cd /cluster/data/rn4
    hgGoldGapGl -noGl rn4 /cluster/data/rn4 .


# CYTOBAND (DONE 1/30/06 angie)
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/cytoBand
    cd /cluster/data/rn4/bed/cytoBand
    wget ftp://ftp.ncbi.nih.gov/genomes/R_norvegicus/mapview/ideogram.gz
    zcat ideogram.gz | sort -k1,1 -k6n,6n > ideogram.sorted
    /cluster/bin/scripts/createNcbiCytoBand ideogram.sorted
    # Load the bed file into both cytoBand and cytoBandIdeo:
    hgLoadBed -noBin -sqlTable=$HOME/kent/src/hg/lib/cytoBand.sql \
      rn4 cytoBand cytoBand.bed
    hgLoadBed -noBin -sqlTable=$HOME/kent/src/hg/lib/cytoBandIdeo.sql \
      rn4 cytoBandIdeo cytoBand.bed
    # Doh, the file does not have stain information!  All of the bands 
    # are the same as in rn3, so grab stain info from there.
    hgsql rn4 -e '\
      create table bandToStain select name,gieStain from rn3.cytoBand; \
      update cytoBand,bandToStain \
        set cytoBand.gieStain = bandToStain.gieStain \
        where cytoBand.name = bandToStain.name; \
      update cytoBandIdeo,bandToStain \
        set cytoBandIdeo.gieStain = bandToStain.gieStain \
        where cytoBandIdeo.name = bandToStain.name; \
      drop table bandToStain;'


# PROCESS SIMPLE REPEATS INTO MASK (DONE 1/30/06 angie)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kkstore01
    cd /cluster/data/rn4/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/rn4
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # Here's the coverage for the filtered TRF:
    ssh kolossus
    cat /cluster/data/rn4/bed/simpleRepeat/trfMaskChrom/*.bed \
      > /tmp/filtTrf.bed
    featureBits rn4 /tmp/filtTrf.bed
#50551402 bases of 2571531505 (1.966%) in intersection


# MASK SEQUENCE WITH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 1/30/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    # Soft-mask (lower-case) the contig and chr .fa's, 
    # then make hard-masked versions from the soft-masked.  
    set trfCtg=bed/simpleRepeat/trfMask
    set trfChr=bed/simpleRepeat/trfMaskChrom
    foreach f (*/chr*.fa)
      echo "repeat- and trf-masking $f"
      maskOutFa -soft $f $f.out $f
      set chr = $f:t:r
      maskOutFa -softAdd $f $trfChr/$chr.bed $f
      echo "hard-masking $f"
      maskOutFa $f hard $f.masked
    end
    foreach c (?{,?})
      echo "repeat- and trf-masking contigs of chr$c, chr${c}_random"
      foreach d ($c/chr*_?{,?})
        set ctg=$d:t
        set f=$d/$ctg.fa
        maskOutFa -soft $f $f.out $f
        maskOutFa -softAdd $f $trfCtg/$ctg.bed $f
        maskOutFa $f hard $f.masked
      end
    end
    # Make 2bit (for hgBlat, browser):
    faToTwoBit */chr*.fa rn4.2bit
    # Make nib (for blastz w/linSpecRep, OK for genbank too):
    mkdir nib
    foreach f (?{,?}/chr*.fa)
      echo $f:t:r
      faToNib -softMask $f nib/$f:t:r.nib
    end


# PUT NIBS ON /SCRATCH (DONE 1/30/06 angie)
    ssh kkstore01
    mkdir /cluster/bluearc/scratch/hg/rn4
    rsync -av /cluster/data/rn4/nib/* /cluster/bluearc/scratch/hg/rn4/nib/
    # Ask cluster-admin to distribute to /scratch on big & small cluster


# MAKE CHROMINFO TABLE WITH 2BIT (DONE 1/30/06 angie)
    ssh kkstore01
    cd /cluster/data/rn4
    mkdir bed/chromInfo
    twoBitInfo rn4.2bit stdout \
    | awk '{print $1 "\t" $2 "\t/gbdb/rn4/rn4.2bit";}' \
      > bed/chromInfo/chromInfo.tab

    # Link to 2bit from /gbdb/rn4/:
    ssh hgwdev
    mkdir /gbdb/rn4
    ln -s /cluster/data/rn4/rn4.2bit /gbdb/rn4/
    # Load /gbdb/rn4/rn4.2bit paths into database and save size info.
    hgsql rn4  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgsql rn4 -e 'load data local infile \
      "/cluster/data/rn4/bed/chromInfo/chromInfo.tab" \
      into table chromInfo;'
    echo "select chrom,size from chromInfo" | hgsql -N rn4 > chrom.sizes
    # take a look at chrom.sizes size
    wc chrom.sizes
#     45      90     789 chrom.sizes
    # Load chromInfo on kolossus too (required for featureBits):
    ssh kolossus
    hgsql rn4  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgsql rn4 -e 'load data local infile \
      "/cluster/data/rn4/bed/chromInfo/chromInfo.tab" \
      into table chromInfo;'


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE 1/30/06 angie)
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvsup

    # Add trackDb directories and a description.html
    mkdir rat/rn4
    cvs add rat/rn4
    cvs add rat/rn4/description.html
    cvs ci rat/rn4
    # Edit that makefile to add rn4 in all the right places and do
    make update DBS=rn4

    mkdir /gbdb/rn4/html
    cvs ci makefile
    # Go public on genome-test.  In a clean tree (no mods, up-to-date):
    cvs up makefile
    make alpha
    # Note: hgcentral*.genome values must correspond
    # with defaultDb.genome values
    hgsql -h genome-testdb hgcentraltest \
      -e 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome, scientificName, \
                htmlPath, hgNearOk, hgPbOk, sourceName) values \
        ("rn4", "Nov. 2004", "/gbdb/rn4/rn4.2bit", "Rat", \
               "chr2:22845558-23004134", 1, 30, "Rat", \
                "Rattus norvegicus", "/gbdb/rn4/html/description.html", \
                0, 0, "Baylor HGSC v. 3.4");'


# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 1/30/06 angie)
    ssh kolossus
    cd /cluster/data/rn4
    #- Build the .tar.gz files -- no genbank for now.
    cat << '_EOF_' > jkStuff/zipAll.csh
rm -rf bigZips
mkdir bigZips
tar cvzf bigZips/chromAgp.tar.gz ?{,?}/chr*.agp
tar cvzf bigZips/chromOut.tar.gz ?{,?}/chr*.fa.out
tar cvzf bigZips/chromFa.tar.gz ?{,?}/chr*.fa
tar cvzf bigZips/chromFaMasked.tar.gz ?{,?}/chr*.fa.masked
cd bed/simpleRepeat
tar cvzf ../../bigZips/chromTrf.tar.gz trfMaskChrom/chr*.bed
cd ../..
'_EOF_'
    # << this line makes emacs coloring happy
    csh -ef ./jkStuff/zipAll.csh >& zipAll.log &
    tail -f zipAll.log
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    cd bigZips
    md5sum *.gz > md5sum.txt
    # Make a README.txt
    cd ..
    mkdir chromGz
    foreach f ( ?{,?}/chr*.fa )
      echo $f:t:r
      gzip -c $f > chromGz/$f:t.gz
    end
    cd chromGz
    md5sum *.gz > md5sum.txt
    # Make a README.txt

    #- Link the .gz and .txt files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    set gp = /usr/local/apache/htdocs/goldenPath/rn4
    mkdir -p $gp/bigZips
    ln -s /cluster/data/rn4/bigZips/{chrom*.tar.gz,*.txt} $gp/bigZips
    mkdir -p $gp/chromosomes
    ln -s /cluster/data/rn4/chromGz/{chr*.gz,*.txt} $gp/chromosomes
    # Take a look at bigZips/* and chromosomes/*
    # Can't make refGene upstream sequence files - no refSeq for yakuba.
    mkdir $gp/database
    # Create README.txt files in database/ to explain the files.


# MAKE 11.OOC (DONE 2/10/06 angie)
    ssh kolossus
    cd /cluster/data/rn4
    mkdir /cluster/bluearc/rn4
    blat rn4.2bit /dev/null /dev/null \
      -tileSize=11 -makeOoc=/cluster/bluearc/rn4/11.ooc -repMatch=1024
#Wrote 25608 overused 11-mers to /cluster/bluearc/rn4/11.ooc


# GENBANK AUTO UPDATE (IN PROGRESS 2/10/06 angie)
    # align with revised genbank process. drop xeno ESTs.
    cd ~/kent/src/makeDb/genbank
    cvsup
    # edit etc/genbank.conf to add rn4

# rn4
rn4.serverGenome = /cluster/data/rn4/rn4.2bit
rn4.clusterGenome = /iscratch/i/rn4/rn4.2bit
rn4.ooc = /cluster/bluearc/rn4/11.ooc
rn4.align.unplacedChroms = chrUn,chr*_random
rn4.lift = /cluster/data/rn4/jkStuff/liftAll.lft
rn4.refseq.mrna.native.pslCDnaFilter  = ${ordered.refseq.mrna.native.pslCDnaFilter}
rn4.refseq.mrna.xeno.pslCDnaFilter    = ${ordered.refseq.mrna.xeno.pslCDnaFilter}
rn4.genbank.mrna.native.pslCDnaFilter = ${ordered.genbank.mrna.native.pslCDnaFilter}
rn4.genbank.mrna.xeno.pslCDnaFilter   = ${ordered.genbank.mrna.xeno.pslCDnaFilter}
rn4.genbank.est.native.pslCDnaFilter  = ${ordered.genbank.est.native.pslCDnaFilter}
rn4.downloadDir = rn4
rn4.refseq.mrna.xeno.load  = yes
rn4.refseq.mrna.xeno.loadDesc = yes
rn4.mgcTables.default = full
rn4.mgcTables.mgc = all

    cvs ci etc/genbank.conf
    # update /cluster/data/genbank/
    make etc-update

    ssh kkstore02
    cd /cluster/data/genbank
    nice bin/gbAlignStep -initial rn4 &
    # load database when finished
    ssh hgwdev
    cd /cluster/data/genbank
    nice ./bin/gbDbLoadStep -drop -initialLoad rn4 &

    # enable daily alignment and update of hgwdev
#TODO
    cd ~/kent/src/makeDb/genbank
    cvsup
    # add rn4 to:
        etc/align.dbs
        etc/hgwdev.dbs 
    cvs commit
    make etc-update


# PRODUCING GENSCAN PREDICTIONS (DONE 1/31/06 angie)
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/genscan
    cd /cluster/data/rn4/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Run on small cluster (more mem than big cluster).
    ssh kki
    cd /cluster/data/rn4/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    cp /dev/null genome.list
    foreach f ( `ls -1S /cluster/data/rn4/*/chr*_*/chr*_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    wc -l genome.list
#591 genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para make jobList
    para time
#Completed: 589 of 591 jobs
#Crashed: 2 jobs
#CPU time in finished jobs:     110813s    1846.88m    30.78h    1.28d  0.004 y
#IO & Wait Time:                  8627s     143.79m     2.40h    0.10d  0.000 y
#Average job time:                 203s       3.38m     0.06h    0.00d
#Longest finished job:            4230s      70.50m     1.18h    0.05d
#Submission to last job:         11260s     187.67m     3.13h    0.13d
    # If there are crashes, diagnose with "para problems" / "para crashed".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    ssh kkr5u00
    cd /cluster/data/rn4/bed/genscan
    /cluster/bin/x86_64/gsBig /cluster/data/rn4/10/chr10_3/chr10_3.fa.masked gtf/chr10_3.fa.gtf -trans=pep/chr10_3.fa.pep -subopt=subopt/chr10_3.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/x86_64/gsBig /cluster/data/rn4/9/chr9_21/chr9_21.fa.masked gtf/chr9_21.fa.gtf -trans=pep/chr9_21.fa.pep -subopt=subopt/chr9_21.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000

    # Convert these to chromosome level files as so:
    ssh kkstore01
    cd /cluster/data/rn4/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/rn4/bed/genscan
    ldHgGene rn4 genscan genscan.gtf
    hgPepPred rn4 generic genscanPep genscan.pep
    hgLoadBed rn4 genscanSubopt genscanSubopt.bed


# MAKE GCPERCENT (DONE 1/30/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/bed/gc5Base
    cd /cluster/data/rn4/bed/gc5Base
    hgGcPercent -wigOut -doGaps -file=stdout -win=5 -verbose=2 rn4 \
       /cluster/data/rn4 \
    | wigEncode stdin gc5Base.wig gc5Base.wib
    ssh hgwdev
    mkdir /gbdb/rn4/wib
    cd /cluster/data/rn4/bed/gc5Base
    ln -s `pwd`/gc5Base.wib /gbdb/rn4/wib
    hgLoadWiggle -pathPrefix=/gbdb/rn4/wib rn4 gc5Base gc5Base.wig


# ENSEMBL GENES (DONE 1/30/06 angie)
    mkdir /cluster/data/rn4/bed/ensembl
    cd /cluster/data/rn4/bed/ensembl
    # Get the ensembl gene data from 
    # http://www.ensembl.org/Rattus_norvegicus/martview
    # Follow this sequence through the pages:
    # Page 1) Make sure that the Rattus_norvegicus choice is selected. Hit next.
    # Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
    # Page 3) Choose the "Structures" box. 
    # Page 4) Choose GTF as the ouput.  choose gzip compression.  hit export.
    # Save as ensembl.gff.gz
    # Add "chr" to front of each line in the gene data gtf file to make 
    # it compatible with our software.
    gunzip -c ensembl.gff.gz \
    | perl -wpe 's/^([0-9]+|X|Y|M|Un(_random)?)/chr$1/ \
                 || die "Line $. doesnt start with rat chrom:\n$_"' \
    > ensGene.gtf
    ssh hgwdev
    ldHgGene -gtf -genePredExt rn4 ensGene \
      /cluster/data/rn4/bed/ensembl/ensGene.gtf

    # ensGtp associates geneId/transcriptId/proteinId for hgPepPred and 
    # hgKnownToSuper.  Use ensMart to create it as above, except:
    # Page 3) Choose the "Features" box. In "Ensembl Attributes", check 
    # Ensembl Gene ID, Ensembl Transcript ID, Ensembl Peptide ID.  
    # Choose Text, tab-separated as the output format.  Result name ensGtp.
    # Save file as ensGtp.txt.gz
    gunzip ensGtp.txt.gz
    hgsql rn4 < ~/kent/src/hg/lib/ensGtp.sql
    hgsql rn4 -e 'load data local infile "ensGtp.txt" into table ensGtp'

    # Load Ensembl peptides:
    # Get them from ensembl as above in the gene section except for
    # Page 3) Choose the "Sequences" box. 
    # Page 4) Transcripts/Proteins.  Peptide.  Format = FASTA.
    # Save file as ensemblPep.fa.gz
    gunzip -c ensemblPep.fa.gz \
    | perl -wpe 's/^>.*\|(ENSRNOT\d+\.\d+).*/>$1/' \
    > ensPep.fa
    hgPepPred rn4 generic ensPep ensPep.fa


# CPGISSLANDS (WUSTL) (DONE 1/30/06 angie)
    ssh hgwdev
    mkdir /cluster/data/rn4/bed/cpgIsland
    cd /cluster/data/rn4/bed/cpgIsland
    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    mv cpglh.exe /cluster/data/rn4/bed/cpgIsland/
    
    ssh kolossus
    cd /cluster/data/rn4/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      nice ./cpglh.exe $f > $fout
    end
    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd /cluster/data/rn4/bed/cpgIsland
    hgLoadBed rn4 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed


# CPGISLANDS (ANDY LAW) (DONE 1/30/06 angie)
    # See notes in makeGalGal2.doc
    ssh kolossus
    mkdir /cluster/data/rn4/bed/cpgIslandGgfAndy
    cd /cluster/data/rn4/bed/cpgIslandGgfAndy
    #	Build the preProcGgfAndy program in
    #	kent/src/oneShot/preProcGgfAndy into your ~/bin/$MACHTYPE
    # Use masked sequence since this is a mammal...
    cp /dev/null cpgIslandGgfAndyMasked.bed
    foreach f (../../*/chr*.fa.masked)
      set chr = $f:t:r:r
      echo preproc and run on masked $chr
      ~/bin/x86_64/preProcGgfAndy $f \
      | /cluster/home/angie/ggf-andy-cpg-island.pl \
      | perl -wpe 'chomp; ($s,$e,$cpg,$n,$c,$g,$oE) = split("\t"); $s--; \
                   $gc = $c + $g;  $pCpG = (100.0 * 2 * $cpg / $n); \
                   $pGc = (100.0 * $gc / $n); \
                   $_ = "'$chr'\t$s\t$e\tCpG: $cpg\t$n\t$cpg\t$gc\t" . \
                        "$pCpG\t$pGc\t$oE\n";' \
      >> cpgIslandGgfAndyMasked.bed
    end
    # load into database:
    ssh hgwdev
    cd /cluster/data/rn4/bed/cpgIslandGgfAndy
    sed -e 's/cpgIslandExt/cpgIslandGgfAndyMasked/g' \
      $HOME/kent/src/hg/lib/cpgIslandExt.sql > cpgIslandGgfAndyMasked.sql
    hgLoadBed rn4 cpgIslandGgfAndyMasked -tab -noBin \
      -sqlTable=cpgIslandGgfAndyMasked.sql cpgIslandGgfAndyMasked.bed
#Loaded 91097 elements of size 10
    featureBits rn4 cpgIslandExt
#9629809 bases of 2571531505 (0.374%) in intersection
    featureBits rn4 cpgIslandGgfAndyMasked
#43899646 bases of 2571531505 (1.707%) in intersection
    wc -l ../cpgIsland/cpgIsland.bed *bed
#  15809 ../cpgIsland/cpgIsland.bed
#  91097 cpgIslandGgfAndyMasked.bed


# LIFTOVER RGD (DONE 2/9/06 angie)
    # ftp://rgd.mcw.edu/pub/RGD_genome_annotations/ still has 3.1 (rn3) not 
    # 3.4 (rn4).  Jim said these are interesting enough that we should lift 
    # over at least the QTLs.
    ssh kolossus
    mkdir /cluster/data/rn4/bed/rgdLiftover
    cd /cluster/data/rn4/bed/rgdLiftover
    wget ftp://rgd.mcw.edu/pub/RGD_genome_annotations/V3.1/GFF_files/rgd_rat_qtl_12052005.gff
    awk '{print $1"\t"$4-1"\t"$5"\t"$10}' rgd_rat_qtl_12052005.gff \
    | sed -e 's/Chr/chr/g; s/"//g; s/RGD://g; s/;//g' \
      > rgdQtl_rn3.bed
    awk '{printf "%s\t%s\t", $12, $10; \
          for (i = 14;i <= NF; ++i ) {printf "%s ", $i} printf "\n"} ' \
      rgd_rat_qtl_12052005.gff \
    | sed -e 's/"//g; s/RGD://g; s/;\t/\t/g' \
      > rgdQtlLink.tab
    # liftOver rgdQtl_rn3.bed \
    #   /cluster/data/rn3/bed/blat.rn4.2006-02-07/rn3ToRn4.over.chain.gz \
    #   rgdQtl.bed rgdQtl.unmapped
    # liftOver of rgdQtl_rn3.bed did not go well -- out of 903 qtls,
    # only 95 were successfully mapped.  772 got "Partially split in new."
    # Since these are enormous, presumably fuzzy-edged regions, just lift 
    # start and end.  If the start and end of each feature seems to be 
    # liftOver'd coherently, "chain" those back up into big regions in rn4.
    perl -we 'while (<>) { \
                chomp;  ($chr, $start, $end, $name) = split; \
                print "$chr\t$start\t" . ($start+100) . "\tstart_$name\n"; \
                print "$chr\t" . ($end-100) . "\t$end\tend_$name\n"; \
              }' \
      rgdQtl_rn3.bed > rgdQtl_rn3_endpoints.bed
    liftOver rgdQtl_rn3_endpoints.bed \
      /cluster/data/rn3/bed/blat.rn4.2006-02-07/rn3ToRn4.over.chain.gz \
      rgdQtl_endpoints.bed rgdQtl_endpoints.unmapped
    # Now 1706 out of 1806 survive... but 100 are deleted in new?!
    # I manually checked 10 of them and they all are either in a gap 
    # or off the end of a chrom.  Makes me wonder if these really are 
    # rn3 coords...  oh well, I guess we can load them up and ask 
    # RGD about them in the meantime.  I submitted a question using their 
    # online form -- my message ID is 439 and I can email rgd@rgd.mcw.edu 
    # with that ID if I don't hear from them in 3 biz days.
    perl -we 'while (<>) { \
                chomp;  ($chr, $start, $end, $name) = split; \
                if ($name =~ /^start_(\S+)/) { \
                  $starts{$1} = [$chr, $start]; \
                } elsif ($name =~ /^end_(\S+)/) { \
                  $ends{$1} = [$chr, $end]; \
                } else { die "parse error line $.: name $name\n"; } \
              } \
              foreach my $name (keys %starts) { \
                if (defined $ends{$name}) { \
                  my ($sChr, $start) = @{$starts{$name}}; \
                  my ($eChr, $end)   = @{$ends{$name}}; \
                  if (($sChr eq $eChr) && $end > $start) { \
                    print "$sChr\t$start\t$end\t$name\n"; \
                  } else { \
                    print STDERR "reject: [$sChr, $start] / [$eChr, $end] / $name\n"; \
                  } \
                } \
              }' \
      rgdQtl_endpoints.bed \
      | sort -k 1,1 -k 2n,2n > rgdQtl.bed
    wc -l rgdQtl.bed
#806 rgdQtl.bed
    ssh hgwdev
    cd /cluster/data/rn4/bed/rgdLiftover
    hgLoadBed rn4 rgdQtl rgdQtl.bed
    hgsql rn4 < ~/kent/src/hg/lib/rgdQtlLink.sql
    hgsql rn4 -e \
      'load data local infile "rgdQtlLink.tab" into table rn4.rgdQtlLink;'
 

# MAKE LINEAGE-SPECIFIC REPEATS VS. HUMAN, MOUSE (DONE 2/8/06 angie)
    ssh kolossus
    mkdir /cluster/data/rn4/rmsk
    cd /cluster/data/rn4/rmsk
    ln -s ../?{,?}/chr*.fa.out .
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Human in extra column 1, Mouse in extra column 2
    foreach outfl ( *.out )
        echo "$outfl"
        nice /cluster/bluearc/RepeatMasker/DateRepeats \
          ${outfl} -query rat -comp human -comp mouse
    end
    # Now extract human (extra column 1), mouse (extra column).
    cd ..
    mkdir linSpecRep.notInHuman
    mkdir linSpecRep.notInMouse
    foreach f (rmsk/*.out_homo-sapiens_mus-musculus)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInHuman/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    wc -l rmsk/*.out
#  4417757 total
    wc -l linSpecRep.notInHuman/*
#  2676056 total
    wc -l linSpecRep.notInMouse/*
#  471417 total
    # Clean up.
    rm -r rmsk
    # Distribute linSpecRep.* for cluster run
    ssh kkstore01
    mkdir /san/sanvol1/scratch/rn4
    rsync -av /cluster/data/rn4/linSpecRep.notInHuman/* \
      /san/sanvol1/scratch/rn4/linSpecRep.notInHuman/
    rsync -av /cluster/data/rn4/linSpecRep.notInMouse/* \
      /san/sanvol1/scratch/rn4/linSpecRep.notInMouse/


# SWAP/CHAIN/NET HG17 (DONE 2/10/06 angie)
    mkdir /cluster/data/rn4/bed/blastz.hg17.swap
    cd /cluster/data/rn4/bed/blastz.hg17.swap
    doBlastzChainNet.pl -swap /cluster/data/hg17/bed/blastz.rn4/DEF \
      -workhorse=kkr5u00 >& do.log & tail -f do.log


# MAKE LINEAGE-SPECIFIC REPEATS FOR NON-MAMMALS (DONE 2/13/06 angie)
    # In an email 2/13/04 to Angie, Arian said we could treat all 
    # human repeats as lineage-specific for human-chicken blastz.  
    # Extrapolate to any mammal vs. anything at least as distant as chicken.
    ssh kkr1u00
    mkdir /iscratch/i/rn4/linSpecRep.notInNonMammal
    foreach f (/cluster/data/rn4/*/chr*.fa.out)
      cp -p $f /iscratch/i/rn4/linSpecRep.notInNonMammal/$f:t:r:r.out.spec
    end
    iSync


# BLASTZ CHICKEN (GALGAL2) (IN PROGRESS 2/13/06 angie)
    ssh kk
    mkdir /cluster/data/hg17/bed/blastz.galGal2.2006-02-13
    cd /cluster/data/hg17/bed/blastz.galGal2.2006-02-13
    # Set L=10000 (higher threshold on blastz's outer loop) and abridge 
    # repeats.
    cat << '_EOF_' > DEF
#rat vs. chicken

# Specific settings for chicken (per Webb email to Brian Raney)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=10000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Rat
SEQ1_DIR=/scratch/hg/rn4/nib
SEQ1_SMSK=/iscratch/i/rn4/linSpecRep.notInNonMammal
SEQ1_CHUNK=10000000
SEQ1_LAP=10000
SEQ1_LEN=/cluster/data/rn4/chrom.sizes

# QUERY: Chicken
SEQ2_DIR=/iscratch/i/galGal2/nib
SEQ2_SMSK=/iscratch/i/galGal2/linSpecRep
SEQ2_CHUNK=10000000
SEQ2_LAP=0
SEQ2_LEN=/cluster/data/galGal2/chrom.sizes

BASE=/cluster/data/hg17/bed/blastz.galGal2.2006-02-13
'_EOF_'
    # << this line keeps emacs coloring happy
    doBlastzChainNet.pl DEF \
      -blastzOutRoot=/cluster/bluearc/blastzRn4GalGal2Out \
      > do.log & tail -f do.log
#TODO
    cd /cluster/data/hg17/bed
    ln -s /cluster/data/hg17/bed/blastz.galGal2.2006-02-13 blastz.galGal2


# STS MARKERS -- Yontao made stsInfoRat.  TODO: figure out what he did,
# redo it (checking scripts into kent/src/ tree), document it here.
# Align sequences and primers to the genome, load up.


# MULTIZ
# PHASTCONS

# AFFY CHIPS

# KNOWN GENES
# do we need a self chains track??

# MGC


# BACTIGPOS - in rn3 this was a download from baylor, but I don't see it now -?
# MGI?
# SNPS?
