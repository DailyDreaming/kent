# This file describes how we made the browser database on the mouse
# genome, February 2003 build.

DOWNLOAD THE MOUSE SEQUENCE FROM NCBI (DONE 02/06/03)
    mkdir -p /cluster/store2/mm.2003.02/ncbi
    cd /cluster/store2/mm.2003.02/ncbi
    mkdir chrfasta contigfasta
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_30
      prompt
      bin
      mget *
      quit
    gunzip *.agp.gz

GET UPDATED MOUSE ASSEMBLY FILES FROM NCBI (DONE 02/19/03)
    # Deanna regenerated allrefcontig.chr.agp for us with _random's.  
    # While downloading that, I noticed some other new files.  I saved 
    # the original copies of those to *.orig.  
    cd /cluster/store2/mm.2003.02/ncbi
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/guests/kent/buildHg6.doc
      cd mouse_30
      prompt
      bin
      mget allrefcontig.chr.agp.gz contig.idmap ctg_coords seq_contig.md
      quit    

BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (DONE 02/06/03)

    # This version of the mouse sequence data is in 
    # /cluster/store2/mm.2003.02/mm3/assembly
    # This will split the mouse sequence into approx. 5 Mbase supercontigs 
    # between non-bridged clone contigs and drop the resulting dir structure 
    # in /cluster/store2/mm.2003.02/mm3.
    # The resulting dir structure will include 1 dir for each chromosome, 
    # each of which has a set of subdirectories, one subdir per supercontig. 
    ssh hgwdev
    # cd into your CVS source tree under kent/src/hg/splitFaIntoContigs
    make
    ssh kkstore
    mkdir /cluster/store2/mm.2003.02/mm3
    cd /cluster/store2/mm.2003.02/mm3
    # splitFaIntoContigs doesn't do right with agp lines arriving in a 
    # different order than fasta chrom sequences.  so split up the agp 
    # into one per chrom.
    foreach c ( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Y Un )
      mkdir $c
      perl -we "while(<>){if (/^chr$c\t/) {print;}}" \
        ../ncbi/allrefcontig.chr.agp \
        > $c/chr$c.agp
      gunzip -c /cluster/store2/mm.2003.02/ncbi/chrfasta/chr$c.fa.gz \
        | perl -wpe 's/^>lcl\|(chr\w+)\.fa.*/>$1/' \
        | splitFaIntoContigs $c/chr$c.agp \
          stdin /cluster/store2/mm.2003.02/mm3 -nSize=5000000
    end

CREATE CHROM-LEVEL AGP AND FASTA FOR _RANDOMS (DONE 02/20/03)
    ssh kkstore
    cd /cluster/store2/mm.2003.02/ncbi
    ../mm3/jkStuff/ncbiToRandomAgps seq_contig.md allrefcontig.chr.agp \
      contig.idmap ../mm3
    cd /cluster/store2/mm.2003.02/mm3
    foreach c (?{,?})
      if (-e $c/chr${c}_random.ctg.agp) then
        echo building $c/chr${c}_random.fa
        gunzip -c ../ncbi/contigfasta/chr$c.fa.gz \
          | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
          > ./tmp.fa
        agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
          $c/chr${c}_random.fa ./tmp.fa
        rm tmp.fa
      endif
    end
    # At 37402 sequences with 50000-long gaps in between, chrUn is just 
    # too damn big to fit in memory on any of our machines!!  So use a 
    # gap size of 1000 (OK with Jim and Terry) just for chrUn.  
    cd /cluster/store2/mm.2003.02/ncbi
    ../mm3/jkStuff/ncbiToRandomAgps -gapLen 1000 -chrom Un \
      seq_contig.md allrefcontig.chr.agp contig.idmap ../mm3
    cd /cluster/store2/mm.2003.02/mm3
    set c=Un
    echo building $c/chr${c}_random.fa
    gunzip -c ../ncbi/contigfasta/chr$c.fa.gz \
      | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
      > ./tmp.fa
    agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
      $c/chr${c}_random.fa ./tmp.fa
    rm tmp.fa
    # Clean these up to avoid confusion later... they're easily rebuilt.
    rm ?{,?}/*.ctg.agp

BREAK UP _RANDOMS INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (DONE 02/20/03)
    ssh kkstore
    cd /cluster/store2/mm.2003.02/mm3
    foreach c (?{,?})
      if (-e $c/chr${c}_random.agp) then
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end

CREATING DATABASE (DONE 02/06/03)

o - Create the database.
     - ssh hgwdev
     - Enter mysql via:
           mysql -u hgcat -pbigsecret
     - At mysql prompt type:
        create database mm3;
        quit
     - make a semi-permanent read-only alias:
        alias mm3 "mysql -u hguser -phguserstuff -A mm3"
o - Use df to ake sure there is at least 5 gig free on hgwdev:/var/lib/mysql


CREATING GRP TABLE FOR TRACK GROUPING (DONE 02/11/03)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from mm2.grp" \
      | hgsql mm3


STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE 02/20/03)

    # Create (unmasked) nib files 
    ssh kkstore
    cd ~/mm
    mkdir -p nib
    foreach f (?{,?}/chr*.fa)
      echo $f:t:r
      faToNib $f nib/$f:t:r.nib
    end
    # Create symbolic links from /gbdb/mm3/nib to real nib files
    ssh hgwdev
    mkdir -p /gbdb/mm3/nib
    foreach f (/cluster/store2/mm.2003.02/mm3/nib/chr*.nib)
      ln -s $f /gbdb/mm3/nib
    end

    # Load /gbdb nib paths into database and save size info.
    ssh hgwdev
    hgsql mm3  < ~/src/hg/lib/chromInfo.sql
    cd ~/mm
    hgNibSeq -preMadeNib mm3 /gbdb/mm3/nib ?/chr*.fa ??/chr*.fa 
    echo "select chrom,size from chromInfo" | hgsql -N mm3 > chrom.sizes

Store o+o info in database.
     cd /cluster/store2/mm.2003.02/mm3
     hgGoldGapGl mm3 /cluster/store2/mm.2003.02 mm3 -noGl

Make and load GC percent table
     ssh hgwdev
     mkdir -p /cluster/store2/mm.2003.02/mm3/bed/gcPercent
     cd /cluster/store2/mm.2003.02/mm3/bed/gcPercent
     hgsql mm3  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent mm3 ../../nib


ADD MAP CONTIGS TRACK (DONE 02/28/03)
    ssh hgwdev
    mkdir -p ~/mm3/bed/ctgPos
    cd ~/mm3/bed/ctgPos
    # hgCtgPos uses the lift files... but mouse lift files are for the 
    # 5MB contigs from splitFaIntoContigs, not for the real NT_ contigs 
    # from the assembly.  (In the future, we should go with the NT's!)  
    # So... just for this release, go straight from the seq_contig.md 
    # to the table def'n: contig, size, chrom, chromStart, chromEnd 
    perl -we \
     'while (<>) { \
        if (/^\d+\s+(\w+)\s+(\d+)\s+(\d+)\s+\S+\s+(NT_\d+)\s+.*ref_strain/) { \
          $chr=$1; $start=$2; $start -= 1; $end=$3; $ctg=$4; \
          print "$ctg\t" . ($end-$start) . "\tchr$chr\t$start\t$end\n"; \
        } \
      }' /cluster/store2/mm.2003.02/ncbi/seq_contig.md \
    > ctgPos.tab
    hgsql mm3 < ~/kent/src/hg/lib/ctgPos.sql
    echo "load data local infile 'ctgPos.tab' into table ctgPos" | hgsql mm3
    # Note: the info is there in seq_contig.md to also do the _random's, 
    # but we'd have to do some more work: duplicate the gaps of 50000 between 
    # contigs for all _random's except chrUn_random (1000 between).  

MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR MM3 (DONE 02/06/03)
    # Enter mm3 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb values("mm3", "Mouse Feb. 2003", "/gbdb/mm3/nib", "Mouse", "USP18", 1, 30, "Mouse");' \
      | hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add mm3 in all the right places and do
    make update
    make alpha
    cvs commit makefile


MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR MM3 (DONE 02/13/03)
    ssh hgwdev
    echo 'insert into blatServers values("mm3", "blat9", "17778", "1"); \
          insert into blatServers values("mm3", "blat9", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


REPEAT MASKING (DONE 03/05/03)
   Split contigs, run RepeatMasker, lift results
   Notes: 
   * If there is a new version of RepeatMasker, build it and ask the admins 
     to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
   * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
     RepeatMasker runs manageable on the cluster ==> results need lifting.
   * For the NCBI assembly we repeat mask on the sensitive mode setting
     (RepeatMasker -m -s)

        #- Split contigs into 500kb chunks:
        cd ~/mm3
        foreach d ( */chr*_?{,?} )
          cd $d
          set contig = $d:t
          faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -maxN=500000
          cd ../..
        end

        #- Make the run directory and job list:
        cd ~/mm3
        mkdir RMRun
        rm -f RMRun/RMJobs
        touch RMRun/RMJobs
        foreach d ( ?{,?}/chr*_?{,?} )
          foreach f ( $d/chr*_*_*.fa )
            set f = $f:t
            echo /cluster/bin/scripts/RMMouse \
                 /cluster/store2/mm.2003.02/mm3/$d $f \
               '{'check out line+ /cluster/store2/mm.2003.02/mm3/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
        end

        #- Do the run
        ssh kk
        cd ~/mm3/RMRun
        para create RMJobs
        para try, para check, para check, para push, para check,...

        #- Lift up the split-contig .out's to contig-level .out's
	ssh kkstore
        cd ~/mm3
        foreach d ( ?{,?}/chr*_?{,?} )
          cd $d
          set contig = $d:t
          liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
          cd ../..
        end

        #- Lift up the contig-level .out's to chr-level
        cd ~/mm3
        ./jkStuff/liftOut5.sh

        #- Load the .out files into the database with:
        ssh hgwdev
        cd ~/mm3
        hgLoadOut mm3 ?/*.fa.out ??/*.fa.out

VERIFY REPEATMASKER RESULTS (IN PROGRESS)

    # Run featureBits on mm3 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits mm3 rmsk
    # --> 1079906607 bases of 2708220133 (39.875%) in intersection
    # --> (orig run, July libs:) 1001999794 bases of 2577261074 (38.878%) in intersection
    featureBits mm2 rmsk
    # --> 1037964664 bases of 2726995854 (38.063%) in intersection


MAKE LIFTALL.LFT (DONE 02/20/03)

    cd ~/mm3
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft

SIMPLE REPEAT TRACK (DONE 02/07/03; _randoms DONE 03/05/03)
    # TRF runs pretty quickly now... it takes a few hours total runtime.
    # Also, it ignores masking of input sequence, so this can be run in 
    # parallel with RepeatMasker!
    # So instead of binrsyncing and para-running, just do this on kkstore:
    ssh kkstore
    mkdir ~/mm3/bed/simpleRepeat
    cd ~/mm3/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    touch jobs.csh
    foreach f (/cluster/store2/mm.2003.02/mm3/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa)
      set fout = $f:t:r.bed
      echo "/cluster/home/kent/bin/i386/trfBig -trf=/cluster/home/kent/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    tcsh jobs.csh |& tee jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    # When job is done do:
    liftUp simpleRepeat.bed ~/mm3/jkStuff/liftAll.lft warn trf/*.bed

    # Load this into the database as so
    ssh hgwdev
    cd ~/mm3/bed/simpleRepeat
    hgLoadBed mm3 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql


PROCESS SIMPLE REPEATS INTO MASK (DONE 02/07/03; _randoms DONE 03/05/03)

    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kkstore
    cd ~/mm3/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd ~/mm3
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
        $c/lift/ordered.lst > $c/lift/oTrf.lst
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
        jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end


MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 03/05/03)
    ssh kkstore
    cd ~/mm3
    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh jkStuff/makeFaMasked.sh
    #- Make hard-masked .fa.masked files as well:
    tcsh jkStuff/makeHardMasked.sh
    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh jkStuff/makeNib.sh
    # Copy the masked contig fa to /scratch:
    rm -f /scratch/hg/mm3/trfFa
    mkdir -p /scratch/hg/mm3/trfFa
    cp -p ~/mm3/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /scratch/hg/mm3/trfFa


MAKE DOWNLOADABLE SEQUENCE FILES (DONE 03/05/03)
    ssh kkstore
    cd ~/mm3
    #- Build the .zip files
    jkStuff/zipAll.sh |& tee zipAll.log
    mkdir zip
    mv *.zip zip
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd ~/mm3/zip
    ../jkStuff/cpToWeb.sh
    cd /usr/local/apache/htdocs/goldenPath/mmFeb2003
    #- Take a look at bigZips/* and chromosomes/*, update their README.txt's

    # Then make the upstream sequence files.
    cd bigZips
    featureBits mm3 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits mm3 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits mm3 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa


PREPARE CLUSTER FOR BLASTZ RUN (DONE 03/05/03)
    # This needs to be done after trf-masking and nib generation.
    ssh kkstore
    # Extract lineage-specific repeats using Arian Smit's script:
    mkdir -p ~/mm3/bed/linSpecRep
    cd ~/mm3/bed/linSpecRep
    foreach f (~/mm3/*/*.out)
        ln -sf $f .
    end
    /cluster/bin/scripts/rodentSpecificRepeats.pl *.out
    /cluster/bin/scripts/perl-rename 's/(\.fa|\.nib)//' *.out.*spec
    /cluster/bin/scripts/perl-rename 's/\.(rod|prim)spec/.spec/' *.out.*spec
    rm *.out
    cd ..
    rm -rf /scratch/hg/mm3/linSpecRep
    mkdir -p /scratch/hg/mm3
    cp -Rp linSpecRep /scratch/hg/mm3
    # RepeatMasker .out:
    cd ~/mm3
    rm -rf /scratch/hg/mm3/rmsk
    mkdir -p /scratch/hg/mm3/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /scratch/hg/mm3/rmsk
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /scratch/hg/mm3/chromTrfMixedNib
    mkdir -p /scratch/hg/mm3/chromTrfMixedNib
    cp -p mixedNib/chr*.nib /scratch/hg/mm3/chromTrfMixedNib
    # Ask cluster-admin@cse.ucsc.edu to binrsync /scratch/hg to clusters

    # Jim's comments Feb 12 '03 about the order in which to run blastz:
    # In general we should do
    # 1) hg/mm
    # 2) mm/rn
    # 3) rn/hg
    # 4) hg/hg
    # 5) mm/mm
    # 6) rn/rn
    # There is now an 'axtSwap' program that might let us
    # get out of having to run the inverse of 1,2 & 3,  though
    # 2 in particular is so fast perhaps it's just as well to
    # do the inverse explicitly.


MAKING AND STORING mRNA AND EST ALIGNMENTS (DONE 02/09/03)

    # Load up the local disks of the cluster with refSeq.fa, mrna.fa and est.fa
    # from /cluster/store2/mrna.133  into /scratch/hg/mrna.133
    # Make sure that /scratch/hg/mm3/trfFa is loaded with chr*_*.fa and pushed 
    # to the cluster nodes.
    ssh kk
    cd ~/mm/bed
    foreach i (refSeq mrna est)
      mkdir $i
      cd $i
      ls -1S /mnt/scratch/hg/mm3/trfFa/*.fa > genome.lst
      ls -1 /mnt/scratch/hg/mrna.133/Mus_musculus/$i.fa > mrna.lst
      cp -p ~/lastMm/bed/$i/gsub .
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      cd ..
    end 

    # In each dir: para try, para check, para push, para check....
      
    # Process refSeq mRNA and EST alignments into near best in genome.
    ssh kkstore
    cd ~/mm/bed

      cd refSeq
      pslSort dirs raw.psl /cluster/store2/tmp psl
      pslReps -minCover=0.2 -sizeMatters -minAli=0.98 -nearTop=0.002 raw.psl contig.psl /dev/null
      liftUp -nohead all_refSeq.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /cluster/store2/tmp all_refSeq.psl
      pslCat -dir chrom > refSeqAli.psl
      cd ..

      cd mrna
      pslSort dirs raw.psl /cluster/store2/tmp psl
      pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl contig.psl /dev/null
      liftUp -nohead all_mrna.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /cluster/store2/tmp all_mrna.psl
      cd ..

      cd est
      pslSort dirs raw.psl /cluster/store2/tmp psl
      pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl contig.psl /dev/null
      liftUp -nohead all_est.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /cluster/store2/tmp all_est.psl
      cd ..

    # Load refSeq alignments into database
      ssh hgwdev
      cd ~/mm/bed/refSeq
      hgLoadPsl mm3 -tNameIx refSeqAli.psl

    # Load mRNA alignments into database.
      ssh hgwdev
      cd ~/mm/bed/mrna/chrom
      foreach i (*.psl)
          mv $i $i:r_mrna.psl
      end
      hgLoadPsl mm3 *.psl
      cd ..
      hgLoadPsl mm3 all_mrna.psl -nobin

    # Load EST alignments into database.
      ssh hgwdev
      cd ~/mm/bed/est/chrom
      foreach i (*.psl)
            mv $i $i:r_est.psl
      end
      hgLoadPsl mm3 *.psl
      cd ..
      hgLoadPsl mm3 all_est.psl -nobin

    # Create subset of ESTs with introns and load into database.
      - ssh kkstore
      cd ~/mm
      tcsh jkStuff/makeIntronEst.sh
      - ssh hgwdev
      cd ~/mm/bed/est/intronEst
      hgLoadPsl mm3 *.psl


ADD REFSEQ/MRNA/EST ALIGNMENTS TO _RANDOMS (DONE 03/06/03)
    # Note: in future builds, we should get the _randoms in the beginning,
    # so this should not be necessary!  
    ssh kk
    cd ~/mm/bed
    # refSeq, mrna done -- est too large for pslSort when run on unmasked, 
    # so rerun est on masked.
    foreach i (refSeq mrna est)
      mkdir ${i}_random
      cd ${i}_random
      ls -1S /mnt/scratch/hg/mm3/contigs/chr*_random_*.fa > genome.lst
      ls -1 /mnt/scratch/hg/mrna.133/Mus_musculus/$i.fa > mrna.lst
      cp -p ~/lastMm/bed/$i/gsub .
      #-- Edit the gsub so it doesn't say -mask=lower!!! 
      # _randoms are all lower right now -- I'm running this before masking.
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      cd ..
    end 
    # para try,check,push,check... in each ${i}_random directory.

    # Now run the "Process..." and "Load..." steps above, but for *_random


CREATE REFSEQ GENES TRACK (DONE 02/09/03)
    # Load the refSeq mRNA
    ssh hgwdev
    mkdir -p /gbdb/mm3/mrna.133
    ln -s /cluster/store2/mrna.133/refSeq/org/Mus_musculus/refSeq.fa \
      /gbdb/mm3/mrna.133
    hgLoadRna new mm3
    hgLoadRna add -type=refSeq mm3 /gbdb/mm3/mrna.133/refSeq.fa \
      /cluster/store2/mrna.133/refSeq/org/Mus_musculus/refSeq.ra

    # Produce refGene, refPep, refMrna, and refLink tables as so:
    # Get the proteins:
    ssh kkstore
    cd ~/mm/bed/refSeq
    wget ftp://ftp.ncbi.nih.gov/refseq/M_musculus/mRNA_Prot/mouse.faa.gz
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/loc2ref
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/mim2loc
    gunzip mouse.faa.gz
    ssh hgwdev
    cd ~/mm/bed/refSeq
    hgRefSeqMrna mm3 \
      /gbdb/mm3/mrna.133/refSeq.fa \
      /cluster/store2/mrna.133/refSeq/org/Mus_musculus/refSeq.ra \
      all_refSeq.psl loc2ref mouse.faa mim2loc
    # Don't worry about the "No gene name" errors

    # Add RefSeq status info
    hgRefSeqStatus -mouse mm3 loc2ref


REFFLAT (DONE 02/25/03)
    # create precomputed join of refFlat and refGene:
    echo 'CREATE TABLE refFlat (KEY geneName (geneName), KEY name (name), KEY chrom (chrom)) SELECT refLink.name as geneName, refGene.* FROM refLink,refGene WHERE refLink.mrnaAcc = refGene.name' | hgsql mm3


LOAD MRNA DATA (DONE 02/09/03)
    ssh hgwdev
    ln -s /cluster/store2/mrna.133/org/Mus_musculus/mrna.fa /gbdb/mm3/mrna.133
    ln -s /cluster/store2/mrna.133/org/Mus_musculus/est.fa /gbdb/mm3/mrna.133
    hgLoadRna add -type=mRNA mm3 /gbdb/mm3/mrna.133/mrna.fa \
      /cluster/store2/mrna.133/org/Mus_musculus/mrna.ra
    hgLoadRna add -type=EST mm3 /gbdb/mm3/mrna.133/est.fa \
      /cluster/store2/mrna.133/org/Mus_musculus/est.ra


LOADING MOUSE MM3 HUMAN BLASTZ ALIGNMENTS FROM PENN STATE: (DONE 03/07/03)

    # Translate Penn State .lav files into sorted axt:
    ssh kkstore
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH"
    set seq1_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set seq2_dir="/cluster/store4/gs.14/build31/mixedNib/"
    set tbl="blastzHuman"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
    ssh hgwdev
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH"
    set tbl="blastzHuman"
    cd $base/pslChrom
    hgLoadPsl mm3 chr*_${tbl}.psl

MAKING THE BLASTZBESTHUMAN TRACK FROM PENN STATE MM3 AXT FILES (DONE 03/07/03)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH"
    set seq1_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set seq2_dir="/cluster/store4/gs.14/build31/mixedNib/"
    set tbl="blastzBestHuman"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH"
     set tbl="blastzBestHuman"
     cd $base/pslBest
     hgLoadPsl mm3 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm3/axtBestHg13
     cd /gbdb/mm3/axtBestHg13
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/mm3/axtBestHg13/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('hg13','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql mm3 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql mm3 < axtInfoInserts.sql

MAKING THE HUMAN AXTTIGHT FROM AXTBEST (DONE 03/07/03)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/mm3/bed/blastz.hg13.2003-03-06-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightHuman.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/mm3/bed/blastz.hg13.2003-03-06-ASH/pslTight
    hgLoadPsl mm3 chr*_blastzTightHuman.psl

CREATING HUMAN/MOUSE CHAINS AND NET BASED ON BLASTZ ALIGNMENTS MM3 vs HG12
    # Do small cluster run on kkr1u00
    # Make sure that ~/oo points to the latest human and ~/mm to the 
    # latest mouse.
    # The little cluster run will probably take about 1 hours.
    ssh kkr1u00
    cd /cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH
    mkdir axtChain
    cd axtChain
    mkdir run1
    cd run1
    ls -1S ../../axtChrom/*.axt.gz > input.lst
    echo '#LOOP' > gsub
    echo 'doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}' >> gsub
    echo '#ENDLOOP' >> gsub
    gensub2 input.lst single gsub spec
    para create spec
    echo '#!/bin/csh' > doChain
    echo 'gunzip -c $1 | axtChain stdin  ~/mm/mixedNib ~/oo/mixedNib $2 > $3' >> doChain
    chmod a+x doChain
    para shove

    # Do some sorting on the little cluster job on the file server
    # This will take about 20 minutes.  This also ends up assigning
    # a unique id to each member of the chain.
    ssh kkstore
    cd /cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # Load the chains into the database as so.  This will take about
    # 45 minutes.
    ssh hgwdev
    cd /cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH/axtChain
    cd chain
    foreach i (*.chain)
	set c = $i:r
	hgLoadChain mm3 ${c}_humanChain $i
	echo done $c
    end

    # Create the nets.  You can do this while the database is loading
    # This is fastest done on the file server.  All told it takes about
    # 40 minutes.
    ssh kkstore
    cd /cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH/axtChain
    # First do a crude filter that eliminates many chains so the
    # real chainer has less work to do.
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      chainPreNet $i ~/mm/chrom.sizes ~/oo/chrom.sizes ../preNet/$i
    end
    cd ..
    # Run the main netter, putting the results in n1.
    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      chainNet $i -minSpace=1 ~/mm/chrom.sizes ~/oo/chrom.sizes ../n1/$n /dev/null
    end
    cd ..
    # Classify parts of net as syntenic, nonsyntenic etc.
    cat n1/*.net | netSyntenic stdin hNoClass.net

    # The final step of net creation needs the database.
    # Best to wait for the database load to finish if it
    # hasn't already.
    ssh hgwdev
    cd /cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH/axtChain
    netClass hNoClass.net mm3 hg13 mouse.net -tNewR=$HOME/mm/bed/linSpecRep -qNewR=$HOME/oo/bed/linSpecRep
    rm -r n1 hNoClass.net

    # Load the net into the database as so:
    netFilter -minGap=10 mouse.net |  hgLoadNet mm3 humanNet stdin

    # Move back to the file server to create axt files corresponding
    # to the net.
    ssh kkstore
    cd /cluster/store2/mm.2003.02/mm3/bed/blastz.hg13.2003-03-06-ASH/axtChain
    mkdir ../axtNet
    netSplit mouse.net mouseNet
    cd mouseNet
    foreach i (*.net)
        set c = $i:r
	netToAxt $i ../chain/$c.chain ~/mm/mixedNib ~/oo/mixedNib ../../axtNet/$c.axt
	echo done ../axt/$c.axt
    end
    cd ..
    rm -r mouseNet

    # At this point there is a blastz..../axtNet directory that should
    # be used in place of the axtBest for making the human/mouse
    # conservation track and for loading up the downloads page.


LOADING MOUSE MM3 RAT BLASTZ ALIGNMENTS FROM PENN STATE: (DONE 03/07/03)

    # Translate Penn State .lav files into sorted axt:
    ssh kkstore
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.rn2.2003-03-07-ASH"
    set seq1_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set seq2_dir="/cluster/store4/rn2/mixedNib/"
    set tbl="blastzRat"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r:r
       axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
    ssh hgwdev
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.rn2.2003-03-07-ASH"
    set tbl="blastzRat"
    cd $base/pslChrom
    hgLoadPsl mm3 chr*_${tbl}.psl

MAKING THE BLASTZBESTRAT TRACK FROM PENN STATE MM3 AXT FILES (DONE 03/07/03)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.rn2.2003-03-07-ASH"
    set seq1_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set seq2_dir="/cluster/store4/rn2/mixedNib/"
    set tbl="blastzBestRat"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.rn2.2003-03-07-ASH"
     set tbl="blastzBestRat"
     cd $base/pslBest
     hgLoadPsl mm3 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm3/axtBestRn2
     cd /gbdb/mm3/axtBestRn2
     rm -f *
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/mm3/axtBestRn2/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('rn2','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql mm3 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql mm3 < axtInfoInserts.sql

MAKING THE RAT AXTTIGHT FROM AXTBEST (DONE 03/07/03)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/mm3/bed/blastz.rn2.2003-03-07-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightRat.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/mm3/bed/blastz.rn2.2003-03-07-ASH/pslTight
    hgLoadPsl mm3 chr*_blastzTightRat.psl


LOADING MOUSE MM3 SELF BLASTZ ALIGNMENTS FROM PENN STATE: (DONE 03/10/03)

    # Translate Penn State .lav files into sorted axt:
    ssh kkstore
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.mm3.2003-03-06-ASH"
    set seq1_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set seq2_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set tbl="blastzMouse"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
# Did not load tables for this one -- they're very big, and low demand.
TODO    ssh hgwdev
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.mm3.2003-03-06-ASH"
    set tbl="blastzMouse"
    cd $base/pslChrom
    hgLoadPsl mm3 chr*_${tbl}.psl

MAKING THE BLASTZBESTMOUSE TRACK FROM PENN STATE MM3 AXT FILES (DONE 03/10/03)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh kkstore
    set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.mm3.2003-03-06-ASH"
    set seq1_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set seq2_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set tbl="blastzBestMouse"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    # If a chromosome has so many alignments that axtBest runs out of mem,
    # run axtBest in 2 passes to reduce size of the input to final axtBest:
    foreach chrdir (lav/chr{1,2,3,4,6,7,X})
      set chr=$chrdir:t
      echo two-pass axtBesting $chr
      foreach d ($chrdir/*.lav)
        set smallout=$d.axt
        lavToAxt $d $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $smallout
      end
      foreach a ($chrdir/*.axt)
        axtBest $a $chr $a:r.axtBest
      end
      cat `ls -1 $chrdir/*.axtBest | sort -g` \
        > $chrdir/$chr.axtBestPieces
      axtBest $chrdir/$chr.axtBestPieces $chr axtBest/$chr.axt
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end
    rm lav/chr*/*.axt*

    # Load tables
     ssh hgwdev
     set base="/cluster/store2/mm.2003.02/mm3/bed/blastz.mm3.2003-03-06-ASH"
     set tbl="blastzBestMouse"
     cd $base/pslBest
     hgLoadPsl mm3 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm3/axtBestMm3
     cd /gbdb/mm3/axtBestMm3
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/mm3/axtBestMm3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('mm3','Best Mouse Mouse','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql mm3 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql mm3 < axtInfoInserts.sql

MAKING THE MOUSE SELF AXTTIGHT FROM AXTBEST (DONE 03/10/03)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kkstore
    cd ~/mm3/bed/blastz.mm3.2003-03-06-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMouse.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/mm3/bed/blastz.mm3.2003-03-06-ASH/pslTight
    hgLoadPsl mm3 chr*_blastzTightMouse.psl


PRODUCING GENSCAN PREDICTIONS (TODO - REDO)
    
    ssh kkstore
    mkdir -p ~/mm3/bed/genscan
    cd ~/mm3/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir -p gtf pep subopt
       
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    cd ~/mm3/bed/genscan
    ls -1S /cluster/store2/mm.2003.02/mm3/?{,?}/chr*_*/chr*_*.fa.masked \
      > genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    # Note: I changed this to 1800000 in this build because some jobs were 
    # taking so long I thought they had crashed.
#LOOP
/cluster/home/kent/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=1800000
#ENDLOOP
    echo "" > dummy.list
    gensub2 genome.list dummy.list gsub jobList
    para create jobList
    para try
    para check
    para push
    # Issue either one of the following two commands to check the
    # status of the cluster and your jobs, until they are done.
    parasol status
    para check
    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.  
    # chr8_24

    # Convert these to chromosome level files as so:     
    ssh kkstore
    cd ~/mm3/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/chr*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/chr*.bed > \
      /dev/null
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/mm3/bed/genscan
    ldHgGene mm3 genscan genscan.gtf
    hgPepPred mm3 generic genscanPep genscan.pep
    hgLoadBed mm3 genscanSubopt genscanSubopt.bed > /dev/null


TWINSCAN GENE PREDICTIONS (TODO)

    mkdir -p ~/mm3/bed/twinscan
    cd ~/mm3/bed/twinscan
    mv Gtf.tgz Gtf.020610.tgz
    mv Ptx.tgz Ptx.020610.tgz
    rm chr*.gtf chr*.ptx chr*.fa *.tab
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X)
      wget http://genes.cs.wustl.edu/mouse/12-3-02/gtf/chr$c.gtf
      wget http://genes.cs.wustl.edu/mouse/12-3-02/ptx/chr$c.ptx
    end
    ldHgGene mm3 twinscan chr*.gtf -exon=CDS
    - pare down to id:
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X)
      perl -wpe 's/^\>.*\s+source_id\s*\=\s*(\S+).*$/\>$1/;' < \
        chr$c.ptx > chr$c-fixed.fa
    end
    hgPepPred mm3 generic twinscanPep chr*-fixed.fa

NCBI GENE MODELS (TODO)

    mkdir -p ~/mm3/bed/ncbiGenes
    cd ~/mm3/bed/ncbiGenes
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/maps/chr_genes.gtf.gz
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/protein/protein.fa.gz
    gunzip chr_genes.gtf.gz
    gunzip protein.fa.gz
    - Process the .gtf and .fa together to join IDs
    ../../jkStuff/mungeNCBIids chr_genes.gtf protein.fa |& uniq
    ldHgGene mm3 ncbiGenes chr_genes-fixed.gtf
    hgPepPred mm3 generic ncbiPep protein-fixed.fa

NCBI GENOMESCAN MODELS (TODO)

    mkdir -p ~/mm3/bed/genomeScan
    cd ~/mm3/bed/genomeScan
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/maps/chr_GenomeScan.gtf.gz
    # Remove the ".1" at the end of transcript_id's:
    gunzip -c chr_GenomeScan.gtf.gz | \
      perl -wpe 's/transcript_id "([^\"]+)\.1"/transcript_id "$1"/' > \
      chr_GenomeScan-fixed.gtf
    ldHgGene mm3 genomeScan chr_GenomeScan-fixed.gtf
    wget ftp://ftp.ncbi.nih.gov/genomes/M_musculus/MGSCv3_Release1/protein/GS_prot.fsa.gz
    hgPepPred mm3 generic genomeScanPep GS_prot.fsa


GET FRESH MRNA SEQUENCE FROM GENBANK

This will create a genbank.133 directory containing compressed
GenBank flat files and a mrna.133 containing unpacked sequence
info and auxiliary info in a relatively easy to parse (.ra)
format.

  o - Point your browser to ftp://ftp.ncbi.nih.gov/genbank and
      look at the README.genbank.  Figure out the current release number
      (which is 133).
  o - Consider deleting one of the older genbank releases.  It''s
      good to at least keep one previous release though.
  o - Where there is space make a new genbank directory.  Create a
      symbolic link to it:
          mkdir /cluster/store2/genbank.133
          ln -s /cluster/store2/genbank.133 ~/genbank
      cd ~/genbank
  o - ftp ftp.ncbi.nih.gov  (do anonymous log-in).  Then do the
      following commands inside ftp:
           cd genbank
           prompt
           mget gbpri* gbrod* gbv* gbsts* gbest* gbmam* gbinv* gbbct* gbhtc* gbpat* gbphg* gbpln*
      This will take at least 2 hours.
  o - Make the refSeq subdir and download files:
       mkdir -p /cluster/store2/mrna.133/refSeq
       cd /cluster/store2/mrna.133/refSeq

  o - ftp ftp.ncbi.nih.gov  (do anonymous log-in).  Then do the
      following commands inside ftp:
           cd refseq/cumulative
           prompt
           mget *.gz
  o - Unpack this into species-specific fa files and get extra info with:
      cd /cluster/store2/mrna.133/refSeq
      gunzip -c rscu.gbff.Z  | \
        gbToFaRa -byOrganism=org ../anyRna.fil refSeq.fa refSeq.ra refSeq.ta stdin

  o - ssh kkstore
      cd /cluster/store2/mrna.133

# Make the RNAs
        gunzip -c /cluster/store2/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa -byOrganism=org anyRna.fil mrna.fa mrna.ra mrna.ta stdin

# Make the ESTs
        gunzip -c /cluster/store2/genbank.133/gbest*.gz | \
        gbToFaRa anyRna.fil est.fa est.ra est.ta stdin -byOrganism=org

# Make the nonhuman RNAs
        gunzip -c /cluster/store2/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa humanXenoRna.fil humanXenoRna.fa humanXenoRna.ra humanXenoRna.ta stdin

# Make the nonMouse RNAs
        gunzip -c /cluster/store2/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa mouseXenoRna.fil mouseXenoRna.fa mouseXenoRna.ra mouseXenoRna.ta stdin

# Make the nonRat RNAs
        gunzip -c /cluster/store2/genbank.133/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa ratXenoRna.fil ratXenoRna.fa ratXenoRna.ra ratXenoRna.ta stdin

# Make the nonhuman ESTs
        gunzip -c /cluster/store2/genbank.133/gbest*.gz | \
        gbToFaRa humanXenoRna.fil humanXenoEst.fa humanXenoEst.ra humanXenoEst.ta stdin


PRODUCING CROSS_SPECIES mRNA ALIGMENTS (DONE 03/06/03)

    # Here you align non-mouse mRNAs against the masked genome on the
    # cluster you set up during the previous step.
    # Make sure that gbpri, gbmam, gbrod, and gbvert are downloaded from 
    # Genbank into /cluster/store2/genbank.133 and unpacked by organism into 
    # /cluster/store2/mrna.133/org. 

    # Set up cluster run more or less as so:
      ssh kk
      cd ~/mm3/bed
      mkdir xenoMrna
      cd xenoMrna
      ls -1S /scratch/hg/mm3/trfFa/* > genome.lst
      cp -R /cluster/store2/mrna.133/org /mnt/scratch/hg/mrna.133
    # The below ls command fails when you have too many files so skip it and 
    # instead run the find command after it.
    #      ls -1S /mnt/scratch/hg/mrna.133/org/*/mrna.fa > allMrna.lst
      find /mnt/scratch/hg/mrna.133/org -name mrna.fa -ls \
        | awk '{print $7,$11}' | grep -v /Mus_musculus/ \
        | sort -gr | awk '{print $2}' \
        >  allMrna.lst
    # Put the first line of allMrna.lst into 1.org, the second line into 
    # 2.org, and so forth:
      foreach n (1 2 3 4 5 6)
        head -$n allMrna.lst | tail -1 > $n.org
      end
    # After the 6th line just leave the rest in 7.org.
      tail +7 allMrna.lst > 7.org
    # Then
      ls -1 *.org > mrna.lst
      cp ~/lastMm/bed/xenoMrna/gsub .
      mkdir psl
      gensub2 genome.lst mrna.lst gsub spec
      para create spec
      para try
      para check
    # If all looks well do
      para push

    # Sort xeno mRNA alignments as so:
       ssh kkstore
       cd ~/mm3/bed/xenoMrna
       pslSort dirs raw.psl /cluster/store2/temp psl
       pslReps raw.psl cooked.psl /dev/null -minAli=0.25
       liftUp chrom.psl ../../jkStuff/liftAll.lft warn cooked.psl
       pslSortAcc nohead chrom /cluster/store2/temp chrom.psl
       pslCat -dir chrom > xenoMrna.psl
       rm -r chrom raw.psl cooked.psl chrom.psl

    # Load into database as so:
       ssh hgwdev
       cd ~/mm3/bed/xenoMrna
       hgLoadPsl mm3 xenoMrna.psl -tNameIx

    # Make the xenoRna file
       # Make a /gbdb symlink for the .fa (not .ra)
       cd /gbdb/mm3/mrna.133
       ln -s /cluster/store2/mrna.133/mouseXenoRna.fa mouseXenoRna.fa
       hgLoadRna add -type=xenoRna mm3 /gbdb/mm3/mrna.133/mouseXenoRna.fa \
         /cluster/store2/mrna.133/mouseXenoRna.ra

PRODUCING ESTORIENTINFO TABLE (DONE - 2/19/03 MATT; _randoms DONE 03/06/03)

This table is needed for proper orientation of ESTs in the
browser.  Many will appear on the wrong strand without it.
This involves a cluster run.  First load the EST psl files
as so:
     ssh kkstore
     cd ~/mm3/bed/est
     pslSortAcc nohead contig /cluster/store2/temp contig.psl
     mkdir /mnt/scratch/hg/mm3/est
     cp -r contig /mnt/scratch/hg/mm3/est

Wait for these to finish.
     cd ..
     mkdir estOrientInfo
     cd estOrientInfo
     mkdir ei
     ls -1S /mnt/scratch/hg/mm3/est/contig/* > psl.lst
     cp ~/lastMm/bed/estOrientInfo/gsub .
Update gsub to refer to mouse contig sequence currently on
/scratch, and mouse ESTs on /scratch.
     gensub2 psl.lst single gsub spec
     para create spec
Then run the  job on the cluster
     ssh kk
     cd ~/mm3/bed/estOrientInfo
     para try
     sleep 60
     para check
If things look good
     para push

Wait for this to finish then
     liftUp estOrientInfo.bed ../../jkStuff/liftAll.lft warn ei/*.tab
Load them into database as so:
     ssh hgwdev
     cd ~/mm3/bed/estOrientInfo
     hgLoadBed mm3 estOrientInfo estOrientInfo.bed \
       -sqlTable=/cluster/home/kent/src/hg/lib/estOrientInfo.sql

PRODUCING MRNAORIENTINFO TABLE (DONE 03/06/03)
    ssh kkstore
    cd ~/mm3/bed/mrna
    pslSortAcc nohead contig /cluster/store2/temp contig.psl
    mkdir /mnt/scratch/hg/mm3/mrna
    cp -r contig /mnt/scratch/hg/mm3/mrna
    mkdir -p ~/mm3/bed/mrnaOrientInfo/oi
    cd ~/mm3/bed/mrnaOrientInfo
    ls -1S /mnt/scratch/hg/mm3/mrna/contig/* > psl.lst
    cp ~/lastMm/bed/mrnaOrientInfo/gsub .
    echo placeholder > single
    gensub2 psl.lst single gsub spec

    ssh kk
    cd ~/mm3/bed/mrnaOrientInfo
    para create spec
    para try, para check, para push, para check,...
    liftUp mrnaOrientInfo.bed ../../jkStuff/liftAll.lft warn oi/*.tab

    ssh hgwdev
    cd ~/mm3/bed/mrnaOrientInfo
    hgLoadBed mm3 mrnaOrientInfo mrnaOrientInfo.bed \
       -sqlTable=/cluster/home/kent/src/hg/lib/mrnaOrientInfo.sql


CREATE RNACLUSTER TABLE (DONE 03/06/03)
    # Make sure that refSeqAli, estOrientInfo and mrnaOrientInfo tables are 
    # made already (see above).
    ssh hgwdev
    mkdir -p ~/mm3/bed/rnaCluster/chrom
    cd ~/mm3/bed/rnaCluster
    foreach i (~/mm3/?{,?})
      foreach f ($i/chr*.fa)
        set c = $f:t:r
        clusterRna mm3 /dev/null chrom/$c.bed -chrom=$c
        echo done $c
      end
    end
    hgLoadBed mm3 rnaCluster chrom/*.bed


PRODUCING TETRAODON FISH ALIGNMENTS (TODO)

o - Download sequence from ... and put it on the cluster local disk
    at
       /scratch/hg/fish
o - Do fish/mouse alignments.
       ssh kk
       cd ~/mm/bed
       mkdir blatFish
       cd blatFish
       mkdir psl
       ls -1S /scratch/hg/fish/* > fish.lst
       ls -1S /scratch/hg/mm3/trfFa/* > mouse.lst
       cp ~/lastMm/blatFish/gsub .
       gensub2 mouse.lst fish.lst gsub spec
       para create spec
       para try
     Make sure jobs are going ok with para check.  Then
       para push
     wait about 2 hours and do another
       para push
     do para checks and if necessary para pushes until done
     or use para shove.
o - Sort alignments as so 
       pslCat -dir psl | liftUp -type=.psl stdout ~/mm/jkStuff/liftAll.lft warn stdin | pslSortAcc nohead chrom /cluster/store2/tmp stdin
o - Copy to hgwdev:/scratch.  Rename to correspond with tables as so and 
    load into database:
       ssh hgwdev
       cd ~/mm/bed/blatFish/chrom
       foreach i (*.psl)
           set r = $i:r
           mv $i ${r}_blatFish.psl
       end
       hgLoadPsl mm3 *.psl
       #*** Make /gbdb/mm3/fish_seq15jun2001 links
       hgLoadRna addSeq mm3 /gbdb/mm3/fish_seq15jun2001/*.fa


PRODUCING FUGU FISH ALIGNMENTS (DONE 03/13/03)

    # sequence was previously downloaded to /cluster/store3/fuguSeq/ from
    #   ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_mask.fasta.Z
    #   ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3_prot.fasta.Z
    # Load it up on /mnt/scratch:
    ssh kkstore
    mkdir -p /mnt/scratch/hg/fugu
# Next time, use /cluster/store3/fuguSeq/split2.5Mb !!!
    cp -p /cluster/store3/fuguSeq/split/*.fa /mnt/scratch/hg/fugu/

    ssh kk
    mkdir ~/mm/bed/blatFugu
    cd ~/mm/bed/blatFugu
    ls -1S /mnt/scratch/hg/fugu/* > fugu.lst
    ls -1S /scratch/hg/mm3/trfFa/* > mouse.lst
    # Create dir structure for run
    mkdir psl
    foreach ctg (`ls -1 /scratch/hg/mm3/trfFa/`)
      mkdir psl/$ctg:t:r
    end
    cp ~/lastMm/bed/blatFugu/gsub .
    gensub2 mouse.lst fugu.lst gsub spec
    para create spec
    para try
    # Make sure jobs are going ok with para check.  Then
    para push
    # wait about 2 hours and do another
    para push
    # do para checks and if necessary para pushes until done or use para shove.
    ssh kkstore
    cd ~/mm/bed/blatFugu
    pslCat -dir psl/* \
      | liftUp -type=.psl stdout ~/mm3/jkStuff/liftAll.lft warn stdin \
      | pslSortAcc nohead chrom /cluster/store2/tmp stdin
    # load into database:
    ssh hgwdev
    cd ~/mm3/bed/blatFugu/chrom
    foreach i (*.psl)
      set r = $i:r
      mv $i ${r}_blatFugu.psl
    end
    hgLoadPsl mm3 *.psl
    mkdir -p /gbdb/mm3/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta /gbdb/mm3/fuguSeq/
    hgLoadRna addSeq mm3 /gbdb/mm3/fuguSeq/fugu_v3_mask.fasta


LOAD SOFTBERRY GENES (DONE 02/04/03)
     cd /cluster/store2/mm.2003.02/mm3/bed
     mkdir softberry
     cd softberry
     wget ftp://www.softberry.com/pub/SC_MOU_FEB03/Softb_mouse_gff_f03.tar.gz
     gunzip -c Softb_mouse_gff_f03.tar.gz | tar xvf -
     ldHgGene mm3 softberryGene chr*.gff
     hgPepPred mm3 softberry *.protein
     hgSoftberryHom mm3 *.protein

LOAD GENEID GENES (DONE 03/18/03)
    mkdir -p ~/mm3/bed/geneid/download
    cd ~/mm3/bed/geneid/download
    set webroot = \
      http://genome.imim.es/genepredictions/M.musculus/mmFeb2003/geneid_v1.1
    foreach f (~/mm3/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget $webroot/$chr.gtf
      wget $webroot/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene mm3 geneid download/*.gtf -exon=CDS
    hgPepPred mm3 generic geneidPep download/*-fixed.prot

SGP GENE PREDICTIONS (4/17/03 KRR)
    mkdir -p ~/mm3/bed/sgp/download
    cd ~/mm3/bed/sgp/download
    #foreach f (~/mm3/?{,?}/chr?{,?}{,_random}.fa)
    # Doesn't have chr_random entries KRR
    foreach f (~/mm3/?{,?}/chr?{,?}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/M.musculus/mmFeb2003/SGP/humangp20021114/$chr.gtf
      wget http://genome.imim.es/genepredictions/M.musculus/mmFeb2003/SGP/humangp20021114/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene mm3 sgpGene download/*.gtf -exon=CDS
    hgPepPred mm3 generic sgpPep download/*-fixed.prot


TIGR GENE INDEX (TODO)
    mkdir -p ~/mm3/bed/tigr
    cd ~/mm3/bed/tigr
    wget ftp://ftp.tigr.org/private/NHGI_mgi_jiashu/TGI_track_MouseGenome_Nov2002.tgz
    gunzip -c TGI*.tgz | tar xvf -
    foreach f (*cattle*)
      set f1 = `echo $f | sed -e 's/cattle/cow/g'`
      mv $f $f1
    end
    foreach o (mouse cow human pig rat)
      setenv O $o
      foreach f (chr*_$o*s)
        tail +2 $f | perl -wpe 's /THC/TC/; s/(TH?C\d+)/$ENV{O}_$1/;' > $f.gff
      end
    end
    ldHgGene -exon=TC mm3 tigrGeneIndex *.gff


LOAD STS MAP (TODO)
     - login to hgwdev
      cd ~/mm/bed
      mm3 < ~/src/hg/lib/stsMap.sql
      mkdir stsMap
      cd stsMap
      bedSort /projects/cc/hg/mapplots/data/tracks/build28/stsMap.bed stsMap.bed
      - Enter database with "mm3" command.
      - At mysql> prompt type in:
          load data local infile 'stsMap.bed' into table stsMap;
      - At mysql> prompt type

LOAD MGI IDs (TODO)
      - The Locuslink ID to MGI IDs converstion data file,
        LL2MGI.txt, from Jackson Lab should be found under
        ~/mm/bed/refSeq
      - login to hgwdev
      
      cd ~/mm/bed/refSeq
      mm3 < ~/src/hg/lib/mgiID.sql
      - Enter database with "mm3" command.
      - At mysql> prompt type in:
          load data local infile 'LL2MGI.txt' into table MGIid;
      - At mysql> prompt type
          quit

LOAD CHROMOSOME BANDS (TODO)
      - login to hgwdev
      cd /cluster/store2/mm.2003.02/mm3/bed
      mkdir cytoBands
      cp /projects/cc/hg/mapplots/data/tracks/build28/cytobands.bed cytoBands
      mm3 < ~/src/hg/lib/cytoBand.sql
      Enter database with "mm3" command.
      - At mysql> prompt type in:
          load data local infile 'cytobands.bed' into table cytoBand;
      - At mysql> prompt type
          quit

LOAD MOUSEREF TRACK (TODO)
    First copy in data from kkstore to ~/mm/bed/mouseRef.  
    Then substitute 'genome' for the appropriate chromosome 
    in each of the alignment files.  Finally do:
       hgRefAlign webb mm3 mouseRef *.alignments

LOAD AVID MOUSE TRACK (TODO)
      ssh cc98
      cd ~/mm/bed
      mkdir avidMouse
      cd avidMouse
      wget http://pipeline.lbl.gov/tableCS-LBNL.txt
      hgAvidShortBed *.txt avidRepeat.bed avidUnique.bed
      hgLoadBed avidRepeat avidRepeat.bed
      hgLoadBed avidUnique avidUnique.bed

LOAD SNPS (TODO)
      - ssh hgwdev
      - cd ~/mm/bed
      - mkdir snp
      - cd snp
      - Download SNPs from ftp://ftp.ncbi.nlm.nih.gov/pub/sherry/mouse.b27.out.gz
      - Unpack.
        createBed < mouse.b27.out > snpNih.bed
        hgLoadBed mm3 snpNih snpNih.bed

LOAD CPGISSLANDS (DONE 03/06/03)
     ssh kkstore
     mkdir -p ~/mm3/bed/cpgIsland
     cd ~/mm3/bed/cpgIsland
     # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
     # copy the tar file to the current directory
     tar xvf cpg_dist.tar 
     cd cpg_dist
     gcc readseq.c cpg_lh.c -o cpglh.exe
     cd ..
     # cpglh.exe requires hard-masked (N) .fa's.  
     # There may be warnings about "bad character" for IUPAC ambiguous 
     # characters like R, S, etc.  Ignore the warnings.  
     foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
       set fout=$f:t:r:r.cpg
       ./cpg_dist/cpglh.exe $f > $fout
       echo Done with $fout
     end
     cp ~/lastMm/bed/cpgIsland/filter.awk .
     awk -f filter.awk chr*.cpg > cpgIsland.bed
     # Load into db
     ssh hgwdev
     cd ~/mm3/bed/cpgIsland
     hgLoadBed mm3 cpgIsland -tab -noBin \
       -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed

LOAD ENSEMBL ESTs (TODO)
     ln -s /cluster/store2/mm.2003.02/mm3 ~/mm3
     mkdir -p ~/mm3/bed/ensembl
     cd ~/mm3/bed/ensembl
     wget http://www.ebi.ac.uk/~stabenau/mouse-est.gz
     wget http://www.ebi.ac.uk/~stabenau/mouse-est.pep.gz
     gunzip -c mouse-est.gz | \
       perl -w -p -e 's/^(\w)/chr$1/' > mouse-est-fixed.gtf
     ldHgGene mm3 ensEst mouse-est-fixed.gtf
> The id behind '>' is internal and was not in our gtf dump, so
> you have to do some more parsing.
     # pick out the transcript= attribute -- that's the id to use:
     # also remove the first line:
     gunzip -c mouse-est.pep.gz | tail +2 | \
       perl -w -p -e 's/^\>gene_id=.*transcript=(\w+)\s+.*$/\>$1/' > \
       mouse-est-fixed.pep
     hgPepPred mm3 generic ensEstPep mouse-est-fixed.pep

LOAD ENSEMBLE GENES (TODO)
     mkdir -p ~/mm3/bed/ensembl
     cd ~/mm3/bed/ensembl
     wget http://www.ebi.ac.uk/~stabenau/mouse-ensembl.gz
     wget http://www.ebi.ac.uk/~stabenau/mouse-ensembl.pep.gz
     gunzip -c mouse-ensembl.gz | \
       perl -w -p -e 's/^(\w)/chr$1/' > mouse-ensembl-fixed.gtf
     ldHgGene mm3 ensGene mouse-ensembl-fixed.gtf
> mouse-ensembl contains stopcodons, due to some glitches in our
> genebuild. The id behind '>' is internal and was not in our gtf dump, so
> you have to do some more parsing.
# pick out the transcript= attribute -- that's the id to use:
# also remove the first line:
     tail +2 mouse-ensembl.pep | \
       perl -w -p -e 's/^\>gene_id=.*transcript=(\w+)\s+.*$/\>$1/' > \
       mouse-ensembl-fixed.pep
     hgPepPred mm3 generic ensPep mouse-ensembl-fixed.pep

LOAD RNAGENES (TODO)
      - login to hgwdev
      - cd ~kent/src/hg/lib
      - mm3 < rnaGene.sql
      - cd /cluster/store2/mm.2003.02/mm3/bed
      - mkdir rnaGene
      - cd rnaGene
      - download data from ftp.genetics.wustl.edu/pub/eddy/pickup/ncrna-oo27.gff.gz
      - gunzip *.gz
      - liftUp chrom.gff ../../jkStuff/liftAll.lft carry ncrna-oo27.gff
      - hgRnaGenes mm3 chrom.gff

LOAD EXOFISH (TODO)
     - login to hgwdev
     - cd /cluster/store2/mm.2003.02/mm3/bed
     - mkdir exoFish
     - cd exoFish
     - mm3 < ~kent/src/hg/lib/exoFish.sql
     - Put email attatchment from Olivier Jaillon (ojaaillon@genoscope.cns.fr)
       into /cluster/store2/mm.2003.02/mm3/bed/exoFish/all_maping_ecore
     - awk -f filter.awk all_maping_ecore > exoFish.bed
     - hgLoadBed mm3 exoFish exoFish.bed

LOAD MOUSE SYNTENY (TODO)
     - login to hgwdev.
     - cd ~/kent/src/hg/lib
     - mm3 < mouseSyn.sql
     - mkdir ~/mm/bed/mouseSyn
     - cd ~/mm/bed/mouseSyn
     # Put Deanna Church's (church@ncbi.nlm.nih.gov) email attatchment as
     # mouseSyn.txt
     - awk -f format.awk *.txt > mouseSyn.bed
     - delete first line of mouseSyn.bed
     - Enter database with "mm3" command.
     - At mysql> prompt type in:
          load data local infile 'mouseSyn.bed' into table mouseSyn


LOAD GENIE (TODO)
     mkdir -p ~/mm3/bed/genieAlt
     cd ~/mm3/bed/genieAlt
     wget http://www.neomorphic.com/mgap/mgscv3/gtf/mgscv3.genie.gtf.tgz
     gunzip -c mgscv3.genie.gtf.tgz | tar xvf -
     ldHgGene mm3 genieAlt mgscv3.genie.gtf/chr*.gtf
     wget http://www.neomorphic.com/mgap/mgscv3/fa/mgscv3.aa.tgz
     gunzip -c mgscv3.aa.tgz | tar xvf -
     hgPepPred mm3 genie geniePep chr*.aa.fa

LOAD GENIE CLONE BOUNDS (TODO)
     mkdir -p ~/mm3/bed/genieBounds
     cd ~/mm3/bed/genieBounds
     wget http://www.neomorphic.com/mgap/mgscv3/cb.bed/mgscv3_cb.bed.tgz
     gunzip -c mgscv3_cb.bed.tgz | tar xvf -
     - Trim the track definition from each file (these are actually custom 
       track files):
     foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Un)
       tail +2 chr${c}_cb.bed > chr${c}_cb-fixed.bed
     end
     hgLoadBed mm3 genieBounds *-fixed.bed

LOAD JACKSON LABS QTL (TODO)
    ssh hgwdev
    mkdir ~/mm3/bed/jaxQTL2
    # Save the email attachment from Sridhar Ramachandran at Jackson Labs
    # (bed 8+, jaxQTL2 format).
    # Strip the column headers and load into the database.  
    tail +2 QTLBedFormat.txt > jaxQTL2.bed
    hgLoadBed -noBin -tab -sqlTable=$HOME/kent/src/hg/lib/jaxQTL2.sql \
      mm3 jaxQTL2 jaxQTL2.bed


MAKING MOUSE AND RAT SYNTENY
#
syntenicBest.pl -db=mm3 -table=blastzBestHuman
smooth.pl
joinsmallgaps.pl
fillgap.pl -db=mm3 -table=blastzBestHuman
synteny2bed.pl
hgLoadBed mm3 syntenyHuman ucsc100k.bed

syntenicBest.pl -db=mm3 -table=blastzBestRat
smooth.pl
joinsmallgaps.pl
fillgap.pl -db=mm3 -table=blastzBestRat
synteny2bed.pl
hgLoadBed mm3 syntenyRat ucsc100k.bed



CREATING THE mm3Rn2L SAMPLE TRACK (a.k.a WIGGLE TRACK)
------------------------------------------------------
o - refer to the script at src/hg/sampleTracks/makeMm3Rn2.doc



