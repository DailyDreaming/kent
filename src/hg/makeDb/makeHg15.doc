#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on 
# NCBI build 32 (March, 2003 freeze)

# [For importing GTF tracks, use /projects/compbio/bin/validate_gtf.pl]

# HOW TO BUILD A ASSEMBLY FROM NCBI FILES
# ---------------------------------------

# NOTE: It is best to run most of this stuff on eieio since it
# is not averse to handling files > 2Gb

# 0) Make gs.16 directory, gs.16/build33 directory, and gs.16/ffa directory.
    mkdir /cluster/store5/gs.16
    mkdir /cluster/store5/gs.16/build33
    mkdir /cluster/store5/gs.16/agp
    mkdir /cluster/store5/gs.16/ffa

#    Make a symbolic link from /cluster/store1 to this location
	
    cd /cluster/store1
    ln -s /cluster/store5/gs.16 ./gs.16

#    Make a symbolic link from your home directory to the build dir:

    ln -s /cluster/store5/gs.16/build33 ~/oo

# 1) Download seq_contig.md, ncbi_build33.agp, contig_overlaps.agp 
# and contig fa file into gs.16/build33 directory. 

# Download certificates.txt in gs.16/build33 directory (first time in build33)

# Download all finished agp's and fa's into gs.16/agp

# Download sequence.inf and ncbi_build33.fa files into gs.16/ffa, and unzip
# ncbi_build33.fa.

# *** For build33, files split into reference.agp/reference.fa (main O&O), DR51.agp/DR51.fa,
#     and DR52.agp/DR52.fa. (alternate versions of MHC region).  These were concatenated 
#     to get the ncbi_build33.agp and ncbi_build33.fa

# 2) Sanity check things with 
    /cluster/bin/i386/checkYbr build33/ncbi_build33.agp ffa/ncbi_build33.fa \
      build33/seq_contig.md
#      report any errors back to Richa and Greg at NCBI.

# 3) Convert fa files into UCSC style fa files and place in "contigs" directory
#    inside the gs.16/build33 directory 

    cd build33
    mkdir contigs
    /cluster/bin/i386/faNcbiToUcsc -split -ntLast ../ffa/ncbi_build33.fa \
      contigs

# 3.1) Make a fake chrM contig
    cd ~/oo
    mkdir M
# copy in chrM.fa, chrM.agp and chrM.gl from previous version.
    mkdir M/NT_999999
    cp chrM.fa NT_999999/NT_999999.fa

# copied chrM.fa, chrM.agp, chrM.gl, chrM.trf.bed, lift directory, NT_999999/NT_999999.fa - not sure which ones we need

# 4) Determine the chromosome sizes from agps

    /cluster/bin/scripts/detChromSizes ../agp

# 4.1) Create lift files (this will create chromosome directory structure) and inserts file

    /cluster/bin/scripts/createNcbiLifts -s chrom_sizes seq_contig.md .

# 5) Create contig agp files (will create contig directory structure)
	
    /cluster/bin/scripts/createNcbiCtgAgp seq_contig.md ncbi_build33.agp .

# 5.1) Create contig gl files

    ~kent/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md

# 6) Create chromsome agp files

    /cluster/bin/scripts/createNcbiChrAgp .

# Since we received final agp's, these were substituted in for the chr agp's
# with all completely commented lines removed.

# 6.1) Copy over jkStuff from previous build
    mkdir jkStuff
    cp /cluster/store1/gs.14/build31/jkStuff/*.sh jkStuff
    /build31/jkStuff/*.csh jkStuff
    cp /cluster/store1/gs.14/build31/jkStuff/*.gsub jkStuff        

# 6.3) Create chromosome gl files
  
    jkStuff/liftGl.sh contig.gl

# 7) Distribute contig .fa to appropriate directory (assumes all files
#    are in "contigs" directory).

    cd ~/hg15
    /cluster/bin/scripts/distNcbiCtgFa contigs .
    rm -r contigs

# 8) Reverse complement NT contig fa files that are flipped in the assembly
#    (uses faRc program)
# Not done for build33 because all contigs on + strand.  It should be this
# way for the rest of the assemblies

    /cluster/bin/scripts/revCompNcbiCtgFa seq_contig.md .


# GET FRESH MRNA/EST AND REFSEQ SEQUENCE FROM GENBANK (DONE 4/10/03)
    # Run this just before the sequence gets here!  It's OK to work on 
    # this in parallel with Terry's steps above, or in parallel with 
    # RepeatMasker below, but DO NOT let this hold up RepeatMasker.  

    # This will create a genbank.134 directory containing compressed
    # GenBank flat files and a mrna.134 containing unpacked sequence
    # info and auxiliary info in a relatively easy to parse (.ra)
    # format.

    # Point your browser to ftp://ftp.ncbi.nih.gov/genbank and look at 
    # the README.genbank.  Figure out the current release number.  (134)
    lynx ftp://ftp.ncbi.nih.gov/genbank/README.genbank
    # Consider deleting one of the older genbank releases.  It's
    # good to at least keep one previous release though.

    # Where there is space make a new genbank directory.  Create a
    # symbolic link to it:
    ssh eieio
    mkdir /cluster/store5/genbank.134
    ln -s /cluster/store5/genbank.134 ~/genbank
    cd ~/genbank
    # ncftp is handy -- it does anonymous login; "prompt" command not needed.
    ncftp ftp.ncbi.nih.gov
      cd genbank
      mget gbpri* gbrod* gbv* gbsts* gbest* gbmam* gbinv* gbbct* gbhtc* gbpat* gbphg* gbpln*
      quit
    # This will take at least 2 hours.

    # Make the refSeq subdir and download files:
    ssh eieio
    mkdir -p /cluster/store5/mrna.134/refSeq/041003
    cd /cluster/store5/mrna.134/refSeq/041003
    ncftp ftp.ncbi.nih.gov
      cd refseq/cumulative
      mget *.Z
      quit
    # Get extra info & human proteins from NCBI:
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/loc2ref
    wget ftp://ftp.ncbi.nih.gov/refseq/LocusLink/mim2loc
    wget ftp://ftp.ncbi.nih.gov/refseq/H_sapiens/mRNA_Prot/hs.faa.gz
    gunzip hs.faa.gz
    # Unpack this into species-specific fa files and get extra info with:
    cd /cluster/store5/mrna.134/refSeq/041003
    cp /cluster/store2/mrna.133/*.fil ..
    gunzip -c rscu.gbff.Z \
    | gbToFaRa -byOrganism=org ../../anyRna.fil refSeq.{fa,ra,ta} stdin

    # Now unpack and organize the larger genbank mrna/est sequences...
    ssh eieio
    cd /cluster/store5/mrna.134
    # Make the RNAs for all organisms
    gunzip -c \
      /cluster/store5/genbank.134/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
    | gbToFaRa -byOrganism=org anyRna.fil mrna.{fa,ra,ta} stdin
    # Make the ESTs for all organisms
    gunzip -c /cluster/store5/genbank.134/gbest*.gz \
    | gbToFaRa anyRna.fil est.{fa,ra,ta} stdin -byOrganism=org
    # Make the nonhuman RNAs
    gunzip -c \
      /cluster/store5/genbank.134/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
    | gbToFaRa humanXenoRna.fil humanXenoRna.{fa,ra,ta} stdin
    # Make the nonMouse RNAs
    gunzip -c \
      /cluster/store5/genbank.134/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
    | gbToFaRa mouseXenoRna.fil mouseXenoRna.{fa,ra,ta} stdin
    # Make the nonRat RNAs
    gunzip -c \
      /cluster/store5/genbank.134/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
    | gbToFaRa ratXenoRna.fil ratXenoRna.{fa,ra,ta} stdin
    # Make the nonhuman ESTs
    gunzip -c /cluster/store5/genbank.134/gbest*.gz \
    | gbToFaRa humanXenoRna.fil humanXenoEst.{fa,ra,ta} stdin
    # Split the really large ones into smaller pieces for more efficient 
    # cluster runs.  
    mkdir humanXenoRnaSplit humanXenoEstSplit
    faSplit about humanXenoRna.fa 10000000 humanXenoRnaSplit/xenoRna
    faSplit about humanXenoEst.fa 70000000 humanXenoEstSplit/xenoEst
    cd org/Homo_sapiens
    mkdir estSplit
    faSplit about est.fa 250000000 estSplit/est
    # Distribute the files to /iscratch/i/ so they're all ready to be aligned.
    ssh kkr1u00
    mkdir -p /iscratch/i/mrna.134/Homo_sapiens
    cp -p /cluster/store5/mrna.134/refSeq/041003/org/Homo_sapiens/refSeq.fa \
      /iscratch/i/mrna.134/Homo_sapiens/
    cp -p /cluster/store5/mrna.134/org/Homo_sapiens/mrna.fa \
      /iscratch/i/mrna.134/Homo_sapiens/
    cp -p /cluster/store5/mrna.134/org/Homo_sapiens/estSplit/*.fa \
      /iscratch/i/mrna.134/Homo_sapiens/
    cp -p /cluster/store5/mrna.134/humanXenoRnaSplit/*.fa \
      /iscratch/i/mrna.134/Homo_sapiens/
    cp -p /cluster/store5/mrna.134/humanXenoEstSplit/*.fa \
      /iscratch/i/mrna.134/Homo_sapiens/
    ~kent/bin/iSync

# REPEAT MASKING (DONE 041103)
    # Split contigs, run RepeatMasker, lift results
    # Notes: 
    # * If there is a new version of RepeatMasker, build it and ask the admins 
    #   to binrsync it (kkstore:/scratch/hg/RepeatMasker/*).
    # * Contigs (*/NT_*/NT_*.fa) are split into 500kb chunks to make 
    #   RepeatMasker runs manageable on the cluster ==> results need lifting.
    # * For the NCBI assembly we repeat mask on the sensitive mode setting
    #   (RepeatMasker -s)

    #- Split contigs into 500kb chunks:
    ssh eieio
    cd ~/hg15
    mkdir contigOut
    cd contigOut
    mkdir split
    foreach d (../contigs/NT_* )
      set contig = $d:t
      faSplit size ../contigs/$contig 500000 split/${contig}_ -lift=split/$contig.lft \
        -maxN=500000
    end

    #- Make the run directory and job list:
    cd ~/hg15
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
   foreach f ( /cluster/store5/gs.16/build33/contigOut/split/NT_*.fa )
        set f = $f:t
        echo /cluster/bin/scripts/RMLocalSens \
             /cluster/store5/gs.16/build33/contigOut/split $f \
            '{'check out line+ /cluster/store5/gs.16/build33/contigOut/split/$f.out'}' \
          >> RMRun/RMJobs
    end

    #- Do the run
    ssh kk
    cd ~/hg15/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
    #- Now while that's running, run TRF (simpleRepeat), and RefSeq 
    #- alignments, in parallel.  Also, create the database and the 
    #- tracks that don't rely on cluster runs or on masked sequence.  
    # Distribute the split files and splitting lift files back to our normal
    #  chromosome contig directory tree.
    cd ~/hg15

# Edit script first!
# This copies lft/out/align files from the flat dir structure we were forced to use at first.
# This is a one-time only step.
    /cluster/bin/scripts/distNcbiCtgOut contigOut/split .

    #- Lift up the split-contig .out's to contig-level .out's
    ssh eieio
    cd ~/hg15
    foreach d ( ?{,?}/NT_* )
      cd $d
      set contig = $d:t
      liftUp $contig.fa.out $contig.fa.lft warn ${contig}?*.fa.out > /dev/null
      cd ../..
    end

    #- Lift up RepeatMask .out files to chromosome coordinates via
    tcsh jkStuff/liftOut2.sh
    #- By this point, the database should have been created (below):
    ssh hgwdev
    cd ~/hg15
    hgLoadOut hg15 ?/*.fa.out ??/*.fa.out


# VERIFY REPEATMASKER RESULTS (DONE 041103)

    # Run featureBits on hg15 and on a comparable genome build, and compare:
    ssh hgwdev

    featureBits hg15 rmsk
    # --> 1386879340 bases of 2866468600 (48.383%) in intersection

    featureBits hg13 rmsk
    # --> 1383216615 bases of 2860907679 (48.349%) in intersection

    # Validate the RepeatMasking by randomly selecting a few NT_*.fa files, 
    # manually repeat masking them and matching the .out files with the 
    # related part in the chromosome-level .out files.  For example:
    ssh kkr1u00
    # Pick arbitrary values of $chr and $nt and run these commands: 
    set chr = 1
    set nt  = NT_004321
    mkdir /tmp/RMTest/$nt
    cd /tmp/RMTest/$nt
    cp ~/hg15/$chr/$nt/$nt.fa .
    /scratch/hg/RepeatMasker/RepeatMasker -s $nt.fa
    # Compare $nt.fa.out against the original ~/hg15/$chr/$nt/$nt.fa.out 
    # and against the appropriate part of $chr/chr$chr.fa.out (use the coords 
    # for $nt given in seq_contig.md).  

# CREATING DATABASE  (DONE 04/08/03)
    ssh hgwdev
    # if you haven't already:
    ln -s /cluster/store5/gs.16/build33 ~/oo
    ln -s /cluster/store5/gs.16/build33 ~/hg15
    # Make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
    # Create the database.
    echo 'create database hg15' | hgsql hg14
    # make a semi-permanent read-only alias (add this to your .cshrc/.bashrc):
        alias hg15 mysql -u hguser -phguserstuff -A hg15
    # Initialize the relational-mrna and external sequence info tables:
    hgLoadRna new hg15
    # Copy over grp table (for track grouping) from another database:
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg14.grp" \
    | hgsql hg15

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE 041103)
    ssh hgwdev
    # Enter hg15 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb values("hg15", "Human April 2003", \
            "/gbdb/hg15/nib", "Human", "DUSP18", 1, 80, "Human");' \
    | hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P .
    # Edit that makefile to add hg15 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE HGCENTRALTEST BLATSERVERS ENTRY (DONE 04/12/03 -jk)
    ssh hgwdev
    # Substitute BBB with the correct number for the hostname:
    echo 'insert into blatServers values("hg15", "blat2", "17778", "1"); \
          insert into blatServers values("hg15", "blat2", "17779", "0");' \
    | hgsql -h genome-testdb hgcentraltest


# MAKE LIFTALL.LFT, NCBI.LFT (DONE 041103)
    cd ~/hg15
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft
    # Create jkStuff/ncbi.lft for lifting stuff built with the NCBI assembly.
    # Note: this ncbi.lift will not lift floating contigs to chr_random coords,
    # but it will show the strand orientation of the floating contigs 
    # (grep for '|').
    mdToNcbiLift seq_contig.md jkStuff/ncbi.lft 
    # If a lift file has been edited (e.g. as in 6.2.5 above), edit ncbi.lft 
    # to match. If no step 6.2.5 then no editing needed


# SIMPLE REPEAT [TRF] TRACK (DONE 041103)
    # Distribute contigs to /iscratch/i
    ssh kkr1u00
    rm -rf /iscratch/i/gs.16/build33/contigs
    mkdir -p /iscratch/i/gs.16/build33/contigs
    cd ~/hg15
    cp contigs/*.fa /iscratch/i/gs.16/build33/contigs
    # Make sure the total size looks like what you'd expect:
    du -sh /iscratch/i/gs.16/build33/contigs
    ~kent/bin/iSync

    # Create cluster parasol job like so:
    mkdir -p ~/hg15/bed/simpleRepeat
    cd ~/hg15/bed/simpleRepeat
    cp ~/hg14/bed/simpleRepeat/gsub .
    mkdir trf
    ls -1S /iscratch/i/gs.16/build33/contigs/*.fa > genome.lst
    echo "" > dummy.lst
    ssh kk
    cd ~/hg15/bed/simpleRepeat
    gensub2 genome.lst dummy.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check
    # When cluster run is done
    liftUp simpleRepeat.bed ~/hg15/jkStuff/liftAll.lft warn trf/*.bed

    # Load into the database:
    ssh hgwdev
    cd ~/hg15/bed/simpleRepeat
    ~matt/bin/i386/hgLoadBed hg15 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql


# REFSEQ ALIGNMENTS AND REFGENE TRACK PREP (DONE 041103)
    # Make sure contigs have been distributed to /iscratch/i/ (should have 
    # been done for simpleRepeat/TRF above)
    # Make sure refSeq.fa is under /iscratch/i too (GENBANK above)
    ssh kk
    mkdir ~/hg15/bed/refSeq
    cd ~/hg15/bed/refSeq
    mkdir psl
    ls -1S /iscratch/i/gs.16/agp/*.fa > genome.lst
    # Remove DR51.fa, DR52.fa and bottomDrawer.fa from the list in genome.lst
    # Edit each fa file to say chr1, chr2, etc. in the top comment line.
    ls -1 /iscratch/i/mrna.134/Homo_sapiens/refSeq.fa > mrna.lst
    cp ~/hg13/bed/refSeq/gsub .
    # Edit the file to make it do blat.x -band -q=rna -trimHardA
    gensub2 genome.lst mrna.lst gsub spec
    
    # Run this on the small cluster if needed
    ssh kkr1u00 
    para create spec
    para try, para check, para push, para check....
    para time > time
    # When cluster is done, process refSeq alignments into near best in genome.
    ssh eieio
    cd ~/hg15/bed/refSeq
    pslSort dirs raw.psl /tmp psl
    pslReps -minCover=0.15 -sizeMatters -minAli=0.98 -nearTop=0.001 raw.psl \
      all_refSeq.psl /dev/null
    pslSortAcc nohead chrom /tmp all_refSeq.psl
    pslCat -dir chrom > refSeqAli.psl
    # After the database has been created, go to "LOAD REFGENE" below...


# PROCESS SIMPLE REPEATS INTO MASK (DONE 041103 ms&jk)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd ~/hg15/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/NT_*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd ~/hg15
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end


# MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (done 4/11/03 jk)
    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above.
    ssh eieio
    cd ~/hg15
    # Make chr*.fa from contig .fa
    tcsh jkStuff/chrFa.sh

    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh jkStuff/makeFaMasked.sh
    #- Make hard-masked .fa.masked files as well:
    tcsh jkStuff/makeHardMasked.sh
    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh jkStuff/makeNib.sh

    # Copy the masked contig fa to /iscratch and /scratch:
    ssh kkr1u00
    rm -rf /iscratch/i/gs.16/build33/trfFa
    mkdir -p /iscratch/i/gs.16/build33/trfFa
    cp -p ~/hg15/?{,?}/NT_*/NT_??????.fa /iscratch/i/gs.16/build33/trfFa
    ~kent/bin/iSync
    ssh kkstore
    rm -rf /scratch/hg/gs.16/build33/trfFa
    mkdir -p /scratch/hg/gs.16/build33/trfFa
    cp -p ~/hg15/?{,?}/NT_*/NT_??????.fa /scratch/hg/gs.16/build33/trfFa


# PREPARE CLUSTER FOR BLASTZ RUN (041203)
    # This needs to be done after trf-masking and nib generation.
    ssh eieio
    # Extract lineage-specific repeats using Arian Smit's script:
    mkdir -p ~/hg15/bed/linSpecRep
    cd ~/hg15/bed/linSpecRep
    foreach f (~/hg15/*/*.out)
        ln -sf $f .
    end
    /cluster/bin/scripts/primateSpecificRepeats.pl *.out
    /cluster/bin/scripts/perl-rename 's/(\.fa|\.nib)//' *.out.*spec
    /cluster/bin/scripts/perl-rename 's/\.(rod|prim)spec/.spec/' *.out.*spec
    rm *.out
    # Copy files to the kkstore:/scratch
    ssh kkstore
    # lineage-specific repeats:
    cd ~/hg15/bed
    mkdir -p /scratch/hg/gs.16/build33
    rm -rf /scratch/hg/gs.16/build33/linSpecRep
    cp -Rp linSpecRep /scratch/hg/gs.16/build33
    # RepeatMasker .out:
    cd ~/hg15
    rm -rf /scratch/hg/gs.16/build33/rmsk
    mkdir -p /scratch/hg/gs.16/build33/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /scratch/hg/gs.16/build33/rmsk
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /scratch/hg/gs.16/build33/chromTrfMixedNib
    mkdir -p /scratch/hg/gs.16/build33/chromTrfMixedNib
    cd ~/hg15
    cp -p nib/chr*.nib /scratch/hg/gs.16/build33/chromTrfMixedNib

    # Ask cluster-admin@cse.ucsc.edu to binrsync /scratch/hg to clusters
    # Copy to /iscratch as well so we can run blastz before binrsync finishes:
    rm -rf /iscratch/i/gs.16/build33/{linSpecRep,rmsk,chromTrfMixedNib}
    cp -Rp /scratch/hg/gs.16/build33/{linSpecRep,rmsk,chromTrfMixedNib} \
      /iscratch/i/gs.16/build33/
    ssh kkr1u00
    ~kent/bin/iSync

    # Jim's comments Feb 12 '03 about the order in which to run blastz:
    # In general we should do
    # 1) hg/mm
    # 2) mm/rn
    # 3) rn/hg
    # 4) hg/hg
    # 5) mm/mm
    # 6) rn/rn
    # There is now an 'axtSwap' program that might let us
    # get out of having to run the inverse of 1,2 & 3,  though
    # 2 in particular is so fast perhaps it's just as well to
    # do the inverse explicitly.

# SEQUENCE INFO: CHROMINFO (DONE)
    ssh eieio
    cd ~/hg15
    # Sanity-check */lift/ordered.lft length vs. agp length:
    foreach c ( ?{,?} )
      if (-e $c/lift/ordered.lst) then
        set lftLen = `tail -1 $c/lift/ordered.lft | awk '{print $5;}'`
        set agpLen = `tail -1 $c/chr$c.agp | awk '{print $3;}'`
        if ($lftLen != $agpLen) then
          echo "ERROR: chr$c : lftLen=$lftLen, agpLen=$agpLen"
        else
          echo "chr$c : $lftLen"
        endif
      endif
    end
    # Make unmasked nibs -- necessary for building chromInfo.
    mkdir nib
    foreach f (?{,?}/chr?{,?}{,_random}.fa)
      echo making unmasked nib for $f
      faToNib $f nib/$f:t:r.nib
    end
    # Make symbolic links from /gbdb/hg15/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/hg15/nib
    foreach f (/cluster/store5/gs.16/build33/nib/chr*.nib)
      ln -s $f /gbdb/hg15/nib
    end
    # Load /gbdb/hg15/nib paths into database and save size info.
    hgsql hg15  < ~/src/hg/lib/chromInfo.sql
    cd ~/hg15
    hgNibSeq -preMadeNib hg15 /gbdb/hg15/nib ?{,?}/chr?{,?}{,_random}.fa
    echo "select chrom,size from chromInfo" | hgsql -N hg15 > chrom.sizes

# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 4/12/2003 JK)
    ssh eieio
    cd ~/hg15
    #- Build the .zip files
    ./jkStuff/zipAll.sh |& tee zipAll.log
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    mkdir zip
    mv *.zip* zip
    cd zip
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test
    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd ~/hg15/zip
    # Edit cpToWeb.sh to contain the correct destination path.
    ../jkStuff/cpToWeb.sh
    cd /usr/local/apache/htdocs/goldenPath/10april2003
    #- Take a look at bigZips/* and chromosomes/*, update their README.txt's
    # Then make the upstream sequence files.
    cd bigZips
    featureBits hg15 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits hg15 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits hg15 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa


# O+O: ASSEMBLY [GOLD], GAP, COVERAGE, MAP CONTIGS TRACKS (MOSTLY DONE - 041103 
- BUT NEED TO REDO WHEN WE GET THE .gl FILES)
    # Store o+o info in database.
    # Note: for build31, Terry specially requested these files from NCBI:
    # finished.finf
    # draft.finf
    # predraft.finf
    # extras.finf
    ssh eieio
    cd /cluster/store5/gs.16/build33
    if (-f contig_overlaps.agp) then
      jkStuff/liftGl.sh contig.gl
    else
      ssh hgwdev
      hgGoldGapGl -noGl hg15 /cluster/store5/gs.16 build33 
      echo ""
      echo "*** Note from makeHg15.doc:"
      echo "Come back to this step later when we have contig_overlaps.agp\!"
    endif
    ssh hgwdev
    cd /cluster/store5/gs.16/build33
    if (-f contig_overlaps.agp) then
      hgGoldGapGl hg15 /cluster/store5/gs.16 build33 
      cd /cluster/store5/gs.16
      hgClonePos hg15 build33 ffa/sequence.inf /cluster/store5/gs.16 -maxErr=3
    end 
    cd /cluster/store5/gs.16
    hgCtgPos hg15 build33 


# LOAD REFGENE (DONE 041103)
    # Do this after the database has been created and the RefSeq alignments 
    # are done (above)
    # Load refSeq alignments into database
    ssh hgwdev
    cd ~/hg15/bed/refSeq
    hgLoadPsl hg15 -tNameIx refSeqAli.psl
    # Make /gbdb symlinks for refSeq.fa (not .ra)
    mkdir -p /gbdb/hg15/mrna.134
    cd /gbdb/hg15/mrna.134
    ln -s /cluster/store5/mrna.134/refSeq/041003/org/Homo_sapiens/refSeq.fa
    # Load the refSeq mRNA
    cd /cluster/store2/tmp
    hgLoadRna add -type=refSeq hg15 /gbdb/hg15/mrna.134/refSeq.fa \
      /cluster/store5/mrna.134/refSeq/041003/org/Homo_sapiens/refSeq.ra
    cd ~/hg15/bed/refSeq
    hgRefSeqMrna hg15 /gbdb/hg15/mrna.134/refSeq.fa \
      /cluster/store5/mrna.134/refSeq/041003/org/Homo_sapiens/refSeq.ra \
      all_refSeq.psl \
      /cluster/store5/mrna.134/refSeq/041003/loc2ref \
      /cluster/store5/mrna.134/refSeq/041003/hs.faa \
      /cluster/store5/mrna.134/refSeq/041003/mim2loc
    # Don't worry about the "No gene name" errors
    # Add RefSeq status info
    hgRefSeqStatus hg15 /cluster/store5/mrna.134/refSeq/041003/loc2ref
    # Create precomputed join of refFlat and refGene:
    echo 'CREATE TABLE refFlat \
          (KEY geneName (geneName), KEY name (name), KEY chrom (chrom)) \
          SELECT refLink.name as geneName, refGene.* \
          FROM refLink,refGene \
          WHERE refLink.mrnaAcc = refGene.name' \
    | hgsql hg15


# GC PERCENT (DONE 041203)
     ssh hgwdev
     mkdir -p ~/hg15/bed/gcPercent
     cd ~/hg15/bed/gcPercent
     hgsql hg15  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent hg15 ../../nib


# PRELOAD MRNA/EST SEQUENCE INFO INTO DATABASE (DONE 04/08/03)
    # Make /gbdb symlinks for sequence .fa (not .ra)
    mkdir -p /gbdb/hg15/mrna.134
    cd /gbdb/hg15/mrna.134
    ln -s /cluster/store5/mrna.134/org/Homo_sapiens/mrna.fa
    ln -s /cluster/store5/mrna.134/org/Homo_sapiens/est.fa
    ln -s /cluster/store5/mrna.134/humanXenoRna.fa
    ln -s /cluster/store5/mrna.134/humanXenoEst.fa
    # Store the sequence (non-alignment) info in database.
    cd /cluster/store2/tmp
    hgLoadRna add -type=mRNA hg15 /gbdb/hg15/mrna.134/mrna.fa \
      /cluster/store5/mrna.134/org/Homo_sapiens/mrna.ra
    hgLoadRna add -type=EST hg15 /gbdb/hg15/mrna.134/est.fa \
      /cluster/store5/mrna.134/org/Homo_sapiens/est.ra
    hgLoadRna add -type=xenoRna hg15 /gbdb/hg15/mrna.134/humanXenoRna.fa \
      /cluster/store5/mrna.134/humanXenoRna.ra
    hgLoadRna add -type=xenoEst hg15 /gbdb/hg15/mrna.134/humanXenoEst.fa \
      /cluster/store5/mrna.134/humanXenoEst.ra


# MAKING AND STORING mRNA AND EST ALIGNMENTS (DONE 4/12/2002 MS&JK ESTs Partially Redone)
    # Make sure that /scratch/hg/gs.16/build33/trfFa is loaded with NT_*.fa 
    # and has been pushed to the big cluster nodes.  (MASK SEQUENCE above)
    # Make sure mrna/est .fa's are under /iscratch/i too (GENBANK above)
mrna is done against unmasked 041203
    ssh kk
    mkdir -p ~/hg15/bed/{mrna,est}/psl
    cd ~/hg15/bed/mrna
    ls -1S /scratch/hg/gs.16/build33/trfFa/* > genome.lst
    ls -1S /iscratch/i/mrna.134/Homo_sapiens/mrna.fa > mrna.lst
    cp ~/hg13/bed/mrna/gsub .
    gensub2 genome.lst mrna.lst gsub spec
    para create spec
    para try
    cd ~/hg15/bed/est
    ls -1S /scratch/hg/gs.16/build33/trfFa/* > genome.lst
    ls -1S /iscratch/i/mrna.134/Homo_sapiens/est*.fa > mrna.lst
    echo '#LOOP \
/cluster/home/kent/bin/i386/blat {check in line+ $(path1)} {check in line+ $(path2)} -ooc={check in exists /scratch/hg/h/11.ooc} {check out line+ psl/$(root1)_$(root2).psl} \
#ENDLOOP' > gsub
    gensub2 genome.lst mrna.lst gsub spec
    para create spec
    para try
    # In each dir (~/hg15/bed/mrna, ~/hg15/bed/est):
    para check, para push, para check....
    # para time > time
      
    # Process mRNA and EST alignments into near best in genome.
    cd ~/hg15/bed/mrna
    pslSort dirs raw.psl /tmp psl
    pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl contig.psl \
      /dev/null
    liftUp -nohead all_mrna.psl ../../jkStuff/liftAll.lft warn contig.psl
    pslSortAcc nohead chrom /tmp all_mrna.psl

    ssh eieio
    cd ~/hg15/bed/est
    pslSort dirs raw.psl /tmp/psl psl
    pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl contig.psl \
      /dev/null
    liftUp -nohead all_est.psl ../../jkStuff/liftAll.lft warn contig.psl
    pslSortAcc nohead chrom /cluster/store3/tmp all_est.psl

    # Load mRNA alignments into database. 
    ssh hgwdev
    cd ~/hg15/bed/mrna/chrom
    rm -f *_mrna.psl
    foreach i (*.psl)
      mv $i $i:r_mrna.psl
    end
    hgLoadPsl hg15 *.psl
    cd ..
    hgLoadPsl hg15 all_mrna.psl -nobin

    # Load EST alignments into database.
    ssh hgwdev
    cd ~/hg15/bed/est/chrom
    rm -f *_est.psl
    foreach i (*.psl)
      mv $i $i:r_est.psl
    end
    hgLoadPsl hg15 *.psl
    cd ..
    hgLoadPsl hg15 all_est.psl -nobin
    # Sequence info should have already been loaded into database (PRELOAD)


# SPLICED ESTS (INTRONEST) (DONE 4/12/03 JK)
    # Create subset of ESTs with introns and load into database.
    ssh eieio
    cd ~/hg15
    tcsh jkStuff/makeIntronEst.sh
    ssh hgwdev
    cd ~/hg15/bed/est/intronEst
    hgLoadPsl hg15 *.psl

# ESTORIENTINFO, MRNAORIENTINFO, GENE BOUNDS (RNACLUSTER) (DONE 041303 MS+JK)
    # Put orientation info on ESTs and mRNAs into database:
    ssh eieio
    cd ~/hg15/bed/est
    pslSortAcc nohead contig /cluster/store3/tmp contig.psl
    cd ~/hg15/bed/mrna
    pslSortAcc nohead contig /cluster/store3/tmp contig.psl
    # Distribute the est and mrna psl files to /iscratch/i
    ssh kkr1u00
    rm -rf /iscratch/i/gs.16/build33/bed
    mkdir -p /iscratch/i/gs.16/build33/bed
    cp -r ~/hg15/bed/est/contig /iscratch/i/gs.16/build33/bed/est
    cp -r ~/hg15/bed/mrna/contig /iscratch/i/gs.16/build33/bed/mrna
    ~kent/bin/iSync
    # mrna: use big cluster.
    ssh kk
    mkdir -p ~/hg15/bed/mrnaOrientInfo/oi
    cd ~/hg15/bed/mrnaOrientInfo
    ls -1S /iscratch/i/gs.16/build33/bed/mrna/*.psl > psl.lst
    ls -1S /iscratch/i/mrna.134/Homo_sapiens/mrna*.fa > mrna.lst
    cp ~/hg14/bed/mrnaOrientInfo/gsub .
    # Edit gsub to point to the correct paths.
    gensub2 psl.lst mrna.lst gsub spec
    para create spec
    para try 
    para check, para push, para check, ....

    # When the cluster run is done do:
    ssh hgwdev
    cd ~/hg15/bed/mrnaOrientInfo
    liftUp mrnaOrientInfo.bed ~/hg15/jkStuff/liftAll.lft warn oi/*.tab
    hgLoadBed hg15 mrnaOrientInfo mrnaOrientInfo.bed \
      -sqlTable=$HOME/kent/src/hg/lib/mrnaOrientInfo.sql > /dev/null

    # est: use small cluster (I/O intensive).  Use 2-level output dir 
    # (input est.fa has been split into multiple files).  
    ssh kkr1u00
    mkdir -p ~/hg15/bed/estOrientInfo/oi
    cd ~/hg15/bed/estOrientInfo
    foreach f (`cat mrna.lst`)
      mkdir oi/$f:t:r
    end
    ls -1S /iscratch/i/gs.16/build33/bed/est/*.psl > psl.lst
    ls -1S /iscratch/i/mrna.134/Homo_sapiens/est*.fa > mrna.lst
    cp ~/hg14/bed/estOrientInfo/gsub .
    # Edit gsub to point to the correct paths.
    gensub2 psl.lst mrna.lst gsub spec
    para create spec
    para try 
    para check, para push, para check, ....

    # When the cluster run is done do:
    ssh hgwdev
    cd ~/hg15/bed/estOrientInfo
    # oi/*/*.tab -> argument list too long... so cat the lowest level together:
    foreach d (oi/*)
      cat $d/*.tab > $d.tab
    end
    liftUp estOrientInfo.bed ~/hg15/jkStuff/liftAll.lft warn oi/*.tab
    bedSort estOrientInfo.bed estOrientInfo.bed
    hgLoadBed hg15 estOrientInfo estOrientInfo.bed \
      -sqlTable=$HOME/kent/src/hg/lib/estOrientInfo.sql > /dev/null

    # Create rnaCluster table (depends on {est,mrna}OrientInfo above)
    cd ~/hg15
    # Create a list of accessions that come from RAGE libraries and need to
    # be excluded. (added by Chuck Wed Nov 27 13:09:07 PST 2002)
    ~/kent/src/hg/geneBounds/clusterRna/generateRageAccList.csh hg15 \
      rage.libs
    mkdir -p ~/hg15/bed/rnaCluster/chrom
    # Exclude accesions in the RAGE file
    foreach f (?{,?}/chr*.fa)
      set c = $f:t:r
      set out = bed/rnaCluster/chrom/$c.bed
      echo clusterRna -mrnaExclude=hg15.rage.libs hg15 /dev/null $out -chrom=$c
      clusterRna -mrnaExclude=hg15.rage.libs hg15 /dev/null $out -chrom=$c
    end

    cd bed/rnaCluster
    hgLoadBed hg15 rnaCluster chrom/*.bed > /dev/null


# GENEBANDS (DONE 4/13/03 JK)
    # Create precomputed geneBands table:
    ssh hgwdev
    hgGeneBands hg15 geneBands.txt
    hgsql hg15 < ~/kent/src/hg/lib/geneBands.sql
    echo "load data local infile 'geneBands.txt' into table geneBands;" \
    | hgsql hg15
    rm geneBands.txt


# PRODUCING GENSCAN PREDICTIONS (DONE 4/13/03 MS&JK)

    ssh eieio
    mkdir -p ~/hg15/bed/genscan
    cd ~/hg15/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir -p gtf pep subopt
    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequencable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/store5/gs.16/build33/?{,?}/NT_*/NT_??????.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
        
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    cd ~/hg15
    cd bed/genscan
    # Create template file, gsub, for gensub2.  For example (3-line file):
#LOOP    rm -f genome.list
/cluster/home/kent/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
    echo "" > dummy.list
    gensub2 genome.list dummy.list gsub jobList
    para create jobList
    para try
    para check
    para push
    # Issue either one of the following two commands to check the
    # status of the cluster and your jobs, until they are done.
    parasol status
    para check
    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.  In build33, this was 22/NT_011519.
    # Convert these to chromosome level files as so:     
    ssh eieio
    cd ~/hg15/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/NT*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/NT*.bed > \
      /dev/null
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/hg15/bed/genscan
    ldHgGene hg15 genscan genscan.gtf
    hgPepPred hg15 generic genscanPep genscan.pep
    hgLoadBed hg15 genscanSubopt genscanSubopt.bed > /dev/null


# CPGISLANDS (DONE 041203)
    ssh eieio
    mkdir -p ~/hg15/bed/cpgIsland
    cd ~/hg15/bed/cpgIsland
    # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
    # copy the tar file to the current directory
    tar xvf cpg_dist.tar 
    cd cpg_dist
    gcc readseq.c cpg_lh.c -o cpglh.exe
    cd ..
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
      set fout=$f:t:r:r.cpg
      echo producing $fout...
      ./cpg_dist/cpglh.exe $f > $fout
    end
    cp ~/hg13/bed/cpgIsland/filter.awk .
    awk -f filter.awk chr*.cpg > cpgIsland.bed
    ssh hgwdev
    cd ~/hg15/bed/cpgIsland
    hgLoadBed hg15 cpgIsland -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed


CREATE GOLDEN TRIANGLE (todo)

# Make sure that rnaCluster table is in place.   Then extract Affy 
# expression info into a form suitable for Eisen's clustering program with:
      cd ~/hg15/bed
      mkdir triangle
      cd triangle
      eisenInput hg15 affyHg10.txt
Transfer this to Windows and do k-means clustering
with k=200 with cluster.  Transfer results file back
to ~/hg15/bed/triangle/affyCluster_K_G200.kgg.  Then
do
      promoSeqFromCluster hg15 1000 affyCluster_K_G200.kgg kg200.unmasked
Then RepeatMask the .fa file inkg200.unmasked, and copy masked versions
to kg200.   Then
      cat kg200/*.fa > all1000.fa
and set up cluster Improbizer run to do 100 controls for every real
run on each - putting the output in imp.200.1000.e.  When improbizer
run is done make a file summarizing the runs as so:
      cd imp.200.1000.e
      motifSig ../imp.200.1000.e.iri ../kg200 motif control*
get rid of insignificant motifs with:
      cd ..
      awk '{if ($2 > $3) print; }' imp.200.1000.e.iri > sig.200.1000.e.iri
turn rest into just dnaMotifs with
      iriToDnaMotif sig.200.1000.e.iri motif.200.1000.e.txt
Extract all promoters with
      featureBits hg15 rnaCluster:upstream:1000 -bed=upstream1000.bed -fa=upstream1000.fa
Locate motifs on all promoters with
      dnaMotifFind motif.200.1000.e.txt upstream1000.fa hits.200.1000.e.txt -rc -markov=2
      liftPromoHits upstream1000.bed hits.200.1000.e.txt triangle.bed

# CREATE STS/FISH/BACENDS/CYTOBANDS DIRECTORY STRUCTURE AND SETUP (DONE 4/8/2003)

# Create directory structure to hold information for these tracks
        cd /projects/hg2/booch/psl/

# Change Makefile parameters for OOVERS, GSVERS, PREVGS, PREVOO
        make new

# Update all Makefiles with latest OOVERS and GSVERS, DATABASE, and locations of .fa files
# Makefile in:
#     /gs.16/build33/
#     /gs.16/build33/bacends
#     /gs.16/build33/cytobands
#     /gs.16/build33/cytoPlots
#     /gs.16/build33/fish
#     /gs.16/build33/fosends
#     /gs.16/build33/geneticPlots
#     /gs.16/build33/primers
#     /gs.16/build33/recombrate
#     /gs.16/build33/sts
#     /gs.16/build33/stsPlots
	
# Create accession_info file
	make accession_info.rdb

# UPDATE STS INFORMATION (TODO 4/7/2003)
# Download and unpack updated information from dbSTS:
# In a web browser, go to ftp://ftp.ncbi.nih.gov/repository/dbSTS/.  
# Download dbSTS.sts, dbSTS.aliases, and dbSTS.FASTA.dailydump.Z to /projects/hg2/booch/psl/update
	cd /projects/hg2/booch/psl/update
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.sts
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.aliases
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.FASTA.dailydump.Z
        gunzip dbSTS.FASTA.dailydump.Z

# Create updated files
        cd /projects/hg2/booch/psl/update

# Edit Makefile to latest sts.X version from PREV, and update STS files
        make update

# Make new directory for this info and move files there
        mkdir /cluster/store1/sts.7
        cp all.STS.fa /cluster/store1/sts.7
        cp all.primers /cluster/store1/sts.7
        cp all.primers.fa /cluster/store1/sts.7

# Copy new files to cluster
        ssh kkstore
        cd /cluster/store1/sts.7
        cp /cluster/store1/sts.7/*.* /scratch/hg/STS

# Ask for propagation from sysadmin

# Load the sequences (change sts.# to match correct location)
	ssh hgwdev
	mkdir /gbdb/hg15/sts.7
	cd /gbdb/hg15/sts.7
	ln -s /cluster/store1/sts.7/all.STS.fa ./all.STS.fa
	ln -s /cluster/store1/sts.7/all.primers.fa ./all.primers.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg15 /gbdb/hg15/sts.7/all.STS.fa
	hgLoadRna addSeq hg15 /gbdb/hg15/sts.7/all.primers.fa


# CREATE STS MARKER ALIGNMENTS (DONE TSF 4/12/2003)

# Create full sequence alignments
        ssh kk
        cd /cluster/home/booch/sts

# Update Makefile with latest OOVERS and GSVERS and
# run cluster jobs
        make new
        make jobList 
        para create jobList
        para push 
	# wait until alignments done
        make stsMarkers.psl

# Copy files to final destination and remove originals
        make copy.assembly
        make clean

# Create primer alignments
        ssh kk
        cd /cluster/home/booch/primers
        
# Update Makefile with latest OOVERS and GSVERS and
# run cluster jobs
        make new
        make jobList.scratch
        para create jobList
        para push

# Do an initial quick filter of results (takes a while, still) and create 
# final file - best done on eieio since disks local
	ssh eieio
	make filter
        make primers.psl

# Copy files to final destination and remove
        make copy.assembly
        make clean
        
# Create ePCR alignments
        ssh kk
        cd /cluster/home/booch/epcr

# Update Makefile with latest OOVERS and GSVERS
        make new
        make jobList
        para create jobList
        para push
        make all.epcr

# Copy files to final destination and remove
        make copy.assembly
        make clean
        

# CREATE AND LOAD STS MARKERS TRACK (DONE TSF 4/12/2003)

# Copy in current stsInfo2.bed and stsAlias.bed files
        cd /projects/hg2/booch/psl/gs.16/build33
        cp ../update/stsInfo2.bed .
        cp ../update/stsAlias.bed .

# Create final version of sts sequence placements
        ssh kks00
        cd /projects/hg2/booch/psl/gs.16/build33/sts
        make stsMarkers.final

# Create final version of primers placements
# Make sure PRIMERS variable in Makefile is pointing to current version
        cd /projects/hg2/booch/psl/gs.16/build33/primers
        make primers.final

# Create bed file
        cd /projects/hg2/booch/psl/gs.16/build33
        make stsMap.bed

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg15 < all_sts_primer.sql
        hgsql hg15 < all_sts_seq.sql
        hgsql hg15 < stsAlias.sql
        hgsql hg15 < stsInfo2.sql
        hgsql hg15 < stsMap.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.16/build33/sts/
        echo 'load data local infile "stsMarkers.psl.filter.lifted" into table all_sts_seq;' | hgsql hg15
	cd /projects/hg2/booch/psl/gs.16/build33/primers/
        echo 'load data local infile "primers.psl.filter.lifted" into table all_sts_primer;' | hgsql hg15
	cd /projects/hg2/booch/psl/gs.16/build33/
        echo 'load data local infile "stsAlias.bed" into table stsAlias;' | hgsql hg15
        echo 'load data local infile "stsInfo2.bed" into table stsInfo2;' | hgsql hg15
	echo 'load data local infile "stsMap.bed" into table stsMap;' | hgsql hg15


# UPDATE BACEND SEQUENCES (DONE TSF 4/10/2003)

# Download new files. Make new directory based on previous one
	mkdir /cluster/store1/bacends.4
	cd /cluster/store1/bacends.4
	wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/BACENDS/AllBACends.mfa.gz
	wget ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/BACENDS/cl_acc_gi_len.gz
	gunzip AllBACends.mfa.gz
	gunzip cl_acc_gi_len.gz

# Convert fa file
	cp /cluster/store1/bacends.3/convert.pl .
	convert.pl < AllBACends.mfa > BACends.fa

# Create new pairs files
	convertBacEndPairInfo cl_acc_gi_len

# Split file into pieces and copy to cluster to propagate
	/cluster/bin/i386/faSplit sequence BACends.fa 100 BACends
        ssh kkstore
        cd /cluster/store1/bacends.4
	rm /scratch/hg/bacEnds/hs/BACends*.fa
        mv /cluster/store1/bacends.4/BACends???.fa /scratch/hg/bacEnds/hs/
	cp /cluster/store1/bacends.4/BACends.fa /scratch/hg/bacEnds/hs/

# Ask for propagation from sysadmin

# Load the sequences (change bacends.# to match correct location)
	ssh hgwdev
	mkdir /gbdb/hg15/bacends.4
	cd /gbdb/hg15/bacends.4
	ln -s /cluster/store1/bacends.4/BACends.fa ./BACends.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg15 /gbdb/hg15/bacends.4/BACends.fa
                
IN PROGRESS - MATT
# BACEND SEQUENCE ALIGNMENTS (TO DO)
# (alignments done without RepeatMasking)

# Create full sequence alignments
	ssh kk
        cd /cluster/home/booch/bacends

# Update Makefile with latest OOVERS and GSVERS and run cluster jobs
        make new
        make jobList
        para create jobList
        para push 

# Compile alignments and lift the files (takes a while)
	ssh eieio
	make bacEnds.psl.lifted
DONE TO HERE - MATT FINISHING FOR TERRY
# Copy files to final destination and remove
        make copy.assembly - This step failed, I do not have write perms to Terry's dir
        make clean # DONT'T DO THIS (may want to wait until sure they're OK)


# BACEND PAIRS TRACK (TO DO)

# Add /projects/compbiousr/booch/booch/scripts to your path

# Update Makefile with new location of pairs/singles 
# files, if necessary (DONE)
        cd /projects/hg2/booch/psl/gs.16/build33/bacends

# Make initial file of alignments
	make bacEnds.rdb
 
# Try to fish out more pairs
	make bacEndsMiss.psl

# Re-make bacEnds.rdb with new info
	make bacEnds.rdb
 
# Create bacEndPairs track file
        make bacEndPairs.bed

# Create bacEndPairsBad and bacEndPairsLong files
	make bacEndPairsBad.bed

# Create psl file to load
	make bacEnds.load.psl

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg15 < all_bacends.sql
        hgsql hg15 < bacEndPairs.sql
        hgsql hg15 < bacEndPairsBad.sql
        hgsql hg15 < bacEndPairsLong.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.16/build33/bacends/
        echo 'load data local infile "bacEnds.load.psl" into table all_bacends;' | hgsql hg15        
        echo 'load data local infile "bacEndPairs.bed" into table bacEndPairs;' | hgsql hg15
        echo 'load data local infile "bacEndPairsBad.bed" into table bacEndPairsBad;' | hgsql hg15
        echo 'load data local infile "bacEndPairsLong.bed" into table bacEndPairsLong;' | hgsql hg15


# FOSEND SEQUENCE ALIGNMENTS (TO DO)

# Create full sequence alignments
        ssh kk
        cd /cluster/home/booch/fosends

# Update Makefile with latest OOVERS and GSVERS and run cluster jobs
        make new
        make jobList
	para create jobList
        para push

# Compile alignments and lift the files (takes a while)
	ssh eieio
	make fosEnds.psl.lifted

# Copy files to final destination and remove
        make copy.assembly
        make clean


# FOSEND PAIRS TRACK (TODO)

# Update Makefile with location of pairs files, if necessary
        ssh kks00
        cd /projects/hg2/booch/psl/gs.16/build33/fosends

# Make initial file of alignments
	make fosEnds.rdb
 
# Try to fish out more pairs
	make fosEndsMiss.psl

# Re-make bacEnds.rdb with new info
	make fosEnds.rdb
 
# Create bacEndPairs track file
        make fosEndPairs.bed

# Create bacEndPairsBad and bacEndPairsLong files
	make fosEndPairsBad.bed

# Create psl file to load
	make fosEnds.load.psl

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg15 < all_fosends.sql
        hgsql hg15 < fosEndPairs.sql
        hgsql hg15 < fosEndPairsBad.sql
        hgsql hg15 < fosEndPairsLong.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.16/build33/fosends/
        echo 'load data local infile "fosEnds.load.psl" into table all_fosends;' | hgsql hg15        
        echo 'load data local infile "fosEndPairs.bed" into table fosEndPairs;' | hgsql hg15
        echo 'load data local infile "fosEndPairsBad.bed" into table fosEndPairsBad;' | hgsql hg15
        echo 'load data local infile "fosEndPairsLong.bed" into table fosEndPairsLong;' | hgsql hg15

# Load the sequences (change fosends.# to match correct location) (done for hg15 early 4/9/2003)
	mkdir /gbdb/hg15/fosends.3
	cd /gbdb/hg15/fosends.3
	ln -s /cluster/store1/fosends.3/fosEnds.fa ./fosEnds.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg15 /gbdb/hg15/fosends.3/fosEnds.fa
                

# UPDATE FISH CLONES INFORMATION (DONE 4/9/2003)

# Download the latest info from NCBI
        # point browser at http://www.ncbi.nlm.nih.gov/genome/cyto/cytobac.cgi?CHR=all&VERBOSE=ctg
        # change "Show details on sequence-tag" to "yes"
        #change "Download or Display" to "Download table for UNIX"
        # press Submit - save as /projects/hg2/booch/psl/fish/hbrc/hbrc.YYYYMMDD.table

# Format file just downloaded.  
        cd /projects/hg2/booch/psl/fish/

# Edit Makefile to point at file just downloaded (variables HBRC, HBRCFORMAT)
        make HBRC

# Copy it to the new freeze location
        cp /projects/hg2/booch/psl/fish/all.fish.format /projects/hg2/booch/psl/gs.16/build33/fish/


# CREATE AND LOAD FISH CLONES TRACK (TO DO)
# (must be done after STS markers track and BAC end pairs track)

# Extract the file with clone positions from database
        ssh hgwdev
        echo 'select * into outfile "/tmp/booch/clonePos.txt" from clonePos' | hgsql hg15
        mv /tmp/booch/clonePos.txt /projects/hg2/booch/psl/gs.16/build33/fish

# Create bed file
        cd /projects/hg2/booch/psl/gs.16/build33/fish
        make bed

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg15 < fishClones.sql

# Load the table
	cd /projects/hg2/booch/psl/gs.16/build33/fish/
        echo 'load data local infile "fishClones.bed" into table fishClones;' | hgsql hg15
        

# CREATE AND LOAD CHROMOSOME BANDS TRACK (TO DO)
# (must be done after FISH Clones track) 

# Create bed file
        ssh hgwdev
        # DONE - DON'T Do AGAIN! make setBands.txt   # NOTE: may get errors if inserts file out-of-sync with pctSetBands file 
        #make cytobands.pct.ranges DONE - DON'T DO AGAIN!
        make predict

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg15 < cytoBand.sql
        
# Load the table
	cd /projects/hg2/booch/psl/gs.16/build33/cytobands/
	echo 'load data local infile "cytobands.bed" into table cytoBand;' | hgsql hg15


CREATE CHROMOSOME REPORTS (TO DO)


# CREATE STS MAP COMPARISON PLOTS AND GENETIC PLOTS (TO DO)
# (Must wait until after the STS Map track has been finished for STS and genetic plots)
# (Must wait until after the CytoBand, FISH tracks have been finished for cytogenetic plots)

# Create sts plots
        cd /projects/hg2/booch/psl/gs.16/build33/stsPlots
        make stsplots

# Create genetic plots
        cd /projects/hg2/booch/psl/gs.16/build33/geneticPlots
        make all
        matlab -nodesktop
        >> allplot_ncbi('/cse/grads/booch/tracks/gs.16/build33/geneticPlots/','build33', 'jpg');
        >> quit

# Create cytogenetic plots
        cd /projects/hg2/booch/psl/gs.16/build33/cytoPlots
        make bandplots
	

# Set up directories where these will end up
        ssh hgwdev
        cd /usr/local/apache/htdocs/goldenPath/mapPlots

# Update Makefile with OOVERS, GSVERS, and FREEZE date
        make new

# Copy over files
        make sts
	make genetic
	make band

# Update the index.html to include links to these new plots, and delete oldest set
# Update the arch.html with the oldest set just removed from index.html
# Check changes to index.html and arch.html into CVS
# Ask for plots to be pushed to hgwbeta (and RR eventually)


# PRODUCING CROSS_SPECIES mRNA ALIGNMENTS (DONE 4/12/03 JK)
    # Make sure masked contigs are in /scratch/hg/gs.16/build33/trfFa 
    # Make sure split-up xenoRna sequence is under /iscratch too (GENBANK)
    ssh kkstore
    mkdir -p ~/hg15/bed/xenoMrna
    cd ~/hg15/bed/xenoMrna
    mkdir psl
    ls -1S /scratch/hg/gs.16/build33/trfFa/*.fa > human.lst
    ls -1S /iscratch/i/mrna.134/Homo_sapiens/xenoRna*.fa > mrna.lst
    # Using split fa -- so create separate output dirs and special gsub:
    foreach f (`cat mrna.lst`)
      mkdir psl/$f:t:r
    end
    echo '#LOOP \
/cluster/home/kent/bin/i386/blat {check in line+ $(path1)} {check in line+ $(path2)} -q=rnax -t=dnax -mask=lower {check out line+ psl/$(root2)/$(root1)_$(root2).psl} \
#ENDLOOP' > gsub
    gensub2 human.lst mrna.lst gsub spec
    para create spec
    ssh kk
    cd ~/hg15/bed/xenoMrna
    para try
    para check
    para push 
    # Do para check until the run is done, doing para push if necessary
    # Sort xeno mRNA alignments as so:
    ssh eieio
    cd ~/hg15/bed/xenoMrna
    pslSort dirs raw.psl /cluster/store2/temp psl/xenoRna*
    pslReps raw.psl cooked.psl /dev/null -minAli=0.25
    liftUp chrom.psl ../../jkStuff/liftAll.lft warn cooked.psl
    pslSortAcc nohead chrom /cluster/store2/temp chrom.psl
    pslCat -dir chrom > xenoMrna.psl
    rm -r chrom raw.psl cooked.psl chrom.psl
    # Load into database as so:
    ssh hgwdev
    cd ~/hg15/bed/xenoMrna
    hgLoadPsl hg15 xenoMrna.psl -tNameIx
    # Sequence info should have already been loaded into database (PRELOAD)


# PRODUCING CROSS_SPECIES EST ALIGNMENTS (TODO)
    # Make sure masked contigs are in /scratch/hg/gs.16/build33/trfFa 
    # Make sure split-up xenoRna sequence is under /iscratch too (GENBANK)
    ssh kkstore
    mkdir -p ~/hg15/bed/xenoEst
    cd ~/hg15/bed/xenoEst
    mkdir psl
    ls -1S /scratch/hg/gs.16/build33/trfFa/*.fa.trf > human.lst
    ls -1S /iscratch/i/mrna.134/Homo_sapiens/xenoEst*.fa > mrna.lst
    # Using split fa -- so create separate output dirs and special gsub:
    foreach f (`cat mrna.lst`)
      mkdir psl/$f:t:r
    end
    echo '#LOOP \
/cluster/home/kent/bin/i386/blat {check in line+ $(path1)} {check in line+ $(path2)} -q=dnax -t=dnax -mask=lower {check out line+ psl/$(root2)/$(root1)_$(root2).psl} \
#ENDLOOP' > gsub
    gensub2 human.lst mrna.lst gsub spec
    ssh kk
    cd ~/hg15/bed/xenoEst
    para create spec
    para try, para check, para push, para check, ...
    # Sort xenoEst alignments:
    ssh eieio
    cd ~/hg15/bed/xenoEst
    pslSort dirs raw.psl /cluster/store2/temp psl/xenoEst*
    pslReps raw.psl cooked.psl /dev/null -minAli=0.10
    liftUp chrom.psl ../../jkStuff/liftAll.lft warn cooked.psl
    pslSortAcc nohead chrom /cluster/store2/temp chrom.psl
    pslCat -dir chrom > xenoEst.psl
    rm -r chrom raw.psl cooked.psl chrom.psl
    # Load into database as so:
    ssh hgwdev
    cd ~/hg15/bed/xenoEst
    hgLoadPsl hg15 xenoEst.psl -tNameIx
    # Sequence info should have already been loaded into database (PRELOAD)


# PRODUCING FUGU ALIGNMENTS (DONE 041203)
    # Distribute fugu sequence to /iscratch/i/fugu/ (if it isn't already there)
    ssh kkr1u00
    rm -rf /iscratch/i/fugu
    mkdir /iscratch/i/fugu
    cp -p /cluster/store3/fuguSeq/split2.5Mb/*.fa /iscratch/i/fugu
    ~kent/bin/iSync

    ssh kk
    mkdir ~/hg15/bed/blatFugu
    cd ~/hg15/bed/blatFugu
    mkdir psl
    foreach f (~/hg15/?{,?}/NT_??????/NT_??????.fa)
      set c=$f:t:r
      mkdir -p psl/$c
    end
    ls -1S /iscratch/i/fugu/*.fa > fugu.lst
    ls -1S /scratch/hg/gs.16/build33/trfFa/*.fa > human.lst
    cp ~/hg14/bed/blatFugu gsub .
    gensub2 human.lst fugu.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check

    # When cluster run is done, sort alignments:
    ssh eieio
    cd ~/hg15/bed/blatFugu
    pslCat -dir psl/NT_?????? | \
      liftUp -type=.psl stdout ~/hg15/jkStuff/liftAll.lft warn stdin | \
      pslSortAcc nohead chrom temp stdin

    # Rename to correspond with tables as so and load into database:
    ssh hgwdev
    cd ~/hg15/bed/blatFugu/chrom
    rm -f chr*_blatFugu.psl
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        mv $i ${r}_blatFugu.psl
    end
    hgLoadPsl hg15 *.psl

    # Make fugu /gbdb/ symlink and load Fugu sequence data.
    mkdir /gbdb/hg15/fuguSeq
    cd /gbdb/hg15/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta
    cd /cluster/store2/tmp
    hgLoadRna addSeq hg15 /gbdb/hg15/fuguSeq/fugu_v3_mask.fasta


TIGR GENE INDEX (TODO)
  o mkdir -p ~/hg15/bed/tigr    
    cd ~/hg15/bed/tigr  
    wget ftp://ftp.tigr.org/private/HGI_ren/TGI_track_HumanGenome_build33.tgz
    tar xvzf TGI*.tgz
    foreach f (*cattle*)
      set f1 = `echo $f | sed -e 's/cattle/cow/g'`
      mv $f $f1
    end
    foreach o (mouse cow human pig rat)
      setenv O $o
      foreach f (chr*_$o*s)
        tail +2 $f | perl -wpe 's /THC/TC/; s/(TH?C\d+)/$ENV{O}_$1/;' > $f.gff
      end
    end
    ldHgGene -exon=TC hg15 tigrGeneIndex *.gff


LOAD MOUSEREF TRACK (todo)
    First copy in data from eieio to ~/hg15/bed/mouseRef.  
    Then substitute 'genome' for the appropriate chromosome 
    in each of the alignment files.  Finally do:
       hgRefAlign webb hg15 mouseRef *.alignments

LOAD AVID MOUSE TRACK (todo)
      ssh cc98
      cd ~/hg15/bed
      mkdir avidMouse
      cd avidMouse
      wget http://pipeline.lbl.gov/tableCS-LBNL.txt
      hgAvidShortBed *.txt avidRepeat.bed avidUnique.bed
      hgLoadBed avidRepeat avidRepeat.bed
      hgLoadBed avidUnique avidUnique.bed

LOAD SNPS (TODO)
      ssh hgwdev
      cd ~/hg15/bed
      mkdir snp
      cd snp
      mkdir build110
      cd build110
      ln -s ../../../seq_contig.md .
      ln -s ~/hg13/bed/cpgIsland/filter.awk .

     -Download SNPs from ftp://ftp.ncbi.nlm.nih.gov/pub/sherry/gp.ncbi.b31.gz
     -Unpack
      calcFlipSnpPos seq_contig.md gp.ncbi.b31 gp.ncbi.b31.flipped
      mv gp.ncbi.b31 gp.ncbi.b31.original
      gzip gp.ncbi.b31.original

      grep RANDOM       gp.ncbi.b31.flipped >  snpTsc.txt
      grep MIXED        gp.ncbi.b31.flipped >> snpTsc.txt
      grep BAC_OVERLAP  gp.ncbi.b31.flipped >  snpNih.txt
      grep OTHER        gp.ncbi.b31.flipped >> snpNih.txt

      awk -f filter.awk snpTsc.txt > snpTsc.contig.bed
      awk -f filter.awk snpNih.txt > snpNih.contig.bed

      liftUp snpTsc.bed ../../jkStuff/liftAll.lft warn snpTsc.contig.bed
      liftUp snpNih.bed ../../jkStuff/liftAll.lft warn snpNih.contig.bed

      hgLoadBed hg15 snpTsc snpTsc.bed
      hgLoadBed hg15 snpNih snpNih.bed

     -gzip all of the big files

LOAD ENSEMBL GENES (TODO)
     cd ~/hg15/bed
     mkdir ensembl
     cd ensembl

        Get the ensembl gene data as below:
        GET http://www.ebi.ac.uk/~stabenau/human_8_30.gtf.gz > ensGene.gz
        (The above may only be a temproary location)

        Get the ensembl protein data from http://www.ensembl.org/Homo_sapiens/martview
        Follow this sequence through the pages:
        Page 1) Make sure that the Homo_sapiens choice is selected. Hit next.
        Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
        Page 3) Choose the "Structures" box. 
        Page 4) Choose Transcripts/Proteins and GTF as the ouput, choose gzip compression and then hit export.

        gunzip the file and name to ensembl.gtf


# Ensembl handles random chromosomes differently than us, so we
# strip this data.  Fortunately it just loses a couple of genes.
     grep -v ^6_DR51 ensembl.gtf | grep -v _NT_ > unrandom.gtf

# Add "chr" to front of each line in the gene data gtf file to make 
# it compatible with ldHgGene 
     ~matt/bin/addchr.pl unrandom.gtf ensGene.gtf
     ./fixEns.pl ensGene.gtf ensFixed.gtf 
     ldHgGene hg15 ensGene ensGene.gtf

o - Load Ensembl peptides:
     Get them from ensembl as above in the gene section except for
     Page 3) Choose the "Sequences" box. 
     Page 4) Choose GTF as the ouput, choose gzip compression and then hit export.

     Substitute ENST for ENSP in ensPep with the program called subs
     edit subs.in to read: ENSP|ENST
     subs -e ensPep.fa > /dev/null

     Run fixPep.pl ensPep.fa ensembl.pep
     hgPepPred hg15 generic ensPep ensembl.pep


    LOAD SANGER 22 Pseudogenes 
    cd ~/hg15/bed/sanger22
    cp ~/hg10/bed/sanger22/cChr22.3.lx.pseudogene.gff .
    replace ^chr22 with hg10:chr22 in Chr22.3.lx.pseudogene.gff
    liftUp -type=.gff pseudo.gff hg15.lft Chr22.3.lx.pseudogene.gff
    ldHgGene hg15 sanger22pseudo pseudo.gff

LOAD SANGER22 GENES  (TODO)
      cd ~/hg15/bed
      mkdir sanger22
      cd sanger22
      not sure where these files were downloaded from
      grep -v Pseudogene Chr22*.genes.gff | hgSanger22 hg15 stdin Chr22*.cds.gff *.genes.dna *.cds.pep 0
          | ldHgGene hg15 sanger22pseudo stdin
  # Note: this creates sanger22extras, but doesn't currently create
  # a correct sanger22 table, which are replaced in the next steps
      sanger22-gff-doctor Chr22.3.1x.cds.gff Chr22.3.1x.genes.gff \
          | ldHgGene hg15 sanger22 stdin
      sanger22-gff-doctor -pseudogenes Chr22.3.1x.cds.gff Chr22.3.1x.genes.gff \
          | ldHgGene hg15 sanger22pseudo stdin

      hgPepPred hg15 generic sanger22pep *.pep

              
              LOAD SANGER 20 GENES (todo)
     # First download files from James Gilbert's email to ~/hg15/bed/sanger20 and
     # go to that directory while logged onto hgwdev.  Then:
        grep -v Pseudogene chr_20*.gtf | ldHgGene hg15 sanger20 stdin
        hgSanger20 hg15 *.gtf *.info


# JAX ORTHOLOG (still valid???) (TODO)
    # Add Jackson labs info
    cd ~/hg15/bed
    mkdir jaxOrtholog
    cd jaxOrtholog
    wget ftp://ftp.informatics.jax.org/pub/informatics/reports/HMD_Human3.rpt
    cp /cluster/store1/gs.12/build29/bed/jaxOrtholog/filter.awk .
    awk -f filter.awk *.rpt > jaxOrtholog.tab
    # Drop (just in case), create and load the table like this:
    echo 'drop table jaxOrtholog;' | hgsql hg15
    hgsql hg15 < ~/src/hg/lib/jaxOrtholog.sql
    echo "load data local infile '"`pwd`"/jaxOrtholog.tab' into table \
          jaxOrtholog;" \
    | hgsql hg15


LOAD RNAGENES
      ssh hgwdev
      mkdir -p ~/hg15/bed/rnaGene
      cd ~/hg15/bed/rnaGene
      wget ftp://ftp.genetics.wustl.edu/pub/eddy/pickup/ncrna-hg15.gff.gz
      gunzip -c ncrna-hg15.gff.gz | grep -v '^#' > contig.gff
      liftUp chrom.gff ../../jkStuff/liftAll.lft warn contig.gff
      echo 'drop table hgRnaGene;' | hgsql hg15
      hgsql hg15 < ~/kent/src/hg/lib/rnaGene.sql
      hgRnaGenes hg15 chrom.gff

LOAD EXOFISH (todo)
     - login to hgwdev
     - cd /cluster/store5/gs.16/build33/bed
     - mkdir exoFish
     - cd exoFish
     - hg15 < ~kent/src/hg/lib/exoFish.sql
     - Put email attatchment from Olivier Jaillon (ojaaillon@genoscope.cns.fr)
       into /cluster/store5/gs.16/build33/bed/exoFish/all_maping_ecore
     - awk -f filter.awk all_maping_ecore > exoFish.bed
     - hgLoadBed hg15 exoFish exoFish.bed

LOAD MOUSE SYNTENY (TODO)
     ssh hgwdev
     mkdir -p ~/hg15/bed/mouseSyn
     cd ~/hg15/bed/mouseSyn
     # Saved Michael Kamal's email attachment: allDirectedSegmentsBySize300.txt
     # Process the .txt file (minus header) into a bed 6 + file:
     grep -v "^#" allDirectedSegmentsBySize300.txt \
       | awk '($6 > $5) {printf "%s\t%d\t%d\t%s\t%d\t%s\t%d\t%d\t%s\n", $4, $5-1, $6, $1, 999, $7, $2-1, $3, $8;} \
              ($5 > $6) {printf "%s\t%d\t%d\t%s\t%d\t%s\t%d\t%d\t%s\n", $4, $6-1, $5, $1, 999, $7, $2-1, $3, $8;}' \
       > mouseSynWhd.bed
     hgLoadBed -noBin -sqlTable=$HOME/kent/src/hg/lib/mouseSynWhd.sql \
       hg15 mouseSynWhd mouseSynWhd.bed

LOAD GENIE (todo)
     - cat */ctg*/ctg*.affymetrix.gtf > predContigs.gtf
     - liftUp predChrom.gtf ../../jkStuff/liftAll.lft warn predContigs.gtf
     - ldHgGene hg15 genieAlt predChrom.gtf

     - cat */ctg*/ctg*.affymetrix.aa > pred.aa
     - hgPepPred hg15 genie pred.aa 

     - hg15
         mysql> delete * from genieAlt where name like 'RS.%';
         mysql> delete * from genieAlt where name like 'C.%';

LOAD SOFTBERRY GENES (TODO)
     mkdir -p ~/hg15/bed/softberry
     cd ~/hg15/bed/softberry
     wget ftp://www.softberry.com/pub/sc_fgenesh_hum_mar03up/sc_fgenesh_hum_mar03up.tar.gz
     gunzip -c sc_fgenesh_hum_mar03up.tar.gz | tar xvf -
     ldHgGene hg15 softberryGene chr*.gff
     hgPepPred hg15 softberry *.protein
     hgSoftberryHom hg15 *.protein

LOAD GENEID GENES (TODO)
    mkdir ~/hg15/bed/geneid
    cd ~/hg15/bed/geneid
    mkdir download
    cd download
    # Now download *.gtf and *.prot from 
    wget -r http://www1.imim.es/genepredictions/H.sapiens/golden_path_20021114/geneid_v1.1/
    # oops, due to links in the index.html, it tries to get too much.  
    # ctrl-c it when it starts to download other directories.
    mv www1.imim.es/genepredictions/H.sapiens/golden_path_20021114/geneid_v1.1/*.{gtf,prot} .
    rm -r www1.imim.es/
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene hg15 geneid download/*.gtf -exon=CDS
    hgPepPred hg15 generic geneidPep download/*-fixed.prot

LOAD ACEMBLY (TODO)
    mkdir -p ~/hg15/bed/acembly
    cd ~/hg15/bed/acembly
    # Get acembly*gene.gff from Jean and Danielle Thierry-Mieg
    wget ftp://ftp.ncbi.nih.gov/repository/acedb/ncbi_31.human.genes/acembly.ncbi_31.genes.proteins.fasta.tar.gz
    wget ftp://ftp.ncbi.nih.gov/repository/acedb/ncbi_31.human.genes/acembly.ncbi_31.genes.gff.tar.gz
    gunzip -c acembly.ncbi_31.genes.gff.tar.gz | tar xvf -
    gunzip -c acembly.ncbi_31.genes.proteins.fasta.tar.gz | tar xvf -
    cd acembly.ncbi_31.genes.gff
    # Save just the floating-contig features to different files for lifting 
    # and lift up the floating-contig features to chr*_random coords:
    foreach f (acemblygenes.*.gff)
      set c=$f:r:e
      egrep '^[a-zA-Z0-9]+\|NT_[0-9][0-9][0-9][0-9][0-9][0-9]' $f | \
        perl -wpe 's/^(\w+)\|(\w+)/$1\/$2/' > ctg-chr${c}_random.gff
      if (-e ../../../$c/lift/random.lft) then
        liftUp chr${c}_random.gff ../../../$c/lift/random.lft warn \
          ctg-chr${c}_random.gff
      endif
      # Strip out _random or floating contig lines from the normal chrom gff,
      # and add the "chr" prefix:
      grep -v ^$c\| $f | grep -v ^Hs | perl -wpe 's/^/chr/;' > chr$c.gff
    end

    cd ../acembly.ncbi_31.genes.proteins.fasta
    #- Remove G_t*_ prefixes from acemblyproteins.*.fasta:
    foreach f (acemblyproteins.*.fasta)
      perl -wpe 's/^\>G_t[\da-zA-Z]+_/\>/' $f > chr$f:r:e.fa
    end

    #- Load into database:
    cd ..
    ldHgGene hg15 acembly acembly.ncbi_31.genes.gff/chr*.gff
    hgPepPred hg15 generic acemblyPep \
      acembly.ncbi_31.genes.proteins.fasta/chr*.fa

LOAD GENOMIC DUPES (todo)
o - Load genomic dupes
    ssh hgwdev
    cd ~/hg15/bed
    mkdir genomicDups
    cd genomicDups
    wget http://codon/jab/web/takeoff/hg1533_dups_for_kent.zip
    unzip *.zip
    awk -f filter.awk oo33_dups_for_kent > genomicDups.bed
    mysql -u hgcat -pbigSECRET hg15 < ~/src/hg/lib/genomicDups.sql
    hgLoadBed hg15 -oldTable genomicDups genomicDupes.bed

LOAD NCI60 (TODO)
o - # ssh hgwdev
    cd /projects/cc/hg/mapplots/data/NCI60/dross_arrays_nci60/
    mkdir hg15
    cd hg15
    findStanAlignments hg15 ../BC2.txt.ns ../../image/cumulative_plates.011204.list.human hg15.image.psl >& hg15.image.log 
    cp ../experimentOrder.txt ./
    sed -e 's/ / \.\.\//g' < experimentOrder.txt > epo.txt
    stanToBedAndExpRecs  hg15.image.good.psl hg15.nci60.exp hg15.nci60.bed `cat epo.txt`
    hg15S -A < ../../scripts/nci60.sql
    echo "load data local infile 'hg15.nci60.bed' into table nci60" | hg15S -A
    mkdir /cluster/store5/gs.16/build33/bed/nci60
    mv hg15.nci60.bed /cluster/store5/gs.16/build33/bed/nci60
    rm *.psl 

LOAD AFFYRATIO [GNF] (TODO)
o - # ssh hgwdev
    cd /cluster/store1/sugnet/
    mkdir gs.16
    mkdir gs.16/build33
    mkdi20r gs.16/build33/affyGnf
    cd gs.16/build33/affyGnf
    cp /projects/compbiodata/microarray/affyGnf/sequences/HG-U95Av2_target ./
    ls -1 /cluster/store5/gs.16/build33/trfFa.1204/ > allctg.lst
    echo "/cluster/store1/sugnet/gs.16/build33/affyGnf/HG-U95Av2_target" > affy.lst
    echo '#LOOP\n/cluster/bin/i386/blat -mask=lower -minIdentity=95 -ooc=/cluster/store5/gs.16/build33/jkStuff/post.refCheck.old/11.ooc /cluster/store5/gs.16/build33/trfFa.1204/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > template.sub
    gensub2 allctg.lst affy.lst template.sub para.spec
    # ssh kkr1u00
    para create para.spec
    para try
    para check
    para push
    # exit kkr1u00
    pslSort dirs hg15.affy.psl tmp psl >& pslSort.log
    liftUp hg15.affy.lifted.psl /cluster/store5/gs.16/build33/jkStuff/liftAll.lft warn hg15.affy.psl
    pslAffySelect seqIdent=.95 basePct=.95 in=hg15.affy.lifted.psl out=hg15.affy.pAffySelect.95.95.psl
    affyPslAndAtlasToBed hg15.affy.pAffySelect.95.95.psl  /projects/compbiodata/microarray/affyGnf/human_atlas_U95_gnf.noquotes.txt affyRatio.bed affyRatio.exr >& affyPslAndAtlasToBed.log 
    hg15S -A </projects/compbiodata/microarray/affyGnf/browserFiles/affyRatio.sql 
    echo "load data local infile 'affyRatio.bed' into table affyRatio" | hg15S -A
    mkdir /cluster/store5/gs.16/build33/bed/affyGnf
    rm -rf psl tmp err *.psl *.bed HG-U95Av2_target 

# LOAD SAGE DATA (TODO)
    ssh hgwdev
    cd ~/kent/src/hg/sage
    make
    # XXX = uniGene build for which SAGE was built -- not necessarily current!
    # Figure out the build number by peeking at this file:
    lynx ftp://ftp.ncbi.nih.gov/pub/sage/map/info.txt
    set version = XXX
    mkdir /projects/cc/hg/sugnet/sage/sage.$version
    cd /projects/cc/hg/sugnet/sage/sage.$version
    ncftp ftp://ftp.ncbi.nih.gov/pub/sage
      mget -R map/readme.txt map/info.txt extr info map/Hs
      quit
    mkdir map
    mv Hs map
    cd map/Hs/NlaIII
    unzip -j SAGEmap_tag_ug-rel.zip
    cd ../../../extr/
    ../../scripts/summarizeCounts.pl expCounts.tab ./SAGE_*
    ../../scripts/countGenesPerTag.pl expCounts.tab allTags.count.tab
    ../../scripts/createArraysForTags.pl allTags.count.tab tagExpArrays.tab \
      ./SAGE_*
    ../../scripts/countsPerExp.pl expCounts.tab expList.tab
    cd ../map/Hs/NlaIII/ 
    perl -e 'while (<>) { \
               chomp($_); \
               @p = split(/\t/, $_); \
               print "$p[2]\t$p[3]\t$p[0]\n"\
             }' \
      < SAGEmap_tag_ug-rel | sort | sed -e 's/ /_/g' \
      > SAGEmap_ug_tag-rel_Hs
    cd -
    createSageSummary ../map/Hs/NlaIII/SAGEmap_ug_tag-rel_Hs \
      tagExpArrays.tab sageSummary.sage
    # Create the uniGene alignments 
    # ~/hg15/uniGene/hg15.uniGene.lifted.pslReps.psl
    # -- see "MAKE UNIGENE ALIGNMENTS" below
    cd /projects/cc/hg/sugnet/sage/sage.XXX/extr
    addAveMedScoreToPsls \
      ~/hg15/bed/uniGene.$version/hg15.uniGene.lifted.pslReps.psl \
      sageSummary.sage  uniGene.wscores.bed
    hgLoadBed hg15 uniGene_2 uniGene.wscores.bed
    hgsql hg15 < ~kent/src/hg/lib/sage.sql 
    echo "load data local infile 'sageSummary.sage' into table sage" \
        | hgsql hg15
    cd ../info
    ../../scripts/parseRecords.pl ../extr/expList.tab  > sageExp.tab
    hgsql hg15 < ~/kent/src/hg/lib/sageExp.sql 
    echo "load data local infile 'sageExp.tab' into table sageExp" | hgsql hg15
    # update ~/kent/src/hg/makeDb/trackDb/human/hg15/uniGene_2.html 
    # with current uniGene date. 

    
# MAKE UNIGENE ALIGNMENTS (TODO)
    # Download of the latest UniGene version is now automated by a 
    # cron job -- see /cluster/home/angie/crontab , 
    # /cluster/home/angie/unigeneVers/unigene.csh .  
    # If hgwdev gets rebooted, that needs to be restarted... maybe there's 
    # a more stable place to set up that cron job.  

    # substitute XXX -> the uniGene version used by SAGE, if building the 
    # uniGene/SAGE track;  or just the latest uniGene version in 
    # /projects/cc/hg/sugnet/uniGene/ , if doing uniGene alignments only.
    set version = XXX
    cd /projects/cc/hg/sugnet/uniGene/uniGene.$version
    gunzip Hs.seq.uniq.gz 
    ../countSeqsInCluster.pl Hs.data counts.tab
    ../parseUnigene.pl Hs.seq.uniq Hs.seq.uniq.simpleHeader.fa leftoverData.tab
    # Distribute UniGene sequence to /iscratch/i/ (kkstore can see /projects)
    ssh kkstore
    set version = XXX # same as above
    mkdir -p /iscratch/i/uniGene.$version
    cp -p \
  /projects/cc/hg/sugnet/uniGene/uniGene.$version/Hs.seq.uniq.simpleHeader.fa \
      /iscratch/i/uniGene.$version
    ssh kkr1u00
    ~kent/bin/iSync
    ssh kk
    set version = XXX # same as above
    mkdir -p ~/hg15/bed/uniGene.$version
    cd ~/hg15/bed/uniGene.$version
    ls -1S /cluster/store5/gs.16/build33/trfFa/* > allctg.lst
    ls -1S /iscratch/i/uniGene.$version/Hs.seq.uniq.simpleHeader.fa \
      > uniGene.lst
    echo '#LOOP\n/cluster/bin/i386/blat -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc $(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > template.sub
    gensub2 allctg.lst uniGene.lst template.sub para.spec
    para create para.spec
    mkdir psl
    para try
    para check
    para push
    # ssh eieio
    set version = XXX # same as above
    cd ~/hg15/bed/uniGene.$version
    pslSort dirs raw.psl tmp psl >& pslSort.log
    liftUp -type=.psl stdout ../../jkStuff/liftAll.lft warn raw.psl \
    | pslReps -minCover=0.2 -sizeMatters -minAli=0.965 -nearTop=0.002 \
      stdin hg15.uniGene.lifted.pslReps.psl /dev/null
    # use hg15.uniGene.lifted.pslReps.psl for building SAGE track (above).


# LOADING MOUSE MM3 BLASTZ ALIGNMENTS FROM PENN STATE: (DONE 041303)

    # Translate Penn State .lav files into sorted axt:
    ssh eieio
    set base="/cluster/store5/gs.16/build33/bed/blastz.mm3.2003-04-12-03-MS"
    set seq1_dir="/cluster/store5/gs.16/build33/nib/"
    set seq2_dir="/cluster/store2/mm.2003.02/mm3/mixedNib/"
    set tbl="blastzMm3"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtSort stdin $out
      popd
    end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo $c
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
    ssh hgwdev
    set base="/cluster/store5/gs.16/build33/bed/blastz.mm3.2003-04-12-03-MS"
    set tbl="blastzMm3"
    cd $base/pslChrom
    hgLoadPsl hg15 chr*_${tbl}.psl

# MAKING THE BLASTZBESTMOUSE TRACK FROM PENN STATE MM3 AXT FILES (DONE - 041303)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh eieio
    tcsh
    set base="/cluster/store5/gs.16/build33/bed/blastz.mm3.2003-04-12-03-MS"
    set tbl="blastzBestMm3"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store5/gs.16/build33/bed/blastz.mm3.2003-04-12-03-MS"
     set tbl="blastzBestMm3"
     cd $base/pslBest
     hgLoadPsl hg15 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
# Not done for build 32:
     mkdir -p /gbdb/hg15/axtBestMm3
     cd /gbdb/hg15/axtBestMm3
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/hg15/axtBestMm3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('mm3','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql hg15 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql hg15 < axtInfoInserts.sql

# MAKING THE AXTTIGHT FROM AXTBEST (DONE 041203)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd ~/hg15/bed/blastz.mm3.2003-04-12-03-MS/axtBest
    mkdir -p ../axtTight
    tcsh
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMm3.psl
    end

    # Load tables into database
    ssh hgwdev
    cd ~/hg15/bed/blastz.mm3.2003-04-12-03-MS/pslTight
    hgLoadPsl hg15 chr*_blastzTightMm3.psl

# BEGINNING OF RAT BLASTZ

# LOADING RAT RN2 BLASTZ ALIGNMENTS FROM PENN STATE: (TO DO)

    # Translate Penn State .lav files into sorted axt:
    ssh eieio
    set base="/cluster/store5/gs.16/build33/bed/blastz.rn2.2003-03-18-ASH"
    set seq1_dir="/cluster/store5/gs.16/build33/mixedNib/"
    set seq2_dir="/cluster/store4/rn2/mixedNib/"
    set tbl="blastzRn2"
    cd $base
    mkdir -p axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin $seq1_dir $seq2_dir stdout \
        | axtSort stdin $out
      popd
    end

# STOPPED HERE -- big data, low demand.
    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    # Load tables
    ssh hgwdev
    set base="/cluster/store5/gs.16/build33/bed/blastz.rn2.2003-03-18-ASH"
    set tbl="blastzRn2"
    cd $base/pslChrom
    hgLoadPsl hg15 chr*_${tbl}.psl

# MAKING THE BLASTZBESTRAT TRACK FROM PENN STATE RN2 AXT FILES (TO DO)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh eieio
    set base="/cluster/store5/gs.16/build33/bed/blastz.rn2.2003-03-18-ASH"
    set tbl="blastzBestRn2"
    cd $base
    mkdir -p axtBest pslBest
    foreach chrdir (lav/chr*)
      set chr=$chrdir:t
      echo axtBesting $chr
      axtBest axtChrom/$chr.axt $chr axtBest/$chr.axt -minScore=300
      echo translating axtBest to psl for $chr
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store5/gs.16/build33/bed/blastz.rn2.2003-03-18-ASH"
     set tbl="blastzBestRn2"
     cd $base/pslBest
     hgLoadPsl hg15 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
# Not done for build 32:
     mkdir -p /gbdb/hg15/axtBestRn2
     cd /gbdb/hg15/axtBestRn2
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/hg15/axtBestRn2/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('rn2','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql hg15 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql hg15 < axtInfoInserts.sql

# MAKING THE AXTTIGHT FROM AXTBEST (TO DO)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd ~/hg15/bed/blastz.rn2.2003-03-18-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightRn2.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/hg15/bed/blastz.rn2.2003-03-18-ASH/pslTight
    hgLoadPsl hg15 chr*_blastzTightRn2.psl

# XXX END OF RAT BLASTZ

# BEGINNING OF HUMAN BLASTZ

# LOADING HUMAN HG15 (SELF) BLASTZ ALIGNMENTS: (TO DO)

    # Translate Penn State .lav files into sorted axt, with alignments 
    # to self/diagonal dropped:
    ssh eieio
    set base="/cluster/store5/gs.16/build33/bed/blastz.hg15.2003-03-18-ASH"
    set seq1_dir="/cluster/store5/gs.16/build33/mixedNib/"
    set seq2_dir="/cluster/store5/gs.16/build33/mixedNib/"
    set tbl="blastzHuman"
    cd $base
    mkdir -p axtChrom
    # sometimes alignments are so huge that they cause axtSort to run out 
    # of memory.  Run them in two passes like this:
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=$base/axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      foreach d (*.lav)
        set smallout=$d.axt
        lavToAxt $d $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $smallout
      end
      cat `ls -1 *.lav.axt | sort -g` \
        > $out
      popd
    end

# STOPPED HERE -- big data, low demand.
    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo translating $c.axt to psl
      axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load tables
    ssh hgwdev
    set base="/cluster/store5/gs.16/build33/bed/blastz.hg15.2003-03-18-ASH"
    set tbl="blastzHuman"
    cd $base/pslChrom
    hgLoadPsl hg15 chr*_${tbl}.psl

# MAKING THE BLASTZBESTHUMAN TRACK FROM UNFILTERED AXT FILES (TO DO)

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh eieio
    set base="/cluster/store5/gs.16/build33/bed/blastz.hg15.2003-03-18-ASH"
    set tbl="blastzBestHuman"
    cd $base
    mkdir -p axtBest pslBest
    # run axtBest in 2 passes to reduce size of the input to final axtBest:
    foreach chrdir (lav/*)
      set chr=$chrdir:t
      echo two-pass axtBesting $chr
      foreach a ($chrdir/*.axt)
        axtBest $a $chr $a:r.axtBest
      end
      cat `ls -1 $chrdir/*.axtBest | sort -g` \
        > $chrdir/$chr.axtBestPieces
      axtBest $chrdir/$chr.axtBestPieces $chr axtBest/$chr.axt
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/${chr}_${tbl}.psl
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/store5/gs.16/build33/bed/blastz.hg15.2003-03-18-ASH"
     set tbl="blastzBestHuman"
     cd $base/pslBest
     hgLoadPsl hg15 chr*_${tbl}.psl

    # Make /gbdb links and add them to the axtInfo table:
# Not done for build 32:
     mkdir -p /gbdb/hg15/axtBestHg15
     cd /gbdb/hg15/axtBestHg15
     foreach f ($base/axtBest/chr*.axt)
       ln -s $f .
     end
     cd $base/axtBest
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/hg15/axtBestHg15/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo VALUES ('hg15','Blastz Best Human Self','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql hg15 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql hg15 < axtInfoInserts.sql

# MAKING THE AXTTIGHT FROM AXTBEST (TO DO)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd ~/hg15/bed/blastz.hg15.2003-03-18-ASH/axtBest
    mkdir -p ../axtTight
    foreach i (*.axt)
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end
    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightHuman.psl
    end
    # Load tables into database
    ssh hgwdev
    cd ~/hg15/bed/blastz.hg15.2003-03-18-ASH/pslTight
    hgLoadPsl hg15 chr*_blastzTightHuman.psl


# XXX END OF HUMAN BLASTZ


# LIFTING REPEATMASKER .ALIGN FILES (TODO)

foreach d (?{,?}/NT_??????)
  set c=$d:t
  cd $d
  echo $c to $c.fa.align
  /cluster/bin/scripts/liftRMAlign.pl $c.lft > $c.fa.align
  cd ../..
end

foreach chr (?{,?})
  cd $chr
  echo making symbolic links for chr$chr NT .fa.align files
  foreach ctg (NT_??????)
    ln -s $ctg/$ctg.fa.align
  end
  cd ..
  if (-e $chr/lift/ordered.lft) then
    echo making $chr/chr$chr.fa.align
    /cluster/bin/scripts/liftRMAlign.pl $chr/lift/ordered.lft \
      > $chr/chr$chr.fa.align
  endif
  if (-e $chr/lift/random.lft) then
    echo making $chr/chr${chr}_random.fa.align
    /cluster/bin/scripts/liftRMAlign.pl $chr/lift/random.lft \
      > $chr/chr${chr}_random.fa.align
  endif
  echo removing symbolic links for chr$chr NT .fa.align files
  rm $chr/NT_??????.fa.align
end


# TWINSCAN GENE PREDICTIONS (TODO)
    mkdir -p ~/hg15/bed/twinscanchr_gtf
    cd ~/hg15/bed/twinscan
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y)
      rm -f chr$c.{gtf,ptx}
      wget http://genome.cs.wustl.edu/~bio/human/NCBI31/12-30-02/chr_gtf/chr$c.gtf
      wget http://genome.cs.wustl.edu/~bio/human/NCBI31/12-30-02/chr_ptx/chr$c.ptx
      # clean up chrom name and put chrom in transcript_id:
      perl -wpe 's/^chr(\w+)\.\d+\.\d+(.*)transcript_id "(\d+\.\d+).a"/chr$1$2transcript_id "$1.$3.a"/' \
        < chr$c.gtf > chr$c-fixed.gtf
      # pare down protein FASTA header to id and add missing .a:
      perl -wpe 's/^\>.*\s+source_id\s*\=\s*(\S+)\s+chr=(\w+).*$/\>$2.$1.a/;' \
        < chr$c.ptx > chr$c-fixed.fa
    end
    ldHgGene hg15 twinscan chr*-fixed.gtf -exon=CDS
    hgPepPred hg15 generic twinscanPep chr*-fixed.fa


# LOAD CHIMP DATA (TODO)
    # Download the chimp sequence and distribute to /iscratch/i
    ssh hgwdev
    mkdir /cluster/store1/chimpSeq
    cd /cluster/store1/chimpSeq
    wget http://www.cs.uni-duesseldorf.de/~ebersber/annotation_track_chimp/downloads/mpi-aligned_seqparts_jun02.fa.gz
    gunzip *.gz
    ssh kkr1u00
    mkdir /iscratch/i/chimp
    cp -p /cluster/store1/chimpSeq/*.fa /iscratch/i/chimp/
    # Make sure it unpacked OK
    ~kent/bin/iSync
    ssh kk
    mkdir ~/hg15/bed/blatChimp
    cd ~/hg15/bed/blatChimp
    cp ~/hg13/bed/blatChimp/gsub .
    ls -1S /iscratch/i/chimp/*.fa > chimp.lst
    ls -1S /scratch/hg/gs.16/build33/trfFa.1204/*.fa.trf > human.lst
    mkdir psl
    gensub2 human.lst chimp.lst gsub spec
    para create spec
    para try
    para push
    para check

    # Sort alignments as so
    ssh eieio
    cd ~/hg15/bed/blatChimp
    pslCat -dir psl \
    | liftUp -type=.psl stdout ~/hg15/jkStuff/liftAll.lft warn stdin \
    | pslSortAcc nohead chrom temp stdin
    pslCat -dir chrom > blatChimp.psl

    ssh hgwdev
    cd ~/hg15/bed/blatChimp
    hgLoadPsl hg15 blatChimp.psl         


# SGP GENE PREDICTIONS (TODO)
    mkdir -p ~/hg15/bed/sgp/download
    cd ~/hg15/bed/sgp/download
    foreach f (~/hg15/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_20021114/SGP/$chr.gtf
      wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_20021114/SGP/$chr.prot
    end
    wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_20021114/SGP/chrUn.gtf -O chrUn_random.gtf
    wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_20021114/SGP/chrUn.prot -O chrUn_random.prot
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene hg15 sgpGene download/*.gtf -exon=CDS
    hgPepPred hg15 generic sgpPep download/*-fixed.prot

# ALIGNED ANCIENT REPEATS FROM MOUSE BLASTZ (TODO)
    ssh eieio
    mkdir -p ~/hg15/bed/aarMm2
    cd ~/hg15/bed/aarMm2
    set mmdir=../blastz.mm2.2002-12-5-ASH
    foreach aar ($mmdir/aar/*.aar.gz)
      set c = $aar:t:r:r
      echo translating chr$c aar to axt
      zcat $aar \
      | $HOME/kent/src/hg/makeDb/hgAar/aarToAxt \
      | axtToPsl stdin $mmdir/S1.len $mmdir/S2.len stdout \
      > chr${c}_aarMm2.psl
    end   
    ssh hgwdev
    cd ~/hg15/bed/aarMm2
    hgLoadPsl hg15 *.psl

# ALIGNMENT COUNTS FOR WIGGLE TRACK
    # this needs to be updated to reflected the full process.
 
    - Generate BED table of AARs used to select regions.
        cat ../bed/aarMm2/*.psl | awk 'BEGIN{OFS="\t"} {print $14,$16,$17,"aar"}' >aarMm2.bed
    
    - Generate background counts with windows that have a 6kb counts,
      with a maximum windows size of 512kb and sliding the windows by
        foreach axt (../../blastz.mm2.2002-08-01/axtBest/chr*.axt)
           set chr=$axt:t:r
           set tab=$chr.6kb-aar.cnts  (??? need better name ???)
           hgCountAlign -selectBed=aarMm2.bed -winSize=512000 -winSlide=1000 -fixedNumCounts=6000 -countCoords $axt $tab
        end

    - Generate counts for AARs with 50b windows, slide by 5b
        foreach axt (../../blastz.mm2.2002-08-01/axtBest/chr*.axt)
           set chr=$axt:t:r
           set tab=$chr.50b-aar.cnts  (??? need better name ???)
           hgCountAlign -selectBed=aarMm2.bed -winSize=50 -winSlide=5 $axt $tab
        end

    - Generate counts for all with 50b windows, slide by 5b
        foreach axt (../../blastz.mm2.2002-08-01/axtBest/chr*.axt)
           set chr=$axt:t:r
           set tab=$chr.50b.cnts  (??? need better name ???)
           hgCountAlign -winSize=50 -winSlide=5 $axt $tab
        end


REFFULL (TODO)

o ssh to eieio
 mkdir -p /cluster/store5/gs.16/build33/bed/refFull
 cd /cluster/store5/gs.16/build33/bed/refFull

 Download the sequence: wget ftp://blue3.ims.u-tokyo.ac.jp/pub/db/hgc/dbtss/ref-full.fa.gz

 gunzip it and split the ref-rull.fa file into about 200 pieces
 gunzip ref-full.fa.gz
 faSplit sequence ref-full.fa 50 splitRefFull
 ssh kkstore
 cd /cluster/store5/gs.16/build33/bed/refFull
 mkdir /scratch/hg/refFull
 splitRefFull* /scratch/hg/refFull/
 ls -1S /scratch/hg/gs.16/build33/contig.0729/*.fa > genome.lst
 ls -1S /scratch/hg/refFull/split*.fa > refFull.lst

o - Request the admins to do a binrsync to the cluster of /scratch/hg/refFull

o - Use BLAT to generate refFull alignments as so:
      Make sure that /scratch/hg/gs.16/build33/contig/ is loaded
      with NT_*.fa and pushed to the cluster nodes.

          ssh kk
          cd /cluster/store5/gs.16/build33/bed/refFull
          mkdir -p psl
#          run mkdirs.sh script to create sudirs in the psl directory
#               in order to modularize the blat job.
          gensub2 genome.lst refFull.lst gsub spec
          para create spec
          
    Now run a para try/push and para check in each one.

o - Process refFull alignments into near best in genome.
      cd ~/hg15/bed
      cd refFull
      pslSort dirs raw.psl /tmp psl/*
      pslReps -minCover=0.2 -sizeMatters -minAli=0.965 -nearTop=0.001 raw.psl contig.psl /dev/null
      liftUp -nohead all_refFull.psl ../../jkStuff/liftAll.lft warn contig.psl
      pslSortAcc nohead chrom /tmp all_refFull.psl

o - Load refFull alignments into database
      ssh hgwdev
      cd /cluster/store5/gs.16/build33/bed/refFull
      pslCat -dir chrom > refFullAli.psl
      hgLoadPsl hg15 -tNameIx refFullAli.psl


MAKING PROMOTER FILES
    cd /usr/local/apache/htdocs/goldenPath/14nov2002/bigZips
    featureBits hg15 -fa=upstream1000.fa refGene:upstream:1000
    zip upstream1000.zip upstream1000.fa
    featureBits hg15 -fa=upstream2000.fa refGene:upstream:2000
    zip upstream2000.zip upstream2000.fa
    featureBits hg15 -fa=upstream5000.fa refGene:upstream:5000
    zip upstream5000.zip upstream5000.fa
    rm upstream*.fa
    
#MAKING MOUSE AND RAT SYNTENY (IN PROGRESS)

cd ~/hg15
mkdir syntenyMouse
# Copy all the needed scripts from ~/hg14

./syntenicBest.pl -db=hg15 -table=blastzBestMm3
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg15 -table=blastzBestMm3
./synteny2bed.pl
hgLoadBed hg15 syntenyMouse ucsc100k.bed
DONE TO HERE - MATT

syntenicBest.pl -db=hg15 -table=blastzBestRn2
smooth.pl
joinsmallgaps.pl
fillgap.pl -db=hg15 -table=blastzBestRn2
synteny2bed.pl
hgLoadBed hg15 syntenyRat ucsc100k.bed

