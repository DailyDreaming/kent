#!/bin/csh -f
exit

# NHGRI DNASE I HYPERSENSITIVE SITES (2004-10-15 kate)
    # Data from Greg Crawford <crawford@mail.nih.gov> at the Collins Lab

    cd /cluster/data/encode/NHGRI

    set data = lab/DNaseI_HS_NHGRI_ENCODE2.txt
    sed '/^track/d' $data > DNAseHS.bed
    hgLoadBed hg16 encode_NHGRI_DNAseHS DNAseHS.bed


# STANFORD PROMOTERS FROM RICK MYERS LAB (2004-10-17 kate)
# Updated with new data 2005-05-26 angie, see below

    /cluster/data/encode/StanfordPromoters
    mkdir StanfordPromoters_20040825
    cd StanfordPromoters_20040825

    csh makePromoterFiles.csh > promoterExps.tab
    wc -l promoterExps.exp
        # 14

    # currently hgTracks only looks in hgFixed for the experiment table
    #  (add a trackDb option)
    hgExperiment hgFixed encode_Stanford_Promoters \
                    promoterExps.tab promoterPos.bed promoterData.tab
    hgLoadBed hg16 encode_Stanford_Promoters encode_Stanford_Promoters.tab

    # data update (2005-04-12 kate IN PROGRESS) 
    /cluster/data/encode/StanfordPromoters
    mkdir -p 2005-04-12; cd 2005-04-12
    mkdir lab; cd lab
    # save from email
    ls
    # ENCODE_DATA_SUBMIT_2005.04.12.txt  UCSCREADME.txt
    # NOTE: scores are outside of 1-1000.  I've asked for
    # a redo from Sara.

    # UPDATED 2005-05-26 angie
    mkdir /cluster/data/encode/StanfordPromoters/2005-05-25
    cd /cluster/data/encode/StanfordPromoters
    rm latest previous
    ln -s StanfordPromoters_20040825 previous
    ln -s 2005-05-25 latest
    mkdir latest/lab
    cd latest/lab
    # Saved email attachments from Sara Hartman.  
    # Used ooffice to translate Description.doc to Description.html and 
    # NegativeControlDataStanfordPromoters.xls to tab-sep'd ....txt.
    # Datafile column descriptions from Sara's email 5/25/2005, augmented 
    # with the bed9+ fields that we will shuffle them into:
    # 1->4) Accession number of the mRNA used to predict the promoter
    # 2->10) Gene model ID. If a gene has more than one predicted promoter 
    #        they would have the same gene model ID.
    # 3->1) chromosome
    # 4->6) strand (0 for negative, 1 for positive)
    # 5->2) Promoter Start coordinate
    # 6->3) Promoter End Coordinate
    # 7->X) Promoter length
    # 8->11) Promoter Name [really a description -- some of these are quoted]
    # 9->12) Luciferase signal A
    # 10->13) Renilla Signal A
    # 11->14) Luciferase Signal B
    # 12->15) Renilla Signal B
    # 13->16) Average Luciferase/Renilla Ratio
    # 14->17) Normalized Luciferase/Renilla Ratio
    # 15->18) Normalized and log2 transformed Luciferase Renilla Ratio
    # 16->5) Score (from 0-1000)
    # -- The Average file is like that but missing columns 9 to 14.
    # Some cell-line data files have some rows with "Bad Txfn" in the last 
    # 4 columns; Sara said we should ignore those rows.
    foreach f (StanfordPromoters_*.txt)
      set cellType = `echo $f | sed -e 's/StanfordPromoters_//; s/\.txt//;'`
      echo $cellType
      if ($cellType == "Average") then
        tail +2 $f \
        | perl -wpe 'chomp; @w = split("\t"); $w[7] =~ s/^\"(.*)\"$/$1/; \
                     $w[3] =~ tr/01/-+/; \
                     $_ = join("\t", \
  $w[2], $w[4], $w[5], $w[0], $w[9], $w[3], $w[4], $w[5], 0, $w[1], $w[7], \
  $w[8]) . "\n";' \
	| makeColoredBed > encodeStanfordPromoters$cellType.bed
      else
        tail +2 $f \
	| grep -v "Bad Txfn" \
        | perl -wpe 'chomp; @w = split("\t"); $w[7] =~ s/^\"(.*)\"$/$1/; \
                     $w[3] =~ tr/01/-+/; \
                     $_ = join("\t", \
  $w[2], $w[4], $w[5], $w[0], $w[15], $w[3], $w[4], $w[5], 0, $w[1], $w[7], \
  $w[8], $w[9], $w[10], $w[11], $w[12], $w[13], $w[14]) . "\n";' \
	| makeColoredBed > encodeStanfordPromoters$cellType.bed
      endif
    end
    foreach f (encode*.bed)
      set track = $f:r
      if ($track == "encodeStanfordPromotersAverage") then
        hgLoadBed -tab -noBin -sqlTable=$HOME/kent/src/hg/lib/$track.sql \
	  hg16 $track $f
      else
        sed -e "s/encodeStanfordPromoters/$track/" \
          $HOME/kent/src/hg/lib/encodeStanfordPromoters.sql > /tmp/esp.sql
        hgLoadBed -tab -noBin -sqlTable=/tmp/esp.sql hg16 $track $f
      endif
    end
    featureBits hg16 -enrichment encode_Stanford_Promoters \
      encodeStanfordPromotersSnu182
#encode_Stanford_Promoters 0.011%, encodeStanfordPromotersSnu182 0.011%, both 0.011%, cover 99.84%, enrich 9194.85x
    featureBits hg16 encode_Stanford_Promoters \!encodeStanfordPromotersSnu182 \
      -bed=stdout
#chr21   32827801        32828259        chr21.1
#chr21   33617743        33617751        chr21.2
#chr11   1749652 1749673 chr11.1
#chr7    126437698       126437700       chr7.1
#chr5    131669622       131669641       chr5.1
#508 bases of 2865248791 (0.000%) in intersection
    # -- of those, only the first is not in the new set at all.  
    featureBits hg16 \!encode_Stanford_Promoters encodeStanfordPromotersSnu182 \
      -bed=stdout
#chr21   33617194        33617203        chr21.1
#chr18   32827801        32828259        chr18.1
#chr7    126438195       126438196       chr7.1
#chr2    235023631       235024097       chr2.1
#934 bases of 2865248791 (0.000%) in intersection
    # -- only the second and the last are not in the old set at all.
    # Put the negative control data spreadsheet out for download.
    mkdir -p \
  /usr/local/apache/htdocs/goldenPath/hg16/encode/datafiles/stanfordPromoters
    nice gzip NegativeControlDataStanfordPromoters.txt
    cp -p NegativeControlDataStanfordPromoters.{xls,txt.gz} \
  /usr/local/apache/htdocs/goldenPath/hg16/encode/datafiles/stanfordPromoters/
    # Added a README.txt.


# UVA DNA REPLICATION TEMPORAL PROFILING (2004-10-22 kate)
# Updated with new data 2005-05-25 angie, see below
    # Dutta lab (Univ. Virginia) replication data
    #       Submitted as custom track, coords on hg15

    cd /cluster/data/encode/UVa
    mkdir 2004-10-22
    ln -s 2004-10-22  latest
    cd latest
    mkdir -p lab
    cd lab
    # download data
    # data (was MS-WORD)
    dos2unix lab/Dutta_Rep_profile.txt
    # documentation (ditto)
    dos2unix lab/UCSC-_data_release.txt

    # split file of customtracks into multiple files
    ./splitCustomTracks.pl lab/Dutta_Rep_profile.txt repl
    wc -l *.?-?{,?}
        # 163 repl.0-2
        # 301 repl.2-4
        # 296 repl.4-6
        # 523 repl.6-8
        # 421 repl.8-10
        # 1704 total

    wc -l lab/Dutta_Rep_profile.txt
      # 1704 lab/Dutta_Rep_profile.txt

    cat > checkEncodeTable.csh << 'EOF'
    hgsql hg16 -N -s -e "SELECT er.name, count(*) FROM encodeRegions er, $1 hs WHERE er.chrom=hs.chrom AND hs.chromStart between er.chromStart AND er.chromEnd group by er.name"
'EOF'
    # << for emacs

    # load w/o binning to maintain ordering by chromStart
    foreach f (repl.?-?{,?})
        liftOver $f /cluster/data/hg15/bed/liftOver/hg15ToHg16.over.chain \
                    $f.hg16.bed $f.unmapped
        set time = `echo $f:e | sed 's/-/_/'`
        hgLoadBed -noBin hg16 encode_UVA_DNARep_$time $f.hg16.bed
        csh checkEncodeTable.csh encode_UVA_DNARep_$time > $time.ct
    end
    wc -l *.hg16.bed
        # 160 repl.0-2.hg16.bed
        # 298 repl.2-4.hg16.bed
        # 294 repl.4-6.hg16.bed
        # 520 repl.6-8.hg16.bed
        # 416 repl.8-10.hg16.bed
       # 1688 total
    wc -l *.unmapped
          # 0 repl.0-2.unmapped
          # 0 repl.2-4.unmapped
          # 0 repl.4-6.unmapped
          # 0 repl.6-8.unmapped
          # 0 repl.8-10.unmapped
          # 0 total
    cut -f 1 *.ct | sort | uniq > regions
    wc -l regions
     # 43 regions (1 missing)
    hgsql  hg16 -N -s -e "SELECT name from encodeRegions" | sort | diff - regions 
    # UPDATED 2005-05-25 WITH NEW DATA (angie)
    cd /cluster/data/encode/UVa
    mkdir 2005-05-25
    rm latest
    ln -s 2005-05-25 latest
    ln -s 2004-10-22 previous
    cd latest
    mkdir lab
    cd lab
    # saved email attachments here.
    # symlink to nicer names:
    ln -s encode0to2hrAuD4030.bed.txt repl.0
    ln -s encode2to4hrAuD4030.bed.txt repl.2
    ln -s encode4to6hrAuD4030.bed.txt repl.4
    ln -s encode6to8hrAuD4030.bed.txt repl.6
    ln -s encode8to10hrAuD4030.bed.txt repl.8
    wc -l repl.*
#    249 repl.0
#    618 repl.2
#    305 repl.4
#    569 repl.6
#    429 repl.8
#   2170 total
    # Any 0-length items?
    foreach f (encode*)
      echo $f
      awk '$3 == $2 {print;}' $f
    end
    # Any >1Mbp items?  (Previously there were some of these items spanning 
    # multiple encode regions...
    cd lab
    foreach f (encode*)
      echo $f
      awk '$3 - $2 > 1000000 {print;}' $f
    end
    cd ..
    foreach F (lab/repl.?)
      set f = $F:t
      echo $f
      tail +2 $F \
      | liftOver stdin /cluster/data/hg15/bed/liftOver/hg15ToHg16.over.chain \
          $f.hg16.bed $f.unmapped
      set time = $f:e
      hgLoadBed -noBin hg16 encodeUvaDnaRep$time $f.hg16.bed
      csh /cluster/data/encode/UVa/2004-10-22/checkEncodeTable.csh \
        encodeUvaDnaRep$time > $time.ct
    end
    wc -l *.bed
#    248 repl.0.hg16.bed
#    616 repl.2.hg16.bed
#    304 repl.4.hg16.bed
#    568 repl.6.hg16.bed
#    428 repl.8.hg16.bed
#   2164 total
    wc -l *.unmapped
#      0 repl.0.unmapped
#      2 repl.2.unmapped
#      0 repl.4.unmapped
#      0 repl.6.unmapped
#      0 repl.8.unmapped
#      2 total
    cat repl.2.unmapped 
##Split in new
#chr21   39652869        39703581
    # The main chr21 over.chain is interrupted by a little inversion chain 
    # 39661243 39662854... so try liftOvering the start and end:
    cat > hg15.chr21troublespot.bed <<EOF
chr21 39652869 39652870
chr21 39703580 39703581
EOF
    liftOver hg15.chr21troublespot.bed \
       /cluster/data/hg15/bed/liftOver/hg15ToHg16.over.chain \
       hg16.chr21troublespot.{bed,unmapped}
    cat hg16.chr21troublespot.*
#chr21   39652870        39652871
#chr21   39703140        39703141
    # OK, manually add an entry for chr21 39652870 39703141 to repl.2.hg16.bed:
    $EDITOR repl.2.hg16.bed
    wc -l repl.2.hg16.bed
#    617 repl.2.hg16.bed
    # Reload:
    hgLoadBed -noBin hg16 encodeUvaDnaRep2 repl.2.hg16.bed

    # Look for ENCODE regions completely missing from all 5 tables:
    cut -f 1 *.ct | sort | uniq > regions
    wc -l regions
    # 43 regions (1 missing)
    hgsql  hg16 -N -s -e "SELECT name from encodeRegions" | sort \
    | diff - regions 
    # < ENm011
    foreach t (0 2 4 6 8)
      set t2 = `expr $t + 2`
      featureBits hg16 -enrichment encode_UVA_DNARep_${t}_$t2 \
        encodeUvaDnaRep$t
    end
#encode_UVA_DNARep_0_2 0.154%, encodeUvaDnaRep0 0.154%, both 0.154%, cover 99.90%, enrich 648.98x
#encode_UVA_DNARep_2_4 0.621%, encodeUvaDnaRep2 0.621%, both 0.620%, cover 99.93%, enrich 161.04x
#encode_UVA_DNARep_4_6 0.181%, encodeUvaDnaRep4 0.181%, both 0.181%, cover 99.75%, enrich 551.92x
#encode_UVA_DNARep_6_8 0.418%, encodeUvaDnaRep6 0.418%, both 0.418%, cover 99.90%, enrich 239.17x
#encode_UVA_DNARep_8_10 0.178%, encodeUvaDnaRep8 0.177%, both 0.177%, cover 99.42%, enrich 562.02x


# UCSD CHIP/CHIP (2004-09-30 kate)
    # Bing Ren's Lab
    # Provided by Chunxu Qu [mailto:qchunxu@ucsd.edu] on Oct. 1, 2004

    # Unpack data and rename files 

    ssh kksilo
    cd /cluster/data/encode
    mkdir -p UCSD/project1
    cd UCSD/project1
    gunzip project1.tar.gz
    foreach f (*.wig)
        mv $f $f.bed
    end

    # consists of 8 custom track wiggle BED files
    ssh hgwdev
    mkdir /gbdb/hg16/encode/UCSD_ChIP/wib
    cd /cluster/data/encode/UCSD/project1
    mkdir wig
    cd wig
    cat > makeWig.csh << 'EOF'
    foreach f (../*.bed)
        # get base name
        set b = $f:t:r:r
        # strip non-informative parts of name
        set n = `echo $b | sed -e 's/ave_//' -e 's/_p//' | tr '[a-z]' '[A-Z]'`
        echo $n
        # create wiggle data files from BED
        # NOTE: wigBedToBinary has been replaced by wigEncode
        sed -e '/^browser/d' -e '/^track/d' $f | \
            wigBedToBinary stdin $n.wig $n.wib
        ln -s `pwd`/$n.wib /gbdb/hg16/encode/UCSD_ChIP/wib
        # load into database
        hgLoadWiggle hg16 encode_UCSD_ChIP_$n $n.wig \
                    -pathPrefix=/gbdb/hg16/encode/UCSD_ChIP/wib
    end
    'EOF'
    # << for emacs

    csh makeWig.csh >&! makeWig.log &
    # Converted stdin, upper limit 16.00, lower limit 0.00, etc.

    hgsql hg16 -s -e "select count(*) from encode_UCSD_ChIP_RNAP_HELA"
        # 19571

    # create entries in trackDb, default height 16 pixels
    # Use Jim's suggestion to associate a color with a cell line
         # Pol2 Hela (black)
         # Pol2 THP1 (darkish blue)
         # Pol2 IMR90 (darkish red)
         # Pol2 HCT116 (darkish green)
         # TAF1 Hela (black)
         # TAF1 THP1 (darkish blue)
         # TAF1 IMR90 (darkish red)
         # TAF1 HCT116 (darkish green)

    # UCSD/Ludwig Institute Histone Methylation (2005-04-21 kate)
    # NOTE: this data was submitted 12/14/04, but somehow fell thru
    # the cracks (it was the week before CSHL).
    # Files received from email:  ave_AcH3_imr90.wig ave_MeH3K4_imr90.wig
# Provided by Chunxu Qu [mailto:qchunxu@ucsd.edu]

    cd /cluster/data/encode/UCSD
    cd project1
    mv ave_AcH3_imr90.wig ave_AcH3_imr90_p.wig.bed
    mv ave_MeH3K4_imr90.wig ave_MeH3K4_imr90_p.wig.bed
    mkdir -p /gbdb/hg16/encode/UcsdChip/wib
    mkdir wig.2005-04-21
    cd latest
    # edit makeWig.csh to use wigEncode and standard table naming
    cat > makeWig.csh << 'EOF'
    foreach f (../*.bed)
        # get base name
        set b = $f:t:r:r
        # convert to standard format (initial caps) "AntibodyCell"
        set n = `echo $b | perl -wpe 's/ave_(.*)_(.*)_p/\u\L$1\E\u\L$2\E/'`
        echo $n
        # create wiggle data files from BED
        sed -e '/^browser/d' -e '/^track/d' $f | \
            wigEncode stdin $n.wig $n.wib
        ln -s `pwd`/$n.wib /gbdb/hg16/encode/UcsdChip/wib
        # load into database
        hgLoadWiggle hg16 encodeUcsdChip$n $n.wig \
                    -pathPrefix=/gbdb/hg16/encode/UcsdChip/wib
    end
'EOF'
    # << for emacs
    csh makeWig.csh >&! makeWig.log &

    # cleanup TODO: remove old /gbdb files, doc files, tables 
    # on hgwdev, beta & RR

    # try as bedGraph type 
    cd /cluster/data/encode/UCSD
    cd project1
    mkdir bed.2005-04-21
    ln -s bed.2005-04-21 latest
    cd latest 
    cat > makeBed.csh << 'EOF'
    foreach f (../*.bed)
        # get base name
        set b = $f:t:r:r
        # convert to standard format (initial caps) "AntibodyCell"
        set n = `echo $b | perl -wpe 's/ave_(.*)_(.*)_p/\u\L$1\E\u\L$2\E/'`
        echo $n
        # create wiggle data files from BED
        sed -e '/^browser/d' -e '/^track/d' $f > $n.bed
        # load into database
        hgLoadBed hg16 encodeUcsdChip$n $n.bed
    end
'EOF'
    # << for emacs
    csh makeBed.csh >&! makeBed.log &
    # set up 4 composite tracks (per antibody), 4 cell lines each
    # using colors to highlight cell types:
         # Hela (black)
         # THP1 (darkish blue)
         # IMR90 (darkish red)
         # HCT116 (darkish green)

# UCSD Histone Methylation Chip/chip on IFN-g induced Hela (2005-05-26)
    cd /cluster/data/encode/UCSD
    mkdir -p 2005-05-26
    cd 2005-05-26
    # copied files from ftp dir

    # bed format; use vi to strip header lines
    cp tmH3K4_p0.wig tmH3K4_p0.bed
    cp tmH3K4_p30.wig tmH3K4_p30.bed
    
    # save originals
    mv tmH3K4_p0.wig tmH3K4_p0.wig.orig
    mv tmH3K4_p30.wig tmH3K4_p30.wig.orig

    # load
    wigEncode tmH3K4_p0.bed tmH3K4_p0.wig tmH3K4_p0.wib
    ln -s `pwd`/tmH3K4_p0.wib /gbdb/hg16/encode/UcsdChip/wib
    hgLoadWiggle hg16 encode_UCSD_ChIP_tmH3K4_p0 tmH3K4_p0.wig -pathPrefix=/gbdb/hg16/encode/UcsdChip/wib

    

# STANFORD MLAGAN MSA OF FREEZE2 (2004-11-17 kate)
#       From George Asimenos, Batzoglou lab (asimenos@stanford.edu)
    
    cd /cluster/data/encode
    cd MLAGAN/freeze2
    mkdir lab out tmp
    set tmpDir = /cluster/data/encode/MLAGAN/freeze2/tmp
    set outDir = /cluster/data/encode/MLAGAN/freeze2/out
    cd lab
    wget -r http://ai.stanford.edu/~asimenos/beta_encode_Nov_2004/
    mv ai.stanford.edu/*asimenos/beta* .
    rm -fr ai.stanford.edu
    cd beta_encode_Nov_2004/data
cat > makeMaf.csh << 'EOF'
    set tmpDir = /cluster/data/encode/MLAGAN/freeze2/tmp
    set outDir = /cluster/data/encode/MLAGAN/freeze2/out
    foreach r (EN*)
        echo $r
        set c = `echo "SELECT chrom from encodeRegions WHERE name='$r'" | \
                        hgsql -N hg16`
        set start =  \
                `echo "SELECT chromStart from encodeRegions WHERE name='$r'" | \
                        hgsql -N hg16`
        set size = \
                `echo "SELECT size from chromInfo WHERE chrom='$c'" | \
                        hgsql -N hg16`
        bunzip2 -c $r/$r.maf.bz2 | \
          /cluster/data/encode/MLAGAN/mafCoord.pl human hg16.$c $start $size |\
            sed 's/^a$/a score=0.0/' > $tmpDir/$r.db.maf
        /cluster/bin/penn/maf_project $tmpDir/$r.db.maf hg16.$c \
                        > $outDir/$r.human.maf
    end
'EOF'
    csh makeMaf.csh >&! makeMaf.log &

    mkdir /gbdb/hg16/encode_MSA2_MLAGAN
    ln -s $outDir/*.human.maf /gbdb/hg16/encode_MSA2_MLAGAN
    hgLoadMaf -WARN hg16 encode_MSA2_MLAGAN

    # create description page from lab/index.html


# AFFY TRANSCRIPTION AND CHIP/CHIP TEMPORAL PROFILING (2004-12-08 kate)
#	(RELOADED TABLES 2005-05-31 as bedGraph types - Hiram)

    # HL60 cells stimulated with Retinoic Acid
    # Transcription and PolII ChIP/Chip at 4 timepoints (8 experiments)
    # wig & bed for each experiment 
    # filenames: EC_HL60_RA_RNA_00hr_AS.hs.NCBIv34.{bed,wig}
    #            EC_HL60_RA_RNApol2_00hr_AS_b.hs.NCBIv34.{bed,wig}
    # Use these to construct 16 tracks:
    # track encodeAffyRnaHl60Hr{00,02,08,32}
    # track encodeAffyChIpRnapHl60Hr{00,02,08,32}
    # RNA/Affy HL60 0hr
    # ChIP/Affy Pol2 0hr

    mkdir -p /gbdb/hg16/encode/Affy/2004-12-03/wib
    cd /cluster/data/encode
    mkdir -p Affy/Dec03_2004
    cd Affy/Dec03_2004
    wget http://transcriptome.affymetrix.com/download/ENCODE/ucsc_formats.tar.bz2
    bunzip2 ucsc_formats.tar.bz2
        # trailing garbage after EOF ignored
    tar xvf ucsc_formats.tar
    # NOTE: the script below creates $hrs as 0,2,8,32
    # and tables were renamed to 00,02,08,32, so change script
    # next time it's loaded.
    cd ucsc_formats
cat > load.csh << 'EOF'
    foreach f (bed/*.bed)
        set base = $f:t:r
        set info = `echo $f:t | sed 's/EC_HL60_RA_\([^_][^_]*\)_\([0-9][0-9]*\)hr.*/\1.\2/'`
        set hrs = `expr $info:e + 0`
        set exp = `echo $info:r |  \
                        sed -e 's/RNApol2/ChIpRnap/' -e 's/RNA/Rna/'`
        if ($exp == "Rna") then
            set meas = "Sig"
        else
            set meas = "Pval"
        endif
        set track = encodeAffy${exp}Hl60SitesHr$hrs
        sed '1d' $f | \
            hgLoadBed -noBin hg16 $track stdin
        set ct = `hgsql -N -s -e "select count(*) from $track" hg16`
        echo "track $track"
        echo "$f:t	$ct"
        set track = encodeAffy${exp}Hl60${meas}Hr$hrs
        sed '/^track/d' wig/$base.wig | wigEncode stdin $track.wig $track.wib
        ln -s `pwd`/$track.wib /gbdb/hg16/encode/Affy/2004-12-03/wib
        # load into database
        hgLoadWiggle hg16 ${track} $track.wig \
                    -pathPrefix=/gbdb/hg16/encode/Affy/2004-12-03/wib
    end
'EOF'
    # << for emacs
    csh load.csh >&! load.log &
    grep EC_HL60 load.log | grep -v wig > loaded.txt
    # email loaded.txt to contributor
    awk '{print $1}' bed/*.bed | sort | uniq > chroms.txt
    # use in trackDb chromosomes setting
    grep encodeAffy load.log > trackDb.ra
    # use as basis of hg16 trackDb entries
    # (create 4 composite tracks)

    cd description
    # edit
    cp EC_HL60_RA_RNA_00hr_AS_hs.NCBIv34.bed.dsc encodeAffyRnaHl60Sites.html
    cp EC_HL60_RA_RNA_00hr_AS_hs.NCBIv34.wig.dsc encodeAffyRnaHl60Sig.html
    cp EC_HL60_RA_RNApol2_00hr_AS_hs.NCBIv34.bed.dsc encodeAffyChIpRnapHl60Sites.html
    cp EC_HL60_RA_RNApol2_00hr_AS_hs.NCBIv34.wig.dsc encodeAffyChIpRnapHl60Pval.html


# BOSTON UNIVERSITY / ZHIPING WENG LAB FIRST EXON DATA (WORKING 2005-01-27 kate)

    ssh kksilo
    cd /cluster/data/encode
    mkdir -p BU
    cd BU
    #mkdir -p 2005-01-06
    #ln -s 2005-01-06/latest
    #cd latest
    # copy file from email:  BED.tar.gz
    #tar xvfz BED.tar.gz

    #mkdir -p 2005-04-29
    #ln -s 2005-04-29/latest
    mkdir -p 2005-05-04
    ln -s 2005-05-04 latest
    cd latest
    # save file from email
    tar xvfz BED.BUMay4.tar.gz

    cd BED
    cp rcPCREncodeDataDescription.html ~/kent/src/hg/makeDb/trackDb/human/hg16/encodeBuFirstExon.html
    # checkin description file and edit
    cd ..

    # adjust chromStart
    cat > lowerStart.awk << 'EOF'
        {printf ("%s\t%d\t%d\t%s\t%d\t%s\t%d\t%d\t%s\t%d\t%s\t%s\t%s\n",
                $1, $2-1, $3, $4, $5, $6, $7-1, $8, $9, $10, $11, $12, $13);}
'EOF'
    # rearrange data colums to be BED 13, add RGB values to "reserved" field
    # based on score
    makeColoredBed < BED/cerebralcortex.bed | \
                        awk -f lowerStart.awk > encodeBuFirstExonCerebrum.bed
    makeColoredBed < BED/colon.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonColon.bed
    makeColoredBed < BED/heart.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonHeart.bed
    makeColoredBed < BED/kidney.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonKidney.bed
    makeColoredBed < BED/liver.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonLiver.bed
    makeColoredBed < BED/lung.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonLung.bed
    makeColoredBed < BED/skeletalmuscle.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonSkMuscle.bed
    makeColoredBed < BED/spleen.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonSpleen.bed
    makeColoredBed < BED/stomach.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonStomach.bed
    makeColoredBed < BED/testis.bed  | \
                        awk -f lowerStart.awk > encodeBuFirstExonTestis.bed

    # take a look at data distribution (previous was skewed toward 0)
    awk '{print $5}' *.bed | sort -n > scores.txt
    textHistogram scores.txt -binSize=100 -maxBinCount=11
    # 0       107.000000
    # 100     8.000000
    # 200     32.000000
    # 300     53.000000
    # 400     91.000000
    # 500     130.000000
    # 600     186.000000
    # 700     118.000000
    # 800     33.000000
    # 900     1.000000
    # 1000    1.000000
    ## cluster at 0, followed by a nice bell curve

    cat > load.csh << 'EOF'
    foreach f (Cerebrum Colon Heart Kidney Liver Lung SkMuscle Spleen Stomach Testis)
        hgLoadBed hg16 -noBin encodeBuFirstExon encodeBuFirstExon$f.bed -sqlTable=${HOME}/kent/src/hg/lib/encodeBuFirstExon.sql
        hgsql hg16 -e "DROP TABLE IF EXISTS encodeBuFirstExon$f"
        hgsql hg16 -e "ALTER TABLE encodeBuFirstExon RENAME TO encodeBuFirstExon$f"
        checkTableCoords hg16 encodeBuFirstExon$f
    end
'EOF'

    csh load.csh >&! load.log

    # generate list of chromosomes with data for trackDb entry
    foreach f (Cerebrum Colon Heart Kidney Liver Lung SkMuscle Spleen Stomach Testis)
        /cluster/data/encode/scripts//showChromList.csh hg16 encodeBuFirstExon$f
    end
        #chr11,chr13,chr15,chr16,chr19,chr2,chr5,chr7,chr9,chrX


# GENCODE Sanger Havana annotations  (IN PROGRESS 2005-03-21 kate)
    # Data update 2005-04-22 with all 44 regions
    # Data update 2005-05-20
    ssh hgwdev
    mkdir -p /cluster/data/encode/Gencode
    cd /cluster/data/encode/Gencode
    mkdir -p 2005-05-20
    cd 2005-05-20
    wget --timestamping --force-directories --directory-prefix=. \
	--dont-remove-listing --recursive --level=3 --no-parent \
	--no-host-directories --cut-dirs=5 \
        "ftp://genome.imim.es/pub/other/gencode/data/havana-encode/*"
#  This fetches the directories:
#	drwxrwxr-x  2 4096 Mar  7 16:01 CHR_coord
#	drwxrwxr-x  2 4096 Mar  7 16:02 ENCODE_coord
#	-rw-r--r--  1 2874 Feb 10 13:44 README.txt
#	drwxrwxr-x  4 4096 Mar  7 16:02 old

    # special handling for ENm006 -- submitted in hg17 coords
    # convert hg17 coord file to hg16 using liftOver 
    cd CHR_coord
    liftOver -gff ENm006_hg17_CHR_coord.gtf \
        /cluster/data/hg17/bed/liftOver/hg17ToHg16.chain \
                ENm006_CHR_coord.mapped.gtf unmapped
    # check coordinates and manually adjust as needed 
    ldHgGene -gtf -genePredExt hg16 encodeGencodeENm006 ENm006_CHR_coord.mapped.gtf
# invalid gffGroup detected on line: chrX VEGA_Known      exon    153120186      153120333        0.000000        +       .       gene_id "F8"; transcript_id "RP11-115M6.7-003"; 
# GFF/GTF group RP11-115M6.7-003 on chrX-, this line is on chrX+, all group members must be on same seq and strand
    # manually blat exon and CDS coords for this exon (exon-1)
    # they map to same place as liftOver, but on - strand.
    # edit 2 entires in the ".fixed" file to reflect this
    ldHgGene -gtf -genePredExt hg16 encodeGencodeENm006 ENm006_CHR_coord.fixed.gtf
    # Read 292 transcripts in 4564 lines in 1 files
    # 292 groups 1 seqs 13 sources 3 feature types
    # 292 gene predictions
    checkTableCoords hg16 encodeGencodeENm006
    # hg16.encodeGencodeENm006 has 10 records with blockStart[0] != start.
    #hg16.encodeGencodeENm006 has 7 records with blockEnd[n-1] != end.
    # run with -verbose=2
    ldHgGene -gtf -genePredExt hg17 encodeGencodeENm006 ENm006_hg17_CHR_coord.gtf
    # 293 gene predictions
    checkTableCoords hg17 encodeGencodeENm006

    # for now, load w/o ENm006
    # load all
    ldHgGene -gtf -genePredExt hg16 encodeGencodeGene EN????_CHR_coord.gtf
    # 777 gene predictions

    ldGencodeIntron hg16 encodeGencodeIntron EN????_CHR_coord.gtf
    # 4023 introns in 12 files

    # UPDATE 4/22/05
    cd /cluster/data/encode/Gencode
    mkdir 2005-04-22
    cd 2005-04-22
    wget --timestamping --force-directories --directory-prefix=. \
	--dont-remove-listing --recursive --level=3 --no-parent \
	--no-host-directories --cut-dirs=5 \
	"ftp://genome.imim.es/pub/other/gencode/data/havana-encode/*"
    # Downloaded: 96,693,888 bytes in 488 files
    wc -l CHR_coord_hg17/global_files/EN*CHR_coord.gtf > entries.txt
         # 45866 total
    cat `ls CHR_coord_hg17/global_files/EN*coord.gtf | grep -v ENm006` > \
        gencode.noENm006
    liftOver -gff gencode.noENm006 \
            /cluster/data/hg17/bed/liftOver/hg17ToHg16.chain \
                gencode.gtf gencode.unmapped
     wc -l gencode.gtf
        # 40857 mapped GTF entries
     grep -v "in new" *.unmapped | wc -l
        # 19 unmapped GTF entries 
     grep -v "in new" *.unmapped | awk '{print $12}' | sort | uniq | wc -l
        # 8 unmapped gene ID's
    ldHgGene -gtf -genePredExt hg16 encodeGencodeGeneNew gencode.gtf
        # Read 2602 transcripts in 40856 lines in 1 files
    checkTableCoords hg16 encodeGencodeNew
    grep -v not_tested gencode.gtf | \
        ldGencodeIntron hg16 encodeGencodeIntronNew stdin
            # 425 introns in 1 files

    # UPDATE 2005-05-20
    cd /cluster/data/encode/Gencode
    mkdir 2005-05-20
    cd 2005-05-20
    wget --timestamping --force-directories --directory-prefix=. \
	--dont-remove-listing --recursive --level=3 --no-parent \
	--no-host-directories --cut-dirs=5 \
    ftp://genome.imim.es/pub/other/gencode/data/havana-encode/version00.3_20may/
    # Downloaded: 14,970,341 bytes in 89 files
    cd version00.3_20may
    wc -l EN*CHR_coord.gtf > ../entries.txt
         # 45268 total
    cat `ls EN*_CHR_coord.gtf | grep -v ENm006` > \
        ../gencode.noENm006.gtf
    cd ..
    liftOver -gff gencode.noENm006.gtf \
            /cluster/data/hg17/bed/liftOver/hg17ToHg16.chain \
                gencode.hg16.gtf gencode.gtf.unmapped
    wc -l gencode.hg16.gtf
        # 40320 gencode.hg16.gtf
    grep -v "in new" *.unmapped | wc -l
        # 8 unmapped GTF entries
    grep -v "in new" *.unmapped | awk '{print $12}' | sort | uniq | wc -l
        # 3 unmapped gene ID's
    grep -v not_tested gencode.hg16.gtf | \
        ldGencodeIntron hg16 encodeGencodeIntron stdin
            # 425 introns in 1 files

    # converting to genePred before lifting to create gene track
    #  due to problems in liftOver -gff found by Mark D.
    # Exclude non-Vega sources as per France Denoued at IMIM 
    grep VEGA gencode.noENm006.gtf > gencode.vega.gtf
    ldHgGene -out=gencode.gp -gtf -genePredExt null null gencode.vega.gtf
        # Read 2542 transcripts in 40133 lines in 1 files
    liftOver -genePred gencode.gp \
            /cluster/data/hg17/bed/liftOver/hg17ToHg16.chain \
                gencode.hg16.gp gencode.gp.unmapped
     wc -l gencode.hg16.gp
        #  2540 gencode.hg16.gp
      wc -l gencode.gp.unmapped
        # 4 -> 2 problem transcripts
        # AC005538.4-001 and AC005538.4-006
        # Each transcript had 1 exon unmapped -- notifying submitter
    ldHgGene -predTab -genePredExt hg16 encodeGencodeGene gencode.hg16.gp
        # 2540 gene predictions
    checkTableCoords hg16 encodeGencodeGene

    # inventory sources for genepreds (genes will be colored by these)
    awk '{print $2}' gencode.vega.gtf | sort | uniq > classes.txt
    wc -l classes.txt
        # 12

    # create gene class table
    hgsql hg16 < ~/kent/src/hg/lib/gencodeGeneClass.sql
    awk '{printf "%s\t%s\n", $10, $2}' gencode.vega.gtf | \
        sed -e 's/"//g' -e 's/;//' -e 's/VEGA_//' | \
        sort | uniq > gencodeGeneClass.tab
    wc -l gencodeGeneClass.tab
        # 2542 gencodeGeneClass.tab
    echo "LOAD DATA LOCAL INFILE 'gencodeGeneClass.tab' into table gencodeGeneClass" | hgsql hg16

    # run Mark D's gene checker on VEGA_Known
    echo " select encodeGencodeGene.* from encodeGencodeGene, gencodeGeneClass where encodeGencodeGene.name=gencodeGeneClass.name and gencodeGeneClass.class='Known'" | hgsql hg16 -N > gencode.known.gp
/cluster/bin/i386/gene-check -incl-ok -nib-dir /cluster/data/hg16/nib -details-out encodeGencodeGene.chk-details gencode.known.gp encodeGencodeGene.chk


# Sanger Chip/chip  (DONE 2005-03-14 kate)
    ssh hgwdev
    cd /cluster/data/encode/sanger/
    mkdir -p chipchip/2005-02-15
    cd chipchip/2005-02-15

    # obtain data files from ftp site
    cp /var/ftp/encode/H3K4me3_GM06990_1.description.txt .
    cp /var/ftp/encode/H3K4me3_GM06990_1.wig.txt .
    rm /var/ftp/encode/H3K*.txt

    # 4 columns: chrom, start, end, score (float)
    # data value range is .12 to 74.875
    # format as BED file
    grep "^chr" H3K4me3_GM06990_1.wig.txt > H3K4me3_GM06990_1.bed

    # create table schema for BED 4 with float score
    cat > table.sql << 'EOF'
    CREATE TABLE tablename (
        chrom varchar(255) not null,        # Chromosome (this species)
        chromStart int unsigned not null,   # Start position in chromosome (forward strand)
        chromEnd int unsigned not null,     # End position in chromosome
        score float not null,       # Overall score
                  #Indices
        INDEX(chrom(13),chromStart),
        INDEX(chrom(13),chromEnd)
    );
    'EOF'

    #	NOTE !*! hgLoadBed has been fixed 2005-06-01 to be able to load
    #	these bedGraph types without this special sql business.

    set tablename = encodeSangerChipH3me3GM06990
    sed "s/tablename/$tablename/" table.sql > $tablename.sql

    hgsql hg16 < $tablename.sql
    hgLoadBed -noBin -sqlTable=$tablename.sql hg16 $tablename H3K4me3_GM06990_1.bed
    # Loaded 17604 elements of size 4

    # create trackDb entry:

    # type bedGraph 4
    # shortLabel ChIP/Sanger
    # longLabel Sanger ChIP/Chip (H3K4me3 GM06990) in ENCODE Regions
    # minLimit 0
    # maxLimit 75


# Genome Institute of Singapore -ChIP/PET of p53 TFBS (IN PROGRESS 2005-03-31 kate)
    cd /cluster/data/encode
    mkdir -p GIS/2005-04-07
    cd GIS/2005-04-07
    # files: description.html, p53ChIP-PET.bed

    sed '1d' p53ChIP-PET.bed | hgLoadBed hg16 encodeGisChipPet stdin
    # Loaded 65513 elements of size 12


# TEST RE-LOADING AFFY TRANSCRIPTION AND CHIP/CHIP TEMPORAL PROFILING
#	- Hiram 2005-05-24
#	as bedGraph type tracks instead of wiggle to provide accurate
#	data retrieval of the original data rather than have the wiggle
#	transformations interferring.  An experiment to see if there is
#	a large difference in storage requirements for this data.
    ssh hgwdev
    mkdir /cluster/data/encode/Affy/Dec03_2004/bedGraph
    cd /cluster/data/encode/Affy/Dec03_2004/bedGraph

    #	NOTE !*! hgLoadBed has been fixed 2005-06-01 to be able to load
    #	these bedGraph types without this special sql business.

    for HR in 00 02 08 32
    do
	rm -f encodeAffyRnaHl60SigHr${HR}.bed
	rm -f bedGraph.sql
	zcat ../ucsc_formats/wig/EC_HL60_RA_RNA_${HR}hr_AS.hs.NCBIv34.wig.gz | \
	    /cluster/bin/scripts/varStepToBedGraph.pl /dev/stdin | \
		sort -k1,1 -k2,2n > encodeAffyRnaHl60SigHr${HR}.bed
	hgsql -e "drop table encodeAffyRnaHl60SigHr${HR}" hg16 2> /dev/stderr
	echo "CREATE TABLE encodeAffyRnaHl60SigHr${HR} (" > bedGraph.sql
	echo 'bin smallint unsigned not null,' >> bedGraph.sql
	echo 'chrom varchar(255) not null,' >> bedGraph.sql
	echo 'chromStart int unsigned not null,' >> bedGraph.sql
	echo 'chromEnd int unsigned not null,' >> bedGraph.sql
	echo 'dataValue float not null,' >> bedGraph.sql
	echo 'INDEX(chrom(6),bin)' >> bedGraph.sql
	echo ');' >> bedGraph.sql
	hgLoadBed -sqlTable=bedGraph.sql hg16 encodeAffyRnaHl60SigHr${HR} \
		encodeAffyRnaHl60SigHr${HR}.bed
    done
    #
    #	Measuring previous data requirements:
    ssh hgwdev
    cd /gbdb/hg16/encode/Affy/2004-12-03/wib
    du -hscL encodeAffyRna*
# 19M     encodeAffyRnaHl60SigHr00.wib
# 19M     encodeAffyRnaHl60SigHr02.wib
# 19M     encodeAffyRnaHl60SigHr08.wib
# 19M     encodeAffyRnaHl60SigHr32.wib
# 76M     total
    #	examining the "show table status" on these tables shows:
    #	index length: 277,504 * 4 = 1,110,016 = 1.06 Mb
    #   data length: 3,291,136 * 4 = 13,181,472 = 12.57 Mb
    #	therefore total size: 76 + 1 + 13 = 90 Mb
    #	These new tables loaded are:
    #	index length: 9,033,728 * 4 = 36,134,912 = 34.46 Mb
    #   data length: 17,331,152 * 4 = 69,096,304 = 65.90 Mb
    #	thus total length: 34 + 66  = 100 Mb
    #	At this density of data these storage areas are certainly
    #	comparable and practically equivalent.

    #	NOTE !*! hgLoadBed has been fixed 2005-06-01 to be able to load
    #	these bedGraph types without this special sql business.

    #	do the other set of data too
    for HR in 00 02 08 32
    do
	rm -f encodeAffyChIpRnapHl60PvalHr${HR}.bed
	rm -f bedGraph.sql
	zcat \
	../ucsc_formats/wig/EC_HL60_RA_RNApol2_${HR}hr_AS_b.hs.NCBIv34.wig.gz \
	    | /cluster/bin/scripts/varStepToBedGraph.pl /dev/stdin | \
		sort -k1,1 -k2,2n > encodeAffyChIpRnapHl60PvalHr${HR}.bed
	hgsql -e "drop table encodeAffyChIpRnapHl60PvalHr${HR}" hg16 2> /dev/stderr
	echo "CREATE TABLE encodeAffyChIpRnapHl60PvalHr${HR} (" > bedGraph.sql
	echo 'bin smallint unsigned not null,' >> bedGraph.sql
	echo 'chrom varchar(255) not null,' >> bedGraph.sql
	echo 'chromStart int unsigned not null,' >> bedGraph.sql
	echo 'chromEnd int unsigned not null,' >> bedGraph.sql
	echo 'dataValue float not null,' >> bedGraph.sql
	echo 'INDEX(chrom(6),bin)' >> bedGraph.sql
	echo ');' >> bedGraph.sql
	hgLoadBed -sqlTable=bedGraph.sql hg16 \
	    encodeAffyChIpRnapHl60PvalHr${HR} \
		encodeAffyChIpRnapHl60PvalHr${HR}.bed
    done
    #
# Sanger Chip/chip updated  (DONE - 2005-05-25 - Hiram)
    ssh hgwdev
    mkdir /cluster/data/encode/sanger/chipchip/2005-05-25
    cd /cluster/data/encode/sanger/chipchip
    rm latest
    ln -s 2005-05-25 latest
    cd 2005-05-25

    cp -p /var/ftp/encode/*GM06990* .

    #	convert to simple bedGraph files:  (stripping browser and track
    #	line definitions from the custom track format), make sure they
    #	are sorted properly.
    grep "^chr" H3K4me1_GM06990_1.wig.txt | sort -k1,1 -k2,2n > \
	H3K4me1_GM06990_1.bed
    grep "^chr" H3K4me3_GM06990_2.wig.txt | sort -k1,1 -k2,2n > \
	H3K4me3_GM06990_2.bed
    grep "^chr" H4ac_GM06990_1.wig.txt | sort -k1,1 -k2,2n > \
	H4ac_GM06990_1.bed 
    grep "^chr" H3K4me2_GM06990_1.wig.txt | sort -k1,1 -k2,2n > \
	H3K4me2_GM06990_1.bed 
    grep "^chr" H3ac_GM06990_1.wig.txt | sort -k1,1 -k2,2n > \
	H3ac_GM06990_1.bed 

    #	find min and max in the data:
    awk '{print $4}' *.bed | sort -n | head -1
    #	0.02
    awk '{print $4}' *.bed | sort -n | tail -1
    #	72.34

    #	This used to be a single track with only one data set
    #	Place these new five data sets into a single composite track

    #	Simplify the naming scheme here:
    ln -s H3K4me1_GM06990_1.bed H3K4me1.bed
    ln -s H3K4me2_GM06990_1.bed H3K4me2.bed
    ln -s H3K4me3_GM06990_2.bed H3K4me3.bed
    ln -s H3ac_GM06990_1.bed H3ac.bed
    ln -s H4ac_GM06990_1.bed H4ac.bed

    #	NOTE !*! hgLoadBed has been fixed 2005-06-01 to be able to load
    #	these bedGraph types without this special sql business.

    #	so the names can now be used in a for loop:
    for T in H3K4me1 H3K4me2 H3K4me3 H3ac H4ac
    do
	hgsql -e "drop table encodeSangerChip${T}" hg16 2> /dev/stderr
	echo "CREATE TABLE encodeSangerChip${T} (" > bedGraph.sql
	echo 'bin smallint unsigned not null,' >> bedGraph.sql
	echo 'chrom varchar(255) not null,' >> bedGraph.sql
	echo 'chromStart int unsigned not null,' >> bedGraph.sql
	echo 'chromEnd int unsigned not null,' >> bedGraph.sql
	echo 'score float not null,' >> bedGraph.sql
	echo 'INDEX(chrom(6),bin)' >> bedGraph.sql
	echo ');' >> bedGraph.sql
	hgLoadBed -sqlTable=bedGraph.sql hg16 encodeSangerChip${T} ${T}.bed
    done

    #	transform the five description pages into one single page.
    #	see hg16/trackDb.ra for encodeSangerChipH3H4 composite track
    #	definitions
    #	clean up /var/ftp/encode
    
    rm -f /var/ftp/encode/Description_H3K4me1_GM06990_1.html
    rm -f /var/ftp/encode/Description_H3K4me2_GM06990_1.html
    rm -f /var/ftp/encode/Description_H3K4me3_GM06990_2.html
    rm -f /var/ftp/encode/Description_H3ac_GM06990_1.html
    rm -f /var/ftp/encode/Description_H4ac_GM06990_1.html
    rm -f /var/ftp/encode/H3K4me1_GM06990_1.wig.txt
    rm -f /var/ftp/encode/H3K4me2_GM06990_1.wig.txt
    rm -f /var/ftp/encode/H3K4me3_GM06990_2.wig.txt
    rm -f /var/ftp/encode/H3ac_GM06990_1.wig.txt
    rm -f /var/ftp/encode/H4ac_GM06990_1.wig.txt

    #	Sanger confirmed they no longer need the old data, remove the
    #	table from hgwdev:
    hgsql -e "drop table encodeSangerChip;" hg16

########################################################################
#  Loading tables UCSD Ludwig Institute ChIP/Chip(H3K4me3 Hela and
#	H3K4Me2 Hela/IFN-g

    ssh hgwdev
    cd /cluster/data/encode/UCSD/2005-05-26
    #	Naming consistency so for() loop can work on this data
    ln -s tmH3K4_p0.wig.orig encodeUcsdChipTriK4IMR90_00.wig.orig
    ln -s tmH3K4_p30.wig.orig encodeUcsdChipTriK4IMR90_30.wig.orig
    #	NOTE !*! hgLoadBed has been fixed 2005-06-01 to be able to load
    #	these bedGraph types without this special sql business.
    for T in 00 30
    do
	grep "^chr" encodeUcsdChipTriK4IMR90_${T}.wig.orig | \
		sort -k1,1 -k2,2n > encodeUcsdChipTriK4IMR90_${T}.bed
	hgsql -e "drop table encodeUcsdChipTriK4IMR90_${T}" hg16 2> /dev/stderr
	echo "CREATE TABLE encodeUcsdChipTriK4IMR90_${T} (" > bedGraph.sql
	echo 'bin smallint unsigned not null,' >> bedGraph.sql
	echo 'chrom varchar(255) not null,' >> bedGraph.sql
	echo 'chromStart int unsigned not null,' >> bedGraph.sql
	echo 'chromEnd int unsigned not null,' >> bedGraph.sql
	echo 'score float not null,' >> bedGraph.sql
	echo 'INDEX(chrom(6),bin)' >> bedGraph.sql
	echo ');' >> bedGraph.sql
	hgLoadBed -sqlTable=bedGraph.sql hg16 encodeUcsdChipTriK4IMR90_${T} \
		encodeUcsdChipTriK4IMR90_${T}.bed
    done

