#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on 
# NCBI build 34 (July 18, 2003 freeze)

# HOW TO BUILD A ASSEMBLY FROM NCBI FILES 
# ---------------------------------------

# Make gs.17 directory, gs.17/build34 directory, and gs.17/ffa directory.
    mkdir /cluster/store4/gs.17
    mkdir /cluster/store4/gs.17/build34
    mkdir /cluster/store4/gs.17/agp
    mkdir /cluster/store4/gs.17/ffa

#    Make a symbolic link from /cluster/store1 to this location
	
    cd /cluster/store1
    ln -s /cluster/store4/gs.17 ./gs.17

#    Make a symbolic link from your home directory to the build dir:

    ln -s /cluster/store4/gs.17/build34 ~/oo

# NCBI download site:

    ftp ftp.ncbi.nih.gov
    # user and password from /cse/guests/kent/buildHg6.doc
    cd build_34    
 
# Download all finished agp's and fa's into gs.17/agp

    mget chr*.agp
    mget chr*.fa.gz
    gunzip *.gz

# Download contig agp's into gs.17/build34

    get ref_placed.agp   # used to be in reference.agp
    get ref_unplaced.agp # used to be in reference.agp
    get DR51.agp
    get PAR.agp          # new for this build - PAR regions added to chrY
    cat ref_placed.agp ref_unplaced.agp DR51.agp > ncbi_build34.agp

# Download contig fa's into gs.17/ffa

    get ref_placed.fa.gz   # used to be in reference.fa
    get ref_unplaced.fa.gz # used to be in reference.fa
    get DR51.fa.gz
    get PAR.fa.gz          # new for this build - PAR regions added to chrY
    get sequence.inf
    cat ref_placed.fa ref_unplaced.fa DR51.fa > ncbi_build34.fa

# Download assembly related files into gs.17/build34

    get seq_contig.md
    get contig_overlaps.agp

# Download questionable join certificates file

    get e-certificates.txt
    mkdir certificates
    mv e-certificates.txt certificates

# Save a copy of the original seq_contig.md file

    cp seq_contig.md seq_contig.md.orig

# For build34, edit the seq_contig.md file to remove the alternative chr7
# sequence supplied by the Toronto group: NT_079590, NT_079591, NT_079592,
# NT_079593, NT_079594, NT_079595, NT_079596, NT_079597

# Edit seq_contig.md to make the DR51 alternative haplotype look like a
# chr6_random sequence:
# 9606  6       32491690        32629063        +       NG_002432       GI:28212469     CONTIG    DR51    1
# to 
# 9606  6|NG_002432     1       137374  +       NG_002432       GI:28212469     CONTIG  DR51      1

# Move this edited DR51 line next to other chr6_random contigs (for creating
#	the lift file)
    
# Sanity check
    /cluster/bin/i386/checkYbr build34/ncbi_build34.agp ffa/ncbi_build34.fa \
      build34/seq_contig.md

# Convert fa files into UCSC style fa files and place in "contigs" directory
# inside the gs.17/build34 directory 

    cd build34
    mkdir contigs
    /cluster/bin/i386/faNcbiToUcsc -split -ntLast ../ffa/ncbi_build34.fa \
      contigs
   
# Copy over chrM contig from previous version
    cd ~/oo
    cp -r gs.17/build33/M .

# Determine the chromosome sizes from agps

    /cluster/bin/scripts/getChromSizes ../agp

# Create lift files (this will create chromosome directory structure) and
#	inserts file
  
    /cluster/bin/scripts/createNcbiLifts -s chrom_sizes seq_contig.md .

# Create contig agp files (will create contig directory structure)
	
    /cluster/bin/scripts/createNcbiCtgAgp seq_contig.md ncbi_build34.agp .

# Create chromsome random agp files.

    /cluster/bin/scripts/createNcbiChrAgp -randomonly .

# Copy the original chrN.agp files from the gs.17/agp directory 
#    into each of the chromosome directories since they contain better 
#    gap information. Delete the comments at top from these.

# Distribute contig .fa to appropriate directory (assumes all files
# are in "contigs" directory).

    # create global data link for everyone.  No more home directory
    # links required.
    ln -s /cluster/store4/gs.17/build34 /cluster/data/hg16
    cd /cluster/data/hg16
    /cluster/bin/scripts/distNcbiCtgFa contigs .
    rm -r contigs

# Copy over jkStuff from previous build (??)
    mkdir jkStuff
    cp /cluster/store1/gs.17/build33/jkStuff/*.sh jkStuff
    /build31/jkStuff/*.csh jkStuff
    cp /cluster/store1/gs.17/build33/jkStuff/*.gsub jkStuff        

# Create contig gl files

    /cluster/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md

# Create chromosome gl files

     jkStuff/liftGl.sh contig.gl

# Files ready for repeat-masking and trf


# CREATE STS/FISH/BACENDS/CYTOBANDS DIRECTORY STRUCTURE AND SETUP 
#        (DONE 2003-07-23 Terry)

# Create directory structure to hold information for these tracks
        cd /projects/hg2/booch/psl/

# Change Makefile parameters for OOVERS, GSVERS, PREVGS, PREVOO
        make new

# Update all Makefiles with latest OOVERS and GSVERS, DATABASE, and locations of .fa files

# Makefiles in:
#     /gs.17/build33/
#     /gs.17/build33/bacends
#     /gs.17/build33/cytobands
#     /gs.17/build33/cytoPlots
#     /gs.17/build33/fish
#     /gs.17/build33/fosends
#     /gs.17/build33/g2g
#     /gs.17/build33/geneticPlots
#     /gs.17/build33/primers
#     /gs.17/build33/recombrate
#     /gs.17/build33/sts
#     /gs.17/build33/stsPlots

# Create accession_info file *****
	make accession_info.rdb


# UPDATE STS INFORMATION (DONE 2003-07-23 Terry)
# Download and unpack updated information from dbSTS:

    	cd /projects/hg2/booch/psl/update
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.sts
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.aliases
	wget ftp://ftp.ncbi.nih.gov/blast/db/FASTA/sts.Z
	mv sts.Z dbSTS.FASTA.dailydump.Z
	gunzip dbSTS.FASTA.dailydump.Z

# Edit Makefile PREV variable to current sts.X version, 
#    and update STS files
        make update

# Make new directory for this info and move files there
        mkdir /cluster/store1/sts.8
        cp all.STS.fa /cluster/store1/sts.8
        cp all.primers /cluster/store1/sts.8
        cp all.primers.fa /cluster/store1/sts.8

# Copy new files to cluster
        ssh kkstore
        cd /cluster/store1/sts.8
        cp /cluster/store1/sts.8 /*.* /scratch/hg/STS

# Ask for propagation from sysadmin

# Load the sequences into the database (after database created)
	ssh hgwdev
	mkdir /gbdb/hg16/sts.8
	cd /gbdb/hg16/sts.8
	ln -s /cluster/store1/sts.8/all.STS.fa ./all.STS.fa
	ln -s /cluster/store1/sts.8/all.primers.fa ./all.primers.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg16 /gbdb/hg16/sts.8/all.STS.fa
	hgLoadRna addSeq hg16 /gbdb/hg16/sts.8/all.primers.fa

# CREATE STS MARKER ALIGNMENTS (DONE 2003-08-03 Terry)

# Create full sequence alignments
        ssh kk
        cd /cluster/home/booch/sts

# Update Makefile with latest OOVERS and GSVERS and
# run cluster jobs
        make new
        make jobList 
        para create jobList
        para push 
	# wait until alignments done
        make stsMarkers.psl

# Copy files to final destination and remove originals
        make copy.assembly
        make clean

# Create primer alignments
        ssh kk
        cd /cluster/home/booch/primers
        
# Update Makefile with latest OOVERS and GSVERS and
# run cluster jobs
        make new
        make jobList.scratch
        para create jobList
        para push

# Do an initial quick filter of results (takes a while, still) and create 
# final file - best done on eieio since disks local
	ssh eieio
	make filter
        make primers.psl

# Copy files to final destination and remove
        make copy.assembly
        make clean
        
# Create ePCR alignments
        ssh kk
        cd /cluster/home/booch/epcr

# Update Makefile with latest OOVERS and GSVERS
        make new
        make jobList
        para create jobList
        para push
        make all.epcr

# Copy files to final destination and remove
        make copy.assembly
        make clean
        

# CREATE AND LOAD STS MARKERS TRACK (DONE 2003-08-03 Terry)

# Copy in current stsInfo2.bed and stsAlias.bed files
        cd /projects/hg2/booch/psl/gs.17/build33
        cp ../update/stsInfo2.bed .
        cp ../update/stsAlias.bed .

# Create final version of sts sequence placements
        ssh kks00
        cd /projects/hg2/booch/psl/gs.17/build33/sts
        make stsMarkers.final

# Create final version of primers placements
# Make sure PRIMERS variable in Makefile is pointing to current version
        cd /projects/hg2/booch/psl/gs.17/build33/primers
        make primers.final

# Create bed file
        cd /projects/hg2/booch/psl/gs.17/build33
        make stsMap.bed

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < all_sts_primer.sql
        hgsql hg16 < all_sts_seq.sql
        hgsql hg16 < stsAlias.sql
        hgsql hg16 < stsInfo2.sql
        hgsql hg16 < stsMap.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.17/build34/sts/
        echo 'load data local infile "stsMarkers.psl.filter.lifted" into table all_sts_seq;' | hgsql hg16
	cd /projects/hg2/booch/psl/gs.17/build34/primers/
        echo 'load data local infile "primers.psl.filter.lifted" into table all_sts_primer;' | hgsql hg16
	cd /projects/hg2/booch/psl/gs.17/build34/
        echo 'load data local infile "stsAlias.bed" into table stsAlias;' | hgsql hg16
        echo 'load data local infile "stsInfo2.bed" into table stsInfo2;' | hgsql hg16
	echo 'load data local infile "stsMap.bed" into table stsMap;' | hgsql hg16


# CREATE AND LOAD RECOMBINATION RATE TRACK (DONE 2003-08-05 Terry)
# (must be done after STS Markers track) 

# Create bed file
	cd /projects/hg2/booch/psl/gs.17/build34/recombrate
	make recombRate.bed

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < recombRate.sql
        
# Load the table
	cd /projects/hg2/booch/psl/gs.17/build34/recombrate/
	echo 'load data local infile "recombRate.bed" into table recombRate;' | hgsql hg16


# UPDATE BACEND SEQUENCES (DONE 2003-07-23 Terry)

# **** Sequences were determined to not have changed since bacends.4 *****
# **** No new sequences downloaded - See makeHg15.doc for download instructions  ***** 

# Load the sequences into the database (after database created)
	ssh hgwdev
	mkdir /gbdb/hg16/bacends.4
	cd /gbdb/hg16/bacends.4
	ln -s /cluster/store1/bacends.4/BACends.fa ./BACends.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg16 /gbdb/hg16/bacends.4/BACends.fa


# BACEND SEQUENCE ALIGNMENTS (DONE 2003-08-01 Terry)
# (alignments done without RepeatMasking)

# Create full sequence alignments
	ssh kk
        cd /cluster/home/booch/bacends

# Update Makefile with latest OOVERS and GSVERS and run cluster jobs
        make new
        make jobList
        para create jobList
        para push 

# Compile alignments and lift the files (takes a while)
	ssh eieio
	make bacEnds.psl.lifted

# Copy files to final destination and remove
        make copy.assembly
        make clean # (may want to wait until sure they're OK)

# BACEND PAIRS TRACK (DONE 2003-08-01 Terry)

# Add /projects/compbiousr/booch/booch/scripts to your path

# Update Makefile with new location of pairs/singles 
# files, if necessary (DONE)
        cd /projects/hg2/booch/psl/gs.17/build33/bacends

# Make initial file of alignments
	make bacEnds.rdb
 
# Try to fish out more pairs
	make bacEndsMiss.psl

# Re-make bacEnds.rdb with new info
	make bacEnds.rdb
 
# Create bacEndPairs track file
        make bacEndPairs.bed

# Create bacEndPairsBad and bacEndPairsLong files
	make bacEndPairsBad.bed

# Create psl file to load
	make bacEnds.load.psl

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < all_bacends.sql
        hgsql hg16 < bacEndPairs.sql
        hgsql hg16 < bacEndPairsBad.sql
        hgsql hg16 < bacEndPairsLong.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.17/build34/bacends/
        echo 'load data local infile "bacEnds.load.psl" into table all_bacends;' | hgsql hg16
        echo 'load data local infile "bacEndPairs.bed" into table bacEndPairs;' | hgsql hg16
        echo 'load data local infile "bacEndPairsBad.bed" into table bacEndPairsBad;' | hgsql hg16
        echo 'load data local infile "bacEndPairsLong.bed" into table bacEndPairsLong;' | hgsql hg16


# FOSEND SEQUENCE ALIGNMENTS (DONE 2003-08-03 Terry)

# Create full sequence alignments
        ssh kk
        cd /cluster/home/booch/fosends

# Update Makefile with latest OOVERS and GSVERS and run cluster jobs
        make new
        make jobList
	para create jobList
        para push

# Compile alignments and lift the files (takes a while)
	ssh eieio
        cd /cluster/home/booch/fosends
	make fosEnds.psl.lifted

# Copy files to final destination and remove
        make copy.assembly
        make clean

# FOSEND PAIRS TRACK (DONE 2003-08-01 Terry)

# Update Makefile with location of pairs files, if necessary
        ssh kks00
        cd /projects/hg2/booch/psl/gs.17/build33/fosends

# Make initial file of alignments
	make fosEnds.rdb

# Try to fish out more pairs
	make fosEndsMiss.psl

# Re-make bacEnds.rdb with new info
	make fosEnds.rdb
 
# Create bacEndPairs track file
        make fosEndPairs.bed

# Create bacEndPairsBad and bacEndPairsLong files
	make fosEndPairsBad.bed

# Create psl file to load
	make fosEnds.load.psl

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < all_fosends.sql
        hgsql hg16 < fosEndPairs.sql
        hgsql hg16 < fosEndPairsBad.sql
        hgsql hg16 < fosEndPairsLong.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.17/build34/fosends/
        echo 'load data local infile "fosEnds.load.psl" into table all_fosends;' | hgsql hg16        
        echo 'load data local infile "fosEndPairs.bed" into table fosEndPairs;' | hgsql hg16
        echo 'load data local infile "fosEndPairsBad.bed" into table fosEndPairsBad;' | hgsql hg16
        echo 'load data local infile "fosEndPairsLong.bed" into table fosEndPairsLong;' | hgsql hg16

# Load the sequences (change fosends.# to match correct location) (done for hg15 early 4/9/2003)
	mkdir /gbdb/hg15/fosends.3
	cd /gbdb/hg15/fosends.3
	ln -s /cluster/store1/fosends.3/fosEnds.fa ./fosEnds.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg15 /gbdb/hg15/fosends.3/fosEnds.fa
                

# UPDATE FISH CLONES INFORMATION (DONE 2003-07-23 Terry)

# Download the latest info from NCBI
        # point browser at http://www.ncbi.nlm.nih.gov/genome/cyto/cytobac.cgi?CHR=all&VERBOSE=ctg
        # change "Show details on sequence-tag" to "yes"
        # change "Download or Display" to "Download table for UNIX"
        # press Submit - save as /projects/hg2/booch/psl/fish/hbrc/hbrc.20030723.table

# Format file just downloaded.  
        cd /projects/hg2/booch/psl/fish/

# Edit Makefile to point at file just downloaded (variables HBRC, HBRCFORMAT)
        make HBRC

# (Manually added 21 results from FHCRC)

# Copy it to the new freeze location
        cp /projects/hg2/booch/psl/fish/all.fish.format /projects/hg2/booch/psl/gs.17/build34/fish/

# Save it as the new "gold" file
	cp all.fish.format all.fish.format.gold

# CREATE AND LOAD FISH CLONES TRACK (DONE 2003-08-08 Terry)
# (must be done after Coverage, STS markers track and BAC end pairs track)

# Extract the file with clone positions from database
        ssh hgwdev
        echo 'select * into outfile "/tmp/booch/clonePos.txt" from clonePos' | hgsql hg16
        mv /tmp/booch/clonePos.txt /projects/hg2/booch/psl/gs.17/build34/fish

# Get current clone/accession information
	ssh kks00
        cd /projects/hg2/booch/psl/gs.17/build34/fish
	wget http://www.ncbi.nlm.nih.gov/genome/clone/DATA/clac.out

# Create initial placement file
	cp /projects/hg2/booch/psl/gs.17/build33/fish/extract.pl . 
	make cyto.markers.bed

# Get sequences for accessions not in genome
	# goto http://www.ncbi.nlm.nih.gov/entrez/batchentrez.cgi?db=Nucleotide
	# select file "/projects/hg2/booch/psl/gs.17/build33/fish/not.found.acc
	# change output to FASTA format
	# download results to "/projects/hg2/booch/psl/gs.17/build33/fish/not.found.fa"

# Place sequences against genome
	make blat

# Try to incorporate new placements
	make cyto.markers.bed2

# Create bed file
        make fishClones.bed

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < fishClones.sql

# Load the table
	cd /projects/hg2/booch/psl/gs.17/build34/fish/
        echo 'load data local infile "fishClones.bed" into table fishClones;' | hgsql hg16
        

# CREATE AND LOAD CHROMOSOME BANDS TRACK (DONE 2003-08-08 Terry)
# (must be done after FISH Clones track) 

# Create bed file
        ssh kks00
	cd /projects/hg2/booch/psl/gs.17/build34/cytobands/
        make setBands.txt   # NOTE: may get errors if inserts file out-of-sync with pctSetBands file 
        make cytobands.pct.ranges
        make predict

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < cytoBand.sql
        
# Load the table
	cd /projects/hg2/booch/psl/gs.17/build34/cytobands/
	echo 'load data local infile "cytobands.bed" into table cytoBand;' | hgsql hg16


# CREATING DATABASE  (DONE - 2003-07-26 - Hiram)
    ssh hgwdev
    # Make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#	Filesystem            Size  Used Avail Use% Mounted on
#	/dev/sda1             472G  416G   31G  93% /var/lib/mysql
    # Create the database.
    echo 'create database hg16' | hgsql hg15
    # make a semi-permanent read-only alias (add this to your .cshrc/.bashrc):
    #	(I have not seen a use for this in any procedures ? -Hiram)
    #		alias hg16 mysql -u hguser -phguserstuff -A hg16
    #	(use 'hgsql hg16' instead)
    # Initialize the relational-mrna and external sequence info tables:
    hgLoadRna new hg16
    # Copy over grp table (for track grouping) from another database:
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg15.grp" \
    | hgsql hg16

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE - 2003-07-26 - Hiram)
    ssh hgwdev
    # Enter hg16 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb (name, description, nibPath, organism, \
	defaultPos, active, orderKey, genome, scientificName) \
	values("hg16", "July 2003", "/gbdb/hg16/nib", "Human", \
	"chr7:26828631-26938371", 1, 10, "Human", "Homo sapiens");' \
	| hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~kent/src/hg/makeDb/trackDb
    cvs up -d -P .
    # Edit that makefile to add hg16 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE LIFTALL.LFT, NCBI.LFT (DONE - 2003-07-26 - Hiram)
    cd /cluster/data/hg16
    mkdir -p jkStuff
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft
    # Create jkStuff/ncbi.lft for lifting stuff built with the NCBI assembly.
    # Note: this ncbi.lift will not lift floating contigs to chr_random coords,
    # but it will show the strand orientation of the floating contigs 
    # (grep for '|').
    mdToNcbiLift seq_contig.md jkStuff/ncbi.lft 
    # If a lift file has been edited (e.g. as in 6.2.5 above), edit ncbi.lft 
    # to match. If no step 6.2.5 then no editing needed

# REPEAT MASKING (DONE - 2003-07-25 - Hiram, REDONE 2003-08-02)
    # Split contigs, run RepeatMasker, lift results
    # Notes: 
    # * Using new RepeatMasker in /cluster/bluearc/RepeatMasker030619
    #	Always check for new RepeatMasker before proceeding
    # * Contigs (*/N{T,G}_*/N{T,G}_*.fa) are split into 500kb chunks to make 
    #   RepeatMasker runs manageable on the cluster ==> results need lifting.
    # * For the NCBI assembly we repeat mask on the sensitive mode setting
    #   (RepeatMasker -s)

    #- Split contigs into 500kb chunks:

    ssh eieio
    cd /cluster/data/hg16
    foreach chrom ( ?{,?} )
	foreach c ( $chrom/N{T,G}_?????? )
      set contig = $c:t
	echo "splitting ${chrom}/${contig}/${contig}.fa"
      faSplit size ${chrom}/${contig}/$contig.fa 500000 \
	${chrom}/${contig}/${contig}_ -lift=${chrom}/${contig}/$contig.lft \
	-maxN=500000
	end
    end

    #- Make the run directory and job list:
    cd /cluster/data/hg16
    mkdir -p jkStuff
    #  According to RepeatMasker help file, no arguments are required to
    #	specify species because its default is set for primate (human)
    #  This run script saves the .tbl file to be sent to Arian.  He uses
    # those for his analysis.  Sometimes he needs the .cat and .align files for
    # checking problems.  Krish needs the .align files, they are large.

    cat << '_EOF_' > jkStuff/RMHuman
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/hg16/$2
/bin/cp $2 /tmp/hg16/$2/
cd /tmp/hg16/$2
/cluster/bluearc/RepeatMasker030619/RepeatMasker -ali -s $2
popd
/bin/cp /tmp/hg16/$2/$2.out ./
 if (-e /tmp/hg16/$2/$2.align) /bin/cp /tmp/hg16/$2/$2.align ./
if (-e /tmp/hg16/$2/$2.tbl) /bin/cp /tmp/hg16/$2/$2.tbl ./
# if (-e /tmp/hg16/$2/$2.cat) /bin/cp /tmp/hg16/$2/$2.cat ./
/bin/rm -fr /tmp/hg16/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg16/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg16
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMHuman

    ssh eieio
    cd /cluster/data/hg16
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
   foreach d ( ?{,?} )
     foreach c ( $d/N{T,G}_*/N{T,G}_*_*.fa )
        set f = $c:t
        set cc = $c:h
        set contig = $cc:t
        echo /cluster/store4/gs.17/build34/jkStuff/RMHuman \
   		/cluster/store4/gs.17/build34/${d}/${contig} $f \
   '{'check out line+ /cluster/store4/gs.17/build34/${d}/${contig}/$f.out'}' \
          >> RMRun/RMJobs
      end
    end

    # We have 6015 jobs in RMJobs:
    wc RMRun/RMJobs
#	6015   42105 1184896 RMRun/RMJobs

    #- Do the run
    ssh kk
    cd /cluster/data/hg16/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
    #- While that is running, you can run TRF (simpleRepeat) on the small
    # cluster.  See SIMPLE REPEAT section below
# CPU time in finished jobs:   33575296s  559588.26m  9326.47h  388.60d  1.065 y
# IO & Wait Time:                238878s    3981.30m    66.36h    2.76d  0.008 y
# Average job time:                7513s     125.21m     2.09h    0.09d
# Longest job:                    18457s     307.62m     5.13h    0.21d
# Submission to last job:         55537s     925.62m    15.43h    0.64d


    #- Lift up the split-contig .out's to contig-level .out's
    ssh eieio
    cd /cluster/data/hg16
    foreach d ( ?{,?}/N{T,G}_* )
        cd $d
        set contig = $d:t
        liftUp $contig.fa.out $contig.lft warn ${contig}_?{,?,??}.fa.out 
        cd ../..
    end

    #- Lift up RepeatMask .out files to chromosome coordinates via
    # picked up jkStuff/liftOut2.sh from the hg15 build.  Reset the
    # liftUp command from ~kent/bin/$MACHTYPE to be from
    # /cluster/bin/i386.  Took the redirection to dev/null off of the
    # command and capture the output here to see what errors we have.

    ./jkStuff/liftOut2.sh > liftOut2.out 2>&1 &

    #- By this point, the database should have been created (above):
    ssh hgwdev
    cd /cluster/data/hg16
    hgLoadOut hg16 ?/*.fa.out ??/*.fa.out

    # errors during this load:
Processing 2/chr2.fa.out
Strange perc. field -6.1 line 243430 of 2/chr2.fa.out
Strange perc. field -5.6 line 243430 of 2/chr2.fa.out
Strange perc. field -6.1 line 243432 of 2/chr2.fa.out
Strange perc. field -5.6 line 243432 of 2/chr2.fa.out
Processing 5/chr5.fa.out
Strange perc. field -0.3 line 4339 of 5/chr5.fa.out
Processing 19/chr19.fa.out
Strange perc. field -18.6 line 77032 of 19/chr19.fa.out

# SIMPLE REPEAT [TRF] TRACK (DONE - 2003-07-25 - Hiram)
    # Distribute contigs to /iscratch/i
    ssh kkr1u00
    rm -rf /iscratch/i/gs.17/build34/contigs
    mkdir -p /iscratch/i/gs.17/build34/contigs
    cd /cluster/data/hg16
    cp -p contigs/*.fa /iscratch/i/gs.17/build34/contigs
    # Make sure the total size looks like what you'd expect:
    du ./contigs /iscratch/i/gs.17/build34/contigs
    # 2839768 ./contigs
    # 2839768 /iscratch/i/gs.17/build34/contigs
    ~kent/bin/iSync

    # Create cluster parasol job like so:
    mkdir -p /cluster/data/hg16/bed/simpleRepeat
    cd /cluster/data/hg16/bed/simpleRepeat
    mkdir trf
    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    ls -1S /iscratch/i/gs.17/build34/contigs/*.fa > genome.lst
    gensub2 genome.lst single gsub spec
    para create spec
    para try
    para check
    para push
    para check
#  Completed: 472 of 472 jobs
# CPU time in finished jobs:      36177s     602.95m    10.05h    0.42d  0.001 y
# IO & Wait Time:                  2038s      33.97m     0.57h    0.02d  0.000 y
# Average job time:                  81s       1.35m     0.02h    0.00d
# Longest job:                     6992s     116.53m     1.94h    0.08d
# Submission to last job:         10703s     178.38m     2.97h    0.12d
    # When cluster run is done, a couple of extra files not caught in
    # the above sequence
    ./runTrf /cluster/store4/gs.17/build34/M/NT_999999/NT_999999.fa trf/NT_999999.bed
    # That produces an empty .bed file, mark it so:
    echo "# trf run produces nothing for this one" >> trf/NT_999999.bed

    liftUp simpleRepeat.bed /cluster/data/hg16/jkStuff/liftAll.lft \
	warn trf/*.bed  > lu.out 2>&1

    # Load into the database:
    ssh hgwdev
    cd /cluster/data/hg16/bed/simpleRepeat
    /cluster/bin/i386/hgLoadBed hg16 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
#	stringTab = 0
#	Reading simpleRepeat.bed
#	Loaded 627883 elements
#	Sorted
#	Saving bed.tab
#	Loading hg16

# PROCESS SIMPLE REPEATS INTO MASK (DONE - 2003-07-27 - Hiram - REDONE 07-30)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd /cluster/data/hg16/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/hg16
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end

# MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE - 2003-07-27)
#							 -Hiram
    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above.
    ssh eieio
    cd /cluster/data/hg16

    # Make chr*.fa from contig .fa
    #  Copied chrFa.sh from hg15/jkStuff - reset  path from ~kent to
    #  /cluster for the ctgToChromFa comand
    tcsh ./jkStuff/chrFa.sh > chrFa.out 2>&1 &

    # copied these three scripts from hg15 - fixup path names to
    # reference /cluster/bin instead of ~kent/bin

    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh ./jkStuff/makeFaMasked.sh > maFaMasked.out 2>&1
    #- Make hard-masked .fa.masked files as well:
    tcsh ./jkStuff/makeHardMasked.sh > maHardMasked.out 2>&1
    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh ./jkStuff/makeNib.sh > maNib.out 2>&1

    # Make symbolic links from /gbdb/hg16/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/hg16/nib
    foreach f (/cluster/store4/gs.17/build34/nib/chr*.nib)
      ln -s $f /gbdb/hg16/nib
    end
    # Load /gbdb/hg16/nib paths into database and save size info.
    hgsql hg16  < ~/kent/src/hg/lib/chromInfo.sql
    cd /cluster/data/hg16
    hgNibSeq -preMadeNib hg16 /gbdb/hg16/nib ?{,?}/chr?{,?}{,_random}.fa
    echo "select chrom,size from chromInfo" | hgsql -N hg16 > chrom.sizes

    # Copy the masked contig fa to /iscratch and /scratch:
    #	And everything else we will need for blastz runs, etc ...
    ssh kkr1u00
    rm -rf /iscratch/i/gs.17/build34/trfFa
    mkdir -p /iscratch/i/gs.17/build34/trfFa
    cp -p /cluster/data/hg16/?{,?}/N{T,G}_*/N{T,G}_??????.fa /iscratch/i/gs.17/build34/trfFa
    rm -rf /iscratch/i/gs.17/build34/bothMaskedNibs
    mkdir -p /iscratch/i/gs.17/build34/bothMaskedNibs
    cp -p /cluster/data/hg16/nib/*.nib /iscratch/i/gs.17/build34/bothMaskedNibs
    rm -rf /iscratch/i/gs.17/build34/rmsk
    mkdir -p /iscratch/i/gs.17/build34/rmsk
    cp -p /cluster/data/hg16/?{,?}/*.out /iscratch/i/gs.17/build34/rmsk
    ~kent/bin/iSync

    # ssh kkstore
    #  Since kkstore is currently /cluster/bluearc/scratch, better to do
    #  this on eieio and copy to 
    rm -rf /scratch/hg/gs.17/build34/trfFa
    mkdir -p /scratch/hg/gs.17/build34/trfFa
    cp -p /cluster/data/hg16/?{,?}/N{T,G}_*/N{T,G}_??????.fa /scratch/hg/gs.17/build34/trfFa
    rm -rf /scratch/hg/gs.17/build34/bothMaskedNibs
    mkdir /scratch/hg/gs.17/build34/bothMaskedNibs
    cp -p /cluster/data/hg16/nib/*.nib /scratch/hg/gs.17/build34/bothMaskedNibs
    rm -rf /scratch/hg/gs.17/build34/rmsk
    mkdir -p /scratch/hg/gs.17/build34/rmsk
    cp -p /cluster/data/hg16/?{,?}/*.out /scratch/hg/gs.17/build34/rmsk

    # request rsync of kkstore /scratch


# O+O: ASSEMBLY [GOLD], GAP, COVERAGE, MAP CONTIGS TRACKS (DONE - 2003-07-27)
# Store o+o info in database.
    ssh eieio
    cd /cluster/store4/gs.17/build34
    if (-f contig_overlaps.agp) then
      jkStuff/liftGl.sh contig.gl
    else
      ssh hgwdev
      hgGoldGapGl -noGl hg16 /cluster/store4/gs.17 build34 
      echo ""
      echo "*** Note from makeHg15.doc:"
      echo "Come back to this step later when we have contig_overlaps.agp\!"
    endif
    ssh hgwdev
    cd /cluster/store4/gs.17/build34
    if (-f contig_overlaps.agp) then
      hgGoldGapGl hg16 /cluster/store4/gs.17 build34 
      cd /cluster/store4/gs.17
      /cluster/bin/i386/hgClonePos hg16 build34 ffa/sequence.inf /cluster/store4/gs.17 -maxErr=3
    end 
    cd /cluster/store4/gs.17
    hgCtgPos hg16 build34 

# CREATE NON-STANDARD JOIN CERTIFICATES WEB PAGE AND TABLE

# Filter certificates file to only contain those relevant to current assembly

    cd ~/hg16/certificates
    /cluster/bin/scripts/extractCertificates.pl e-certificates.txt ~/hg16 \
    > e-certificates.filter.txt

# Create initial web page and table for loading into database

    hgCert e-certificates.filter.txt > certificates.html

# Donna's edits to html page

# Load cert table into database

    ssh hgwdev
    cd ~/hg16/certificates
    hgsql hg16 < kent/src/hg/lib/certificate.sql 
    echo 'load data local infile "cert.tab" into table certificate;' | hgsql hg16

# AUTO UPDATE GENBANK MRNA RUN  (WORKING - 2003-07-30 - Hiram)

    ssh eieio
    cd /cluster/store5/genbank
    # This is a new organism, edit the etc/genbank.conf file and add:
	# hg16
	hg16.genome = /scratch/hg/gs.17/build34/bothMaskedNibs/chr*.nib
	hg16.lift = /cluster/store4/gs.17/build34/jkStuff/liftAll.lft
	hg16.genbank.est.xeno.load = yes
	hg16.mgcTables.default = full
	hg16.mgcTables.mgc = all
	hg16.downloadDir = hg16

    ssh eieio
    cd /cluster/store5/genbank
    nice bin/gbAlignStep -iserver=no -clusterRootDir=/cluster/bluearc/genbank \
	-srcDb=genbank -type=mrna -verbose=1 -initial hg16
# Completed: 49591 of 49591 jobs
# CPU time in finished jobs:    3853288s   64221.47m  1070.36h   44.60d  0.122 y
# IO & Wait Time:                246323s    4105.38m    68.42h    2.85d  0.008 y
# Average job time:                  83s       1.38m     0.02h    0.00d
# Longest job:                    21265s     354.42m     5.91h    0.25d
# Submission to last job:         22930s     382.17m     6.37h    0.27d

    # Load the results from the above
    ssh hgwdev
    cd /cluster/store5/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg16

#	To get this next one started, the above results need to be
#	moved out of the way.  These things can be removed if there are
#	no problems to debug
    ssh eieio
    cd /cluster/bluearc/genbank/work
    mv initial.hg16 initial.hg16.genbank.mrna

    ssh eieio
    cd /cluster/store5/genbank
    nice bin/gbAlignStep -iserver=no -clusterRootDir=/cluster/bluearc/genbank \
	-srcDb=refseq -type=mrna -verbose=1 -initial hg16
# Completed: 68740 of 68740 jobs
# CPU time in finished jobs:    1253290s   20888.16m   348.14h   14.51d  0.040 y
# IO & Wait Time:                309126s    5152.10m    85.87h    3.58d  0.010 y
# Average job time:                  23s       0.38m     0.01h    0.00d
# Longest job:                    13290s     221.50m     3.69h    0.15d
# Submission to last job:         13609s     226.82m     3.78h    0.16d

    # The iservers came back on-line, so use them for this run.
    #  The batch file can be found in:
    #	/cluster/store5/genbank/work/initial.hg16/align
    ssh hgwdev
    cd /cluster/store5/genbank
    nice bin/gbDbLoadStep -verbose=1 hg16

    nice bin/gbAlignStep -srcDb=genbank -type=est -verbose=1 -initial hg16

# GC PERCENT (DONE 2003-07-31 - Hiram)
     ssh hgwdev
     mkdir -p /cluster/data/hg16/bed/gcPercent
     cd /cluster/data/hg16/bed/gcPercent
     hgsql hg16  < ~/kent/src/hg/lib/gcPercent.sql
     hgGcPercent hg16 ../../nib

# MAKE HGCENTRALTEST BLATSERVERS ENTRY (DONE - 2003-07-31 - Hiram)
    ssh hgwdev
    # Substitute BBB with the correct number for the hostname:
    echo 'insert into blatServers values("hg16", "blat6", "17778", "1"); \
          insert into blatServers values("hg16", "blat6", "17779", "0");' \
    | hgsql -h genome-testdb hgcentraltest


# PRODUCING GENSCAN PREDICTIONS (DONE - 2003-08-01 - Hiram)

    ssh eieio
    mkdir -p /cluster/data/hg16/bed/genscan
    cd /cluster/data/hg16/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir -p gtf pep subopt
    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequencable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/store4/gs.17/build34/?{,?}/N{T,G}_*/N{T,G}_??????.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
        
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    cd /cluster/data/hg16/bed/genscan
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/home/hiram/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push
# Completed: 491 of 491 jobs		(this was with only 6 CPUs available)
# CPU time in finished jobs:     216220s    3603.67m    60.06h    2.50d  0.007 y
# IO & Wait Time:                 85597s    1426.62m    23.78h    0.99d  0.003 y
# Average job time:                 615s      10.24m     0.17h    0.01d
# Longest job:                    10986s     183.10m     3.05h    0.13d
# Submission to last job:         54395s     906.58m    15.11h    0.63d


    # Issue either one of the following two commands to check the
    # status of the cluster and your jobs, until they are done.
    parasol status
    para check
    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.  In build33, this was 22/NT_011519.
    #  In build34 there were NO failures !
    # Convert these to chromosome level files as so:     
    ssh eieio
    cd /cluster/data/hg16/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/N{T,G}*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/N{T,G}*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/hg16/bed/genscan
    ldHgGene hg16 genscan genscan.gtf
#	Reading genscan.gtf
#	Read 42974 transcripts in 326300 lines in 1 files
#	  42974 groups 41 seqs 1 sources 1 feature types
#	42974 gene predictions
    hgPepPred hg16 generic genscanPep genscan.pep
#	Processing genscan.pep
    hgLoadBed hg16 genscanSubopt genscanSubopt.bed
#	stringTab = 0
#	Reading genscanSubopt.bed
#	Loaded 518038 elements
#	Sorted
#	Creating table definition for 
#	Saving bed.tab
#	Loading hg16


# CPGISLANDS (DONE - 2003-08-01 - Hiram)
    ssh eieio
    mkdir -p /cluster/data/hg16/bed/cpgIsland
    cd /cluster/data/hg16/bed/cpgIsland
    # Copy program as built for previous hg build:
    mkdir cpg_dist
    cp -p ~/hg15/bed/cpgIsland/cpg_dist/cpglh.exe ./cpg_dist
    #  This step used to read, but I do not immediately see the .tar
    #  file anywhere:  (there is a copy in ~/rn3/bed/cpgIsland)
    # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
    # copy the tar file to the current directory
    # tar xvf cpg_dist.tar 
    # cd cpg_dist
    # gcc readseq.c cpg_lh.c -o cpglh.exe
    # cd ..
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
      set fout=$f:t:r:r.cpg
      echo producing $fout...
      ./cpg_dist/cpglh.exe $f > $fout
    end
    cat << '_EOF_' > filter.awk
/* chr1\t1325\t3865\t754\tCpG: 183\t64.9\t0.7 */
/* Transforms to:  (tab separated columns above, spaces below) */
/* chr1  1325    3865    CpG: 183  754  183 489  64.9  0.7 */
{
width = $3-$2;
printf("%s\t%s\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\n",
  $1,$2,$3,$5,$6,width,$6,width*$7*0.01,100.0*2*$6/($3-$2),$7);}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed
    ssh hgwdev
    cd /cluster/data/hg16/bed/cpgIsland
    hgLoadBed hg16 cpgIsland -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed
#	stringTab = 1
#	Reading cpgIsland.bed
#	Loaded 27596 elements
#	Sorted
#	Saving bed.tab
#	Loading hg16

# VERIFY REPEATMASKER RESULTS (DONE - 2003-08-01 - Hiram)

    # Run featureBits on hg16 and on a comparable genome build, and compare:
    ssh hgwdev

    featureBits hg16 rmsk
    # --> 1388770568 bases of 2865697954 (48.462%) in intersection
    # --> 1388044886 bases of 2865697954 (48.437%) in intersection
    # --> 1388157103 bases of 2863665240 (48.475%) in intersection
    featureBits hg15 rmsk
    # --> 1386879340 bases of 2866466359 (48.383%) in intersection
    featureBits hg13 rmsk
    # --> 1383216615 bases of 2860907679 (48.349%) in intersection

# PREPARE CLUSTER FOR BLASTZ RUN (DONE - 2003-08-05 - Hiram)

    ssh eieio
    #  This is where kkstore /scratch is kept:
    cd /cluster/bluearc/scratch/hg/gs.17/build34/rmsk
    #  The following will mark each line for rat and mouse
    #	Rat first will column 1, Mouse second will be column 2
    foreach outfl ( *.out )
	echo "$outfl"
	/cluster/bluearc/RepeatMasker030619/DateRepsinRMoutput.pl \
	${outfl} -query human -comp rat -comp mouse
    end
    #	Now extract each one, 1 = Rat, 2 = Mouse
    cd /cluster/bluearc/scratch/hg/gs.17/build34
    mkdir linSpecRep.notInRat
    mkdir linSpecRep.notInMouse
    foreach f (rmsk/*.out_rat_mus)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInRat/$base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 2 $f > \
                        linSpecRep.notInMouse/$base.out.spec
    end
    #  That produced no difference at all between those two targets.
    #  Have requested confirmation from Arian

#  BLASTZ MOUSE (DONE - 2003-08-07 - Hiram)

    ssh eieio
    cd /cluster/bluearc/mm3.RM030619

    foreach f (rmsk.spec/*.out_rat_hum)
	set base = $f:t:r:r
	echo $base.out.spec
	/cluster/bin/scripts/extractLinSpecReps 2 $f > \
		linSpecRep.notInHuman/$base.out.spec
    end

    ssh eieio
    mkdir -p /cluster/data/hg16/bed/blastz.mm3
    cd /cluster/data/hg16/bed/blastz.mm3

    cat << '_EOF_' > DEF
# mouse vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.17/build34/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.17/build34/linSpecRep.notInMouse
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Mouse
SEQ2_DIR=/iscratch/i/mm3.RM030619/mixedNib/
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/mm3.RM030619/linSpecRep.notInHuman/
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/store4/gs.17/build34/bed/blastz.mm3

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

# Save the DEF file in the current standard place
    DS=`date -I`
    cp DEF ~angie/hummus/DEF.mm3-hg16.$DS

    ssh kk
    cd ~hg16/bed/blastz.mm3
    cd /cluster/data/hg16/bed/blastz.mm3

    # source the DEF file to establish environment for following commands
    bash
    . ./DEF

    # follow the next set of directions slavishly
    mkdir -p $BASE/run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > $BASE/run/j

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    sh $BASE/xdir.sh
    cd $BASE/run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2

    # make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
	# 39663 jobs
    para try
    para check
    para push
    # ... etc ...
    # With competition on the cluster:
# Completed: 39663 of 39663 jobs
# CPU time in finished jobs:   14365996s  239433.27m  3990.55h  166.27d  0.456 y
# IO & Wait Time:                681029s   11350.48m   189.17h    7.88d  0.022 y
# Average job time:                 379s       6.32m     0.11h    0.00d
# Longest job:                     9275s     154.58m     2.58h    0.11d
# Submission to last job:         53023s     883.72m    14.73h    0.61d

    # post-process blastz
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3
    #   source the DEF file again in case you are coming back to this
    #	(must be bash shell)

    . ./DEF
    
    # a new run directory
    mkdir -p run.1
    
    mkdir -p $BASE/lav
    
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1

    # make sure the job list is OK
    wc -l jobList
       # 312 jobs 
    head jobList

    # run on cluster
    ssh kk
    cd /cluster/data/hg16/bed/blastz.mm3/run.1
    para create jobList
    para try
    para check
    para push
    # etc.
# Completed: 339 of 339 jobs
# CPU time in finished jobs:      11666s     194.44m     3.24h    0.14d  0.000 y
# IO & Wait Time:                 69155s    1152.58m    19.21h    0.80d  0.002 y
# Average job time:                 238s       3.97m     0.07h    0.00d
# Longest job:                     1332s      22.20m     0.37h    0.02d
# Submission to last job:          1497s      24.95m     0.42h    0.02d

    # convert lav files to axt
    ssh kk
    cd /cluster/data/hg16/bed/blastz.mm3
    mkdir axtChrom
    
    # a new run directory
    mkdir run.2
    cd run.2

    # create template file for gensub2
    # usage:  blastz-chromlav2axt lav-dir axt-file seq1-dir seq2-dir
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-chromlav2axt /cluster/store4/gs.17/build34/bed/blastz.mm3/lav/$(root1) {check out line+ /cluster/store4/gs.17/build34/bed/blastz.mm3/axtChrom/$(root1).axt} /iscratch/i/gs.17/build34/bothMaskedNibs /iscratch/i/mm3.RM030619/mixedNib/
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    ls -1S /cluster/store4/gs.17/build34/bed/blastz.mm3/lav > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 42 jobs
    head jobList

    cd /cluster/data/hg16/bed/blastz.mm3/run.2
    para create jobList
    para try
    para check
    para push
    # The two crashed jobs are about chr19 and chr19_random
    #  Its chr19_random .fa file is almost all masked sequence
    #  The resulting .axt file is empty.  The chr19 is too big
#Completed: 40 of 42 jobs
#Crashed: 2 jobs
#CPU time in finished jobs:       1908s      31.80m     0.53h    0.02d  0.000 y
#IO & Wait Time:                 22178s     369.64m     6.16h    0.26d  0.001 y
#Average job time:                 602s      10.04m     0.17h    0.01d
#Longest job:                     1723s      28.72m     0.48h    0.02d
#Submission to last job:          1802s      30.03m     0.50h    0.02d
    # To fixup the chr19 axtsort problem
    # sometimes alignments are so huge that they cause axtSort to run out 
    # of memory.  Run them in two passes like this:
    ssh kkr1u00
    cd /cluster/data/hg16/bed/blastz.mm3
    set base=/cluster/data/hg16/bed/blastz.mm3
    set seq1_dir=/iscratch/i/gs.17/build34/bothMaskedNibs
    set seq2_dir=/iscratch/i/mm3.RM030619/mixedNib/
    foreach c (lav/chr19)
      pushd $c
      set chr=$c:t
      set out=axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      foreach d (*.lav)
        set smallout=$d.axt
        lavToAxt $d $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $smallout
      end
      cat `ls -1 *.lav.axt | sort -g` > $base/$out
      popd
    end

    #	Remove the empty axtChrom/chr19_random.axt file to avoid future
    #	processing errors

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3
    mkdir -p pslChrom
    set tbl = "blastzMm3"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 20 minutes
    #	chr19 came along later
    ssh kkr1u00
    set tbl = "blastzMm3"
    foreach f (axtChrom/chr19.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # Load database tables
    ssh hgwdev
    set tbl = "blastzMm3"
    cd /cluster/data/hg16/bed/blastz.mm3/pslChrom
    /cluster/bin/i386/hgLoadPsl hg16 chr*_${tbl}.psl
    # This takes 30 minutes to an hour
    # and later chr19
    /cluster/bin/i386/hgLoadPsl hg16 chr19_${tbl}.psl
    # create trackDb/human/hg16 and get a trackDb.ra file started with:
#	track blastzMm3
#	shortLabel Mouse Blastz
#	longLabel Blastz All Mouse (Feb. 03) Alignments
#	group compGeno
#	priority 130
#	visibility hide
#	color 100,50,0
#	altColor 255,240,200
#	spectrum on
#	type psl xeno mm3
#	otherDb mm3
    # remake trackDb tables

    # redo chr1 (featureBits shows 7% lower aligments than hg16)
    # (DONE 2003-09-09 kate)
    # blastz run ended prematurely -- .tmp files leftover, not moved to .out's 
    ssh kk
    cd /cluster/data/hg16/bed/blastz.mm3
    bash
    . ./DEF
    cd $BASE
    mkdir run.chr1
    # create job list for human chr1, with parasol output file validation
    ~angie/hummus/make-joblist $DEF | \
        /cluster/bin/scripts/blastz-clusterjob.pl $BASE | \
            grep 'run chr1.nib' | \
            sed -e 's#^#/cluster/bin/penn/#'  \
                > $BASE/run.chr1/spec
    grep 'chr1/' $BASE/xdir.sh > $BASE/xdir.chr1.sh
    mv raw/chr1 raw/chr1.old
    mkdir raw/chr1
    sh xdir.chr1.sh
    cd run.chr1
    para create spec
	# 2925 jobs
    para try
    para check
    para push
    # ... etc ...
    ssh eieio
    bash
    cd /cluster/data/hg16/bed/blastz.mm3
    . DEF
    mv lav/chr1 lav/chr1.old
    mkdir run.chr1.lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
        | grep 'lav chr1 ' > run.chr1.lav/jobList
    cd run.chr1.lav
    wc -l jobList
       # 25 jobs 
    head jobList
    # run on cluster
    ssh kk
    cd /cluster/data/hg16/bed/blastz.mm3/run.chr1.lav
    para create jobList
    para try
    para check
    para push
    # etc.
    
    # convert lav files to chrom axt
    /cluster/bin/scripts/blastz-chromlav2axt /cluster/data/hg16/bed/blastz.mm3/lav/chr1 /cluster/data/hg16/bed/blastz.mm3/axtChrom/chr1.axt /cluster/data/hg16/nib /cluster/data/mm3.RM030619/mixedNib

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3
    mv pslChrom/chr1_blastzMm3.psl pslChrom/chr1_blastzMm3.psl.old
    /cluster/bin/i386/axtToPsl axtChrom/chr1.axt S1.len S2.len \
                pslChrom/chr1_blastzMm3.psl
    # reload database table
    hgsql hg16 -e "drop table chr1_blastzMm3"
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/pslChrom
    /cluster/bin/i386/hgLoadPsl hg16 chr1_blastzMm3.psl

    # make chain
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain/run1
    mv chain/chr1.chain chain/chr1.chain.old
    mv out/chr1.out out/chr1.out.old
    axtFilter -notQ=chrUn_random /cluster/data/hg16/bed/blastz.mm3/axtChrom/chr1.axt | axtChain stdin \
	/cluster/data/hg16/nib \
	/cluster/data/mm3/mixedNib chain/chr1.chain > out/chr1.out 

    # sort chains
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    mv all.chain all.chain.old
    chainMergeSort run1/chain/*.chain > all.chain
    mv chain chain.old
    mkdir chain
    chainSplit chain all.chain

    # reload chr1 chain into database
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain/chain
    hgLoadChain hg16 chr1_chainMm3 chr1.chain 
        # Loading 510456 chains into hg16.chr1_chainMm3

    # make net
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    cd chain
    /cluster/bin/i386/chainPreNet chr1.chain /cluster/data/hg16/chrom.sizes \
                        /cluster/data/mm3/chrom.sizes ../preNet/chr1.chain
    cd ..
    cd preNet
    mv ../n1/chr1.net ../n1/chr1.net.old
    /cluster/bin/i386/chainNet chr1.chain -minSpace=1 \
                /cluster/data/hg16/chrom.sizes \
                /cluster/data/mm3/chrom.sizes ../n1/chr1.net /dev/null
    cd ..
    cp hNoClass.net hNoClass.net.old
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net

    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    netClass hNoClass.net hg16 mm3 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/mm3.RM030619/linSpecRep.notInHuman

    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    # rm -r n1 hNoClass.net

    # Make a 'syntenic' subset of these with
    mv mouseSyn.net mouseSyn.net.old
    netFilter -syn mouse.net > mouseSyn.net

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg16 netMm3 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg16 syntenyNetMm3 stdin

    # make tight subset of net
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    mv ../axtNet/chr1.axt ../axtNet/chr1.old.axt
    netToAxt mouseNet/chr1.net chain/chr1.chain /cluster/data/hg16/nib \
                /cluster/data/mm3.RM030619/mixedNib ../axtNet/chr1.axt
    mv ../axtTight/chr1.axt ../axtTight/chr1.axt.old
    cd ../axtNet
    subsetAxt chr1.axt ../axtTight/chr1.axt \
                /cluster/data/subsetAxt/coding.mat 3400

    # translate to psl
    cd ../axtTight
    axtToPsl chr1.axt ../S1.len ../S2.len ../pslTight/chr1_blastzTightMm3.psl

    # Load table into database
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/pslTight
    hgLoadPsl hg16 chr1_blastzTightMm3.psl
        # $ featureBits -chrom=chr1 hg16 chr1_blastzTightMm3.psl
        # 14052627 bases of 221562941 (6.342%) in intersection
        # hg15: 13990547 bases of 218713898 (6.397%) in intersection


    # make axtNet300
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    netSplit mouse.net mouseNet
    mv ../axtNet300/chr1.axt ../axtNet300/chr1.axt.old
    netToAxt -maxGap=300 mouseNet/chr1.net chain/chr1.chain /cluster/data/hg16/nib /cluster/data/mm3.RM030619/mixedNib ../axtNet300/chr1.axt

    # create 2-way maf file for humor alignment
    set multizDir = /cluster/data/hg16/bed/humor.2003-09-02
    cd /cluster/data/hg16
    set mouseDir = bed/blastz.mm3/axtNet300
    axtSort $mouseDir/chr1.axt $mouseDir/chr1.axt.sorted
    mv $mouseDir/chr1.axt.sorted $mouseDir/chr1.axt 
    axtToMaf $mouseDir/chr1.axt \
            /cluster/data/hg16/chrom.sizes /cluster/data/mm3/chrom.sizes \
            $multizDir/maf/chr1.mm3.maf.unfixed -tPrefix=hg16. -qPrefix=mm3.
    /cluster/bin/scripts/fixmaf.pl \
            < $multizDir/maf/chr1.mm3.maf.unfixed > $multizDir/maf/chr1.mm3.maf
    rm $multizDir/maf/chr1.mm3.maf.unfixed


# NET MOUSE BLASTZ (DONE - 2003-08-22 - Hiram)

    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg16/chrom.sizes \
                        /cluster/data/mm3/chrom.sizes ../preNet/$i
    end
    # This foreach loop will take about 15 min to execute.

    cd ..
    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg16/chrom.sizes \
                            /cluster/data/mm3/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    # memory usage 2490523648, utime 15421 s/100, stime 3665

    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    ~/bin/i386/netClass hNoClass.net hg16 mm3 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/mm3.RM030619/linSpecRep.notInHuman

    # If things look good do
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn mouse.net > mouseSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg16 netMm3 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg16 syntenyNetMm3 stdin
    # make net
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    mkdir mouseNet
    netSplit mouse.net mouseNet
    foreach n (mouseNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt mouseNet/$c.net chain/$c.chain \
		/cluster/bluearc/scratch/hg/gs.17/build34/bothMaskedNibs \
		/cluster/data/mm3.RM030619/mixedNib \
		../axtNet/$c.axt
	echo "Complete: $c.net -> $c.axt"
    end


# MAKE BLASTZ BEST MOUSE MM3 (DONE - 2003-08-26 - Hiram)

    #  IMPORTANT NOTE - This axtBest process has been replaced by the
    #  chain to net to axt process.  Note procedure below continues
    #  after the chain and nets have been produced.

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChrom
    mkdir -p /cluster/bluearc/hg16/bed/blastz.mm3/axtChrom
    
    # copy chrom axt's to bluearc, to avoid hitting fileserver too hard
    cp -p *.axt /cluster/bluearc/hg16/bed/blastz.mm3/axtChrom
    # chr19 came along later:
    cp -p chr19.axt /cluster/bluearc/hg16/bed/blastz.mm3/axtChrom

    ssh kk
    cd /cluster/data/hg16/bed/blastz.mm3
    mkdir -p axtBest pslBest
    mkdir run.3
    cd run.3

    # create script to filter files 
    cat << '_EOF_' > doBestAxt
#!/bin/csh -f
# usage: doBestAxt chr axt-file best-file psl-file
/cluster/bin/i386/axtBest $2 $1 $3 -minScore=300
sleep 1
/cluster/bin/i386/axtToPsl $3 /cluster/data/hg16/bed/blastz.mm3/S1.len \
	/cluster/data/hg16/bed/blastz.mm3/S2.len $4
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x doBestAxt
    cd ../axtChrom
    ls -1S | sed 's/.axt$//' > ../run.3/chrom.list
    cd ../run.3

    # create template for cluster job
    cat << '_EOF_' > gsub
#LOOP
doBestAxt $(root1) {check in line+ /cluster/bluearc/hg16/bed/blastz.mm3/axtChrom/$(root1).axt} {check out line+ /cluster/data/hg16/bed/blastz.mm3/axtBest/$(root1).axt} {check out line+  /cluster/data/hg16/bed/blastz.mm3/pslBest/$(root1)_blastzBestMm3.psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 41 jobs
    head jobList

    ssh kk
    cd /cluster/data/hg16/bed/blastz.mm3
    cd run.3
    para create jobList
    para try
    para check
    para push
    #  With the chr19 situation, went back and reran this situation.
    #	for some unknown reason the first time it had 9 failed jobs:
Completed: 32 of 41 jobs
Crashed: 9 jobs
CPU time in finished jobs:        827s      13.78m     0.23h    0.01d  0.000 y
IO & Wait Time:                  1299s      21.65m     0.36h    0.02d  0.000 y
Average job time:                  66s       1.11m     0.02h    0.00d
Longest job:                      361s       6.02m     0.10h    0.00d
Submission to last job:          1195s      19.92m     0.33h    0.01d
    # And then rerunning those 9 failed jobs, only chr19 failed:
Completed: 8 of 9 jobs
Crashed: 1 jobs
CPU time in finished jobs:        748s      12.47m     0.21h    0.01d  0.000 y
IO & Wait Time:                  2290s      38.16m     0.64h    0.03d  0.000 y
Average job time:                 380s       6.33m     0.11h    0.00d
Longest job:                     1247s      20.78m     0.35h    0.01d
Submission to last job:          1261s      21.02m     0.35h    0.01d

    #	Better yet, Jim says to be consistent, do all the chroms in
    #	this manner:
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    mkdir mouseNet
    netSplit mouse.net mouseNet
    foreach n (mouseNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt mouseNet/$c.net chain/$c.chain \
		/cluster/bluearc/scratch/hg/gs.17/build34/bothMaskedNibs \
		/cluster/data/mm3.RM030619/mixedNib \
		../axtNet/$c.axt
	echo "Complete: $c.net -> $c.axt"
    end

    mkdir -p /cluster/data/hg16/bed/blastz.mm3/axtBest
    cd /cluster/data/hg16/bed/blastz.mm3/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area (DONE 2003-09-24 kate)
    cd /cluster/data/hg16/bed/blastz.mm3/axtNet
    gzip *.axt
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg16/vsMm3/axtNet
    cp -p *.axt.gz /usr/local/apache/htdocs/goldenPath/hg16/vsMm3/axtNet
    # add README.txt file to dir, if needed

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestMm3.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestMm3.psl
	echo "Done: ${c}_blastzBestMm3.psl"
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/data/hg16/bed/blastz.mm3"
     set tbl="blastzBestMm3"
     cd $base/pslBest
     /cluster/bin/i386/hgLoadPsl hg16 chr*_${tbl}.psl

     # check results
     # the original axtBest stuff from the axtBest operation:
#  featureBits hg16 blastzBestMm3
#  1027438291 bases of 2865248791 (35.859%) in intersection
     #  After going through the chain->net->axt operation:
#  featureBits hg16 blastzBestMm3
#   991468768 bases of 2865248791 (34.603%) in intersection
     #  And finally after fixing a blastz execution problem on chr1:
#  1007362800 bases of 2865248791 (35.158%) in intersection

#  featureBits hg15 blastzBestMm3
#  1035090465 bases of 2866466359 (36.110%) in intersection


    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg16/axtBestMm3
     cd /gbdb/hg16/axtBestMm3
     foreach f (/cluster/data/hg16/bed/blastz.mm3/axtNet/chr*.axt)
       ln -s $f .
     end
     cd /cluster/data/hg16/bed/blastz.mm3/axtNet
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/hg16/axtBestMm3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('mm3','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     hgsql hg16 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql hg16 < axtInfoInserts.sql


# MAKING THE AXTTIGHT FROM AXTBEST (DONE - 2003-08-25 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtNet
    mkdir -p ../axtTight
    tcsh
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightMm3.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/pslTight
    hgLoadPsl hg16 chr*_blastzTightMm3.psl

    # copy to axt's to download area (DONE 2003-09-24 kate)
    cd /cluster/data/hg16/bed/blastz.mm3/axtTight
    gzip *.axt
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg16/vsMm3/axtTight
    cp -p *.axt.gz /usr/local/apache/htdocs/goldenPath/hg16/vsMm3/axtTight
    # add README.txt file to dir, if needed

# CHAIN MOUSE BLASTZ (DONE 2003-08-28 - Hiram)

# Run axtChain on little cluster
    ssh kkr1u00
    mkdir -p /cluster/data/hg16/bed/blastz.mm3/axtChain/run1
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg16/bed/blastz.mm3/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#    axtFilter -notQ=chrUn_random $1 | axtChain stdin

    cat << '_EOF_' > doChain
#!/bin/csh
    axtFilter -notQ=chrUn_random $1 | axtChain stdin \
	/iscratch/i/gs.17/build34/bothMaskedNibs \
	/iscratch/i/mm3.RM030619/mixedNib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    mkdir out chain

    # 41 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
Completed: 41 of 41 jobs
CPU time in finished jobs:      31379s     522.98m     8.72h    0.36d  0.001 y
IO & Wait Time:                 10761s     179.35m     2.99h    0.12d  0.000 y
Average job time:                1028s      17.13m     0.29h    0.01d
Longest job:                    10327s     172.12m     2.87h    0.12d
Submission to last job:         10327s     172.12m     2.87h    0.12d

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain

    # these steps take ~20 minutes
    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg16 ${c}_chainMm3 $i
        echo done $c
    end

# NET MOUSE BLASTZ (DONE - 2003-08-22 - Hiram)

    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg16/chrom.sizes \
                        /cluster/data/mm3/chrom.sizes ../preNet/$i
    end
    # This foreach loop will take about 15 min to execute.

    cd ..
    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg16/chrom.sizes \
                            /cluster/data/mm3/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    # memory usage 2490523648, utime 15421 s/100, stime 3665

    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    ~/bin/i386/netClass hNoClass.net hg16 mm3 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInMouse \
	-qNewR=/cluster/bluearc/mm3.RM030619/linSpecRep.notInHuman

    # If things look good do
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn mouse.net > mouseSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg16 netMm3 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg16 syntenyNetMm3 stdin

    # Add entries for net and chain to human/hg16 trackDb


#  BLASTZ RAT  (DONE - 2003-08-07 - Hiram)

    ssh eieio
    mkdir -p /cluster/data/hg16/bed/blastz.rn3
    cd /cluster/data/hg16/bed/blastz.rn3

    cat << '_EOF_' > DEF
# rat vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.17/build34/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/gs.17/build34/linSpecRep.notInRat
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Rat
SEQ2_DIR=/iscratch/i/rn3/bothMaskedNibs
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/store4/gs.17/build34/bed/blastz.rn3

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

# Save the DEF file in the current standard place
    DS=`date -I`
    cp DEF ~angie/hummus/DEF.rn3-hg16.$DS

    ssh kk
    cd /cluster/data/hg16/bed/blastz.rn3

    # source the DEF file to establish environment for following commands
    . ./DEF

    # follow the next set of directions slavishly
    mkdir -p $BASE/run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > $BASE/run/j

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    sh $BASE/xdir.sh
    cd $BASE/run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2

    # make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
	# 39663 jobs
    para try
    para check
    para push
    # ... etc ...
# Completed: 41697 of 41697 jobs
# CPU time in finished jobs:   14155946s  235932.43m  3932.21h  163.84d  0.449 y
# IO & Wait Time:               1005629s   16760.49m   279.34h   11.64d  0.032 y
# Average job time:                 364s       6.06m     0.10h    0.00d
# Longest job:                     4310s      71.83m     1.20h    0.05d
# Submission to last job:         35086s     584.77m     9.75h    0.41d


    # post-process blastz
    ssh kk
    cd /cluster/data/hg16/bed/blastz.rn3
    #   source the DEF file again in case you are coming back to this
    #	(must be bash shell)

    . ./DEF
    
    # a new run directory
    mkdir -p run.1
    
    mkdir -p $BASE/lav
    
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1

    # make sure the job list is OK
    wc -l jobList
       # 339 jobs 
    head jobList

    # run on cluster
    ssh kk
    cd /cluster/data/hg16/bed/blastz.rn3/run.1
    para create jobList
    para try
    para check
    para push
    # etc.
# Completed: 339 of 339 jobs
# CPU time in finished jobs:       6562s     109.37m     1.82h    0.08d  0.000 y
# IO & Wait Time:                154475s    2574.58m    42.91h    1.79d  0.005 y
# Average job time:                 475s       7.92m     0.13h    0.01d
# Longest job:                      924s      15.40m     0.26h    0.01d
# Submission to last job:           933s      15.55m     0.26h    0.01d

    # convert lav files to axt
    ssh kk
    cd /cluster/data/hg16/bed/blastz.rn3
    mkdir axtChrom
    
    # a new run directory
    mkdir run.2
    cd run.2

    # create template file for gensub2
    # usage:  blastz-chromlav2axt lav-dir axt-file seq1-dir seq2-dir
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-chromlav2axt /cluster/store4/gs.17/build34/bed/blastz.rn3/lav/$(root1) {check out line+ /cluster/store4/gs.17/build34/bed/blastz.rn3/axtChrom/$(root1).axt} /iscratch/i/gs.17/build34/bothMaskedNibs /iscratch/i/rn3/bothMaskedNibs
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    ls -1S /cluster/store4/gs.17/build34/bed/blastz.rn3/lav > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 42 jobs
    head jobList

    para create jobList
    para try
    para check
    para push
    # ... etc ...
    #  The crashed job is again chr19_random
# Completed: 41 of 42 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:       1507s      25.12m     0.42h    0.02d  0.000 y
# IO & Wait Time:                 17520s     292.00m     4.87h    0.20d  0.001 y
# Average job time:                 464s       7.73m     0.13h    0.01d
# Longest job:                     1214s      20.23m     0.34h    0.01d
# Submission to last job:          1214s      20.23m     0.34h    0.01d

    #	Remove the empty axtChrom/chr19_random.axt file to avoid future
    #	processing errors

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3
    mkdir -p pslChrom
    set tbl = "blastzRn3"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 20 minutes

    # Load database tables
    ssh hgwdev
    set tbl = "blastzRn3"
    cd /cluster/data/hg16/bed/blastz.rn3/pslChrom
    /cluster/bin/i386/hgLoadPsl hg16 chr*_${tbl}.psl
    # This takes 30 minutes to an hour
    #	New entry in human/hg16/trackDb.ra
#	track blastzRn3
#	shortLabel Rat Blastz
#	longLabel Merged Blastz Rat (June 03) Alignments
#	group compGeno
#	priority 142
#	visibility hide
#	color 100,50,0
#	altColor 255,240,200
#	spectrum on
#	type psl xeno rn3
#	otherDb rn3

# MAKE BLASTZ BEST RAT RN3 (DONE - 2003-08-08 - Hiram - Redone 08-26)

    # IMPORTANT NOTE - this axtBest process has been replaced by
    #	the chain -> net -> netToAxt process.  So, after chains and
    #	nets have been created, pick up this best process below.

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtChrom
    mkdir -p /cluster/bluearc/hg16/bed/blastz.rn3/axtChrom
    
    # copy chrom axt's to bluearc, to avoid hitting fileserver too hard
    cp -p *.axt /cluster/bluearc/hg16/bed/blastz.rn3/axtChrom

    ssh kk
    cd /cluster/data/hg16/bed/blastz.rn3
    mkdir -p axtBest pslBest
    mkdir run.3
    cd run.3

    # create script to filter files 
    cat << '_EOF_' > doBestAxt
#!/bin/csh -f
# usage: doBestAxt chr axt-file best-file psl-file
/cluster/bin/i386/axtBest $2 $1 $3 -minScore=300
sleep 1
/cluster/bin/i386/axtToPsl $3 /cluster/data/hg16/bed/blastz.rn3/S1.len \
	/cluster/data/hg16/bed/blastz.rn3/S2.len $4
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x doBestAxt
    cd ../axtChrom
    ls -1S | sed 's/.axt$//' > ../run.3/chrom.list
    cd ../run.3

    # create template for cluster job
    cat << '_EOF_' > gsub
#LOOP
doBestAxt $(root1) {check in line+ /cluster/bluearc/hg16/bed/blastz.rn3/axtChrom/$(root1).axt} {check out line+ /cluster/data/hg16/bed/blastz.rn3/axtBest/$(root1).axt} {check out line+  /cluster/data/hg16/bed/blastz.rn3/pslBest/$(root1)_blastzBestRn3.psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 41 jobs
    head jobList

    cd /cluster/data/hg16/bed/blastz.rn3
    cd run.3
    para create jobList
    para try
    para check
    para push
        # 106 minutes, almost all I/O time:
# Completed: 41 of 41 jobs
# CPU time in finished jobs:       2225s      37.09m     0.62h    0.03d  0.000 y
# IO & Wait Time:                 36349s     605.81m    10.10h    0.42d  0.001 y
# Average job time:                 941s      15.68m     0.26h    0.01d
# Longest job:                     6415s     106.92m     1.78h    0.07d
# Submission to last job:          6417s     106.95m     1.78h    0.07d

    #	Better yet, Jim says to be consistent, do all the chroms in
    #	this manner:
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain
    mkdir ratNet
    netSplit rat.net ratNet

    mkdir ../axtNet
    foreach n (ratNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt -maxGap=25 ratNet/$c.net chain/$c.chain \
		/cluster/bluearc/scratch/hg/gs.17/build34/bothMaskedNibs \
		/cluster/bluearc/rat/rn3/softNib \
		../axtNet/$c.axt
	echo "Complete: $c.net -> $c.axt"
    end

    mkdir -p /cluster/data/hg16/bed/blastz.rn3/axtBest
    cd /cluster/data/hg16/bed/blastz.rn3/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area (DONE 2003-09-24 kate)
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtNet
    gzip *.axt
    ssh hgwdev
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg16/vsRn3/axtNet
    cd /cluster/data/hg16/bed/blastz.rn3/axtNet
    cp -p *.axt.gz /usr/local/apache/htdocs/goldenPath/hg16/vsRn3/axtNet
    # add README.txt file to dir, if needed

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestRn3.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestRn3.psl
	echo "Done: ${c}_blastzBestRn3.psl"
    end

    # Load tables
     ssh hgwdev
     cd /cluster/data/hg16/bed/blastz.rn3/pslBest
     /cluster/bin/i386/hgLoadPsl hg16 chr*_blastzBestRn3.psl

     # check results
#  Via the netToAxt process:
#    featureBits hg16 blastzBestRn3
#    976121391 bases of 2865248791 (34.068%) in intersection
#  With the original axtBest process, before the netToAxt process:
#    featureBits hg16 blastzBestRn3
#    1002119325 bases of 2865248791 (34.975%) in intersection

#  Hg15 results:
#    featureBits hg15 blastzBestRn3
#    992724355 bases of 2866466359 (34.632%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg16/axtBestRn3
     cd /gbdb/hg16/axtBestRn3
     ln -s /cluster/data/hg16/bed/blastz.rn3/axtNet/chr*.axt .

     cd /cluster/data/hg16/bed/blastz.rn3/axtNet
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/hg16/axtBestRn3/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('rn3','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     #	Already done above.  This table needs definition only once
     # hgsql hg16 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql hg16 < axtInfoInserts.sql


# MAKING RAT AXTTIGHT FROM AXTBEST (DONE - 2003-08-26 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtNet
    mkdir -p ../axtTight
    tcsh
    foreach i (*.axt)
      echo $i
      subsetAxt  $i ../axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    end

    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightRn3.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.rn3/pslTight
    hgLoadPsl hg16 chr*_blastzTightRn3.psl

    # copy  axt's to download area (DONE 2003-09-24 kate)
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtTight
    gzip *.axt
    ssh hgwdev
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg16/vsRn3/axtTight
    cd /cluster/data/hg16/bed/blastz.rn3/axtTight
    cp -p *.axt.gz /usr/local/apache/htdocs/goldenPath/hg16/vsRn3/axtTight
    # add README.txt file to dir, if needed

# CHAIN RAT BLASTZ (DONE 2003-08-08 - Hiram)

# Run axtChain on little cluster
    ssh kkr1u00
    cd /cluster/data/hg16/bed/blastz.rn3
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/hg16/bed/blastz.rn3/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#    axtFilter -notQ=chrUn_random $1 | axtChain stdin

    cat << '_EOF_' > doChain
#!/bin/sh
axtFilter $1 | axtChain stdin \
	/iscratch/i/gs.17/build34/bothMaskedNibs \
	/iscratch/i/rn3/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    mkdir out chain

    # 41 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
    # With only 6 CPUs available:
# Completed: 40 of 40 jobs
# CPU time in finished jobs:      21791s     363.19m     6.05h    0.25d  0.001 y
# IO & Wait Time:                 12491s     208.18m     3.47h    0.14d  0.000 y
# Average job time:                 857s      14.28m     0.24h    0.01d
# Longest job:                     2724s      45.40m     0.76h    0.03d
# Submission to last job:          5875s      97.92m     1.63h    0.07d

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain
    /cluster/bin/i386/chainMergeSort run1/chain/*.chain > all.chain
    /cluster/bin/i386/chainSplit chain all.chain
    # these steps take ~20 minutes
    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg16 ${c}_chainRn3 $i
        echo done $c
    end

CREATE bigZips stuff for release (DONE 2003-08-01, 08-06, 08-08 - Hiram)

    # make bigZips/mrna.zip (markd 8 aug 2003)
    # on hgbeta: 
    cd /genbank
    ./bin/i386/gbGetSeqs -get=seq -db=hg16 -native genbank mrna download/hg16/bigZips/mrna.fa 
    zip download/hg16/bigZips/mrna.zip  download/hg16/bigZips/mrna.fa 
    rm download/hg16/bigZips/mrna.fa 

    ssh hgwdev
    #  This stuff has to work in a different way because this stuff
    #	updates on a daily basis. - (DONE 2003-08-09 - Hiram)
    cd /usr/local/apache/htdocs/goldenPath/hg16/bigZips
    featureBits hg16 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits hg16 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits hg16 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa

# MAKING MOUSE AND RAT SYNTENY (MOUSE done 2003-09-16)(RAT Done 2003-08-28)

ssh hgwdev
mkdir -p /cluster/data/hg16/bed/syntenyMm3
cd /cluster/data/hg16/bed/syntenyMm3
# Copy all the needed scripts from /cluster/data/hg15/bed/syntenyMouse
cp -p /cluster/data/hg15/bed/syntenyMouse/*.pl .

./syntenicBest.pl -db=hg16 -table=blastzBestMm3
./smooth.pl
./joinsmallgaps.pl
./fillgap.pl -db=hg16 -table=blastzBestMm3
./synteny2bed.pl
hgLoadBed hg16 syntenyMm3 ucsc100k.bed

#	And for the Rat, same thing, different directory:
mkdir ../syntenyRn3
cd ../syntenyRn3
../syntenyMm3/syntenicBest.pl -db=hg16 -table=blastzBestRn3
#	smooth.pl overwrites genomeBest2phase created by the previous
#	run of this above.  Runs quickly.
../syntenyMm3/smooth.pl
# joinsmallgaps.pl overwrites genomeBest3phase created above. Runs quickly.
../syntenyMm3/joinsmallgaps.pl
# fillgap.pl creates genomeBestFinal
../syntenyMm3/fillgap.pl -db=hg16 -table=blastzBestRn3
# synteny2bed.pl creates ucsc100k.bed
../syntenyMm3/synteny2bed.pl
hgLoadBed hg16 syntenyRn3 ucsc100k.bed
# Loaded 1537 elements

# NET RAT BLASTZ (WORKING - 2003-08-11 - Hiram)

    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg16/chrom.sizes \
                        /cluster/data/rn3/chrom.sizes ../preNet/$i
    end
    # This foreach loop will take about 15 min to execute.

    cd ..
    mkdir n1 
    cd preNet
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=1 /cluster/data/hg16/chrom.sizes \
                            /cluster/data/rn3/chrom.sizes ../n1/$n /dev/null
    end

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    # memory usage 2511495168, utime 15658 s/100, stime 3383

    # The netClass operations requires an "ancientRepeat" table to exist
    # in either hg16 or rn3.  So, create the table:

    ssh hgwdev
    mkdir -p /cluster/data/hg16/bed/ancientRepeat
    cd /cluster/data/hg16/bed/ancientRepeat
    # mysqldump needs write permission to this directory
    # and you need to use your read/write enabled user with password
    chmod 777 .
    mysqldump --user=<r/w user> --password=<r/w pass> --all --tab=. hg16 \
	ancientRepeat
    chmod 775 .
    hgsql hg16 < ancientRepeat.sql
    mysqlimport -u<r/w user> -p<r/w pass> hg16 ancientRepeat.txt
    # This is a hand curated table obtained from Arian.
	
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain
    /cluster/bin/i386/netClass hNoClass.net hg16 rn3 mouse.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInRat \
	-qNewR=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman

    # If things look good do
    ssh eieio
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn mouse.net > mouseSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain
    netFilter -minGap=10 mouse.net |  hgLoadNet hg16 netRn3 stdin
    netFilter -minGap=10 mouseSyn.net | hgLoadNet hg16 syntenyNetRn3 stdin

    # Add entries for net and chain to human/hg16 trackDb


# Make Known Genes Track

  This task has many steps and currently it is described by two documents:

 	1. makeProteins072003.doc

 	   describes how the protein databases, biosql072003 and proteins072003,
 	   were built

 	2. makeKgHg16.doc

	   describes how the Known Genes related database tables
	   were built for hg16.  makeKgHg16.doc could be merged 
 	   with makeHg16.doc after minor editing of the format style.

# LIFTING REPEATMASKER .ALIGN FILES

# for this work, I had to delete some comments that were in the .align files.
# The edited files were
#   NT_008046_01.fa.align   (around line 10586)
#   NT_008046_75.fa.align   (around line 3320)
# The lines I deleted are:
#
# These elements can be clipped out with the options is_clip or is_only.
# The latter does not run the 'normal' RepeatMasker routine and positions in the current
# .out file will not correspond with the -is_only reconstructed sequence.
#
foreach d (?{,?}/NT_??????)
  set c=$d:t
  cd $d
  echo $c to $c.fa.align
  /cluster/bin/scripts/liftRMAlign.pl $c.lft > $c.fa.align
  cd ../..
end

foreach chr (?{,?})
  cd $chr
  echo making symbolic links for chr$chr NT .fa.align files
  foreach ctg (NT_??????)
    ln -s $ctg/$ctg.fa.align
  end
  cd ..
  if (-e $chr/lift/ordered.lft) then
    echo making $chr/chr$chr.fa.align
    /cluster/bin/scripts/liftRMAlign.pl $chr/lift/ordered.lft \
      > $chr/chr$chr.fa.align
  endif
  if (-e $chr/lift/random.lft) then
    echo making $chr/chr${chr}_random.fa.align
    /cluster/bin/scripts/liftRMAlign.pl $chr/lift/random.lft \
      > $chr/chr${chr}_random.fa.align
  endif
  echo removing symbolic links for chr$chr NT .fa.align files
  rm $chr/NT_??????.fa.align
end


# TWINSCAN GENE PREDICTIONS (9/2/03 KRR)

    cd /cluster/data/hg16/bed
    rm -fr twinscan
    mkdir twinscan
    cd twinscan
    set dir = genome.cs.wustl.edu/predictions/human/NCBI34 
    set tarFile = NCBI34_Hs_09_01_03.tgz
    wget http://$dir/$tarFile
    wget http://$dir/md5sum.txt

    # check file transferred correctly
    #md5sum $tarFile | diff - md5sum.txt
    # sum file has header line, so excise it
    sed '1d' md5sum.txt > md5sum.txt.fixed
    md5sum $tarFile | diff - md5sum.txt.fixed
    tar xvfz $tarFile
    unset tarFile dir

    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y)
      # pare down protein FASTA header to id and add missing .a:
      echo chr$c
      perl -wpe 's/^(\>\S+)\s.*$/$1.a/' \
                    < chr_ptx/chr$c.ptx > chr_ptx/chr$c-fixed.fa
    end
    ldHgGene hg16 twinscan chr_gtf/chr*.gtf -gtf
    hgPepPred hg16 generic twinscanPep chr_ptx/chr*-fixed.fa


# LOAD GENEID GENES (DONE - 2003-09-02 - Hiram)
    mkdir -p /cluster/data/hg16/bed/geneid/download
    cd /cluster/data/hg16/bed/geneid/download

    # Now download *.gtf and *.prot from 
    set dir = genome.imim.es/genepredictions/H.sapiens/golden_path_200307/geneid_v1.1/
    foreach c (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un)
      wget http://$dir/chr$c.gtf
      wget http://$dir/chr${c}_random.gtf
      wget http://$dir/chr$c.prot
      wget http://$dir/chr${c}_random.prot
    end
    wget http://$dir/readme
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
      echo "done $f"
    end
    cd ..
    ldHgGene hg16 geneid download/*.gtf -exon=CDS
#	Read 32255 transcripts in 281180 lines in 40 files
#	  32255 groups 40 seqs 1 sources 3 feature types
#	32255 gene predictions
    hgPepPred hg16 generic geneidPep download/*-fixed.prot


# HUMAN/MOUSE/RAT ALIGMNMENT USING HUMOR(MULTIZ) (IN PROGRESS 2003-0829 kate)
# Multiple alignment with Mm3, Rn3

    ssh eieio

    # make mouse axtNet300
    cd /cluster/data/hg16/bed/blastz.mm3/axtChain/mouseNet
    mkdir -p ../../axtNet300
    foreach f (chr*.net)
        set c = $f:r
        echo "mouse axtNet300 on $c"
        netToAxt -maxGap=300 $c.net ../chain/$c.chain /cluster/data/hg16/nib /cluster/data/mm3.RM030619/mixedNib ../../axtNet300/$c.axt
    end

    # make rat axtNet300
    cd /cluster/data/hg16/bed/blastz.rn3/axtChain/ratNet
    mkdir -p ../../axtNet300
    foreach f (chr*.net)
        set c = $f:r
        echo "rat axtNet300 on $c"
        netToAxt -maxGap=300 $c.net ../chain/$c.chain /cluster/data/hg16/nib /cluster/data/rn3/nib ../../axtNet300/$c.axt
    end

    # create 2-way maf files
    #set multizDir = /cluster/data/hg16/bed/humor.2003-09-02
    set multizDir = /cluster/data/hg16/bed/humor.2003-09-08
    mkdir -p $multizDir/maf
    cd /cluster/data/hg16
    set mouseDir = bed/blastz.mm3/axtNet300
    set ratDir = bed/blastz.rn3/axtNet300
    foreach c (`cut -f 1 chrom.sizes`)
        echo "making mouse mafs on $c"
        # NOTE: this sort should probably be earlier in the pipeline
        axtSort $mouseDir/$c.axt $mouseDir/$c.axt.sorted
        mv $mouseDir/$c.axt.sorted $mouseDir/$c.axt 
        axtToMaf $mouseDir/$c.axt /cluster/data/hg16/chrom.sizes /cluster/data/mm3/chrom.sizes $multizDir/maf/$c.mm3.maf.unfixed -tPrefix=hg16. -qPrefix=mm3.
        /cluster/bin/scripts/fixmaf.pl \
                < $multizDir/maf/$c.mm3.maf.unfixed > $multizDir/maf/$c.mm3.maf

        echo "making rat mafs on $c"
        axtSort $ratDir/$c.axt $ratDir/$c.axt.sorted
        mv $ratDir/$c.axt.sorted $ratDir/$c.axt
        axtToMaf $ratDir/$c.axt /cluster/data/hg16/chrom.sizes /cluster/data/rn3/chrom.sizes $multizDir/maf/$c.rn3.maf.unfixed -tPrefix=hg16. -qPrefix=rn3.
        /cluster/bin/scripts/fixmaf.pl \
                < $multizDir/maf/$c.rn3.maf.unfixed > $multizDir/maf/$c.rn3.maf
        rm $multizDir/maf/*.unfixed
    end


    # copy maf files to bluearc for cluster run
    set clusterDir = /cluster/bluearc/hg16/bed
    mkdir $clusterDir/blastz.mm3/mafNet300
    cp $multizDir/maf/*.mm3.maf $clusterDir/blastz.mm3/mafNet300
    mkdir /cluster/bluearc/hg16/bed/blastz.rn3/mafNet300
    cp $multizDir/maf/*.rn3.maf $clusterDir/blastz.rn3/mafNet300

    # create scripts to run on cluster
    # run "humor"
    cd $multizDir
    mkdir hmr
    mkdir run
    cd run
cat << EOF > doHumor.kk
/cluster/bin/penn/humor.v4 $clusterDir/blastz.mm3/mafNet300/\$1.mm3.maf $clusterDir/blastz.rn3/mafNet300/\$1.rn3.maf > $multizDir/hmr/\$1.hmr.maf
EOF
    chmod +x doHumor.kk
    
cat << EOF > gsub 
#LOOP
doHumor.kk \$(root1) {check out line+ $multizDir/hmr/\$(root1).hmr.maf}
#ENDLOOP
EOF
    cd $clusterDir/blastz.mm3/mafNet300
    # NOTE: probably want a better way to make the chrom list 
    ls *.maf | awk -F. '{print $1}' > $multizDir/run/chrom.list
    cd $multizDir/run
    gensub2 chrom.list single gsub jobList

    # run jobs
    ssh kkr9u01
    #set multizDir = /cluster/data/hg16/bed/humor.2003-09-02
    set multizDir = /cluster/data/hg16/bed/humor.2003-09-08
    cd $multizDir/run
    para create jobList
    para try
    para check
    para push
    # longest job 27 minutes

    # setup external files for database reference
    ssh hgwdev
    mkdir -p /gbdb/hg16/humorMm3Rn3
    cd /gbdb/hg16/humorMm3Rn3
    foreach f ($multizDir/hmr/*.maf)
        ln -s $f .
    end

    # load into database
    cd $multizDir/hmr/*.maf
    /cluster/bin/i386/hgLoadMaf -warn hg16 humorMm3Rn3

    # Create upstream files
    ssh hgwdev
    cd /usr/local/apache/htdocs/goldenPath/hg16/humorMm3Rn3
    echo hg16 mm3 rn3 > org.txt
    foreach i (1000 2000 5000)
    featureBits hg16 refGene:upstream:$i -fa=/dev/null -bed=up.bad
    awk -F '\t' '{printf("%s\t%s\t%s\t%s\t%s\t%s\n", $1, $2, $3, substr($4, 0, 9), 0, $5)}' up.bad > up.bed
    rm up.bad
    mafFrags hg16 humorMm3Rn3 up.bed upstream$i.maf -orgs=org.txt
    rm up.bed
    end


#  MAKING BLASTZ SELF (DONE - 2003-08-08 - Hiram)

    # The procedure for lineage spec business with self is to simply
    # use the actual repeat masker output for this human assembly as
    # the lineage specific repeats for itself.  Thus, merely make
    # symlinks to the repeat masker out files and name them as expected
    # for blastz.  In this case they are called notInHuman but they
    # really mean InHuman.  Yes, it is confusing, but that's just the
    # nature of the game in this case.

    ssh eieio
    mkdir -p /cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInHuman
    cd /cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInHuman
    foreach f (../rmsk/*.fa.out)
	set base = $f:t:r:r
	echo $base.out.spec
	ln -s $f $base.out.spec
    end

    ssh eieio
    mkdir -p /cluster/data/hg16/bed/blastzSelf
    cd /cluster/data/hg16/bed/blastzSelf

    cat << '_EOF_' > DEF
# human vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Human
SEQ1_DIR=/iscratch/i/gs.17/build34/bothMaskedNibs
# not used
SEQ1_RMSK=
# not used
SEQ1_FLAG=
SEQ1_SMSK=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInHuman
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Human
SEQ2_DIR=/iscratch/i/gs.17/build34/bothMaskedNibs
# not currently used
SEQ2_RMSK=
# not currently used
SEQ2_FLAG=
SEQ2_SMSK=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/store4/gs.17/build34/bed/blastzSelf

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

# Save the DEF file in the current standard place
    DS=`date -I`
    cp DEF ~angie/hummus/DEF.hg16-hg16.$DS

    ssh kk
    cd /cluster/data/hg16/bed/blastzSelf

    # source the DEF file to establish environment for following commands
    . ./DEF

    # follow the next set of directions slavishly
    mkdir -p $BASE/run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > $BASE/run/j

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    sh $BASE/xdir.sh
    cd $BASE/run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    # 114921 j
    head j2

    # make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
	# 114921 jobs
    para try
    para check
    para push
    # ... etc ...
    #  With some cluster difficulties, bluearc hangups, etc:
Completed: 114921 of 114921 jobs
CPU time in finished jobs:   19898031s  331633.85m  5527.23h  230.30d  0.631 y
IO & Wait Time:              42606494s  710108.24m 11835.14h  493.13d  1.351 y
Average job time:                 544s       9.06m     0.15h    0.01d
Longest job:                   111877s    1864.62m    31.08h    1.29d
Submission to last job:        344744s    5745.73m    95.76h    3.99d

    # post-process blastz
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf
    #   source the DEF file again in case you are coming back to this
    #	(must be bash shell)

    . ./DEF
    
    # a new run directory
    mkdir -p run.1
    
    mkdir -p $BASE/lav
    
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1

    # make sure the job list is OK
    wc -l jobList
       # 339 jobs 
    head jobList

    # run on cluster
    ssh kk
    cd /cluster/data/hg16/bed/blastzSelf/run.1
    para create jobList
    para try
    para check
    para push
    # etc.
#Completed: 339 of 339 jobs
#CPU time in finished jobs:      21101s     351.68m     5.86h    0.24d  0.001 y
#IO & Wait Time:                 74915s    1248.58m    20.81h    0.87d  0.002 y
#Average job time:                 283s       4.72m     0.08h    0.00d
#Longest job:                     2028s      33.80m     0.56h    0.02d
#Submission to last job:          2993s      49.88m     0.83h    0.03d

    # convert lav files to axt
    ssh kk
    cd /cluster/data/hg16/bed/blastzSelf
    mkdir axtChrom
    
    # a new run directory
    mkdir run.2
    cd run.2

    # create template file for gensub2
    # usage:  blastz-chromlav2axt lav-dir axt-file seq1-dir seq2-dir
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-chromlav2axt /cluster/store4/gs.17/build34/bed/blastzSelf/lav/$(root1) {check out line+ /cluster/store4/gs.17/build34/bed/blastzSelf/axtChrom/$(root1).axt} /iscratch/i/gs.17/build34/bothMaskedNibs /iscratch/i/gs.17/build34/bothMaskedNibs
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    ls -1S /cluster/store4/gs.17/build34/bed/blastzSelf/lav > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 42 jobs
    head jobList

    cd /cluster/data/hg16/bed/blastzSelf/run.2
    para create jobList
    para try
    para check
    para push
    # We have two crashed jobs here.  The data for chr7 and chr19 is
    # too much for the processing.  Have to run those separately on
    #	the file server eieio.
Completed: 40 of 42 jobs
Crashed: 2 jobs
CPU time in finished jobs:       4737s      78.95m     1.32h    0.05d  0.000 y
IO & Wait Time:                 57154s     952.57m    15.88h    0.66d  0.002 y
Average job time:                1547s      25.79m     0.43h    0.02d
Longest job:                     7969s     132.82m     2.21h    0.09d
Submission to last job:          8029s     133.82m     2.23h    0.09d
    # Fixup chr7 and chr19 by running them in two passes like this:
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf
    set base=/cluster/data/hg16/bed/blastzSelf
    set seq1_dir=/cluster/data/hg16/nib
    set seq2_dir=/cluster/data/hg16/nib
    foreach c (lav/chr19 lav/chr7)
      pushd $c
      set chr=$c:t
      set out=axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      foreach d (*.lav)
        set smallout=$d.axt
        lavToAxt $d $seq1_dir $seq2_dir stdout \
        | axtDropSelf stdin stdout \
        | axtSort stdin $smallout
      end
      cat `ls -1 *.lav.axt | sort -g` > $base/$out
      popd
    end

    # translate sorted axt files into psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf
    #  Need to drop overlaps to eliminate diagonals
    #	DropOverlap seems to drop more than axtDropSelf above
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
	mv axtChrom/$c.axt axtChrom/$c.axt
	/cluster/bin/i386/axtDropOverlap axtChrom/$c.axt \
		/cluster/bluearc/hg16/bed/blastzSelf/axtChromDropped/$c.axt
	echo "Done: $c"
    end
    cd /cluster/bluearc/hg16/bed/blastzSelf/axtChromDropped
    gzip *.axt
    #  Needed a deliver of these right away:
    ssh hgwdev
    mkdir -p /usr/local/apache/htdocs/goldenPath/hg16/vsSelf
    cd /usr/local/apache/htdocs/goldenPath/hg16/vsSelf
    cp -p /cluster/bluearc/hg16/bed/blastzSelf/axtChromDropped/*.axt.gz .
	
    ssh eieio
    mkdir -p /cluster/data/hg16/bed/blastzSelf/pslChrom
    cd /cluster/data/hg16/bed/blastzSelf
    set tbl = "blastzSelf"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      zcat /cluster/bluearc/hg16/bed/blastzSelf/axtChromDropped/${c}.axt.gz | \
	/cluster/bin/i386/axtToPsl stdin S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	That takes about 20 minutes

XXXX Pick this up tomorrow, 03-09-12 with pslChromDroppedFix
    # Load database tables
    ssh hgwdev
    set tbl = "blastzSelf"
    cd /cluster/data/hg16/bed/blastzSelf/pslChrom
    /cluster/bin/i386/hgLoadPsl hg16 chr*_blastzSelf.psl
    # This takes 30 minutes to an hour
    # create trackDb/human/hg16 and get a trackDb.ra file started with:

    # remake trackDb tables


# PRODUCE FUGU BLAT ALIGNMENT (IN PROGRESS 2003-08-22 kate)

    # Use masked scaffolds from fr1 assembly (same sequence as
    # previous BlatFugu, however it's repeat and TRF-masked).

    # NOTE: can't access /iscratch/i from fileserver
    ssh kk
    mkdir /cluster/data/hg16/bed/blatFr1
    cd /cluster/data/hg16/bed/blatFr1
    mkdir psl 
    # next time, use N?_?????? (to pick up NG_ contigs)
    foreach f (/cluster/data/hg16/?{,?}/NT_??????/NT_??????.fa)
      set c=$f:t:r
      echo $c
      mkdir -p psl/$c
    end
    # special case for NG_002432
    mkdir -p psl/NG_002432

    # create cluster job
    cd run
    ls -1S /iscratch/i/fugu/trfFa/*.fa > fugu.lst
    ls -1S /scratch/hg/gs.17/build34/trfFa/*.fa > human.lst
cat << 'EOF' > gsub
#LOOP
/cluster/bin/i386/blat -mask=lower -qMask=lower -q=dnax -t=dnax {check in line+ $(path1)} {check in line+ $(path2)} {check out line+ /cluster/data/hg16/bed/blatFr1/psl/$(root1)/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'
    # << this line makes emacs coloring happy
    gensub2 human.lst fugu.lst gsub spec
    para create spec
       # 283798 jobs  
    para try
    para check
    para push
    para check
        # cd psl
        # count files with aligments
        # find . -not -size 427c | wc -l
        # 89878
        # count files with no aligments
        # find . -size 427c | wc -l
        # 195265

   # When cluster run is done, sort alignments
   # into chrom directory
    ssh eieio
    cd /cluster/data/hg16/bed/blatFr1
    pslCat -dir psl/N?_?????? | \
      liftUp -type=.psl stdout \
        /cluster/data/hg16/jkStuff/liftAll.lft warn stdin | \
      pslSortAcc nohead chrom temp stdin
        # 15 minutes ?
        # Processed 855648 lines into 4 temp files

    # Rename to correspond with tables and load into database:
    ssh hgwdev
    cd /cluster/data/hg16/bed/blatFr1/chrom
    rm -f chr*_blatFr1.psl
    foreach i (chr?{,?}{,_random}.psl)
        set r = $i:r
        echo $r
        mv $i ${r}_blatFr1.psl
    end
    hgLoadPsl hg16 *.psl
        # $ featureBits hg16 blatFr1 refGene:CDS
        # 12787423 bases of 2865248791 (0.446%) in intersection
        # $ featureBits hg15 blatFugu refGene:CDS
        # 12427544 bases of 2866466359 (0.434%) in intersection

    # Edit trackDb.ra to include blatFr1

    # Make fugu /gbdb/ symlink and load Fugu sequence data.
    mkdir /gbdb/hg16/fuguSeq
    cd /gbdb/hg16/fuguSeq
    ln -s /cluster/data/fr1/fugu_v3.masked.fa
    # hide .tab file
    cd /cluster/store2/tmp
    hgLoadSeq hg16 /gbdb/hg16/fuguSeq/fugu_v3.masked.fa


# MAKE BLASTZ BEST SELF (RE-DONE - 2003-08-28 - Hiram)

    #	Pick up on this process below after chain and nets have been
    #	done.  This run.3 business is obsolete

    # Consolidate AXT files to chrom level, sort, pick best, make psl.
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf/axtChrom
    mkdir -p /cluster/bluearc/hg16/bed/blastzSelf/axtChrom
    
    # copy chrom axt's to bluearc, to avoid hitting fileserver too hard
    cp -p *.axt /cluster/bluearc/hg16/bed/blastzSelf/axtChrom

    ssh kk
    cd /cluster/data/hg16/bed/blastzSelf
    mkdir -p axtBest pslBest
    mkdir run.3
    cd run.3

    # create script to filter files 
    cat << '_EOF_' > doBestAxt
#!/bin/csh -f
# usage: doBestAxt chr axt-file best-file psl-file
/cluster/bin/i386/axtBest $2 $1 $3 -minScore=300
sleep 1
/cluster/bin/i386/axtToPsl $3 /cluster/data/hg16/bed/blastzSelf/S1.len \
	/cluster/data/hg16/bed/blastzSelf/S2.len $4
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x doBestAxt
    cd ../axtChrom
    ls -1S | sed 's/.axt$//' > ../run.3/chrom.list
    cd ../run.3

    # create template for cluster job
    cat << '_EOF_' > gsub
#LOOP
doBestAxt $(root1) {check in line+ /cluster/bluearc/hg16/bed/blastzSelf/axtChrom/$(root1).axt} {check out line+ /cluster/data/hg16/bed/blastzSelf/axtBest/$(root1).axt} {check out line+  /cluster/data/hg16/bed/blastzSelf/pslBest/$(root1)_blastzBestMm3.psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 chrom.list single gsub jobList
    wc -l jobList
        # 42 jobs
    head jobList

    ssh kkr1u00
    cd /cluster/data/hg16/bed/blastzSelf/run.3
    para create jobList
    para try
    para check
    para push
Completed: 38 of 42 jobs
Crashed: 4 jobs
CPU time in finished jobs:       1884s      31.41m     0.52h    0.02d  0.000 y
IO & Wait Time:                  8421s     140.34m     2.34h    0.10d  0.000 y
Average job time:                 271s       4.52m     0.08h    0.00d
Longest job:                     2061s      34.35m     0.57h    0.02d
Submission to last job:          2277s      37.95m     0.63h    0.03d
    #  Some of these files are getting too big for this operation
    # We will have to get back to these via the chains, nets and a
    # netToAxt trick

    # Problems:
/cluster/data/hg16/bed/blastzSelf/axtBest/chr19.axt is empty
/cluster/data/hg16/bed/blastzSelf/pslBest/chr19_blastzBestMm3.psl is empty
Out of memory - request size 1564 bytes
/cluster/data/hg16/bed/blastzSelf/axtBest/chr7.axt is empty
/cluster/data/hg16/bed/blastzSelf/pslBest/chr7_blastzBestMm3.psl is empty
Out of memory - request size 634045604 bytes
/cluster/data/hg16/bed/blastzSelf/axtBest/chr1.axt is empty
/cluster/data/hg16/bed/blastzSelf/pslBest/chr1_blastzBestMm3.psl is empty
ut of memory - request size 984185908 bytes
/cluster/data/hg16/bed/blastzSelf/axtBest/chr2.axt is empty
/cluster/data/hg16/bed/blastzSelf/pslBest/chr2_blastzBestMm3.psl is empty
Out of memory - request size 973662824 bytes

    #   Here is the replacement process for the above sequence
    #	Better yet, Jim says to be consistent, do all the chroms in
    #	this manner:
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf/axtChain
    mkdir humanNet
    mkdir ../axtNet
    netSplit human.net humanNet
    foreach n (humanNet/chr*.net)
	set c=$n:t:r
	echo "netToAxt: $c.net -> $c.axt"
	rm -f ../axtNet/$c.axt
	netToAxt humanNet/$c.net chain/$c.chain \
		/cluster/bluearc/scratch/hg/gs.17/build34/bothMaskedNibs \
		/cluster/bluearc/scratch/hg/gs.17/build34/bothMaskedNibs \
		../axtNet/$c.axt
	echo "Complete: $c.net -> $c.axt"
    end

    mkdir -p /cluster/data/hg16/bed/blastzSelf/axtBest
    cd /cluster/data/hg16/bed/blastzSelf/axtBest
    ln -s ../axtNet/chr*.axt .

    #  Convert those axt files to psl
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo "processing $c.axt -> ${c}_blastzBestSelf.psl"
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestSelf.psl
	echo "Done: ${c}_blastzBestSelf.psl"
    end

    # Load tables
     ssh hgwdev
     set base="/cluster/data/hg16/bed/blastzSelf"
     set tbl="blastzBestSelf"
     cd $base/pslBest
     /cluster/bin/i386/hgLoadPsl hg16 chr*_${tbl}.psl

    # check results
    #  After going through the chain->net->axt operation:
    #	featureBits hg16 blastzBestSelf
    #	1388295977 bases of 2865248791 (48.453%) in intersection

    # Hg15 doesn't have a BestSelf, gave this a try with the following
    # result:
    #	featureBits hg15 blastzSelf
    #	Out of memory - request size 6 bytes

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/hg16/axtBestSelf
     cd /gbdb/hg16/axtBestSelf
     ln -s /cluster/data/hg16/bed/blastzSelf/axtNet/chr*.axt .

     cd /cluster/data/hg16/bed/blastzSelf/axtNet
     rm -f axtInfoInserts.sql
     touch axtInfoInserts.sql
     foreach f (/gbdb/hg16/axtBestSelf/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('hg16','Blastz Best in Genome','$chr','$f');" \
         >> axtInfoInserts.sql
     end
     #  This table has already been created above
     # hgsql hg16 < ~/kent/src/hg/lib/axtInfo.sql
     hgsql hg16 < axtInfoInserts.sql

=======
# MAKE BLASTZ BEST SELF (NOT NECESSARY - NOT USEFUL - NOT NEEDED - NOT DONE)

# MAKING CHAIN SELF BLASTZ (DONE - 2003-08-27 - Hiram)
# MAKING CHAIN SELF BLASTZ (RE-DONE - 2003-09-04 - Hiram)
#				2003-09-04 - with dropped overlap axtChrom

# Run axtChain on little cluster
    ssh kkr1u00
    mkdir -p /cluster/data/hg16/bed/blastzSelf/axtChain/run1
    cd /cluster/data/hg16/bed/blastzSelf/axtChain/run1
    mkdir out chain

  ls -1S /cluster/bluearc/hg16/bed/blastzSelf/axtChromDropped/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#	The -notQ_random (new argument to axtFilter) will omit any
#	*_random from the query.

    cat << '_EOF_' > doChain
#!/bin/csh
~/bin/i386/axtFilter -notQ_random $1 | axtChain stdin \
	/iscratch/i/gs.17/build34/bothMaskedNibs \
	/iscratch/i/gs.17/build34/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    mkdir out chain

    gensub2 input.lst single gsub jobList
	# edit jobList and remove the first one that does chr19
	#	It is a job that would fail anyway after more than an
	#	hour of run time.  It will be done separately below
    para create jobList
    # 41 jobs
    para try
    para push # ... etc ...
# Completed: 41 of 41 jobs
# CPU time in finished jobs:      27107s     451.78m     7.53h    0.31d  0.001 y
# IO & Wait Time:                 16236s     270.60m     4.51h    0.19d  0.001 y
# Average job time:                1057s      17.62m     0.29h    0.01d
# Longest job:                     4989s      83.15m     1.39h    0.06d
# Submission to last job:        240988s    4016.47m    66.94h    2.79d

    #  The chr19 recovery process:
    ssh kk
    mkdir -p /cluster/data/hg16/bed/blastzSelf/axtChain/run1.19
    cd /cluster/data/hg16/bed/blastzSelf/axtChain/run1.19
    cat << '_EOF_' > gsubQ
#LOOP
doChainQ.sh $(path2) $(path1) {check out line+ chain/$(root1).$(path2).chain} {check out line+ out/$(root1).$(path2).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChainQ.sh
#!/bin/sh
~/bin/i386/axtFilter -notQ_random -q=$1 $2 | axtChain stdin \
	/cluster/store4/gs.17/build34/nib \
	/cluster/store4/gs.17/build34/nib $3 > $4
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x doChainQ.sh
    #  This is a mistake, this should have been chr19.axt only
  ls -1S /cluster/bluearc/hg16/bed/blastzSelf/axtChromDropped/*.axt > input.lst
    pushd /cluster/data/hg16
    ls -d ?{,?} | sed -e "s/^/chr/" | grep -v chr19 \
	> /cluster/data/hg16/bed/blastzSelf/axtChain/run1.19/chrom19.lst
    popd

    mkdir out chain
    gensub2 input.lst chrom19.lst gsubQ spec19
    para create spec19
    para try
    para check
    para push
    ... etc ...
Completed: 948 of 1050 jobs
Crashed: 102 jobs
CPU time in finished jobs:      45918s     765.30m    12.75h    0.53d  0.001 y
IO & Wait Time:               1700328s   28338.80m   472.31h   19.68d  0.054 y
Average job time:                1842s      30.70m     0.51h    0.02d
Longest job:                    13247s     220.78m     3.68h    0.15d
Submission to last job:         13268s     221.13m     3.69h    0.15d
    # the "crashed 102" jobs are empty chains.
    # This mistakenly did them all, the input.lst should have been
    #	chr19 only.
# So, copy the chr19 results to the ../run1/chain result location
cp -p chain/chr19*.chain ../run1/chain

    # now on the cluster server, sort chains
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain

    # these steps take ~20 minutes
    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastzSelf/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain hg16 ${c}_chainSelf $i
        echo done $c
    end


# NET SELF BLASTZ (RE-DONE 2003-09-09 - DONE - 2003-08-27 - Hiram)

    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf/axtChain
    mkdir preNet
    cd chain
    foreach i (*.chain)
      echo preNetting $i
      /cluster/bin/i386/chainPreNet $i /cluster/data/hg16/chrom.sizes \
                        /cluster/data/hg16/chrom.sizes ../preNet/$i
    end

    # This foreach loop will take about 15 min to execute.

    cd ..
    mkdir n1 
    cd preNet
#	Probably OK to make this minSpace=10, used to be 1
    foreach i (*.chain)
      set n = $i:r.net
      echo primary netting $i
      /cluster/bin/i386/chainNet $i -minSpace=10 \
			/cluster/data/hg16/chrom.sizes \
                        /cluster/data/hg16/chrom.sizes ../n1/$n /dev/null
    end
    #  The above takes about 5 minutes

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 200167424, utime 2489 s/100, stime 161

    ssh hgwdev
    cd /cluster/data/hg16/bed/blastzSelf/axtChain
    ~/bin/i386/netClass hNoClass.net hg16 hg16 human.net \
	-tNewR=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInHuman \
	-qNewR=/cluster/bluearc/scratch/hg/gs.17/build34/linSpecRep.notInHuman

    # If things look good do
    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastzSelf/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet hg16 netSelf stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet hg16 syntenyNetSelf stdin

    # Add entries for net and chain to human/hg16 trackDb

# MAKING SELF AXTTIGHT FROM AXTCHROM (DONE - 2003-09-09 - Hiram)

    ssh eieio
    cd /cluster/data/hg16/bed/blastzSelf/axtChrom
    mkdir -p /cluster/data/hg16/bed/blastzSelf/axtTight
    tcsh

    foreach i (*.axt)
      echo $i
      subsetAxt  $i /cluster/data/hg16/bed/blastzSelf/axtTight/$i \
        ~kent/src/hg/mouseStuff/subsetAxt/90.mat 5000
    end

    # translate to psl
    cd ../axtTight
    mkdir -p ../pslTight
    foreach i (*.axt)
      set c = $i:r
      axtToPsl $i ../S1.len ../S2.len ../pslTight/${c}_blastzTightSelf.psl
      echo "Done: $i"
    end

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/hg16/bed/blastzSelf/pslTight
    hgLoadPsl hg16 chr*_blastzTightSelf.psl

# MAKING SELF SYNTENY - Can be done after Best (NEEDS TO BE REDONE 2003-09-09)

ssh hgwdev
mkdir -p /cluster/data/hg16/bed/syntenySelf
cd /cluster/data/hg16/bed/syntenySelf
# Use the scripts that were already copied to ../syntenyMm3

The first one takes 3 to 4 hours.

../syntenyMm3/syntenicBest.pl -db=hg16 -table=blastzBestSelf > synBest.out 2>&1
XXXX - Running 2003-08-27 21:32
../syntenyMm3/smooth.pl
../syntenyMm3/joinsmallgaps.pl
../syntenyMm3/fillgap.pl -db=hg16 -table=blastzBestSelf
../syntenyMm3/synteny2bed.pl
#    Load results
hgLoadBed hg16 syntenySelf ucsc100k.bed



# SGP GENE PREDICTIONS (DONE - 2003-09-14 - Hiram - to be verified)
    mkdir -p /cluster/data/hg16/bed/sgp/download
    cd /cluster/data/hg16/bed/sgp/download
    foreach f (/cluster/data/hg16/?{,?}/chr?{,?}{,_random}.fa)
      set chr = $f:t:r
      wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_200307/SGP/$chr.gtf
      wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_200307/SGP/$chr.prot
    end
    wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_200307/SGP/chrUn.gtf -O chrUn_random.gtf
    wget http://genome.imim.es/genepredictions/H.sapiens/golden_path_200307/SGP/chrUn.prot -O chrUn_random.prot
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene hg16 sgpGene download/*.gtf -exon=CDS
#  Read 43109 transcripts in 323911 lines in 39 files
#    43109 groups 39 seqs 1 sources 3 feature types
#  43109 gene predictions
    hgPepPred hg16 generic sgpPep download/*-fixed.prot
#  featureBits hg16 sgpGene
#  39781330 bases of 2865248791 (1.388%) in intersection
#  featureBits hg15 sgpGene
#  40395614 bases of 2866466359 (1.409%) in intersection

LOAD NCI60 (DONE: Fan 10/20/2003)
o - # ssh hgwdev
    cd /projects/cc/hg/mapplots/data/NCI60/dross_arrays_nci60/
    mkdir hg16
    cd hg16
    findStanAlignments hg16 ../BC2.txt.ns ../../image/cumulative_plates.011204.list.human hg16.image.psl >& hg16.image.log
    cp ../experimentOrder.txt ./
    sed -e 's/ / \.\.\//g' < experimentOrder.txt > epo.txt
    egrep -v unknown hg16.image.psl > hg16.image.good.psl
    stanToBedAndExpRecs  hg16.image.good.psl hg16.nci60.exp hg16.nci60.bed `cat epo.txt`
    hgsql hg16 < ../../scripts/nci60.sql
    echo "load data local infile 'hg16.nci60.bed' into table nci60" | hgsql hg16
    mkdir /cluster/store4/gs.17/build34/bed/nci60
    mv hg16.nci60.bed /cluster/store4/gs.17/build34/bed/nci60
    rm *.psl

LOAD AFFYRATIO [GNF done jk Sept 18, 2003] 

    # Set up cluster job to align targets to hg16
    ssh kkr1u00
    cd /cluster/data/hg16/bed
    rm -rf affyGnf/
    mkdir affyGnf
    cd affyGnf/
    mkdir -p /iscratch/i/affy
    cp /projects/compbio/data/microarray/affyGnf/sequences/HG-U95/HG-U95Av2_target /iscratch/i/affy
    iSync

    ssh kk
    cd /cluster/data/hg16/bed/affyGnf
    ls -1 /iscratch/i/affy/HG-U95Av2_target > affy.lst
    ls -1 /scratch/hg/gs.17/build34/trfFa/ > allctg.lst
    echo '#LOOP\n/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc  /scratch/hg/gs.17/build34/trfFa/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > template.sub
    gensub2 allctg.lst affy.lst template.sub para.spec
    mkdir psl
    para create para.spec

    # Actually do the job with usual para try/check/push/time etc.
#Completed: 491 of 491 jobs
#CPU time in finished jobs:       2268s      37.81m     0.63h    0.03d  0.000 y
#IO & Wait Time:                  1437s      23.94m     0.40h    0.02d  0.000 y
#Average job time:                   8s       0.13m     0.00h    0.00d
#Longest job:                       81s       1.35m     0.02h    0.00d
#Submission to last job:           272s       4.53m     0.08h    0.00d

    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create affyU95.psl.
    pslSort dirs raw.psl tmp psl
    pslReps -minCover=0.85 -minAli=0.95 raw.psl contig.psl /dev/null
    liftUp affyU95.psl ../../jkStuff/liftAll.lft warn contig.psl

    # Merge with spot data and load into database.
    ssh hgwdev
    cd /cluster/data/hg16/bed/affyGnf
    /cse/grads/sugnet/bin/i386/affyPslAndAtlasToBed affyU95.psl   /projects/compbiodata/microarray/affyGnf/human_atlas_U95_gnf.noquotes.txt affyRatio.bed affyRatio.exr >& affyPslAndAtlasToBed.log 
    hgLoadBed -sqlTable=$HOME/src/hg/lib/affyRatio.sql hg16 affyRatio affyRatio.bed
    
    # Clean up
    rm -r psl tmp err affyRatio.bed affyRatio.exr bed.tab scores.tab *.debug batch.bak contig.psl raw.psl

LOAD AffyUclaRatio [in progress jk Sept 19, 2003] 

    # Set up cluster job to align targets to hg16
    ssh kkr1u00
    cd /cluster/data/hg16/bed
    rm -rf affyUcla/
    mkdir affyUcla
    cd affyUcla/
    mkdir -p /iscratch/i/affy
    cp /projects/compbio/data/microarray/affyUcla/sequences/HG-U133AB_all /iscratch/i/affy
    iSync

    ssh kk
    cd /cluster/data/hg16/bed/affyGnf
    ls -1 /iscratch/i/affy/HG-U133AB_all > affy.lst
    ls -1 /scratch/hg/gs.17/build34/trfFa/ > allctg.lst
    echo '#LOOP\n/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc  /scratch/hg/gs.17/build34/trfFa/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > template.sub
    gensub2 allctg.lst affy.lst template.sub para.spec
    mkdir psl
    para create para.spec

    # Actually do the job with usual para try/check/push/time etc.


    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create affyU133.psl.
    pslSort dirs raw.psl tmp psl
    pslReps -minCover=0.85 -minAli=0.95 raw.psl contig.psl /dev/null
    liftUp affyU133.psl ../../jkStuff/liftAll.lft warn contig.psl

    # Merge with spot data and load into database.
    ssh hgwdev
    cd /cluster/data/hg16/bed/affyUcla
    affyUclaMergePslData affyUclaMergePslData -pslFile=affyU133.psl -affyFile=/projects/compbio/data/microarray/affyUcla/data/030602_ucla_normal_human_tissue_snapshot.txt -bedOut=affyUcla.bed -expRecordOut=affyUcla.expRecords -expFile=/projects/compbio/data/microarray/affyUcla/data/expNames -toDiffFile=toDiff.txt
    hgLoadBed -sqlTable=$HOME/src/hg/lib/affyUcla.sql hg16 affyUcla affyUcla.bed
    
    # Clean up
    rm -r psl tmp err affyUcla.bed affyUcla.expRecords bed.tab *.debug batch.bak contig.psl raw.psl

# GENE BOUNDS (RNACLUSTER) (DONE 10-05-03 Chuck)
    # Create rnaCluster table (depends on {est,mrna}OrientInfo created but not checked in)
    cd /cluster/store4/gs.17/build34/
    # Create a list of accessions that come from RAGE libraries and need to
    # be excluded. (added by Chuck Wed Nov 27 13:09:07 PST 2002)
    ~/kent/src/hg/geneBounds/clusterRna/generateRageAccList.csh hg16 \
      rage.libs
    mkdir -p bed/rnaCluster/chrom
    # Exclude accesions in the RAGE file
    foreach f (?{,?}/chr*.fa)
      set c = $f:t:r
      set out = bed/rnaCluster/chrom/$c.bed
      echo clusterRna -mrnaExclude=hg16.rage.libs hg16 /dev/null $out -chrom=$c
      clusterRna -mrnaExclude=hg16.rage.libs hg16 /dev/null $out -chrom=$c
    end

    cd bed/rnaCluster
    hgLoadBed hg16 rnaCluster chrom/*.bed > /dev/null

    
# MAKE UNIGENE ALIGNMENTS (DONE - 2003-10-09 - Hiram)
    # Download of the latest UniGene version is now automated by a 
    # cron job -- see /cluster/home/angie/crontab , 
    # /cluster/home/angie/unigeneVers/unigene.csh .  
    # If hgwdev gets rebooted, that needs to be restarted... maybe there's 
    # a more stable place to set up that cron job.  

    # substitute XXX -> the uniGene version used by SAGE, if building the 
    # uniGene/SAGE track;  or just the latest uniGene version in 
    # /projects/cc/hg/sugnet/uniGene/ , if doing uniGene alignments only.
    # set Version = XXX
    set Version = 162			(bash: export Version=162)
    cd /projects/cc/hg/sugnet/uniGene/uniGene.$Version
    gunzip Hs.seq.uniq.gz Hs.data.gz
    ../countSeqsInCluster.pl Hs.data counts.tab
    ../parseUnigene.pl Hs.seq.uniq Hs.seq.uniq.simpleHeader.fa leftoverData.tab
    # Distribute UniGene sequence to /iscratch/i/ (kkstore can see /projects)
    ssh kkstore
    set Version = 162 # same as above
    mkdir -p /iscratch/i/uniGene.$Version
    cp -p \
  /projects/cc/hg/sugnet/uniGene/uniGene.$Version/Hs.seq.uniq.simpleHeader.fa \
      /iscratch/i/uniGene.$Version
    ssh kkr1u00
    ~kent/bin/iSync
    ssh kk
    set Version = 162 # same as above
    mkdir -p /cluster/data/hg16/bed/uniGene.$Version
    cd /cluster/data/hg16/bed/uniGene.$Version
    ls -1S /scratch/hg/gs.17/build34/trfFa/*.fa > allctg.lst
    ls -1S /iscratch/i/uniGene.$Version/Hs.seq.uniq.simpleHeader.fa \
      > uniGene.lst
    cat << '_EOF_' > template.sub
#LOOP
/cluster/bin/i386/blat -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc $(path1) $(path2)  {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'

    gensub2 allctg.lst uniGene.lst template.sub para.spec
    para create para.spec
    mkdir psl
    para try
    para check
    para push
# Checking finished jobsCompleted: 491 of 491 jobs
# CPU time in finished jobs:      39689s     661.49m    11.02h    0.46d  0.001 y
# IO & Wait Time:                 38269s     637.81m    10.63h    0.44d  0.001 y
# Average job time:                 159s       2.65m     0.04h    0.00d
# Longest job:                     1805s      30.08m     0.50h    0.02d
# Submission to last job:          1972s      32.87m     0.55h    0.02d

    # ssh eieio
    set Version = 162 # same as above
    cd /cluster/data/hg16/bed/uniGene.$Version
    pslSort dirs raw.psl tmp psl >& pslSort.log
    liftUp -type=.psl stdout ../../jkStuff/liftAll.lft warn raw.psl \
    | pslReps -minCover=0.2 -sizeMatters -minAli=0.965 -nearTop=0.002 \
      stdin hg16.uniGene.lifted.pslReps.psl /dev/null
    # use hg16.uniGene.lifted.pslReps.psl for building SAGE track (next).
    
# LOAD SAGE DATA (TBD)
    ssh hgwdev
    cd ~/kent/src/hg/sage
    make
    # XXX = uniGene build for which SAGE was built -- not necessarily current!
    # Figure out the build number by peeking at this file:
    wget -O - ftp://ftp.ncbi.nih.gov/pub/sage/map/info.txt 2> /dev/null
    # Or, look at the contents of this directory:
    ls /projects/cc/hg/sugnet/uniGene
#   set Version = XXX
    set Version=162
    mkdir /projects/cc/hg/sugnet/sage/sage.$Version
    cd /projects/cc/hg/sugnet/sage/sage.$Version
    ncftp ftp://ftp.ncbi.nih.gov/pub/sage
      mget -R map/readme.txt map/info.txt extr info map/Hs
      quit
#  That downloaded about 380 Mb of data
    mkdir map
    mv Hs map
    cd map/Hs/NlaIII
    unzip -j SAGEmap_tag_ug-rel.zip
    cd ../../../extr/
    ../../scripts/summarizeCounts.pl expCounts.tab ./SAGE_*
    ../../scripts/countGenesPerTag.pl expCounts.tab allTags.count.tab
    ../../scripts/createArraysForTags.pl allTags.count.tab tagExpArrays.tab \
      ./SAGE_*
    ../../scripts/countsPerExp.pl expCounts.tab expList.tab

    cd ../map/Hs/NlaIII/ 
    cat << '_EOF_' > /tmp/t.pl
#!/usr/local/bin/perl

while (<>) {
 chomp($_);
 @p = split(/\t/, $_);
 print "$p[2]\t$p[3]\t$p[0]\n";
}
'_EOF_'
    chmod +x /tmp/t.pl

    cat SAGEmap_tag_ug-rel | /tmp/t.pl | sort | sed -e 's/ /_/g' \
      > SAGEmap_ug_tag-rel_Hs
    cd ../../../extr
    createSageSummary ../map/Hs/NlaIII/SAGEmap_ug_tag-rel_Hs \
      tagExpArrays.tab sageSummary.sage
    # Create the uniGene alignments 
    # /cluster/data/hg16/uniGene/hg16.uniGene.lifted.pslReps.psl
    # -- see "MAKE UNIGENE ALIGNMENTS" above
    # continuing from above, we are already in this extr directory
    cd /projects/cc/hg/sugnet/sage/sage.$Version/extr
    addAveMedScoreToPsls \
      /cluster/data/hg16/bed/uniGene.$Version/hg16.uniGene.lifted.pslReps.psl \
      sageSummary.sage  uniGene.wscores.bed
    hgLoadBed hg16 uniGene_2 uniGene.wscores.bed
    hgsql hg16 < ~kent/src/hg/lib/sage.sql 
    echo "load data local infile 'sageSummary.sage' into table sage" \
        | hgsql hg16
    cd ../info
    ../../scripts/parseRecords.pl ../extr/expList.tab  > sageExp.tab
    hgsql hg16 < ~/kent/src/hg/lib/sageExp.sql 
    echo "load data local infile 'sageExp.tab' into table sageExp" | hgsql hg16
XXXX need to check the track
    # update ~/kent/src/hg/makeDb/trackDb/human/hg16/uniGene_2.html 
    # with current uniGene date. 

# MAKING FOLDUTR TABLES
# First set up directory structure and extract UTR sequence on hgwdev
    ssh hgwdev
    mkdir -p /cluster/data/hg16/bed/rnaStruct
    cd /cluster/data/hg16/bed/rnaStruct
    mkdir -p utr3/split utr5/split utr3/fold utr5/fold
    utrFa hg16 knownGene utr3 utr3/utr.fa
    utrFa hg16 knownGene utr5 utr5/utr.fa

# Split up files and make files that define job.
    ssh kk
    cd /cluster/data/hg16/bed/rnaStruct
    faSplit sequence utr3/utr.fa 50000 utr3/split/s
    faSplit sequence utr5/utr.fa 50000 utr5/split/s
    ls -1 utr3/split > utr3/in.lst
    ls -1 utr5/split > utr5/in.lst
    cd utr3
    cat > gsub <<end
#LOOP
rnaFoldBig split/\$(path1) fold
#ENDLOOP
end
    cp gsub ../utr5

# Do cluster run for 3' UTRs
    gensub2 in.lst single gsub spec
    para create spec
    para try
    para push
#CPU time in finished jobs:     842416s   14040.26m   234.00h    9.75d  0.027 y
#IO & Wait Time:                 78541s    1309.02m    21.82h    0.91d  0.002 y
#Average job time:                  32s       0.53m     0.01h    0.00d
#Longest job:                     3318s      55.30m     0.92h    0.04d
#Submission to last job:          4282s      71.37m     1.19h    0.05d

# Do cluster run for 5' UTRs 
    cd ../utr5
    gensub2 in.lst single gsub spec
    para create spec
    para try
    para push
#Completed: 25808 of 25808 jobs
#CPU time in finished jobs:      51700s     861.67m    14.36h    0.60d  0.002 y
#IO & Wait Time:                114430s    1907.16m    31.79h    1.32d  0.004 y
#Average job time:                   6s       0.11m     0.00h    0.00d
#Longest job:                     1044s      17.40m     0.29h    0.01d
#Submission to last job:          1164s      19.40m     0.32h    0.01d


# Load database
    ssh hgwdev
    cd /cluster/data/hg16/bed/rnaStruct/utr5
    hgLoadRnaFold hg16 foldUtr5 fold
    cd ../utr3
    hgLoadRnaFold hg16 foldUtr3 fold

# Clean up
    rm -r split fold err batch.bak
    cd ../utr3
    rm -r split fold err batch.bak

# CREATING KNOWNtOsUPER (which enables superFamily stuff in hgNear/hgGene)
# First see if need to update superfamily data from 
# ftp server at supfam.mrc-lmb.cam.ac.uk following instructions
# in /cluster/store1/superFamily/genomes/README.ucsc.  Then
# make sure that knownToEnsembl and ensGtp tables are created, then:
    zcat /cluster/store1/superFamily/genomes/ass_26-Oct-2003.tab.gz | hgKnownToSuper hg16 hs stdin
