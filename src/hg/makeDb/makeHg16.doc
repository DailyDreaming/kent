#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on 
# NCBI build 34 (July 18, 2003 freeze)

# HOW TO BUILD A ASSEMBLY FROM NCBI FILES 
# ---------------------------------------

# Make gs.17 directory, gs.17/build34 directory, and gs.17/ffa directory.
    mkdir /cluster/store4/gs.17
    mkdir /cluster/store4/gs.17/build34
    mkdir /cluster/store4/gs.17/agp
    mkdir /cluster/store4/gs.17/ffa

#    Make a symbolic link from /cluster/store1 to this location
	
    cd /cluster/store1
    ln -s /cluster/store4/gs.17 ./gs.17

#    Make a symbolic link from your home directory to the build dir:

    ln -s /cluster/store4/gs.17/build34 ~/oo

# NCBI download site:

    ftp ftp.ncbi.nih.gov
    # user and password from /cse/guests/kent/buildHg6.doc
    cd build_34    
 
# Download all finished agp's and fa's into gs.17/agp

    mget chr*.agp
    mget chr*.fa.gz
    gunzip *.gz

# Download contig agp's into gs.17/build34

    get ref_placed.agp   # used to be in reference.agp
    get ref_unplaced.agp # used to be in reference.agp
    get DR51.agp
    get PAR.agp          # new for this build - PAR regions added to chrY
    cat ref_placed.agp ref_unplaced.agp DR51.agp > ncbi_build34.agp

# Download contig fa's into gs.17/ffa

    get ref_placed.fa.gz   # used to be in reference.fa
    get ref_unplaced.fa.gz # used to be in reference.fa
    get DR51.fa.gz
    get PAR.fa.gz          # new for this build - PAR regions added to chrY
    get sequence.inf
    cat ref_placed.fa ref_unplaced.fa DR51.fa > ncbi_build34.fa

# Download assembly related files into gs.17/build34

    get seq_contig.md
    get contig_overlaps.agp

# Download questionable join certificates file

    get e-certificates.txt
    mkdir certificates
    mv e-certificates.txt certificates

# Save a copy of the original seq_contig.md file

    cp seq_contig.md seq_contig.md.orig

# For build34, edit the seq_contig.md file to remove the alternative chr7
# sequence supplied by the Toronto group: NT_079590, NT_079591, NT_079592,
# NT_079593, NT_079594, NT_079595, NT_079596, NT_079597

# Edit seq_contig.md to make the DR51 alternative haplotype look like a
# chr6_random sequence:
# 9606  6       32491690        32629063        +       NG_002432       GI:28212469     CONTIG    DR51    1
# to 
# 9606  6|NG_002432     1       137374  +       NG_002432       GI:28212469     CONTIG  DR51      1

# Move this edited DR51 line next to other chr6_random contigs (for creating
#	the lift file)
    
# Sanity check
    /cluster/bin/i386/checkYbr build34/ncbi_build34.agp ffa/ncbi_build34.fa \
      build34/seq_contig.md

# Convert fa files into UCSC style fa files and place in "contigs" directory
# inside the gs.17/build34 directory 

    cd build34
    mkdir contigs
    /cluster/bin/i386/faNcbiToUcsc -split -ntLast ../ffa/ncbi_build34.fa \
      contigs
   
# Copy over chrM contig from previous version
    cd ~/oo
    cp -r gs.16/build33/M .
    # I'm not sure if this chM sequence needs to be in the contigs
    # directory or not.  It is missed during the simpleRepeats
    # operation.  And it is not repeat masked.

# Determine the chromosome sizes from agps

    /cluster/bin/scripts/getChromSizes ../agp

# Create lift files (this will create chromosome directory structure) and
#	inserts file
  
    /cluster/bin/scripts/createNcbiLifts -s chrom_sizes seq_contig.md .

# Create contig agp files (will create contig directory structure)
	
    /cluster/bin/scripts/createNcbiCtgAgp seq_contig.md ncbi_build34.agp .

# Create chromsome random agp files.

    /cluster/bin/scripts/createNcbiChrAgp -randomonly .

# Copy the original chrN.agp files from the gs.17/agp directory 
#    into each of the chromosome directories since they contain better 
#    gap information. Delete the comments at top from these.

# Distribute contig .fa to appropriate directory (assumes all files
# are in "contigs" directory).

    cd ~/hg16
    /cluster/bin/scripts/distNcbiCtgFa contigs .
    rm -r contigs

# Copy over jkStuff from previous build (??)
    mkdir jkStuff
    cp /cluster/store1/gs.16/build33/jkStuff/*.sh jkStuff
    /build31/jkStuff/*.csh jkStuff
    cp /cluster/store1/gs.16/build33/jkStuff/*.gsub jkStuff        

# Create contig gl files

    /cluster/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md

# Create chromosome gl files

     jkStuff/liftGl.sh contig.gl

# Files ready for repeat-masking and trf


# CREATE STS/FISH/BACENDS/CYTOBANDS DIRECTORY STRUCTURE AND SETUP 
#        (DONE 2003-07-23 Terry)

# Create directory structure to hold information for these tracks
        cd /projects/hg2/booch/psl/

# Change Makefile parameters for OOVERS, GSVERS, PREVGS, PREVOO
        make new

# Update all Makefiles with latest OOVERS and GSVERS, DATABASE, and locations of .fa files

# Makefiles in:
#     /gs.16/build33/
#     /gs.16/build33/bacends
#     /gs.16/build33/cytobands
#     /gs.16/build33/cytoPlots
#     /gs.16/build33/fish
#     /gs.16/build33/fosends
#     /gs.16/build33/g2g
#     /gs.16/build33/geneticPlots
#     /gs.16/build33/primers
#     /gs.16/build33/recombrate
#     /gs.16/build33/sts
#     /gs.16/build33/stsPlots

# Create accession_info file *****
	make accession_info.rdb


# UPDATE STS INFORMATION (DONE 2003-07-23 Terry)
# Download and unpack updated information from dbSTS:

    	cd /projects/hg2/booch/psl/update
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.sts
	wget ftp://ftp.ncbi.nih.gov/repository/dbSTS/dbSTS.aliases
	wget ftp://ftp.ncbi.nih.gov/blast/db/FASTA/sts.Z
	mv sts.Z dbSTS.FASTA.dailydump.Z
	gunzip dbSTS.FASTA.dailydump.Z

# Edit Makefile PREV variable to current sts.X version, 
#    and update STS files
        make update

# Make new directory for this info and move files there
        mkdir /cluster/store1/sts.8
        cp all.STS.fa /cluster/store1/sts.8
        cp all.primers /cluster/store1/sts.8
        cp all.primers.fa /cluster/store1/sts.8

# Copy new files to cluster
        ssh kkstore
        cd /cluster/store1/sts.8
        cp /cluster/store1/sts.8 /*.* /scratch/hg/STS

# Ask for propagation from sysadmin

# Load the sequences into the database (after database created)
	ssh hgwdev
	mkdir /gbdb/hg16/sts.8
	cd /gbdb/hg16/sts.8
	ln -s /cluster/store1/sts.8/all.STS.fa ./all.STS.fa
	ln -s /cluster/store1/sts.8/all.primers.fa ./all.primers.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg16 /gbdb/hg16/sts.8/all.STS.fa
	hgLoadRna addSeq hg16 /gbdb/hg16/sts.8/all.primers.fa

# CREATE STS MARKER ALIGNMENTS (DONE 2003-08-03 Terry)

# Create full sequence alignments
        ssh kk
        cd /cluster/home/booch/sts

# Update Makefile with latest OOVERS and GSVERS and
# run cluster jobs
        make new
        make jobList 
        para create jobList
        para push 
	# wait until alignments done
        make stsMarkers.psl

# Copy files to final destination and remove originals
        make copy.assembly
        make clean

# Create primer alignments
        ssh kk
        cd /cluster/home/booch/primers
        
# Update Makefile with latest OOVERS and GSVERS and
# run cluster jobs
        make new
        make jobList.scratch
        para create jobList
        para push

# Do an initial quick filter of results (takes a while, still) and create 
# final file - best done on eieio since disks local
	ssh eieio
	make filter
        make primers.psl

# Copy files to final destination and remove
        make copy.assembly
        make clean
        
# Create ePCR alignments
        ssh kk
        cd /cluster/home/booch/epcr

# Update Makefile with latest OOVERS and GSVERS
        make new
        make jobList
        para create jobList
        para push
        make all.epcr

# Copy files to final destination and remove
        make copy.assembly
        make clean
        

# CREATE AND LOAD STS MARKERS TRACK (DONE 2003-08-03 Terry)

# Copy in current stsInfo2.bed and stsAlias.bed files
        cd /projects/hg2/booch/psl/gs.16/build33
        cp ../update/stsInfo2.bed .
        cp ../update/stsAlias.bed .

# Create final version of sts sequence placements
        ssh kks00
        cd /projects/hg2/booch/psl/gs.16/build33/sts
        make stsMarkers.final

# Create final version of primers placements
# Make sure PRIMERS variable in Makefile is pointing to current version
        cd /projects/hg2/booch/psl/gs.16/build33/primers
        make primers.final

# Create bed file
        cd /projects/hg2/booch/psl/gs.16/build33
        make stsMap.bed

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < all_sts_primer.sql
        hgsql hg16 < all_sts_seq.sql
        hgsql hg16 < stsAlias.sql
        hgsql hg16 < stsInfo2.sql
        hgsql hg16 < stsMap.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.17/build34/sts/
        echo 'load data local infile "stsMarkers.psl.filter.lifted" into table all_sts_seq;' | hgsql hg16
	cd /projects/hg2/booch/psl/gs.17/build34/primers/
        echo 'load data local infile "primers.psl.filter.lifted" into table all_sts_primer;' | hgsql hg16
	cd /projects/hg2/booch/psl/gs.17/build34/
        echo 'load data local infile "stsAlias.bed" into table stsAlias;' | hgsql hg16
        echo 'load data local infile "stsInfo2.bed" into table stsInfo2;' | hgsql hg16
	echo 'load data local infile "stsMap.bed" into table stsMap;' | hgsql hg16


# CREATE AND LOAD RECOMBINATION RATE TRACK (DONE 2003-08-05 Terry)
# (must be done after STS Markers track) 

# Create bed file
	cd /projects/hg2/booch/psl/gs.17/build34/recombrate
	make recombRate.bed

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < recombRate.sql
        
# Load the table
	cd /projects/hg2/booch/psl/gs.17/build34/recombrate/
	echo 'load data local infile "recombRate.bed" into table recombRate;' | hgsql hg16


# UPDATE BACEND SEQUENCES (DONE 2003-07-23 Terry)

# **** Sequences were determined to not have changed since bacends.4 *****
# **** No new sequences downloaded - See makeHg15.doc for download instructions  ***** 

# Load the sequences into the database (after database created)
	ssh hgwdev
	mkdir /gbdb/hg16/bacends.4
	cd /gbdb/hg16/bacends.4
	ln -s /cluster/store1/bacends.4/BACends.fa ./BACends.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg16 /gbdb/hg16/bacends.4/BACends.fa


# BACEND SEQUENCE ALIGNMENTS (DONE 2003-08-01 Terry)
# (alignments done without RepeatMasking)

# Create full sequence alignments
	ssh kk
        cd /cluster/home/booch/bacends

# Update Makefile with latest OOVERS and GSVERS and run cluster jobs
        make new
        make jobList
        para create jobList
        para push 

# Compile alignments and lift the files (takes a while)
	ssh eieio
	make bacEnds.psl.lifted

# Copy files to final destination and remove
        make copy.assembly
        make clean # (may want to wait until sure they're OK)

# BACEND PAIRS TRACK (DONE 2003-08-01 Terry)

# Add /projects/compbiousr/booch/booch/scripts to your path

# Update Makefile with new location of pairs/singles 
# files, if necessary (DONE)
        cd /projects/hg2/booch/psl/gs.16/build33/bacends

# Make initial file of alignments
	make bacEnds.rdb
 
# Try to fish out more pairs
	make bacEndsMiss.psl

# Re-make bacEnds.rdb with new info
	make bacEnds.rdb
 
# Create bacEndPairs track file
        make bacEndPairs.bed

# Create bacEndPairsBad and bacEndPairsLong files
	make bacEndPairsBad.bed

# Create psl file to load
	make bacEnds.load.psl

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < all_bacends.sql
        hgsql hg16 < bacEndPairs.sql
        hgsql hg16 < bacEndPairsBad.sql
        hgsql hg16 < bacEndPairsLong.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.17/build34/bacends/
        echo 'load data local infile "bacEnds.load.psl" into table all_bacends;' | hgsql hg16
        echo 'load data local infile "bacEndPairs.bed" into table bacEndPairs;' | hgsql hg16
        echo 'load data local infile "bacEndPairsBad.bed" into table bacEndPairsBad;' | hgsql hg16
        echo 'load data local infile "bacEndPairsLong.bed" into table bacEndPairsLong;' | hgsql hg16


# FOSEND SEQUENCE ALIGNMENTS (DONE 2003-08-03 Terry)

# Create full sequence alignments
        ssh kk
        cd /cluster/home/booch/fosends

# Update Makefile with latest OOVERS and GSVERS and run cluster jobs
        make new
        make jobList
	para create jobList
        para push

# Compile alignments and lift the files (takes a while)
	ssh eieio
        cd /cluster/home/booch/fosends
	make fosEnds.psl.lifted

# Copy files to final destination and remove
        make copy.assembly
        make clean

# FOSEND PAIRS TRACK (DONE 2003-08-01 Terry)

# Update Makefile with location of pairs files, if necessary
        ssh kks00
        cd /projects/hg2/booch/psl/gs.16/build33/fosends

# Make initial file of alignments
	make fosEnds.rdb

# Try to fish out more pairs
	make fosEndsMiss.psl

# Re-make bacEnds.rdb with new info
	make fosEnds.rdb
 
# Create bacEndPairs track file
        make fosEndPairs.bed

# Create bacEndPairsBad and bacEndPairsLong files
	make fosEndPairsBad.bed

# Create psl file to load
	make fosEnds.load.psl

# Create database tables
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < all_fosends.sql
        hgsql hg16 < fosEndPairs.sql
        hgsql hg16 < fosEndPairsBad.sql
        hgsql hg16 < fosEndPairsLong.sql

# Load the tables
	cd /projects/hg2/booch/psl/gs.17/build34/fosends/
        echo 'load data local infile "fosEnds.load.psl" into table all_fosends;' | hgsql hg16        
        echo 'load data local infile "fosEndPairs.bed" into table fosEndPairs;' | hgsql hg16
        echo 'load data local infile "fosEndPairsBad.bed" into table fosEndPairsBad;' | hgsql hg16
        echo 'load data local infile "fosEndPairsLong.bed" into table fosEndPairsLong;' | hgsql hg16

# Load the sequences (change fosends.# to match correct location) (done for hg15 early 4/9/2003)
	mkdir /gbdb/hg15/fosends.3
	cd /gbdb/hg15/fosends.3
	ln -s /cluster/store1/fosends.3/fosEnds.fa ./fosEnds.fa
	cd /cluster/store2/tmp
	hgLoadRna addSeq hg15 /gbdb/hg15/fosends.3/fosEnds.fa
                

# UPDATE FISH CLONES INFORMATION (DONE 2003-07-23 Terry)

# Download the latest info from NCBI
        # point browser at http://www.ncbi.nlm.nih.gov/genome/cyto/cytobac.cgi?CHR=all&VERBOSE=ctg
        # change "Show details on sequence-tag" to "yes"
        # change "Download or Display" to "Download table for UNIX"
        # press Submit - save as /projects/hg2/booch/psl/fish/hbrc/hbrc.20030723.table

# Format file just downloaded.  
        cd /projects/hg2/booch/psl/fish/

# Edit Makefile to point at file just downloaded (variables HBRC, HBRCFORMAT)
        make HBRC

# (Manually added 21 results from FHCRC)

# Copy it to the new freeze location
        cp /projects/hg2/booch/psl/fish/all.fish.format /projects/hg2/booch/psl/gs.17/build34/fish/

# Save it as the new "gold" file
	cp all.fish.format all.fish.format.gold

# CREATE AND LOAD FISH CLONES TRACK (DONE 2003-08-08 Terry)
# (must be done after Coverage, STS markers track and BAC end pairs track)

# Extract the file with clone positions from database
        ssh hgwdev
        echo 'select * into outfile "/tmp/booch/clonePos.txt" from clonePos' | hgsql hg16
        mv /tmp/booch/clonePos.txt /projects/hg2/booch/psl/gs.17/build34/fish

# Get current clone/accession information
	ssh kks00
        cd /projects/hg2/booch/psl/gs.17/build34/fish
	wget http://www.ncbi.nlm.nih.gov/genome/clone/DATA/clac.out

# Create initial placement file
	cp /projects/hg2/booch/psl/gs.16/build33/fish/extract.pl . 
	make cyto.markers.bed

# Get sequences for accessions not in genome
	# goto http://www.ncbi.nlm.nih.gov/entrez/batchentrez.cgi?db=Nucleotide
	# select file "/projects/hg2/booch/psl/gs.16/build33/fish/not.found.acc
	# change output to FASTA format
	# download results to "/projects/hg2/booch/psl/gs.16/build33/fish/not.found.fa"

# Place sequences against genome
	make blat

# Try to incorporate new placements
	make cyto.markers.bed2

# Create bed file
        make fishClones.bed

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < fishClones.sql

# Load the table
	cd /projects/hg2/booch/psl/gs.17/build34/fish/
        echo 'load data local infile "fishClones.bed" into table fishClones;' | hgsql hg16
        

# CREATE AND LOAD CHROMOSOME BANDS TRACK (DONE 2003-08-08 Terry)
# (must be done after FISH Clones track) 

# Create bed file
        ssh kks00
	cd /projects/hg2/booch/psl/gs.17/build34/cytobands/
        make setBands.txt   # NOTE: may get errors if inserts file out-of-sync with pctSetBands file 
        make cytobands.pct.ranges
        make predict

# Create database table
        ssh hgwdev
        cd /projects/hg2/booch/psl/tables
        hgsql hg16 < cytoBand.sql
        
# Load the table
	cd /projects/hg2/booch/psl/gs.17/build34/cytobands/
	echo 'load data local infile "cytobands.bed" into table cytoBand;' | hgsql hg16


# CREATING DATABASE  (DONE - 2003-07-26 - Hiram)
    ssh hgwdev
    # if you haven't already:
    ln -s /cluster/store4/gs.17/build34 ~/hg16
    # Make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
#	Filesystem            Size  Used Avail Use% Mounted on
#	/dev/sda1             472G  416G   31G  93% /var/lib/mysql
    # Create the database.
    echo 'create database hg16' | hgsql hg15
    # make a semi-permanent read-only alias (add this to your .cshrc/.bashrc):
    #	(I have not seen a use for this in any procedures ? -Hiram)
    #		alias hg16 mysql -u hguser -phguserstuff -A hg16
    #	(use 'hgsql hg16' instead)
    # Initialize the relational-mrna and external sequence info tables:
    hgLoadRna new hg16
    # Copy over grp table (for track grouping) from another database:
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg15.grp" \
    | hgsql hg16

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE - 2003-07-26 - Hiram)
    ssh hgwdev
    # Enter hg16 into hgcentraltest.dbDb so test browser knows about it:
    echo 'insert into dbDb (name, description, nibPath, organism, \
	defaultPos, active, orderKey, genome, scientificName) \
	values("hg16", "July 2003", "/gbdb/hg16/nib", "Human", \
	"chr7:26828631-26938371", 1, 10, "Human", "Homo sapiens");' \
	| hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~kent/src/hg/makeDb/trackDb
    cvs up -d -P .
    # Edit that makefile to add hg16 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE LIFTALL.LFT, NCBI.LFT (DONE - 2003-07-26 - Hiram)
    cd ~/hg16
    mkdir -p jkStuff
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft
    # Create jkStuff/ncbi.lft for lifting stuff built with the NCBI assembly.
    # Note: this ncbi.lift will not lift floating contigs to chr_random coords,
    # but it will show the strand orientation of the floating contigs 
    # (grep for '|').
    mdToNcbiLift seq_contig.md jkStuff/ncbi.lft 
    # If a lift file has been edited (e.g. as in 6.2.5 above), edit ncbi.lft 
    # to match. If no step 6.2.5 then no editing needed

# REPEAT MASKING Fixups (WORKING)
    # The main REPEAT MASKING section below was run when all the
    #	sequences were still in ./contigs.  Since then, the process
    #	above was reworked such that the ./contigs no longer exist.
    #	This quick process here will run RepeatMasker on chroms 6, X,
    #	and Y due to some rearrangements.  This type of processing
    #	should be used for everything.  It is merely a difference in
    #	where the contigs are found to be split.
    #		use: foreach chrom ( ?{,?} ) for everything
    cd ~/hg16
    foreach chrom ( {6,X,Y} )
	foreach c ( $chrom/N{T,G}_* )
      set contig = $c:t
	echo "splitting ${chrom}/${contig}/${contig}.fa"
      faSplit size ${chrom}/${contig}/$contig.fa 500000 \
	${chrom}/${contig}/${contig}_ -lift=${chrom}/${contig}/$contig.lft \
	-maxN=500000
    end

    ssh kk
    cd hg16
    mkdir RMRun6XY
    rm -f RMRun6XY/RMJobs
    touch RMRun6XY/RMJobs
	# use: foreach d ( ?{,?} )  for everything
   foreach d ( {6,X,Y} )
     foreach c ( $d/N{T,G}_*/N{T,G}_*_*.fa )
        set f = $c:t
        set cc = $c:h
        set contig = $cc:t
        echo /cluster/store4/gs.17/build34/jkStuff/RMHuman \
   		/cluster/store4/gs.17/build34/${d}/${contig} $f \
   '{'check out line+ /cluster/store4/gs.17/build34/${d}/${contig}/$f.out'}' \
          >> RMRun6XY/RMJobs
      end
    end
# Checking finished jobsCompleted: 731 of 731 jobs
# CPU time in finished jobs:    5306782s   88446.36m  1474.11h   61.42d  0.168 y
# IO & Wait Time:                 35192s     586.54m     9.78h    0.41d  0.001 y
# Average job time:                7308s     121.80m     2.03h    0.08d
# Longest job:                    10067s     167.78m     2.80h    0.12d
# Submission to last job:         10084s     168.07m     2.80h    0.12d

    #- Lift up the split-contig .out's to contig-level .out's
    ssh eieio
    cd ~/hg16
    foreach d ( {6,X,Y}/N{T,G}_* )
        cd $d
        set contig = $d:t
        liftUp $contig.fa.out $contig.lft warn ${contig}_?{,?}.fa.out 
        cd ../..
    end

hgLoadOut hg16 6/*.fa.out X/*.fa.out Y/*.fa.out


# REPEAT MASKING (DONE - 2003-07-25 - Hiram)
    # Split contigs, run RepeatMasker, lift results
    # Notes: 
    # * Using new RepeatMasker in /cluster/bluearc/RepeatMasker030619
    #	Always check for new RepeatMasker before proceeding
    # * Contigs (*/NT_*/NT_*.fa) are split into 500kb chunks to make 
    #   RepeatMasker runs manageable on the cluster ==> results need lifting.
    # * For the NCBI assembly we repeat mask on the sensitive mode setting
    #   (RepeatMasker -s)

    #- Split contigs into 500kb chunks:
    ssh eieio
    cd ~/hg16
    mkdir contigOut
    cd contigOut
    mkdir split
    foreach d (../contigs/NT_* )
      set contig = $d:t
	echo "splitting $contig"
      faSplit size ../contigs/$contig 500000 split/${contig}/${contig}_ \
	-lift=split/$contig.lft -maxN=500000
    end
    #	There are two NG_* files, these were missed in the main run.
    #	Their runs were performed manually afterwards
    foreach d (../contigs/NG_* )
      set contig = $d:t
	echo "splitting $contig"
      faSplit size ../contigs/$contig 500000 split/${contig}_ \
	-lift=split/$contig.lft -maxN=500000
    end

    #- Make the run directory and job list:
    cd ~/hg16
    mkdir -p jkStuff
    #  According to RepeatMasker help file, no arguments are required to
    #	specify species because its default is set for primate (human)
    #  This run script saves the .tbl file to be sent to Arian.  He uses
    # those for his analysis.  Sometimes he needs the .cat and .align files for
    # checking problems.  They are pretty big, do not want to save them
    # if not absolutely necessary.

    cat << '_EOF_' > jkStuff/RMHuman
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/hg16/$2
/bin/cp $2 /tmp/hg16/$2/
cd /tmp/hg16/$2
/cluster/bluearc/RepeatMasker030619/RepeatMasker -ali -s $2
popd
/bin/cp /tmp/hg16/$2/$2.out ./
# if (-e /tmp/hg16/$2/$2.align) /bin/cp /tmp/hg16/$2/$2.align ./
if (-e /tmp/hg16/$2/$2.tbl) /bin/cp /tmp/hg16/$2/$2.tbl ./
# if (-e /tmp/hg16/$2/$2.cat) /bin/cp /tmp/hg16/$2/$2.cat ./
/bin/rm -fr /tmp/hg16/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg16/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg16
'_EOF_'
    chmod +x jkStuff/RMHuman
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
   foreach f ( /cluster/store4/gs.17/build34/contigOut/split/NT_*.fa )
        set f = $f:t
        echo /cluster/store4/gs.17/build34/jkStuff/RMHuman \
   		/cluster/store4/gs.17/build34/contigOut/split $f \
            '{'check out line+ /cluster/store4/gs.17/build34/contigOut/split/$f.out'}' \
          >> RMRun/RMJobs
    end

    # We have 5994 jobs in RMJobs:
    wc RMRun/RMJobs
#	5994   41958 1140350 RMRun/RMJobs

    #- Do the run
    ssh kk
    cd ~/hg16/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
    #- While that is running, you can run TRF (simpleRepeat) on the small
    # cluster.  See SIMPLE REPEAT section below

    # Manually run the two missed NG_ files:
    /cluster/store4/gs.17/build34/jkStuff/RMHuman \
	/cluster/store4/gs.17/build34/contigOut/split NG_0023920.fa \
	/cluster/store4/gs.17/build34/contigOut/split/NG_0023920.fa.out &
    /cluster/store4/gs.17/build34/jkStuff/RMHuman \
	/cluster/store4/gs.17/build34/contigOut/split NG_0024320.fa \
	/cluster/store4/gs.17/build34/contigOut/split/NG_0024320.fa.out &

# This 'Edit script first!'  note I believe was from Matt.  Looks like
# there was an after the fact move of the *.align files in hg15,
# although these were never used and were not produced in this hg16
# sequence.  I took a look at the script and it was set to ONLY move
# *.align files.  I reset it to move .* files.
# Edit script first!
# This copies lft/out/align files from the flat dir structure we were forced to use at first.
# This is a one-time only step.
    /cluster/bin/scripts/distNcbiCtgOut contigOut/split .
#  Due to missing lift entries, it failed to move the chr6 files:
# NT_0780200.fa      NT_0780201.fa.tbl  NT_0780230.fa      NT_0780231.fa.tbl
# NT_0780200.fa.out  NT_0780202.fa      NT_0780230.fa.out  NT_078023.fa.lft
# NT_0780200.fa.tbl  NT_0780202.fa.out  NT_0780230.fa.tbl
# NT_0780201.fa      NT_0780202.fa.tbl  NT_0780231.fa
# NT_0780201.fa.out  NT_078020.fa.lft   NT_0780231.fa.out
#   So, I moved those manually:
    mv contigOut/split/NT_078020* 6/NT_078020
    mv contigOut/split/NT_078023* 6/NT_078023

    #- Lift up the split-contig .out's to contig-level .out's
    ssh eieio
    cd ~/hg16
    foreach d ( ?{,?}/N{T,G}_* )
      cd $d
      set contig = $d:t
      liftUp $contig.fa.out $contig.fa.lft warn ${contig}?*.fa.out > /dev/null
      cd ../..
    end

    #- Lift up RepeatMask .out files to chromosome coordinates via
    # picked up jkStuff/liftOut2.sh from the hg15 build.  Reset the
    # liftUp command from ~kent/bin/$MACHTYPE to be from
    # /cluster/bin/i386.  Took the redirection to dev/null off of the
    # command and capture the output here to see what errors we have.

    ./jkStuff/liftOut2.sh > liftOut2.out 2>&1 &
    # It does have some errors in chrX and chrY: NT_07958[12345]
    # Same sequences are missing from each.  There is some problem
    # duplication going on here.

    #- By this point, the database should have been created (above):
    ssh hgwdev
    cd ~/hg16
    hgLoadOut hg16 ?/*.fa.out ??/*.fa.out
    # errors during this load:
Processing 2/chr2.fa.out
Strange perc. field -6.1 line 243430 of 2/chr2.fa.out
Strange perc. field -5.6 line 243430 of 2/chr2.fa.out
Strange perc. field -6.1 line 243432 of 2/chr2.fa.out
Strange perc. field -5.6 line 243432 of 2/chr2.fa.out
Processing 5/chr5.fa.out
Strange perc. field -0.3 line 4339 of 5/chr5.fa.out
Processing 19/chr19.fa.out
Strange perc. field -18.6 line 77032 of 19/chr19.fa.out

# SIMPLE REPEAT [TRF] TRACK (DONE - 2003-07-25 - Hiram)
    # Distribute contigs to /iscratch/i
    ssh kkr1u00
    rm -rf /iscratch/i/gs.17/build34/contigs
    mkdir -p /iscratch/i/gs.17/build34/contigs
    cd ~/hg16
    cp -p contigs/*.fa /iscratch/i/gs.17/build34/contigs
    # Make sure the total size looks like what you'd expect:
    du ./contigs /iscratch/i/gs.17/build34/contigs
    # 2839768 ./contigs
    # 2839768 /iscratch/i/gs.17/build34/contigs
    ~kent/bin/iSync

    # Create cluster parasol job like so:
    mkdir -p ~/hg16/bed/simpleRepeat
    cd ~/hg16/bed/simpleRepeat
    mkdir trf
    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'

    ls -1S /iscratch/i/gs.17/build34/contigs/*.fa > genome.lst
    gensub2 genome.lst single gsub spec
    para create spec
    para try
    para check
    para push
    para check
#  Completed: 472 of 472 jobs
# CPU time in finished jobs:      36177s     602.95m    10.05h    0.42d  0.001 y
# IO & Wait Time:                  2038s      33.97m     0.57h    0.02d  0.000 y
# Average job time:                  81s       1.35m     0.02h    0.00d
# Longest job:                     6992s     116.53m     1.94h    0.08d
# Submission to last job:         10703s     178.38m     2.97h    0.12d
    # When cluster run is done, a couple of extra files not caught in
    # the above sequence
    ./runTrf /cluster/store4/gs.17/build34/M/NT_999999/NT_999999.fa trf/NT_999999.bed
    # That produces an empty .bed file, mark it so:
    echo "# trf run produces nothing for this one" >> trf/NT_999999.bed

    liftUp simpleRepeat.bed ~/hg16/jkStuff/liftAll.lft warn trf/*.bed \
	> lu.out 2>&1

    # Load into the database:
    ssh hgwdev
    cd ~/hg16/bed/simpleRepeat
    /cluster/bin/i386/hgLoadBed hg16 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
#	stringTab = 0
#	Reading simpleRepeat.bed
#	Loaded 627883 elements
#	Sorted
#	Saving bed.tab
#	Loading hg16

# PROCESS SIMPLE REPEATS INTO MASK (DONE but problems - 2003-07-27 - Hiram)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh eieio
    cd ~/hg16/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd ~/hg16
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end

# MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE - 2003-07-27)
#							 but problems -Hiram
    # This used to be done right after RepeatMasking.  Now, we mask with 
    # TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above.
    ssh eieio
    cd ~/hg16

    # Make chr*.fa from contig .fa
    #  Copied chrFa.sh from hg15/jkStuff - reset  path from ~kent to
    #  /cluster for the ctgToChromFa comand
    tcsh ./jkStuff/chrFa.sh > chrFa.out 2>&1 &

    # copied these three scripts from hg15 - fixup path names to
    # reference /cluster/bin instead of ~kent/bin

    #- Soft-mask (lower-case) the contig and chr .fa's
    tcsh ./jkStuff/makeFaMasked.sh > maFaMasked.out 2>&1
    #- Make hard-masked .fa.masked files as well:
    tcsh ./jkStuff/makeHardMasked.sh > maHardMasked.out 2>&1
    #- Rebuild the nib, mixedNib, maskedNib files:
    tcsh ./jkStuff/makeNib.sh > maNib.out 2>&1

    # Make symbolic links from /gbdb/hg16/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/hg16/nib
    foreach f (/cluster/store4/gs.17/build34/nib/chr*.nib)
      ln -s $f /gbdb/hg16/nib
    end
    # Load /gbdb/hg16/nib paths into database and save size info.
    hgsql hg16  < ~/kent/src/hg/lib/chromInfo.sql
    cd ~/hg16
    hgNibSeq -preMadeNib hg16 /gbdb/hg16/nib ?{,?}/chr?{,?}{,_random}.fa
    echo "select chrom,size from chromInfo" | hgsql -N hg16 > chrom.sizes

    # Copy the masked contig fa to /iscratch and /scratch:
    ssh kkr1u00
    rm -rf /iscratch/i/gs.17/build34/trfFa
    mkdir -p /iscratch/i/gs.17/build34/trfFa
    cp -p ~/hg16/?{,?}/N{T,G}_*/N{T,G}_??????.fa /iscratch/i/gs.17/build34/trfFa
    ~kent/bin/iSync
    ssh kkstore
    rm -rf /scratch/hg/gs.17/build34/trfFa
    mkdir -p /scratch/hg/gs.17/build34/trfFa
    cp -p ~/hg16/?{,?}/N{T,G}_*/N{T,G}_??????.fa /scratch/hg/gs.17/build34/trfFa


# O+O: ASSEMBLY [GOLD], GAP, COVERAGE, MAP CONTIGS TRACKS (DONE - 2003-07-27)
#	Will need to be redone when chroms X, Y and 6 are fixed	-Hiram
# Store o+o info in database.
    ssh eieio
    cd /cluster/store4/gs.17/build34
    if (-f contig_overlaps.agp) then
      jkStuff/liftGl.sh contig.gl
    else
      ssh hgwdev
      hgGoldGapGl -noGl hg16 /cluster/store4/gs.17 build34 
      echo ""
      echo "*** Note from makeHg15.doc:"
      echo "Come back to this step later when we have contig_overlaps.agp\!"
    endif
    ssh hgwdev
    cd /cluster/store4/gs.17/build34
    if (-f contig_overlaps.agp) then
      hgGoldGapGl hg16 /cluster/store4/gs.17 build34 
      cd /cluster/store4/gs.17
      /cluster/bin/i386/hgClonePos hg16 build34 ffa/sequence.inf /cluster/store4/gs.17 -maxErr=3
    end 
    cd /cluster/store4/gs.17
    hgCtgPos hg16 build34 

# CREATE NON-STANDARD JOIN CERTIFICATES WEB PAGE AND TABLE

# Filter certificates file to only contain those relevant to current assembly

    cd ~/hg16/certificates
    /cluster/bin/scripts/extractCertificates.pl e-certificates.txt ~/hg16 \
    > e-certificates.filter.txt

# Create initial web page and table for loading into database

    hgCert e-certificates.filter.txt > certificates.html

# Donna's edits to html page

# Load cert table into database

    ssh hgwdev
    cd ~/hg16/certificates
    hgsql hg16 < kent/src/hg/lib/certificate.sql 
    echo 'load data local infile "cert.tab" into table certificate;' | hgsql hg16

# AUTO UPDATE GENBANK MRNA RUN  (WORKING - 2003-07-30 - Hiram)

    ssh eieio
    cd /cluster/store5/genbank
    # This is a new organism, edit the etc/genbank.conf file and add:
	# hg16
	hg16.genome = /scratch/hg/gs.17/build34/bothMaskedNibs/chr*.nib
	hg16.lift = /cluster/store4/gs.17/build34/jkStuff/liftAll.lft
	hg16.genbank.est.xeno.load = yes
	hg16.mgcTables.default = full
	hg16.mgcTables.mgc = all
	hg16.downloadDir = hsJul2003

    ssh eieio
    cd /cluster/store5/genbank
    nice bin/gbAlignStep -iserver=no -clusterRootDir=/cluster/bluearc/genbank \
	-srcDb=genbank -type=mrna -verbose=1 -initial hg16
# Completed: 49591 of 49591 jobs
# CPU time in finished jobs:    3853288s   64221.47m  1070.36h   44.60d  0.122 y
# IO & Wait Time:                246323s    4105.38m    68.42h    2.85d  0.008 y
# Average job time:                  83s       1.38m     0.02h    0.00d
# Longest job:                    21265s     354.42m     5.91h    0.25d
# Submission to last job:         22930s     382.17m     6.37h    0.27d

    # Load the results from the above
    ssh hgwdev
    cd /cluster/store5/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad hg16

#	To get this next one started, the above results need to be
#	moved out of the way.  These things can be removed if there are
#	no problems to debug
    ssh eieio
    cd /cluster/bluearc/genbank/work
    mv initial.hg16 initial.hg16.genbank.mrna

    ssh eieio
    cd /cluster/store5/genbank
    nice bin/gbAlignStep -iserver=no -clusterRootDir=/cluster/bluearc/genbank \
	-srcDb=refseq -type=mrna -verbose=1 -initial hg16
# Completed: 68740 of 68740 jobs
# CPU time in finished jobs:    1253290s   20888.16m   348.14h   14.51d  0.040 y
# IO & Wait Time:                309126s    5152.10m    85.87h    3.58d  0.010 y
# Average job time:                  23s       0.38m     0.01h    0.00d
# Longest job:                    13290s     221.50m     3.69h    0.15d
# Submission to last job:         13609s     226.82m     3.78h    0.16d

    # The iservers came back on-line, so use them for this run.
    #  The batch file can be found in:
    #	/cluster/store5/genbank/work/initial.hg16/align
    ssh hgwdev
    cd /cluster/store5/genbank
    nice bin/gbDbLoadStep -verbose=1 hg16

    nice bin/gbAlignStep -srcDb=genbank -type=est -verbose=1 -initial hg16

# GC PERCENT (DONE 2003-07-31 - Hiram)
     ssh hgwdev
     mkdir -p ~/hg16/bed/gcPercent
     cd ~/hg16/bed/gcPercent
     hgsql hg16  < ~/kent/src/hg/lib/gcPercent.sql
     hgGcPercent hg16 ../../nib

# MAKE HGCENTRALTEST BLATSERVERS ENTRY (DONE - 2003-07-31 - Hiram)
    ssh hgwdev
    # Substitute BBB with the correct number for the hostname:
    echo 'insert into blatServers values("hg16", "blat6", "17778", "1"); \
          insert into blatServers values("hg16", "blat6", "17779", "0");' \
    | hgsql -h genome-testdb hgcentraltest


# PRODUCING GENSCAN PREDICTIONS (DONE - 2003-08-01 - Hiram)

    ssh eieio
    mkdir -p ~/hg16/bed/genscan
    cd ~/hg16/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir -p gtf pep subopt
    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequencable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/store4/gs.17/build34/?{,?}/N{T,G}_*/N{T,G}_??????.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
        
    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    cd ~/hg16/bed/genscan
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/home/hiram/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push
# Completed: 491 of 491 jobs
# CPU time in finished jobs:     216220s    3603.67m    60.06h    2.50d  0.007 y
# IO & Wait Time:                 85597s    1426.62m    23.78h    0.99d  0.003 y
# Average job time:                 615s      10.24m     0.17h    0.01d
# Longest job:                    10986s     183.10m     3.05h    0.13d
# Submission to last job:         54395s     906.58m    15.11h    0.63d


    # Issue either one of the following two commands to check the
    # status of the cluster and your jobs, until they are done.
    parasol status
    para check
    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # to 1200000.  In build33, this was 22/NT_011519.
    #  In build34 there were NO failures !
    # Convert these to chromosome level files as so:     
    ssh eieio
    cd ~/hg16/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/N{T,G}*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/N{T,G}*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd ~/hg16/bed/genscan
    ldHgGene hg16 genscan genscan.gtf
#	Reading genscan.gtf
#	Read 42974 transcripts in 326300 lines in 1 files
#	  42974 groups 41 seqs 1 sources 1 feature types
#	42974 gene predictions
    hgPepPred hg16 generic genscanPep genscan.pep
#	Processing genscan.pep
    hgLoadBed hg16 genscanSubopt genscanSubopt.bed
#	stringTab = 0
#	Reading genscanSubopt.bed
#	Loaded 518038 elements
#	Sorted
#	Creating table definition for 
#	Saving bed.tab
#	Loading hg16


# CPGISLANDS (DONE - 2003-08-01 - Hiram)
    ssh eieio
    mkdir -p ~/hg16/bed/cpgIsland
    cd ~/hg16/bed/cpgIsland
    # Copy program as built for previous hg build:
    mkdir cpg_dist
    cp -p ~/hg15/bed/cpgIsland/cpg_dist/cpglh.exe ./cpg_dist
    #  This step used to read, but I do not immediately see the .tar
    #  file anywhere:  (there is a copy in ~/rn3/bed/cpgIsland)
    # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
    # copy the tar file to the current directory
    # tar xvf cpg_dist.tar 
    # cd cpg_dist
    # gcc readseq.c cpg_lh.c -o cpglh.exe
    # cd ..
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    foreach f (../../?{,?}/chr?{,?}{,_random}.fa.masked)
      set fout=$f:t:r:r.cpg
      echo producing $fout...
      ./cpg_dist/cpglh.exe $f > $fout
    end
    cat << '_EOF_' > filter.awk
/* chr1\t1325\t3865\t754\tCpG: 183\t64.9\t0.7 */
/* Transforms to:  (tab separated columns above, spaces below) */
/* chr1  1325    3865    CpG: 183  754  183 489  64.9  0.7 */
{
width = $3-$2;
printf("%s\t%s\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\n",
  $1,$2,$3,$5,$6,width,$6,width*$7*0.01,100.0*2*$6/($3-$2),$7);}
'_EOF_'
    awk -f filter.awk chr*.cpg > cpgIsland.bed
    ssh hgwdev
    cd ~/hg16/bed/cpgIsland
    hgLoadBed hg16 cpgIsland -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIsland.sql cpgIsland.bed
#	stringTab = 1
#	Reading cpgIsland.bed
#	Loaded 27596 elements
#	Sorted
#	Saving bed.tab
#	Loading hg16

