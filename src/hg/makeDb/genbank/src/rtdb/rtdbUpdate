#!/usr/bin/perl
#
# rtdbDownloadStep [-verbose] [-ftp-verbose]
#
# Download RTDB table dumps if new files are available, untar and process
# with rtdbImport.  Download is stored in a directory:
#
#   data/download/rtdb/$year.$month.$day/
#
# with the date being the modification date for the download mgctables.tar
# file.
#
# This also process data into
#   data/processed/rtdb/$year.$month.$day/
#
# Expects a file etc/rtdb.conf which is a PERL script setting the 
# $main::rtdbHttpUrl variable.
#
# -verbose - print details
# -http-verbose - print details of interaction with web server
#
use strict;
use warnings;
use File::Basename;
use POSIX qw(strftime);
use FindBin;
use lib "$FindBin::Bin/../lib";
use gbCommon;
use gbHttp;

my $RTDB_MD5 = "rtdb.md5";
my $RTDB_CONF = "etc/rtdb.conf";
my $RTDB_TRACKDB = "trackDbLocal_rtdb";
my $TRACKDB_SQL = "etc/trackDb.sql";

# Read the configuration file rtdb.conf and get the hash of URLs.
sub readConf($) {
    my($file) = @_;
    my %hash = ();
    open(FILE, "<$file");
    while (<FILE>) {
	chomp;
	if (!/^#/) {	
	    s/\s*//g;
	    my @s = split(/=/);
	    $hash{$s[0]} = $s[1];
	}
    }
    close(FILE);
    return %hash;
}

# The rtdb.tar.gz part of http://whereever/rtdb.tar.gz
sub tarFileName() {
    my $tarFile = $gbHttp::Url;
    $tarFile =~ /\S+\/(\S+)$/;
    $tarFile = $1;
    return $tarFile;
}

# Get date on this computer
sub getLocalDate() {
    my $time = time();
    my $modDateStr = strftime("%Y.%m.%d", localtime($time));
    return $modDateStr;
}
    
# Get the data string based on the modification date of the tables file
# on the web servers.
sub getDownloadDate() {
    my $modDate = httpGetModTime();
    my $modDateStr = strftime("%Y.%m.%d", localtime($modDate));
    if ($gbCommon::verbose) {
        prMsg("$gbHttp::Url modified on $modDateStr");
    }
    return $modDateStr;
}

# Download the tar file into a tmpdir under the download dir
sub downloadTables($) {
    my($downloadDir) = @_;
    my $tarFile = tarFileName();
    my $tableTar = "$downloadDir/tmp/$tarFile";
    unlink($tableTar);
    makeFileDir($tableTar, "02777");
    httpGetOrCheck(0, $tableTar);
}

# Extract tar file, verify contents and install them in download dir.
sub extractTar($) {
    my($downloadDir) = @_;
    my $tmpDir = "$downloadDir/tmp";
    my $oldDir = `pwd`;
    my $tarFile = tarFileName();
    chomp($oldDir);
    chdir($tmpDir) || die("can't chdir($tmpDir)");
    if ($gbCommon::verbose) {
        prMsg("extracting RTDB files");
    }

    # FIXME: at one point, absolute paths were included in the tar (which get
    # extract relatively.  Compensate for this by linking back to this dir)
    my $tarOut = callProg("tar xvfz $tarFile");
    chomp($tarOut);
    foreach my $path (split("\n", $tarOut)) {
        if (dirname($path) ne ".") {
            my $file = basename($path);
            $path =~ s/^\///; # drop leading /
            link($path, $file) || die("can't link $path $file");
        }
    }

    # check files exist before copying.
    foreach my $file (<*.bed>) {
	my $base = basename($file, ".bed");
        if (! (-e "$base.html" && -e "$base.ra")) {
            die("$file also needs to have a .html and a .ra file.");
        }
    }
    if (! -e $RTDB_MD5) {
	die("$RTDB_MD5 not found.");
    }

    # Move files into place
    my @fileList;
    foreach my $file (<*.bed>) {
	my $base = basename($file, ".bed");	
        renameFile($file, "../$file");
	renameFile("$base.html", "../$base.html");
	renameFile("$base.ra", "../$base.ra");
        push(@fileList, "$downloadDir/$file");
        push(@fileList, "$downloadDir/$base.html");
        push(@fileList, "$downloadDir/$base.ra");
    }
    renameFile($RTDB_MD5, "../$RTDB_MD5");
    push(@fileList, "$downloadDir/$RTDB_MD5");
    renameFile($tarFile, "../$tarFile");
    chdir($oldDir) || die("can't chdir($oldDir)");
    removeDir($tmpDir);    
    return @fileList;
}

# Do download for the specified data dir, if it's not there.
sub doDownload($$) {
    my($downloadDir, $force) = @_;
    my $oldDir = `pwd`;
    my $processedDir = "data/processed/rtdb/" . basename($downloadDir);
    my $md5file = "$processedDir/$RTDB_MD5";
    chomp($oldDir);

    # In case we've downloaded on this day already    
    if (-e $downloadDir) {
	my $date = basename($downloadDir);
	my @pastAttempts = glob("$downloadDir*");
	my $numAttempts = scalar(@pastAttempts);
	$downloadDir = $downloadDir . "-" . ($numAttempts + 1);
    }

    if (-e $processedDir) {
	if ($force) {
	    removeDir($processedDir);
	} else {
	    die("We have already processed into $processedDir.  Use -force to override.");
	}
    }
    makeDir($downloadDir, "02777");
    makeDir($processedDir, "02777");
    
    if ($gbCommon::verbose) {
	prMsg("donwloading RTDB in $downloadDir");
    }
    downloadTables($downloadDir);
    my @rtdbFiles = extractTar($downloadDir);
    gbChmod(@rtdbFiles);
    chdir($downloadDir) || die("can't chdir($downloadDir)");
    md5Check($RTDB_MD5);
    chdir($oldDir) || die("can't chdir($oldDir)");	
    for my $file (@rtdbFiles) {
	renameFile($file, "$processedDir/" . basename($file)) || die("Error copying $file to $processedDir");
    }
}

# Load rtdb into the database.
sub doDbLoad($$) {
    my($dir, $db) = @_;
    my $oldDir = `pwd`;
    chomp($oldDir);
    chdir($dir);
    my $trackDbSql = $oldDir . "/" . $TRACKDB_SQL;
    for my $bed (<*.bed>) {
	my $track = basename($bed, ".bed");
	runProg("hgLoadBed $db $track $bed");
	runProg("cat $track.ra >> trackDb.ra");
	runProg("echo >> trackDb.ra");
    }
    runProg("hgTrackDb \"\" $db $RTDB_TRACKDB $trackDbSql .");
    chdir($oldDir) || die("can't chdir($oldDir)");	
}

########## Entry point

my $db = undef;
my $force = 0;
while ($#ARGV >= 0) {
    my $opt = $ARGV[0];
    shift @ARGV;
    if ($opt eq "-verbose") {
        $gbCommon::verbose = 1;
    } elsif ($opt eq "-force") {
        $force = 1;
    } elsif ($opt eq "-http-verbose") {
 #       $gbHttp::verbose = 1;
    } else {
	$db = $opt;
    }
}

if ($#ARGV >= 0) {
    die("Wrong \# args: rtdbUpdate [-verbose] [-http-verbose] [-force] database");
}

# use different task dir to allow running parallel with genbank
beginTask("rtdbbuild", "download");
my %urls = readConf($RTDB_CONF);
my $url = $urls{$db};
if (!defined($url)) {
    die("Can't find database $db in $RTDB_CONF");
}
httpInit($url);

# get the download directory from the ftp file mod date and then
# check a checksum file exists, indicating completion.
my $dateStr = getDownloadDate();
my $downloadDir = "data/download/rtdb/$dateStr";
my $processedDir = "data/processed/rtdb/$dateStr";
doDownload($downloadDir, $force);
doDbLoad($processedDir, $db);

endTask();
