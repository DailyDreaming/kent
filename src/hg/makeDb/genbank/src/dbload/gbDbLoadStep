#!/usr/bin/perl
#
# gbDbLoadStep [options] database ...
#
# Load databases on the current server.
#
# $Id: gbDbLoadStep,v 1.29 2005/01/12 18:25:25 markd Exp $
#
use strict;
use warnings;
use File::Basename;
use FindBin;
use lib "$FindBin::Bin/../lib";
use gbCommon;

my $usage = 
    " gbDbLoadStep [options] database ...\n"
    . "\n"
    . " Load databases on the current server.\n"
    . "\n"
    . " Options:\n"
    . "   -workdir=work/\$host/dbload\n"
    . "   -allowLargeDeletes - override check for deleting large number of\n"
    . "    entries.\n"
    . "   -verbose\n"
    . "   -keep\n"
    . "   -initialLoad\n"
    . "   -srcDb=db - restrict load to srcDb (genbank or refseq)\n"
    . "   -type=type - restrict load to type (mrna or est)\n"
    . "   -getDownloadSeqs=days - create sequence zip files and save in\n"
    . "    \$gbRoot/download  If download/dump.time doesn't exists or time is\n"
    . "    more than \$days days old.\n"
    . "   -drop - drop tables before load.  This removes all of genbank and\n"
    . "    refseq data, not just what is being loaded.\n"
    . "   -reload - reload the selected partation of data; use with -srcDb\n"
    . "    and -type.  This does not work on ESTs, use -drop and reload\n"
    . "    all entries, which will be much faster anyway,\n"
    . "   -maxExtFileUpdate=n - update the gbSeq data for up to this many\n"
    . "    entries. This allows some entries to be changed on each update,\n"
    . "    while avoiding very long loads in a given day.  Implies\n"
    . "    -extFileUpdate\n"
    . "   -extFileUpdate - update the gbSeq table to link each sequence to\n"
    . "    the latest release.  This allows removing fasta files for older\n"
    . "    releases, but is very time consuming.\n"
    . "   -reloadList=file - Force the reload of sequences list in this file.\n"
    . "   -gbdbGenBank=dir - Use dir instead of /gbdb/genbank, for testing.\n"
    . "\n"
    . "If a file:\n"
    . "    var/dbload/\$host/reload.acc\n"
    . "exists, then a reload will be forced for accessions in this file.\n"
    . "If this complates successfully, then the fill will be renamed to:\n"
    . "    var/dbload/\$host/reload.acc.done\n"
    . "A file in the form:\n"
    . "    var/dbload/\$host/reload.\$db.acc\n"
    . "applies only to that database\n";


my $workDir;
my @databases;
my %buildFullMgc;
my %buildAllMgc;
my $verboseArg;
my $hostName;
my @args;
my $drop = 0;
my $allowLargeDeletes = 0;
my $reloadList;
my $varReloadFile;

# check for a reload.acc file in the right place, if it exists, return
# the path, otherwise return undef
sub getVarReloadFile(;$) {
    my($db) = @_;
    my $rf;
    if (defined($db)) {
        $rf  = "var/dbload/${hostName}/reload.${db}.acc";
    } else {
        $rf  = "var/dbload/${hostName}/reload.acc";
    }
    if (-e $rf) {
        if (defined($reloadList)) {
            gbError("-reloadList specified and $rf exists");
        }
        if (defined($varReloadFile)) {
            gbError("only one reload file allowed, found $varReloadFile and $rf");
        }
        return $rf;
    } else {
        return undef;
    }
}

# rename a reload file
sub renameVarReloadFile($) {
    my($rf) = @_;
    renameFile($rf, $rf . ".done");
}

# get the MGC table conf value, or undef if no MGC table load.
sub getMgcConf($) {
    my($db) = @_;
    my $host = callProg("uname -n");
    chomp($host);
    
    # try to find a 
    my $conf = findConf("$db.mgcTables.$host");
    if (!defined($conf)) {
        $conf = findConf("$db.mgcTables.default");
    }
    if (defined($conf)) {
        if ($conf eq "no") {
            $conf = undef;
        } elsif (!(($conf eq "full") || ($conf eq "all"))) {
            gbError("invalid value for $db.mgcTable \"$conf\", expected full, all, or no");
        }
    }
    return $conf;
}

# load MGC tables (note uses several globals)
sub loadMgc($$) {
    my($db, $conf) = @_;
    # find newest MGC build (in data/download/mgc/2003.04.09), looking
    # for md5 file.
    my $mgcGlob = "data/processed/mgc/*/mgc.md5";
    my @mgcCompleteFiles  = sort(glob($mgcGlob));
    if ($#mgcCompleteFiles < 0) {
        gbError("load of MGC track(s) requested, but no MGC files found: $mgcGlob");
    }
    # pick newest and get dir
    my $mgcDir = dirname($mgcCompleteFiles[$#mgcCompleteFiles]);

    # load db which were requests; all overrides full
    my @mgcArgs = ("-workdir=$workDir/$db/mgc");
    if (defined($verboseArg)) {
        push(@mgcArgs, $verboseArg);
    }
    if ($conf eq "all") {
        runProg("mgcDbLoad " . join(" ", @mgcArgs)
                    . " -allMgcTables $db $mgcDir/mgcStatus.tab.gz");
    } elsif ($conf eq "full") {
        runProg("mgcDbLoad " . join(" ", @mgcArgs)
                . " $db $mgcDir/mgcFullStatus.tab.gz");
    }
}

# Build a sequence fa for a download file, or undef if not defined for
# this db
sub makeSeqFa($$$$$) {
    my($db, $srcDb, $type, $orgCat, $outBase) = @_;

    # one create if table is loaded
    my $loadTbl = getDbConfNo($db, "$srcDb.$type.$orgCat.load");
    if (defined($loadTbl) && ($loadTbl eq "yes")) {
        # setup out directory to put 
        my $downloadDir = "download/" . getRelDownloadDir($db) . "/bigZips";
        makeDir($downloadDir);

        my $fa = "$downloadDir/$outBase.fa";
        runProg("gbGetSeqs -get=seq -db=$db -$orgCat $srcDb $type $fa");
        return $fa;
    } else {
        return undef;
    }
}


# create one sequence fa.gz if the table is loaded for this genome.
sub createSeqFaGz($$$$$) {
    my($db, $srcDb, $type, $orgCat, $outBase) = @_;

    my $fa = makeSeqFa($db, $srcDb, $type, $orgCat, $outBase);
    if (defined($fa)) {
        my $gzip =  dirname($fa) . "/$outBase.fa.gz";
        runProg("gzip -1c $fa> $gzip.tmp");
        unlink($fa);
        renameFile("$gzip.tmp", $gzip);
    }
}

# make sequence zip files
sub makeDownloadSeqs($) {
    my($db) = @_;
    createSeqFaGz($db, "genbank", "mrna", "native", "mrna");
    createSeqFaGz($db, "genbank", "mrna", "xeno", "xenoMrna");
    createSeqFaGz($db, "genbank", "est", "native", "est");
    createSeqFaGz($db, "refseq", "mrna", "native", "refMrna");
    #FIXME: not supported gbGetSeqs:
    #createSeqFaGz($db, "native", "refseq", "mrna", "refPep");
    # FIXME: need to add up/down stream seqs
}

# handle download file processing
sub createDownload($$) {
    my($db, $getDownloadSeqsDays) = @_;
    # check time 
    my $timeFile = getDownloadTimeFile($db);
    my $downloadTime = loadTimeFile($timeFile);
    my $deltaDays = (time() - $downloadTime) / (60 * 60 * 24);

    # update if non-existant or out-of-date
    if ($deltaDays > $getDownloadSeqsDays) {
        makeDownloadSeqs($db);
        makeTimeFile($timeFile);
    }
}

# dump gbExtFile table, used to find releases that are no londer needed
sub dumpExtFileTbl($) {
    my($db) = @_;
    my $dumpFile = "$gbCommon::varDir/dbload/$hostName/extFile/" . getDateStamp() . "/$db.extFile.txt";
    makeFileDir($dumpFile);
    runMysql("-N -e 'select * from gbExtFile' $db >$dumpFile.tmp");
    renameFile("$dumpFile.tmp", $dumpFile);
}

# drop genbank tables
sub dropTables($) {
    my($db) = @_;
    if ($gbCommon::verbose) {
        prMsg("dropping tables from $db");
    }
    runProg("gbLoadRna -drop $db");    
}

# load a specific database
sub dbLoad($) {
    my($db) = @_;
    my $dbVarReloadFile = getVarReloadFile($db);
    if ($drop) {
        dropTables($db);
    }
    
    my @dbArgs = @args;
    if ($allowLargeDeletes) {
        push(@dbArgs, "-allowLargeDeletes");
    }
    if (defined($dbVarReloadFile)) {
        push(@dbArgs, "-reloadList=$dbVarReloadFile");
    }
    runProg("gbLoadRna " . join(" ", @dbArgs) . " $db");

    if (defined($dbVarReloadFile)) {
        renameVarReloadFile($dbVarReloadFile);
    }
    dumpExtFileTbl($db);
}


# Entry
$hostName = `hostname`;
chomp($hostName);
my $keep = 0;
my $initialLoad = 0;
my $getDownloadSeqsDays;
my $gbdbGenBank;
my $extFileUpdate = 0;
my $maxExtFileUpdate;
my $srcDb;
my $type;
my $reload = 0;
while (($#ARGV >= 0) && ($ARGV[0] =~ /^-.*/)) {
    my $opt = $ARGV[0];
    shift @ARGV;
    if ($opt =~ /^-workdir($|=)/) {
        $workDir = parseOptEq($opt);
    } elsif ($opt =~ /^-type($|=)/) {
        $type = parseOptEq($opt);
    } elsif ($opt =~ /^-srcDb($|=)/) {
        $srcDb = parseOptEq($opt);
    } elsif ($opt eq "-drop") {
        $drop = 1;
    } elsif ($opt eq "-reload") {
        $reload = 1;
    } elsif ($opt eq "-verbose") {
        $verboseArg = "-verbose";
        $gbCommon::verbose = 1;
    } elsif ($opt =~ /^-verbose=/) {
        $verboseArg = "-verbose=" . parseOptEq($opt);
        $gbCommon::verbose = 1;
    } elsif ($opt eq "-initialLoad") {
        $initialLoad = 1;
    } elsif ($opt eq "-extFileUpdate") {
        $extFileUpdate = 1;
    } elsif ($opt =~ /-maxExtFileUpdate(=|$)/) {
        $maxExtFileUpdate  = parseOptEq($opt);
    } elsif ($opt =~ /^-getDownloadSeqs(=|$)/) {
        $getDownloadSeqsDays = parseOptEq($opt);
    } elsif ($opt eq "-allowLargeDeletes") {
        $allowLargeDeletes = 1;
    } elsif ($opt eq "-keep") {
        $keep = 1;
    } elsif ($opt =~ /^-gbdbGenBank=/) {
        $gbdbGenBank = parseOptEq($opt);
    } elsif ($opt =~ /^-reloadList(=|$)/) {
        $reloadList = parseOptEq($opt);
    } else {
        gbError("invalid option \"$opt\"\n$usage");
    }
}
if ($#ARGV < 0) {
    gbError("wrong # args: $usage");
}
@databases = @ARGV;

# check for a reload file on the file system
$varReloadFile = getVarReloadFile();
if (defined($varReloadFile)) {
    $reloadList = $varReloadFile;
}

# build standard set of arguments to pass
if (!defined($workDir)) {
    $workDir = "work/$hostName/dbload";
}
push(@args, "-workdir=$workDir");
if ($initialLoad) {
    push(@args, "-initialLoad");
}
if (defined($verboseArg)) {
    push(@args, $verboseArg);
}
if (defined($gbdbGenBank)) {
    push(@args, "-gbdbGenBank=$gbdbGenBank");
}
if (defined($srcDb)) {
    push(@args, "-srcDb=$srcDb");
}
if (defined($type)) {
    push(@args, "-type=$type");
}
if ($extFileUpdate) {
    push(@args, "-extFileUpdate");
}
if ($maxExtFileUpdate) {
    push(@args, "-maxExtFileUpdate=$maxExtFileUpdate");
}
if (defined($reloadList)) {
    push(@args, "-reloadList=$reloadList");
}
if ($reload) {
    push(@args, "-reload");
}
             
beginTask("dbload/$hostName", "dbload");
setupHgConf();

# load the database
foreach my $db (@databases) {
    dbLoad($db);
}

# rename reload file if it was used
if (defined($varReloadFile)) {
    renameVarReloadFile($varReloadFile)
}

# process MGC loads
foreach my $db (@databases) {
    my $conf = getMgcConf($db);
    if (defined($conf)) {
        loadMgc($db, $conf);
    }
}

# create dump files if requested
if ($getDownloadSeqsDays) {
    foreach my $db (@databases) {
        createDownload($db, $getDownloadSeqsDays);
    }
}

if (!$keep) {
    runProg("rm -rf $workDir");
}
endTask();

