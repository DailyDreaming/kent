#!/usr/bin/perl
#
# gbDbLoadStep [options] database ...
#
# Load databases on the current server.
#
# Options:
#   -workdir=work/$host/dbload
#   -allowLargeDeletes - override check for deleting large number of
#    entries.
#   -verbose
#   -keep
#   -initialLoad
#   -downloadDump=days - dump genbank tables and mrna.zip to directories
#    to $gbRoot/download  If download/dump.time doesn't exists or time is
#    more than $days days old.
#   -downloadUpdate - update download files under 
#    /usr/local/apache/htdocs/goldenPath/ if they have changed.
#   -drop - drop tables before load.  This removes all of genbank and
#    refseq data, not just what is being loaded.
#  -gbdbGenBank=dir - Use dir instead of /gbdb/genbank, for testing.
#
# $Id: gbDbLoadStep,v 1.14 2003/08/08 23:00:25 genbank Exp $
#
use strict;
use warnings;
use File::Basename;
use FindBin;
use lib "$FindBin::Bin/../lib";
use gbCommon;

my $workDir;
my @databases;
my %buildFullMgc;
my %buildAllMgc;
my $verboseArg;

# get the MGC table conf value, or undef if no MGC table load.
sub getMgcConf($) {
    my($db) = @_;
    my $host = callProg("uname -n");
    chomp($host);
    
    # try to find a 
    my $conf = findConf("$db.mgcTables.$host");
    if (!defined($conf)) {
        $conf = findConf("$db.mgcTables.default");
    }
    if (defined($conf)) {
        if ($conf eq "no") {
            $conf = undef;
        } elsif (!(($conf eq "full") || ($conf eq "all"))) {
            gbError("invalid value for $db.mgcTable \"$conf\", expected full, all, or no");
        }
    }
    return $conf;
}

# load MGC tables (note uses several globals)
sub loadMgc($$) {
    my($db, $conf) = @_;
    # find newest MGC build (in data/download/mgc/2003.04.09), looking
    # for md5 file.
    my $mgcGlob = "data/processed/mgc/*/mgc.md5";
    my @mgcCompleteFiles  = sort(glob($mgcGlob));
    if ($#mgcCompleteFiles < 0) {
        gbError("load of MGC track(s) requested, but no MGC files found: $mgcGlob");
    }
    # pick newest and get dir
    my $mgcDir = dirname($mgcCompleteFiles[$#mgcCompleteFiles]);

    # load db which were requests; all overrides full
    my @mgcArgs = ("-workdir=$workDir/$db/mgc");
    if (defined($verboseArg)) {
        push(@mgcArgs, $verboseArg);
    }
    if ($conf eq "all") {
        runProg("mgcDbLoad " . join(" ", @mgcArgs)
                    . " -allMgcTables $db $mgcDir/mgcStatus.tab.gz");
    } elsif ($conf eq "full") {
        runProg("mgcDbLoad " . join(" ", @mgcArgs)
                . " $db $mgcDir/mgcFullStatus.tab.gz");
    }
}

# dump genbank tables for download
sub dumpGenbankTables($) {
    my($db) = @_;

    # build modo regexp with regexps matching genbank tables.  Don't
    # include blank lines or comments.
    my $tblREStr = "^(";
    my $sep = "";
    foreach my $line (split("\n", readFile("etc/genbank.tbls"))) {
        $line =~ s/\s+//g;
        if (!(($line =~ /^$/) || ($line =~ /^\#.*/))) {
            $tblREStr .= $sep . $line;
            $sep = "|";
        }
    }
    $tblREStr .= "\)\$";
    my $tblRE = qr/$tblREStr/;

    # get list of genbank tables 
    my @tbls = split("\n", callMysql("-N -e 'show tables' $db"));
    my @gbTbls;
    foreach my $tbl (@tbls) {
        if ($tbl =~ $tblRE) {
            push(@gbTbls, $tbl);
        }
    }

    # dump tables as tab and sql files
    my $downLoadDir = "download/" . getConf("$db.downloadDir")
        . "/database";
    my $downloadTmpDir =  makeAbs($downLoadDir . "/tmp");
    removeDir($downloadTmpDir);
    makeDir($downloadTmpDir);
    chmod(0777, $downloadTmpDir) || gbError("chmod $downloadTmpDir");
    runMysqlDump("-T $downloadTmpDir $db " . join(" ", @gbTbls));
    # compress .txt files and move into place
    runProg("gzip -4f " . join(" ", glob("$downloadTmpDir/*.txt")));
    runProg("mv -f " . join(" ", glob("$downloadTmpDir/*")) . " $downLoadDir/");
    removeDir($downloadTmpDir);
}

# dump mrna sequences to download zip.
sub makeMrnaZip($) {
    my($db) = @_;

    # setup directory for download files
    my $downLoadDir = "download/" . getConf("$db.downloadDir")
        . "/bigZips";
    my $downloadTmpDir =  makeAbs($downLoadDir . "/tmp");
    removeDir($downloadTmpDir);
    makeDir($downloadTmpDir);
    chmod(0777, $downloadTmpDir) || gbError("chmod $downloadTmpDir");

    # get native mrnas
    my $fa = "$downloadTmpDir/mrna.fa";
    runProg("gbGetSeqs -get=seq -db=$db -native genbank mrna $fa");

    # zip without directory path and move into place
    my $tmpZip =  "$downloadTmpDir/mrna.zip";
    runProg("zip -j $tmpZip $fa");
    runProg("mv -f $tmpZip $downLoadDir/");
    removeDir($downloadTmpDir);
}

# get download time file for a db
sub getDownloadTimeFile($) {
    my($db) = @_;
    return "download/" . getConf("$db.downloadDir") . "/download.time";
}

# handle download file processing
sub handleDownloadDump($$) {
    my($db, $downloadDumpDays) = @_;
    # check time 
    my $timeFile = getDownloadTimeFile($db);
    my $downloadTime;
    if (! -e $timeFile) {
        $downloadTime = 0;
    } else {
        $downloadTime = loadTimeFile($timeFile);
    }
    my $deltaDays = (time() - $downloadTime) / (60 * 60 * 24);

    # update if non-existant or out-of-date
    if ($deltaDays > $downloadDumpDays) {
        dumpGenbankTables($db);
        makeMrnaZip($db);
        makeTimeFile($timeFile);
    }
}

# update the download files for the web server.  Must check time file
# to keep in-progress dump from being updated
sub updateDownload($) {
    my($db) = @_;
    my $dbDir = getConf("$db.downloadDir");
    my $htdocsDir = "/usr/local/apache/htdocs/goldenPath";

    my $downloadTime = getDownloadTimeFile($db);
    my $htdocsTime = "$htdocsDir/$dbDir/download.time";

    if ((-e $downloadTime) 
        && ((!-e $htdocsTime)
            || (loadTimeFile($downloadTime) > loadTimeFile($htdocsTime)))) {
        # download dir can't have trailing / for rsync
        my $downloadDir = "download/$dbDir";
        $downloadDir =~ s/\/$//;
        my $htdocsDir = "/usr/local/apache/htdocs/goldenPath";
        if ($gbCommon::verbose) {
            prMsg("update download files for $db");
        }
        makeDir("$htdocsDir/$dbDir");
        runProg("rsync -r $downloadDir $htdocsDir");
    }
}

# drop genbank tables
sub dropTables($) {
    my($db) = @_;
    if ($gbCommon::verbose) {
        prMsg("dropping tables from $db");
    }
    runProg("gbLoadRna -drop $db");    
}

# Entry
my $hostName = `hostname`;
chomp($hostName);
my $drop = 0;
my $keep = 0;
my $initialLoad = 0;
my $allowLargeDeletes = 0;
my $downloadDumpDays;
my $downloadUpdate = 0;
my $gbdbGenBank;
while (($#ARGV >= 0) && ($ARGV[0] =~ /^-.*/)) {
    my $opt = $ARGV[0];
    shift @ARGV;
    if ($opt =~ /^-workdir($|=)/) {
        $workDir = parseOptEq($opt);
    } elsif ($opt eq "-drop") {
        $drop = 1;
    } elsif ($opt eq "-verbose") {
        $verboseArg = "-verbose";
        $gbCommon::verbose = 1;
    } elsif ($opt =~ /^-verbose=/) {
        $verboseArg = "-verbose=" . parseOptEq($opt);
        $gbCommon::verbose = 1;
    } elsif ($opt eq "-initialLoad") {
        $initialLoad = 1;
    } elsif ($opt =~ /^-downloadDump(=|$)/) {
        $downloadDumpDays = parseOptEq($opt);
    } elsif ($opt eq "-downloadUpdate") {
        $downloadUpdate = 1;
    } elsif ($opt eq "-allowLargeDeletes") {
        $allowLargeDeletes = 1;
    } elsif ($opt eq "-keep") {
        $keep = 1;
    } elsif ($opt =~ /^-gbdbGenBank=/) {
        $gbdbGenBank = parseOptEq($opt);
    } else {
        gbError("invalid option \"$opt\"");
    }
}
if ($#ARGV < 0) {
    gbError("wrong # args: gbDbLoadStep [options] database ..");
}
@databases = @ARGV;

my @args;
if (!defined($workDir)) {
    $workDir = "work/$hostName/dbload";
}
push(@args, "-workdir=$workDir");
if ($initialLoad) {
    push(@args, "-initialLoad");
}
if (defined($verboseArg)) {
    push(@args, $verboseArg);
}
if (defined($gbdbGenBank)) {
    push(@args, "-gbdbGenBank=$gbdbGenBank");
}

beginTask("dbload/$hostName", "dbload");

# load the database
foreach my $db (@databases) {
    if ($drop) {
        dropTables($db);
    }
    
    my @dbArgs = @args;
    if ($allowLargeDeletes) {
        push(@dbArgs, "-allowLargeDeletes");
    }
    runProg("gbLoadRna " . join(" ", @dbArgs) . " $db");
}

# process MGC loads
foreach my $db (@databases) {
    my $conf = getMgcConf($db);
    if (defined($conf)) {
        loadMgc($db, $conf);
    }
}

# create dump files if requested
if ($downloadDumpDays) {
    foreach my $db (@databases) {
        handleDownloadDump($db, $downloadDumpDays);
    }
}

# update download files in htdocs
if ($downloadUpdate) {
    foreach my $db (@databases) {
        updateDownload($db);
    }
}

if (!$keep) {
    runProg("rm -rf $workDir");
}
endTask();

