#!/usr/bin/perl
#
# gbDbLoadStep [options] database ...
#
# Load databases on the current server.
#
# Options:
#   -workdir=work/$host/dbload
#   -allowLargeDeletes - override check for deleting large number of
#    entries.
#   -verbose
#   -keep
#   -initialLoad
#   -type=type - restrict load to type (mrna or est)
#   -getDownloadSeqs=days - create sequence zip files and save in
#    $gbRoot/download  If download/dump.time doesn't exists or time is
#    more than $days days old.
#   -updateDownloadSeqs - update download sequences files under 
#    /usr/local/apache/htdocs/goldenPath/ if they have changed
#    in gbRoot/download.
#   -drop - drop tables before load.  This removes all of genbank and
#    refseq data, not just what is being loaded.
#   -extFileUpdate - update the gbSeq table to link each sequence to
#    the latest release.  This allows removing fasta files for older
#    releases, but is very time consuming.
#   -reloadList=file - Force the reload of sequences list in this file.
#   -gbdbGenBank=dir - Use dir instead of /gbdb/genbank, for testing.
#
# $Id: gbDbLoadStep,v 1.19 2003/10/28 17:06:58 genbank Exp $
#
use strict;
use warnings;
use File::Basename;
use FindBin;
use lib "$FindBin::Bin/../lib";
use gbCommon;

my $workDir;
my @databases;
my %buildFullMgc;
my %buildAllMgc;
my $verboseArg;

# get the MGC table conf value, or undef if no MGC table load.
sub getMgcConf($) {
    my($db) = @_;
    my $host = callProg("uname -n");
    chomp($host);
    
    # try to find a 
    my $conf = findConf("$db.mgcTables.$host");
    if (!defined($conf)) {
        $conf = findConf("$db.mgcTables.default");
    }
    if (defined($conf)) {
        if ($conf eq "no") {
            $conf = undef;
        } elsif (!(($conf eq "full") || ($conf eq "all"))) {
            gbError("invalid value for $db.mgcTable \"$conf\", expected full, all, or no");
        }
    }
    return $conf;
}

# load MGC tables (note uses several globals)
sub loadMgc($$) {
    my($db, $conf) = @_;
    # find newest MGC build (in data/download/mgc/2003.04.09), looking
    # for md5 file.
    my $mgcGlob = "data/processed/mgc/*/mgc.md5";
    my @mgcCompleteFiles  = sort(glob($mgcGlob));
    if ($#mgcCompleteFiles < 0) {
        gbError("load of MGC track(s) requested, but no MGC files found: $mgcGlob");
    }
    # pick newest and get dir
    my $mgcDir = dirname($mgcCompleteFiles[$#mgcCompleteFiles]);

    # load db which were requests; all overrides full
    my @mgcArgs = ("-workdir=$workDir/$db/mgc");
    if (defined($verboseArg)) {
        push(@mgcArgs, $verboseArg);
    }
    if ($conf eq "all") {
        runProg("mgcDbLoad " . join(" ", @mgcArgs)
                    . " -allMgcTables $db $mgcDir/mgcStatus.tab.gz");
    } elsif ($conf eq "full") {
        runProg("mgcDbLoad " . join(" ", @mgcArgs)
                . " $db $mgcDir/mgcFullStatus.tab.gz");
    }
}

# get the relative download directory for this genome.  It defaults to
# the database name.  Older database have it configured.
sub getRelDownloadDir($) {
    my($db) = @_;
    my $relDir = findConf("$db.downloadDir");
    if (!defined($relDir)) {
        $relDir = $db;
    }
    return $relDir;
}

# create one sequence zip file if the table is loaded for this genome.
sub createSeqZip($$$$$) {
    my($db, $srcDb, $type, $orgCat, $outBase) = @_;

    # on load if table is being loaded
    my $loadTbl = getDbConfNo($db, "$srcDb.$type.$orgCat.load");
    if (defined($loadTbl) && ($loadTbl eq "yes")) {
        # setup out directory to put 
        my $downloadDir = "download/" . getRelDownloadDir($db) . "/bigZips";
        makeDir($downloadDir);

        my $fa = "$downloadDir/$outBase.fa";
        runProg("gbGetSeqs -get=seq -db=$db -$orgCat $srcDb $type $fa");

        # zip without directory path and move into place
        my $zip =  "$downloadDir/$outBase.zip";
        runProg("zip -j $zip.tmp $fa");
        unlink($fa);
        renameFile("$zip.tmp", $zip);
    }
}

# make sequence zip files
sub makeDownloadSeqs($) {
    my($db) = @_;
    createSeqZip($db, "genbank", "mrna", "native", "mrna");
    createSeqZip($db, "genbank", "mrna", "xeno", "xenoMrna");
    #createSeqZip($db, "genbank", "est", "native", "est");
    createSeqZip($db, "refseq", "mrna", "native", "refMrna");
    #FIXME: not supported gbGetSeqs:
    #createSeqZip($db, "native", "refseq", "mrna", "refPep");
}

# get download time file for a db
sub getDownloadTimeFile($) {
    my($db) = @_;
    return "download/" . getRelDownloadDir($db) . "/download.time";
}

# handle download file processing
sub createDownload($$) {
    my($db, $getDownloadSeqsDays) = @_;
    # check time 
    my $timeFile = getDownloadTimeFile($db);
    my $downloadTime;
    if (! -e $timeFile) {
        $downloadTime = 0;
    } else {
        $downloadTime = loadTimeFile($timeFile);
    }
    my $deltaDays = (time() - $downloadTime) / (60 * 60 * 24);

    # update if non-existant or out-of-date
    if ($deltaDays > $getDownloadSeqsDays) {
        makeDownloadSeqs($db);
        makeTimeFile($timeFile);
    }
}

# update the download files for the web server.  Must check time file
# to keep in-progress dump from being updated
sub updateDownload($) {
    my($db) = @_;
    my $dbDir = getRelDownloadDir($db);
    my $htdocsDir = "/usr/local/apache/htdocs/goldenPath";

    my $downloadTime = getDownloadTimeFile($db);
    my $htdocsTime = "$htdocsDir/$dbDir/download.time";

    if ((-e $downloadTime) 
        && ((!-e $htdocsTime)
            || (loadTimeFile($downloadTime) > loadTimeFile($htdocsTime)))) {
        # download dir can't have trailing / for rsync
        my $downloadDir = "download/$dbDir";
        $downloadDir =~ s/\/$//;
        my $htdocsDir = "/usr/local/apache/htdocs/goldenPath";
        if ($gbCommon::verbose) {
            prMsg("update download files for $db");
        }
        makeDir("$htdocsDir/$dbDir");
        runProg("rsync -r $downloadDir $htdocsDir");
    }
}

# drop genbank tables
sub dropTables($) {
    my($db) = @_;
    if ($gbCommon::verbose) {
        prMsg("dropping tables from $db");
    }
    runProg("gbLoadRna -drop $db");    
}

# Entry
my $hostName = `hostname`;
chomp($hostName);
my $drop = 0;
my $keep = 0;
my $initialLoad = 0;
my $allowLargeDeletes = 0;
my $getDownloadSeqsDays;
my $updateDownloadSeqs = 0;
my $gbdbGenBank;
my $extFileUpdate = 0;
my $type;
my $reloadList;
while (($#ARGV >= 0) && ($ARGV[0] =~ /^-.*/)) {
    my $opt = $ARGV[0];
    shift @ARGV;
    if ($opt =~ /^-workdir($|=)/) {
        $workDir = parseOptEq($opt);
    } elsif ($opt =~ /^-type($|=)/) {
        $type = parseOptEq($opt);
    } elsif ($opt eq "-drop") {
        $drop = 1;
    } elsif ($opt eq "-verbose") {
        $verboseArg = "-verbose";
        $gbCommon::verbose = 1;
    } elsif ($opt =~ /^-verbose=/) {
        $verboseArg = "-verbose=" . parseOptEq($opt);
        $gbCommon::verbose = 1;
    } elsif ($opt eq "-initialLoad") {
        $initialLoad = 1;
    } elsif ($opt eq "-extFileUpdate") {
        $extFileUpdate = 1;
    } elsif ($opt =~ /^-getDownloadSeqs(=|$)/) {
        $getDownloadSeqsDays = parseOptEq($opt);
    } elsif ($opt eq "-updateDownloadSeqs") {
        $updateDownloadSeqs = 1;
    } elsif ($opt eq "-allowLargeDeletes") {
        $allowLargeDeletes = 1;
    } elsif ($opt eq "-keep") {
        $keep = 1;
    } elsif ($opt =~ /^-gbdbGenBank=/) {
        $gbdbGenBank = parseOptEq($opt);
    } elsif ($opt =~ /^-reloadList(=|$)/) {
        $reloadList = parseOptEq($opt);
    } else {
        gbError("invalid option \"$opt\"");
    }
}
if ($#ARGV < 0) {
    gbError("wrong # args: gbDbLoadStep [options] database ..");
}
@databases = @ARGV;

my @args;
if (!defined($workDir)) {
    $workDir = "work/$hostName/dbload";
}
push(@args, "-workdir=$workDir");
if ($initialLoad) {
    push(@args, "-initialLoad");
}
if (defined($verboseArg)) {
    push(@args, $verboseArg);
}
if (defined($gbdbGenBank)) {
    push(@args, "-gbdbGenBank=$gbdbGenBank");
}
if (defined($type)) {
    push(@args, "-type=$type");
}
if ($extFileUpdate) {
    push(@args, "-extFileUpdate");
}
if (defined($reloadList)) {
    push(@args, "-reloadList=$reloadList");
}

beginTask("dbload/$hostName", "dbload");

# load the database
foreach my $db (@databases) {
    if ($drop) {
        dropTables($db);
    }
    
    my @dbArgs = @args;
    if ($allowLargeDeletes) {
        push(@dbArgs, "-allowLargeDeletes");
    }
    runProg("gbLoadRna " . join(" ", @dbArgs) . " $db");
}

# process MGC loads
foreach my $db (@databases) {
    my $conf = getMgcConf($db);
    if (defined($conf)) {
        loadMgc($db, $conf);
    }
}

# create dump files if requested
if ($getDownloadSeqsDays) {
    foreach my $db (@databases) {
        createDownload($db, $getDownloadSeqsDays);
    }
}

# update download files in htdocs
if ($updateDownloadSeqs) {
    foreach my $db (@databases) {
        updateDownload($db);
    }
}

if (!$keep) {
    runProg("rm -rf $workDir");
}
endTask();

