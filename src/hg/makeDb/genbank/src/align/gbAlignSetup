#!/usr/bin/env python
#
# $Id: gbAlignSetup,v 1.12.8.8 2005/08/15 06:39:19 markd Exp $
#

usage="""gbAlignSetup [options] database ...

Do setup for the alignment step.

Arguments:
  - database - databases to align

Obtains other parameters from etc/genbank.conf:

  - $db.serverGenome - a glob pattern of where to find the genome
     contig or chromosome nib, or 2bit files on the server.
     For example: 
        mm5.serverGenome = /cluster/data/mm5/nib/chr*.nib

  - $db.clusterGenome - a glob pattern of where to find the genome
     contig or chromosome nib, or 2bit files on the cluster.
     For example: 
        mm5.clusterGenome = /scratch/mus/mm5/softNib/chr*.nib

  - $db.querySplitSize - maximum size of a fasta file for alignment, in
    megabytes

  - $db.lift - the lift file is used find gaps when partitioning sequences.
    optional.

Does:
   - Find updates that are missing alignments in the latest releases for
     each specified database. 
   - Extract tmp fasta file to align into the alignment work directory.
   - Produce a single parasol jobs file to do all of the alignments.
   - create a list of all expected PSL files."""


# Note: jobs-specific paths are created in a multi-level tree
# to avoid large number off files in a single directory. 
#
# An alignment of .../mrna.0.fa and  .../chr10.nib will end up in:
#
#   refseq.12/hg17/full/mrna.0/chr10/chr10.psl
#
# The way the directory names are derived depends on the the genome file
# name:
#
#    chr22.nib -> chr22/chr22.psl
#    chr1.nib:207000000-217000000 -> chr1/2/207000000-217000000.psl
#    
# IMPORTANT NOTE: gbAlignFinish takes advantage of a one-to-one mapping between
# query file and the first directory level to make sorting more efficient, so
# don't change this with understanding what is going on.
#

import sys, os, os.path, re
myBinDir = os.path.normpath(os.path.dirname(sys.argv[0]))
sys.path.append(myBinDir + "/../lib/py")
from optparse import OptionParser
from genbank import procOps, fileOps
from genbank.Config import Config
from genbank.GbIndex import GbIndex, GenBank, RefSeq, MRNA, EST, Native, Xeno
from genbank.GenomeSeqs import GenomeSeqs
from genbank.fileOps import prLine, prRow, prRowv
import glob

absBinDir = os.path.abspath(myBinDir)
mach = os.uname()[4]
if mach == "i686":
    mach = "i386"
machBinDir = absBinDir + "/" + mach
os.environ["PATH"] = machBinDir + ":" + os.environ["PATH"]
gbBlatPath = absBinDir + "/gbBlat"

cmdOpts = None

# global table to make sure we don't generate output file more than
# once
definedPsls = set()

class GenomeWindow(object):
    "information about a single genome window"
    __slots__ = ("seq", "start", "end", "isFullSeq", "spec", "getSize")

    def __init__(self, seq, start, end):
        assert(start < end)
        self.seq = seq
        self.start = start
        self.end = end
        self.isFullSeq = (start == 0) and (end == seq.size)
        # specification for gbBlat (includes size if subrange)
        if self.isFullSeq:
            self.spec = seq.id
        else:
            self.spec = seq.id + ":" + str(seq.size) + ":" + str(start) + "-" + str(end)

    def __str__(self):
        return self.spec

    def getSize(self):
        "get the size of the window"
        return self.end - self.start

class GenomeWindows(list):
    """Class to construct overlapping windows over sequences in a genome.
    contains ordered list of GenomeWindow objects"""

    def __init__(self, genomeSeqs, winSize, overlap):
        if (winSize <= 0):
            raise Exception("window size must be > 0")
        if (overlap < 0):
            raise Exception("window overlap must be >= 0")
        if (winSize <= overlap):
            raise Exception("window size must be > overlap")
        self.winSize = winSize
        self.overlap = overlap

        for seq in genomeSeqs.itervalues():
            if seq.regions == None:
                self._partitionRange(seq, 0, seq.size, winSize, overlap)
            else:
                for reg in seq.regions:
                    self._partitionRange(seq, reg[0], reg[1], winSize, overlap)

    def _partitionRange(self, seq, start, end, winSize, overlap):
        "partition a range into windows"
        assert(start < end)
        winStart = start
        while winStart < end:
            winEnd = winStart + winSize
            if winEnd+overlap >= end:
                # past end or next overlap will take us to end
                winEnd = end
            self.append(GenomeWindow(seq, winStart, winEnd))
            # advance window with overlap.
            winStart += (winSize - overlap)

class CDnaQuery(object):
    "object to store info on one of the extracted cDNA fasta files"

    def __init__(self, procPart, cdnaType, orgCat, numSeqs, numBases, faPath):
        self.procPart = procPart
        self.cdnaType = cdnaType
        self.orgCat = orgCat
        self.numSeqs = numSeqs  
        self.numBases = numBases 
        self.faPath = faPath
        self.name = os.path.splitext(os.path.basename(faPath))[0]

    def makePolyASizes(self):
        "create a poly-A sizes file for this fasta"
        polyAFile = os.path.splitext(self.faPath)[0] + ".polya"
        procOps.callProc(["faPolyASizes", self.faPath, polyAFile])

    def __str__(self):
        return str(self.procPart) + ": nseqs=" + str(self.numSeqs) + ", nbases=" + str(self.numBases) + ": " + self.faPath
        
                        
class CDnaUnaligned(object):
    """object used to find unaligned cDNA partitions and extract fasta files
    to query against genome.  Does all specified orgCats at once, to avoid
    multiple passes throught the cDNA fasta files files"""

    def __init__(self, db, rel, cdnaType, orgCats, querySplitSize, workDir):
        self.db = db
        self.rel = rel
        self.cdnaType = cdnaType
        self.orgCats = orgCats
        self.querySplitSize = querySplitSize
        self.workDir = os.path.normpath(workDir)
        self.numAlign = 0L
        self.unaligned = [] # list of GbProcessedPart objs
        self.queries = {} # list of CDnaQuery objs, by orgCat
        for orgCat in orgCats:
            self.queries[orgCat] = []

        rel.loadAlignedParts(db)
        self._findUnaligned()

    def _needsAligned(self, procPart):
        "determine if procPart is all or partially unaligned"
        if (procPart.cdnaType != self.cdnaType):
            return False  # not interested
        alnPart = procPart.getAlignedPart()
        if alnPart == None:
            return True
        # check if all requested orgCats are there
        if not alnPart.orgCats.issuperset(self.orgCats):
            return True
        return False

    def _findUnaligned(self):
        "find unaligned processed partitions and add them to the object"
        for upd in self.rel.updates:
            for procPart in upd.procParts:
                if self._needsAligned(procPart):
                    self.unaligned.append(procPart)

    def _parseAlignGet(self, procPart, lines):
        "parse output from gbAlignGet"
        cnt = None
        for line in lines:
            row = line.split(" ")
            if row[0] == "alignFa:":
                # alignFa: path orgCat numSeqs numBases
                cdnas = CDnaQuery(procPart, self.cdnaType, row[2], int(row[3]), long(row[4]), row[1])
                self.queries[row[2]].append(cdnas)
            elif row[0] == "alignCnt:":
                cnt = long(row[1])
            else:
                raise Exception("unexpected output from gbAlignGet: " + line)
        if cnt == None:
            raise Exception("gbAlignGet did not output \"alignCnt:\"")
        self.numAlign += cnt

    def _makePolyASizes(self):
        "create polyA sizes files for query fastas"
        for orgCat in self.queries.iterkeys():
            for query in self.queries[orgCat]:
                query.makePolyASizes()

    def _buildPart(self, cmdBase, procPart):
        "run gbAlignGet to get fasta for one partition"
        cmd = list(cmdBase)
        cmd.append(self.rel)
        cmd.append(procPart.update)
        if procPart.accPrefix == None:
            cmd.append(self.cdnaType)
        else:
            cmd.append(self.cdnaType + "." + procPart.accPrefix)
        cmd.append(self.db)

        if cmdOpts.verbose:
            print procOps.fmtCmd(cmd)
        lines = procOps.callProcLines(cmd)

        # process results
        self._parseAlignGet(procPart, lines)
        self._makePolyASizes()

    def buildQueries(self):
        """build cDNA fasta files for unaligned partitions; return count of
        unaligned sequences"""

        # build first part of gbAlignGet command with options
        cmdBase = ["gbAlignGet"];
        if self.querySplitSize > 0:
            cmdBase.append("-fasize=" + str(self.querySplitSize))
        if cmdOpts.verbose:
            cmdBase.append("-verbose=" + str(verbose))
        if cmdOpts.noMigrate:
            cmdBase.append("-noMigrate")
        cmdBase.extend(["-workdir=" + self.workDir,
                        "-orgCats=" + ",".join(self.orgCats)])
        for procPart in self.unaligned:
            self._buildPart(cmdBase, procPart)
            return self.numAlign

class Job(list):
    """Information about a job.  This contains a single query sequence, and
    multiple target windows."""
    # Note: can't contain multiple queries due to gbAlignFinsh assumptions

    __slots__ = ("cdnaQuery", "targetBases")

    def __init__(self, cdnaQuery):
        self.cdnaQuery = cdnaQuery
        self.targetBases = 0L

    def addTargetWin(self, win):
        self.append(win)
        self.targetBases += win.getSize()

    def _getJobPath(self, jobGenDb):
        "generate the path relative to the work directory that is unique to this job"
        # follow the old conventions of a psl directory under the directory
        # with the fasta file.  The job file goes in the psl dir too!
        win = self[0]  # user first window in names
        update = self.cdnaQuery.procPart.update
        path = [update.rel, jobGenDb.db, update, "psl", self.cdnaQuery.name, win.seq.id]
        if win.isFullSeq:
            path.append(win.seq.id)
        else:
            # create subdir from start of range
            s = str(win.start)
            path.append(s[0])
            path.append(s + "-" + str(win.end))
        return "/".join(path)

    def _makeWorkDirRel(self, jobGen, path):
        "removing the workdir directories from path"
        assert(path.startswith(jobGen.workDir))
        return path[len(jobGen.workDir)+1:]
        
    def write(self, jobGenDb, preFilterOpts):
        "write this job spec"
        jobGen = jobGenDb.jobGen
        jobPath = self._getJobPath(jobGenDb)
        
        # create job spec file
        relJobFile = jobPath + ".job"
        jobFile = jobGen.workDir + "/" + relJobFile
        fileOps.ensureFileDir(jobFile)
        fh = open(jobFile, "w")
        prRowv(fh, "type", self.cdnaQuery.orgCat, self.cdnaQuery.cdnaType)
        if jobGenDb.ooc != None:
            prRowv(fh, "ooc", jobGenDb.ooc)

        prRowv(fh, "tdb", jobGenDb.clusterGenome)
        fh.write("tseq")
        for win in self:
            fh.write("\t")
            fh.write(win.spec)
        fh.write("\n")
        if jobGenDb.slow2bit:
            prRowv(fh, "tdbSlow2bit", "yes")
        prRowv(fh, "qdb", self._makeWorkDirRel(jobGen, self.cdnaQuery.faPath))
        prRowv(fh, "preFilterOpts", preFilterOpts)

        # add job
        relPslFile = jobPath + ".psl"
        if relPslFile in definedPsls:
            raise Exception("BUG: psl file already used: " + relPslFile)
        definedPsls.add(relPslFile)
        fileOps.prLine(jobGen.jobFh, gbBlatPath, " ", relJobFile, " {check out exists ", relPslFile, "}")
        fileOps.prLine(jobGen.expectFh, relPslFile)

class Jobs(list):
    """job to to partition target sequence windows into jobs.  This builds
    a list of Job objects for a given update and query fasta and packs
    multiple targets smaller than the window size into jobs."""

    def __init__(self, jobGenDb, cdnaQuery):
        self.jobGenDb = jobGenDb
        self.winSize = jobGenDb.windows.winSize
        self.overlap = jobGenDb.windows.overlap
        self.cdnaQuery = cdnaQuery
        self.pending = []

        for win in jobGenDb.windows:
            self._addWindow(win)

    def _addWindow(self, win):
        "add a window to the object"
        i = self._findJobWithRoom(win)
        if i < 0:
            # make new job
            job = Job(self.cdnaQuery)
            job.addTargetWin(win)
            if job.targetBases < self.winSize:
                self.pending.append(job)
            else:
                self.append(job)
        else:
            # add to existing job
            job = self.pending[i]
            job.addTargetWin(win)
            if job.targetBases >= self.winSize:
                # now full
                del(self.pending[i])
                self.append(job)

    def _findJobWithRoom(self, win):
        """find a job with room for this window, alowing jobs to be overflow
        by the overlap amount"""
        need = win.getSize() - self.overlap
        for i in xrange(len(self.pending)):
            if self.pending[i].targetBases + need < self.winSize:
                return i
        return -1

    def write(self, preFilterOpts):
        "write jobs"
        for job in self:
            job.write(self.jobGenDb, preFilterOpts)
        for job in self.pending:
            job.write(self.jobGenDb, preFilterOpts)

    def prStats(self):
        "print stats about jobs for debugging purposes"
        allJobs = self + self.pending
        job = allJobs[0]
        minBases = job.targetBases
        maxBases = job.targetBases
        minSeqs = len(job)
        maxSeqs = len(job)
        for job in allJobs:
            minBases = min(minBases, job.targetBases)
            maxBases = max(maxBases, job.targetBases)
            minSeqs = min(minSeqs, len(job))
            maxSeqs = max(maxSeqs, len(job))
            
        pp = self.cdnaQuery.procPart
        print >>sys.stderr, "Jobs:",pp.update.rel, pp.update, pp, self.jobGenDb.db, "jobs:", len(allJobs), "minBases:", minBases, "maxBases:", maxBases, "minSeqs:", minSeqs, "maxSeqs:", maxSeqs

class JobGenDb(object):
    "object to generate alignment jobs for a database"
    def __init__(self, jobGen, db):
        self.jobGen = jobGen
        self.conf = jobGen.conf
        self.db = db
        self.querySplitSize = 1024*1024*self.conf.getDbInt(db, "align.querySplitSize")
        self.ooc = self.conf.getDbStrNo(db, "ooc")
        self.genome = None
        self.numAlign = 0L
        self.slow2bit = False

    # matches pre-filter options
    preFilterOptsRe = re.compile("(-minId=)|(-minCover=)|(-maxRepMatch=)|(-minQSize=)|(-polyASizes=)")

    def _getPreFilterOpts(self, rel, cdnaType, orgCat):
        "select non-comparitive pslCDnaFilter options for blat job filtering"
        filterOpts = self.conf.getvDbStrNo(self.db, rel.srcDb, cdnaType, orgCat, "pslCDnaFilter")
        if filterOpts == None:
            return None
        preOpts = []
        for opt in filterOpts.split():
            if JobGenDb.preFilterOptsRe.match(opt):
                preOpts.append(opt)
        if len(preOpts) == 0:
            return None
        else:
            return " ".join(preOpts)

    def _loadGenome(self):
        "load genome sequence info"
        self.genome = GenomeSeqs(self.conf.getDbStr(self.db, "serverGenome"))
        # get nib dir or 2bit file on cluster (FIXME: shouldn't really be a glob)
        self.clusterGenome = self.conf.getDbStr(self.db, "clusterGenome")
        if self.clusterGenome.endswith(".nib"):
            self.clusterGenome = os.path.dirname(self.clusterGenome)
        elif len(self.genome) >= 100000:
            self.slow2bit = True
        lift = self.conf.getDbStrNo(self.db, "lift")
        if lift != None:
            self.genome.addMaxGapRegions(lift, self.conf.getDbInt(self.db, "align.maxGap"))
        self.windows = GenomeWindows(self.genome,
                                     self.conf.getDbInt(self.db, "align.window"),
                                     self.conf.getDbInt(self.db, "align.overlap"))

    def _addOrgCatJobs(self, rel, cdnaType, orgCat, queries):
        "make query jobs for a given orgCat"
        if self.genome == None:
            self._loadGenome()  # lazy
        preFilterOpts = self._getPreFilterOpts(rel, cdnaType, orgCat)
        for cdnaQuery in queries:
            jobs = Jobs(self, cdnaQuery)
            jobs.write(preFilterOpts)
            jobs.prStats()
        
    def _addJobSet(self, rel, cdnaType, orgCats):
        cdnaQueries = CDnaUnaligned(self.db, rel, cdnaType, orgCats,
                                    self.querySplitSize,
                                    self.jobGen.workDir)
        if cdnaQueries.buildQueries() > 0:
            for orgCat in orgCats:
                self._addOrgCatJobs(rel, cdnaType, orgCat, cdnaQueries.queries[orgCat])
            self.numAlign += cdnaQueries.numAlign

    def _getOrgCats(self, rel, cdnaType):
        "determine orgCats that are to be loaded"
        orgCats = set()
        for orgCat in cmdOpts.orgCats:
            if self.conf.getvDbBool(self.db, rel.srcDb, cdnaType, orgCat, "load"):
                orgCats.add(orgCat)
        return orgCats

    def addJobs(self):
        "add jobs, returning the total number of sequences needing align"
        for srcDb in cmdOpts.srcDbs:
            rel = self.jobGen.gbIndex[srcDb].getLatestRel()
            if rel != None:
                for cdnaType in cmdOpts.cdnaTypes:
                    if cdnaType in rel.cdnaTypes:
                        orgCats = self._getOrgCats(rel, cdnaType)
                if len(orgCats) > 0:
                    self._addJobSet(rel, cdnaType, orgCats)
        
class JobGen(object):
    "object to generate alignment jobs"
    def __init__(self, conf, gbIndex, workDir):
        self.conf = conf
	self.gbIndex = gbIndex
        self.workDir = os.path.normpath(workDir)
        self.jobsFile = workDir + "/align.jobs"
        self.jobsFileTmp = self.jobsFile + ".tmp"
        self.expectFile = workDir + "/align.expected"
        self.expectFileTmp = self.expectFile + ".tmp"
        self.numAlign = 0L

        fileOps.ensureDir(workDir)
        if os.path.exists(self.jobsFile):
            raise Exception("job file exists, not overwriting: " + self.jobsFile);
        if os.path.exists(self.jobsFileTmp):
            raise Exception("tmp job file exists, ensure no other alignment is running, then remove working directory: " + self.workDir);

        self.jobFh = open(self.jobsFileTmp, "w")
        self.expectFh = open(self.expectFileTmp, "w")

    def addJobs(self, db):
        "add jobs for unaligned sequences in a database"
        j = JobGenDb(self, db)
        j.addJobs()
        self.numAlign += j.numAlign

    def finish(self):
        "finish jobs file creation"
        self.expectFh.close()
        self.jobFh.close()

        if self.numAlign == 0:
            # leave flag indicating nothing to align
            open(self.workDir + "/align.none", "w").close()
            os.remove(self.expectFileTmp)
            os.remove(self.jobsFileTmp)
        else:
            os.rename(self.expectFileTmp, self.expectFile)
            os.rename(self.jobsFileTmp, self.jobsFile) # must be last

def convertOptToSet(optName, optValue, valid):
    """convert one of the restriction options to a set, validating it's values
    and defaulting to all valid if none are specified"""
    if optValue == None:
        opts = set(valid)
    else:
        opts = set(optValue)
        for o in optValue:
            if not o in valid:
                raise Exception("\"" + o + "\" is not a valid value for " + optName
                                + ", expected one of: " + ", ".join(valid))
            opts.add(o)
    return opts

def main():
    "entry point"
    parser = OptionParser(usage=usage)
    parser.add_option("--workdir", action="store", dest="workdir", default="work/align",
                      help="=work directory where alignment is built. See gbAlignStep for details. Defaults to work/align")
    parser.add_option("--clusterWorkDir",  action="store", dest="clusterWorkDir", default=None,
                      help="location of work directory on cluster.")
    parser.add_option("--verbose", action="store", dest="verbose", type="int", default=0,
                      help="print details")
    parser.add_option("--srcDb", action="append", dest="srcDbs", default=None,
                      help="Restrict the source database to either \"genbank\" or \"refseq\". Maybe repeated.")
    parser.add_option("--type", action="append", dest="cdnaTypes", default=None,
                      help="Restrict the type of sequence processeed to either \"mrna\" or \"est\". Maybe repeated.")
    parser.add_option("--orgCat", action="append", dest="orgCats", default=None,
                      help="""Restrict type of sequences to process to \"native\" or \"xeno\". If not speicifed, categories that are to be loaded are used from genbank.conf. Maybe repeated.""")
    parser.add_option("--noMigrate", action="store_true", dest="noMigrate", default=False,
                      help="Don't migrate alignments.")
    global cmdOpts
    (cmdOpts, databases) = parser.parse_args()
    if len(databases) == 0:
        parser.error("wrong number of arguments")

    # convert restriction options to sets
    cmdOpts.srcDbs = convertOptToSet("--srcDb", cmdOpts.srcDbs, (GenBank, RefSeq))
    cmdOpts.cdnaTypes = convertOptToSet("--type", cmdOpts.cdnaTypes, (MRNA, EST))
    cmdOpts.orgCats = convertOptToSet("--orgCat", cmdOpts.orgCats, (Native, Xeno))

    confFile = "etc/genbank.conf"
    if not os.path.exists(confFile):
        raise Exception(confFile + " not found, must be run from genbank root directory")
    conf = Config(confFile)

    gbIndex = GbIndex()
    jobGen = JobGen(conf, gbIndex, cmdOpts.workdir)
    for db in databases:
        jobGen.addJobs(db)
    jobGen.finish()


main()

