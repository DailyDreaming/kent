#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on the 
# Chicken (Gallus gallus) February 2004 release.


# CREATE BUILD DIRECTORY (DONE 2/23/04 angie)
    ssh kksilo
    mkdir /cluster/store7/galGal2
    ln -s /cluster/store7/galGal2 /cluster/data/galGal2


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 2/23/04 angie)
    mkdir /cluster/data/galGal2/M
    cd /cluster/data/galGal2/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "gallus mitochondrion genome".  That shows the gi number:
    # 5834843 
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=5834843&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Gallus gallus mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# DOWNLOAD WHOLE GENOME SHOTGUN CONTIGS & QUAL (DONE 2/23/04 angie)
    ssh kksilo
    cd /cluster/data/galGal2
    # Contig sequences have been stable for a while:
    wget ftp://genome.wustl.edu/private/chicken_040105/Fasta/chicken_040105.contigs.tar.gz
    # Official location (password-protected):
    # http://genome.wustl.edu/projects/chicken/chicken_analysis/chicken_040105.contigs.tar.gz
    mkdir contigs
    cd contigs
    tar xvfz ../chicken_040105.contigs.tar.gz
    foreach f (chicken_031214.pcap.contigs*)
      set n = `echo $f | sed -e 's/chicken_031214.pcap.contigs//'`
      mv $f contigs$n.fa
    end
    faSize *.fa
#1054180845 bases (107580 N's 1054073265 real) in 111864 sequences in 100 files
#Total size: mean 9423.8 sd 19990.9 min 52 (Contig28908.1) max 441791 (Contig132.21) median 2122
#N count: mean 1.0 sd 5.1
    mkdir /cluster/bluearc/galGal2
    cat ../contigs/*.fa > /cluster/bluearc/galGal2/allContigs.fa
    # Get qual scores too
    cd /cluster/data/galGal2
    wget ftp://genome.wustl.edu/private/chicken_040105/Qual/chicken_040105.contigs.qual.tar.gz
    # Official location (password-protected):
    # http://genome.wustl.edu/projects/chicken/chicken_analysis/chicken_040105.contigs.qual.tar.gz
    

# DOWNLOAD AGP, BUILD AND CHECK CHROM-LEVEL SEQUENCE (DONE 2/24/04 angie)
    ssh kolossus
    cd /cluster/data/galGal2
    wget ftp://genome.wustl.edu/private/lhillier/old/chicken_agp_040224.tar.gz
    # anticipated Official location (password-protected):
    # http://genome.wustl.edu/projects/chicken/chicken_analysis/chicken_agp_040224.tar.gz
    tar xvzf chicken_agp_040224.tar.gz
    cd agp_040224
    cp /dev/null ../chrom.lst
    foreach f (*.agp)
      set chr = `echo $f:r | sed -e 's/^chr//'`
      set base = `echo $chr | sed -e 's/_random$//'`
      mkdir -p ../$base
      cp -p $f ../$base
      if ("$chr" == "$base") echo $chr >> ../chrom.lst
    end
    # OK, tack chrM on there too:
    echo M >> ../chrom.lst
    cd /cluster/data/galGal2
    foreach c (`cat chrom.lst`)
      foreach agp ($c/chr$c{,_random}.agp)
        if (-e $agp) then
          set fa = $agp:r.fa
          echo building $fa from $agp
          agpToFa -simpleMultiMixed $agp $agp:t:r $fa \
            /cluster/bluearc/galGal2/allContigs.fa
        endif
      end
    end
    # checkAgpAndFa prints out way too much info -- keep the end/stderr only:
    foreach c (`cat chrom.lst`)
      foreach agp ($c/chr$c{,_random}.agp)
        if (-e $agp) then
          set fa = $agp:r.fa
          echo checking consistency of $agp and $fa
          ~/bin/$MACHTYPE/checkAgpAndFa $agp $fa | tail -1
        endif
      end
    end
    faSize */chr*.fa
#1133629576 bases (79539536 N's 1054090040 real) in 54 sequences in 54 files
#Total size: mean 20993140.3 sd 41649023.2 min 1525 (chrE64) max 188239860 (chr1) median 4731479
#N count: mean 1472954.4 sd 5969394.3
    # excluding chrM.fa:  note the same #real as for WGS contigs:
#1133612801 bases (79539536 N's 1054073265 real) in 53 sequences in 53 files
#Total size: mean 21388920.8 sd 41944943.4 min 1525 (chrE64) max 188239860 (chr1) median 4731479
#N count: mean 1500746.0 sd 6022991.0


# COMPARE BASE COUNTS WITH WUSTL'S (DONE 2/27/04 angie)
    # Compare LaDeana's size summary file with our chrom faSize output:
    ssh kksilo
    cd /cluster/data/galGal2
    # Download from password-protected location:
    wget --http-user=xxxxxx --http-passwd=xxxxx \
      -O basepairs_per_chromosome \
      http://genome.wustl.edu/projects/chicken/chicken_analysis/rsc/basepairs_per_chromosome
    # Actually, we can only compare total bases with faSize because faSize 
    # doesn't differentiate between an N from a gap and an N base.  
    perl -wpe   'chop; if (! /[0-9]/ || /TOTALS/) { s/^.*$//; next; } \
                 s/^GGA//; \
                 if (s/^(\w+)\s+(\d+)\s+(\d+)\s*$//) { \
                   ($c, $noGapBP, $totalBP) = ($1, $2, $3); \
                   $c =~ s/Unlocalized/Un/; \
                   $chr = "chr$c"; \
                   $c =~ s/_random//; \
                   $faSize = "faSize $c/$chr.fa"; \
                   $faSize = `$faSize`; \
                   if ($faSize =~ /^(\d+) bases \((\d+) N.s (\d+) real/) { \
                     if ($totalBP != $1) { \
                       print "$chr totalBP: WUSTL $totalBP, us $1!\n"; \
                     } \
                   } else { print "parsed faSize wrong:\n$faSize\n"; } \
                 } else { print "what is this?\n$_\n"; }' \
      basepairs_per_chromosome
    # oops, basepairs_per_chromosome doesn't include terminal gaps in total BP
    # counts... told LaDeana:
#chr12 totalBP: WUSTL 19811895, us 19821895!
#chr23 totalBP: WUSTL 5166127, us 5666127!
#chr28 totalBP: WUSTL 4231479, us 4731479!


# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT CONTIGS/GAPS (DONE 2/24/04 angie)
    ssh kksilo
    cd /cluster/data/galGal2
    foreach c (`cat chrom.lst`)
      foreach agp ($c/chr$c{,_random}.agp)
        if (-e $agp) then
          set fa = $agp:r.fa
          echo splitting $agp and $fa
          cp -p $agp $agp.bak
          cp -p $fa $fa.bak
          splitFaIntoContigs $agp $fa . -nSize=5000000
        endif
      end
    end
    # splitFaIntoContigs makes new dirs for _randoms.  Move their contents 
    # back into the main chrom dirs and get rid of the _random dirs.
    foreach d (*_random)
      set base = `echo $d | sed -e 's/_random$//'`
      mv $d/lift/oOut.lst $base/lift/rOut.lst
      mv $d/lift/ordered.lft $base/lift/random.lft
      mv $d/lift/ordered.lst $base/lift/random.lst
      rmdir $d/lift
      mv $d/* $base
      rmdir $d
    end
    # Make a "pseudo-contig" for processing chrM too:
    mkdir M/chrM_1
    sed -e 's/chrM/chrM_1/' M/chrM.fa > M/chrM_1/chrM_1.fa
    mkdir M/lift
    echo "chrM_1/chrM_1.fa.out" > M/lift/oOut.lst
    echo "chrM_1" > M/lift/ordered.lst
    echo "0	M/chrM_1	16775	chrM	16775" > M/lift/ordered.lft


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 2/23/04 angie)
    # This used to hold scripts -- better to keep them inline here so 
    # they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/galGal2/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/galGal2/bed


# CREATING DATABASE (DONE 2/23/04 angie)
    ssh hgwdev
    echo 'create database galGal2' | hgsql ''
    # Use df to make sure there is at least 75G free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
    # /dev/sdc1             1.8T  318G  1.4T  20% /var/lib/mysql


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 2/23/04 angie)
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from hg16.grp" \
      | hgsql galGal2


# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS (DONE 2/24/04 angie)
    # Make nib/, unmasked until RepeatMasker and TRF steps are done.
    # Do this now so we can load up RepeatMasker and run featureBits; 
    # can also load up other tables that don't depend on masking.  
    ssh kksilo
    cd /cluster/data/galGal2
    mkdir nib
    foreach c (`cat chrom.lst`)
      foreach f ($c/chr${c}{,_random}.fa)
        if (-e $f) then
          echo "nibbing $f"
          /cluster/bin/i386/faToNib $f nib/$f:t:r.nib
        endif
      end
    end

    # Make symbolic links from /gbdb/galGal2/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/galGal2/nib
    foreach f (/cluster/data/galGal2/nib/chr*.nib)
      ln -s $f /gbdb/galGal2/nib
    end
    # Load /gbdb/galGal2/nib paths into database and save size info.
    cd /cluster/data/galGal2
    hgsql galGal2  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib galGal2 /gbdb/galGal2/nib */chr*.fa
    echo "select chrom,size from chromInfo" | hgsql -N galGal2 > chrom.sizes
    # take a look at chrom.sizes, should be 54 lines
    wc chrom.sizes


# REPEAT MASKING (DONE 2/25/04 angie)
    #- Split contigs into 500kb chunks, at gaps if possible:
    ssh kksilo
    cd /cluster/data/galGal2
    foreach c (`cat chrom.lst`)
      foreach d ($c/chr${c}*_?{,?})
        cd $d
        echo "splitting $d"
        set contig = $d:t
        ~/bin/i386/faSplit gap $contig.fa 500000 ${contig}_ -lift=$contig.lft \
            -minGapSize=100
        cd ../..
      end
    end

    #- Make the run directory and job list:
    cd /cluster/data/galGal2
    cat << '_EOF_' > jkStuff/RMChicken
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/galGal2/$2
/bin/cp $2 /tmp/galGal2/$2/
cd /tmp/galGal2/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s -spec chicken $2
popd
/bin/cp /tmp/galGal2/$2/$2.out ./
if (-e /tmp/galGal2/$2/$2.align) /bin/cp /tmp/galGal2/$2/$2.align ./
if (-e /tmp/galGal2/$2/$2.tbl) /bin/cp /tmp/galGal2/$2/$2.tbl ./
if (-e /tmp/galGal2/$2/$2.cat) /bin/cp /tmp/galGal2/$2/$2.cat ./
/bin/rm -fr /tmp/galGal2/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/galGal2/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/galGal2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMChicken
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach c (`cat chrom.lst`)
      foreach d ($c/chr${c}{,_random}_?{,?})
          set ctg = $d:t
          foreach f ( $d/${ctg}_?{,?}.fa )
            set f = $f:t
            echo /cluster/data/galGal2/jkStuff/RMChicken \
                 /cluster/data/galGal2/$d $f \
               '{'check out line+ /cluster/data/galGal2/$d/$f.out'}' \
              >> RMRun/RMJobs
          end
      end
    end

    #- Do the run
    ssh kk
    cd /cluster/data/galGal2/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...
#Completed: 2724 of 2724 jobs
#Average job time:                2033s      33.89m     0.56h    0.02d
#Longest job:                     9752s     162.53m     2.71h    0.11d
#Submission to last job:          9771s     162.85m     2.71h    0.11d

    #- Lift up the 500KB chunk .out's to 5MB ("pseudo-contig") level
    ssh kksilo
    cd /cluster/data/galGal2
    foreach d (*/chr*_?{,?})
      set contig = $d:t
      echo $contig
      liftUp $d/$contig.fa.out $d/$contig.lft warn $d/${contig}_*.fa.out \
        > /dev/null
    end

    #- Lift pseudo-contigs to chromosome level
    foreach c (`cat chrom.lst`)
      echo lifting $c
      cd $c
      if (-e lift/ordered.lft && ! -z lift/ordered.lft) then
        liftUp chr$c.fa.out lift/ordered.lft warn `cat lift/oOut.lst` \
        > /dev/null
      endif
      if (-e lift/random.lft && ! -z lift/random.lft) then
        liftUp chr${c}_random.fa.out lift/random.lft warn `cat lift/rOut.lst` \
        > /dev/null
      endif
      cd ..
    end

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/galGal2
    hgLoadOut galGal2 */chr*.fa.out


# RE-RUN PROCESSREPEATS (DONE 2/25/04 angie)
    # Sure hope this is the only time we ever need to do this:
    # Arian sent an update to the ProcessRepeats script -- we can re-run 
    # from .cat files, should go pretty quickly, and Arian says it shouldn't 
    # affect our masking that much.
    ssh kksilo
    cd /cluster/data/galGal2
    foreach d (*/chr*_?{,?})
      echo $d
      rm -rf /tmp/gawdammit
      mkdir /tmp/gawdammit
      cp -p $d/*.cat /tmp/gawdammit
      pushd /tmp/gawdammit
      /cluster/home/angie/cb/RepeatMasker/ProcessRepeats -spec gallus *.cat \
      > /dev/null
      popd
      liftUp $d/$d:t.new.out $d/$d:t.lft warn /tmp/gawdammit/*.out > /dev/null
    end
    # lift *.new.out to chrom-level new.out
    foreach c (`cat chrom.lst`)
      echo lifting $c
      cd $c
      if (-e lift/ordered.lft && ! -z lift/ordered.lft) then
        liftUp chr$c.new.out lift/ordered.lft warn \
          `cat lift/oOut.lst | sed -e 's/.fa.out/.new.out/'` \
        > /dev/null
      endif
      if (-e lift/random.lft && ! -z lift/random.lft) then
        liftUp chr${c}_random.new.out lift/random.lft warn \
          `cat lift/rOut.lst | sed -e 's/.fa.out/.new.out/'` \
        > /dev/null
      endif
      cd ..
    end
    # Compare old .fa.out to new (reloading chr*_rmsk in the process)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/ProcessRepeatsCheck
    cd /cluster/data/galGal2/bed/ProcessRepeatsCheck
    featureBits galGal2 rmsk -bed=rmsk.orig.bed
#104249252 bases of 1054197620 (9.889%) in intersection
    hgLoadOut galGal2 */chr*.new.out
    featureBits galGal2 rmsk -bed=rmsk.new.bed
#104249260 bases of 1054197620 (9.889%) in intersection
    featureBits galGal2 rmsk \!rmsk.orig.bed -bed=notIn.orig.bed
#8 bases of 1054197620 (0.000%) in intersection
    featureBits galGal2 \!rmsk rmsk.orig.bed -bed=notIn.new.bed
#0 bases of 1054197620 (0.000%) in intersection
    # SWEET!
    cat notIn.orig.bed 
#chr1    141589449       141589454       chr1.1
#chr2    110897485       110897488       chr2.1
    # In chr1, looks like these two original lines...
# 1014  31.8  6.7  1.7  chr1      141588904 141589449 (46650411) +  CR1-Y4         LINE/CR1               281 4041  (472)    176
# 1099  27.8  6.2  1.6  chr1      141589455 141589838 (46650022) +  CR1-Y4         LINE/CR1               806 1207    (7)    177
    # ... got merged:
# 1099  30.1  6.5  1.7  chr1      141588904 141589838 (46650022) +  CR1-Y4         LINE/CR1              3454 4508    (7)    176
    # In chr2, 
# 1305  23.6  2.1  1.2  chr2      110897148 110897485 (36693280) C  CR1-Y4         LINE/CR1              (14) 1200    860     96
#  335  20.4  0.9  8.8  chr2      110897489 110897601 (36693164) C  CR1-Y          LINE/CR1             (423) 4090   3987     97
    # get merged to
# 1305  22.8  1.8  3.3  chr2      110897148 110897601 (36693164) C  CR1-Y4         LINE/CR1              (14) 4501   3987     

    # Replace old .fa.outs with .new.outs
    foreach f ( */chr*.new.out */*/chr*_?{,?}.new.out )
      set g = `echo $f | sed -e 's/.new.out/.fa.out/'`
      mv $f $g
    end
    # Remove lowest-level old .fa.out's -- and .fa's while at it
    foreach d (*/chr*_?{,?})
      rm $d/${d:t}_?{,?}.fa.out
      rm $d/${d:t}_?{,?}.fa
    end


# VERIFY REPEATMASKER RESULTS (DONE 2/26/04 angie)
    # Eyeball some repeat annotations in the browser, compare to lib seqs.
    # Run featureBits on galGal2 and on a comparable genome build, and compare:
    ssh hgwdev
    featureBits galGal2 rmsk
#104249260 bases of 1054197620 (9.889%) in intersection
    # slight increase from galGal1:
#103553237 bases of 1054197620 (9.823%) in intersection


# MAKE 10.OOC, 11.OOC FILES FOR BLAT (DONE 2/27/04 angie)
    # Use -repMatch=380 (based on size -- for human we use 1024, and 
    # chicken size is ~37% of human)
    ssh kkr1u00
    mkdir /cluster/data/galGal2/bed/ooc
    cd /cluster/data/galGal2/bed/ooc
    ls -1 /cluster/data/galGal2/nib/chr*.nib > nib.lst
    blat nib.lst /dev/null /dev/null -tileSize=11 \
      -makeOoc=/cluster/bluearc/galGal2/11.ooc -repMatch=380
#Wrote 13552 overused 11-mers to /cluster/bluearc/galGal2/11.ooc
    blat nib.lst /dev/null /dev/null -tileSize=10 \
      -makeOoc=/cluster/bluearc/galGal2/10.ooc -repMatch=380
#Wrote 169709 overused 10-mers to /cluster/bluearc/galGal2/10.ooc
    cp -p /cluster/bluearc/galGal2/*.ooc /iscratch/i/galGal2/
    iSync


# MAKE LIFTALL.LFT (DONE 2/24/04 angie)
    ssh kksilo
    cd /cluster/data/galGal2
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft


# PUT UNMASKED CHUNKS ON BLUEARC (DONE 2/24/04 angie)
    # Some of Terry's staging scripts require a flat dir containing 
    # all contigs; also, doesn't hurt to set aside unmasked seq.
    ssh kksilo
    cd /cluster/data/galGal2
    mkdir /cluster/bluearc/galGal2/unmaskedChunks
    foreach d (*/chr*_?{,?})
      cp -p $d/${d:t}.fa /cluster/bluearc/galGal2/unmaskedChunks
    end


# MAKE STS MARKERS TRACK (TODO 3//04 angie -- need more info from Terry)
    set base = /cluster/data/galGal2/bed/markers
    mkdir -p $base/primers $base/sts
    # Need to find out how Terry built these:
    cp -p /cluster/bluearc/gg1/markers/sts/convert.pl $base
    cp -p /cluster/bluearc/gg1/markers/stsAlias.bed $base
    cp -p /cluster/bluearc/gg1/markers/stsInfoGG.bed $base

    # Need to find out where Terry got these files:
    cp -p /cluster/bluearc/gg1/markers/primers/all.primers{,.fa} $base/primers
    cp -p /cluster/bluearc/gg1/markers/sts/all.sequence.fa $base/sts

    # Run e-PCR on primers
    mkdir $base/primers/epcr
    cd $base/primers/epcr
    mkdir epcr.out
    /cluster/bin/scripts/createCloneList \
      /cluster/bluearc/galGal2/unmaskedChunks
    # That script creates in.lst/$n.in files, where $n is 
    # the contigs number *plus 1*!  in.lst/0.in is empty and makes 
    # para create complain, so get rid of it.  
    rm in.lst/0.in
    egrep -v '/0.in$' files.lst > tmp.lst; mv tmp.lst files.lst
    echo $base/primers/all.primers > epcr.lst
    cat << '_EOF_' > template
#LOOP
/cluster/bin/scripts/runEpcr {check in line+ $(path1)} {check in line+ $(path2)} {check out exists epcr.out/$(root2).epcr}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    /cluster/bin/i386/gensub2 epcr.lst files.lst template jobList
    ssh kk
    set base = /cluster/data/galGal2/bed/markers
    cd $base/primers/epcr
    para create jobList
    para try, check, push, check, ...
#Completed: 251 of 251 jobs
#Average job time:                  30s       0.50m     0.01h    0.00d
#Longest job:                       45s       0.75m     0.01h    0.00d
#Submission to last job:            46s       0.77m     0.01h    0.00d
    cat `ls -1 epcr.out/* | sort -g` > all.epcr

    # blat primers -- with old blat.2 !
    mkdir $base/primers/blat
    cd $base/primers/blat
    mkdir primers.out
    ls -1S /cluster/bluearc/galGal2/unmaskedChunks/*.fa > contigs.lst
    echo $base/primers/all.primers.fa > primers.lst
    cat << '_EOF_' > template
#LOOP
/cluster/home/kent/bin/i386/blat.2 -tileSize=10 -ooc=/cluster/bluearc/galGal2/10.ooc -minMatch=1 -minScore=1 -minIdentity=75 {check in line+ $(path1)} {check in line+ $(path2)} {check out line+ primers.out/$(root1).$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    /cluster/bin/i386/gensub2 contigs.lst primers.lst template jobList
    ssh kk
    set base = /cluster/data/galGal2/bed/markers
    cd $base/primers/blat
    para create jobList
    para try, check, push, check, ...
#Completed: 261 of 261 jobs
#Average job time:                  18s       0.30m     0.00h    0.00d
#Longest job:                       27s       0.45m     0.01h    0.00d
#Submission to last job:            28s       0.47m     0.01h    0.00d
    /cluster/bin/i386/pslSort dirs primers.psl temp primers.out
    rm -r temp

    # Make primers.final from e-PCR and blat results:
    cd $base/primers
    filterPrimers -chicken ../stsInfoGG.bed blat/primers.psl all.primers \
      epcr/all.epcr > primers.psl.filter
    extractPslInfo primers.psl.filter
    mv primers.psl.filter.initial primers.initial
    sort -k 4n primers.initial > primers.final

    # blat sts sequences
    mkdir $base/sts/blat
    cd $base/sts/blat
    mkdir stsMarkers.out
    ls -1S /cluster/bluearc/galGal2/unmaskedChunks/*.fa > contigs.lst
    echo $base/sts/all.sequence.fa > stsMarkers.lst
    cat << '_EOF_' > template
#LOOP
/cluster/bin/i386/blat {check in line+ $(path1)} {check in line+ $(path2)} {check out line+ stsMarkers.out/$(root1).psl}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    /cluster/bin/i386/gensub2 contigs.lst stsMarkers.lst template jobList
    ssh kk
    set base = /cluster/data/galGal2/bed/markers
    cd $base/sts/blat
    para create jobList
    para try, check, push, check, ...
#Completed: 261 of 261 jobs
#Average job time:                  96s       1.59m     0.03h    0.00d
#Longest job:                      199s       3.32m     0.06h    0.00d
#Submission to last job:           199s       3.32m     0.06h    0.00d
    /cluster/bin/i386/pslSort dirs raw.psl temp stsMarkers.out
    /cluster/bin/i386/pslReps -nearTop=0.01 -minCover=0.6 -minAli=0.8 \
      -noIntrons raw.psl stsMarkers.psl /dev/null
    rm -rf temp
    rm -f raw.psl

    cd $base/sts
    filterPsl blat/stsMarkers.psl
    extractUniqPsl stsMarkers.psl.filter stsMarkers.psl.filter
    pslReps stsMarkers.psl.filter.dup.psl stsMarkers.psl.filter.1 /dev/null \
      -noIntrons -minCover=0.80 -minAli=0.90 -nearTop=0.05
    mv stsMarkers.psl.filter stsMarkers.psl.filter.orig
    cat stsMarkers.psl.filter.1 stsMarkers.psl.filter.uniq.psl \
      > stsMarkers.psl.filter
    extractPslInfo -h stsMarkers.psl.filter
    rm stsMarkers.psl.filter.1*
    rm stsMarkers.psl.filter.dup.psl stsMarkers.psl.filter.names \
      stsMarkers.psl.filter.uniq.psl
    extractPslInfo -h stsMarkers.psl.filter
    mv stsMarkers.psl.filter.initial stsMarkers.initial
    sort -k 4n stsMarkers.initial > stsMarkers.final.orig
    ../convert.pl ../stsAlias.bed stsMarkers.final.orig > stsMarkers.final

    cd $base
    combineSeqPrimerPos $base/sts/stsMarkers.final \
      $base/primers/primers.final > stsMarkers_pos.rdb
    # This step needs work -- output is 0-length
    createSTSbed stsInfoGG.bed stsMarkers_pos.rdb > stsMap.bed

    ssh hgwdev
    cd /cluster/data/galGal2/bed/markers
    # Make an stsMarkersTmp so we can at least see the locations
    awk '{printf "%s\t%s\t%s\t%s\t%d\n", $1, $2, $3, $4, $5 * 1000};' \
      sts/stsMarkers.final.orig \
    | liftUp -type=.bed stsMarkersTmp.bed ../../jkStuff/liftAll.lft warn stdin
    hgLoadBed galGal2 stsMarkerTmp stsMarkersTmp.bed 
    # lift & load all_sts_primer
    liftUp primers.filter.lifted.psl ../../jkStuff/liftAll.lft warn \
      primers/primers.psl.filter
    hgLoadPsl -table=all_sts_primer -fastLoad \
      galGal2 primers.filter.lifted.psl
    # lift & load all_sts_seq
    liftUp stsMarkers.filter.lifted.psl ../../jkStuff/liftAll.lft warn \
      sts/stsMarkers.psl.filter
    hgLoadPsl -table=all_sts_seq -fastLoad \
      galGal2 stsMarkers.filter.lifted.psl
    # load sequences
    mkdir /gbdb/galGal2/sts
    ln -s /cluster/data/galGal2/bed/markers/sts/all.sequence.fa \
      /gbdb/galGal2/sts/
    ln -s /cluster/data/galGal2/bed/markers/primers/all.primers.fa \
      /gbdb/galGal2/sts/
    hgLoadSeq galGal2 /gbdb/galGal2/sts/*.fa


# BACENDS (DONE 2/24/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/bacends
    cd /cluster/data/galGal2/bed/bacends
    # download
    wget ftp://ftp.ncbi.nih.gov/genomes/BACENDS/gallus_gallus/AllBACends.mfa.gz
    wget ftp://ftp.ncbi.nih.gov/genomes/BACENDS/gallus_gallus/cl_acc_gi_len.gz
    gunzip *.gz
    /cluster/bin/scripts/convertBacEndPairInfo cl_acc_gi_len >& pairInfo.log
    perl -wpe 's/^>gi\|\d+\|gb\|(\w+)\.\d+\|.*/>$1/' AllBACends.mfa \
      > bacends.fa
    faSize bacends.fa
#146921771 bases (2724913 N's 144196858 real) in 135555 sequences in 1 files
#Total size: mean 1083.9 sd 184.7 min 64 (CC322877.1) max 2431 (CC263290.1) median 1095
#N count: mean 20.1 sd 73.1
    rm AllBACends.mfa
    mkdir /cluster/bluearc/galGal2/bacends
    faSplit sequence bacends.fa 20 /cluster/bluearc/galGal2/bacends/bacends
    ls -1S /cluster/bluearc/galGal2/bacends/*.fa > bacends.lst
    ls -1S /cluster/bluearc/galGal2/unmaskedChunks/*.fa > contigs.lst
    cat << '_EOF_' > template
#LOOP
/cluster/bin/i386/blat $(path1) $(path2) -tileSize=10 -ooc=/cluster/bluearc/galGal2/10.ooc {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    mkdir psl
    gensub2 contigs.lst bacends.lst template jobList
    ssh kk
    cd /cluster/data/galGal2/bed/bacends
    para create jobList
    para try, check, push, check, ...
#Completed: 5180 of 5180 jobs
#Average job time:                  97s       1.62m     0.03h    0.00d
#Longest job:                     5256s      87.60m     1.46h    0.06d
#Submission to last job:          5333s      88.88m     1.48h    0.06d
    # back on kksilo, filter and lift results:
    pslSort dirs raw.psl temp psl
    pslReps -nearTop=0.02 -minCover=0.60 -minAli=0.85 -noIntrons raw.psl \
      bacEnds.psl /dev/null
    liftUp bacEnds.lifted.psl ../../jkStuff/liftAll.lft warn bacEnds.psl
    rm -r temp
    rm raw.psl

    extractUniqPsl bacEnds.lifted.psl bacEnds.psl.filter
    pslReps bacEnds.psl.filter.dup.psl bacEnds.psl.filter.1 /dev/null \
      -noIntrons -minCover=0.80 -minAli=0.90 -nearTop=0.05
    extractUniqPsl bacEnds.psl.filter.1 bacEnds.psl.filter.1
    rm bacEnds.psl.filter.1
    pslReps bacEnds.psl.filter.1.dup.psl bacEnds.psl.filter.2 /dev/null \
      -noIntrons -minCover=0.90 -minAli=0.95 -nearTop=0.01
    extractUniqPsl bacEnds.psl.filter.2 bacEnds.psl.filter.2
    rm bacEnds.psl.filter.2
    pslReps bacEnds.psl.filter.2.dup.psl bacEnds.psl.filter.3 /dev/null \
      -noIntrons -minCover=0.95 -minAli=0.98 -nearTop=0.01
    cat bacEnds.psl.filter.3 \
        bacEnds.psl.filter.uniq.psl \
        bacEnds.psl.filter.1.uniq.psl \
        bacEnds.psl.filter.2.uniq.psl \
    > bacEnds.psl.filter.lifted
    rm *.names bacEnds.psl.filter.3 bacEnds.psl.filter.uniq.psl \
       bacEnds.psl.filter.1.uniq.psl bacEnds.psl.filter.2.uniq.psl

    extractPslInfo -h -be bacEnds.psl.filter.lifted
    mv bacEnds.psl.filter.lifted.initial bacEnds.initial
    findAccession -agp -chicken bacEnds.initial /cluster/data/galGal2
    rm bacEnds.initial
    sort -k 4 bacEnds.initial.acc > bacEnds.sort
    compileBacEnds bacEnds.sort bacEndPairs.txt bacEndSingles.txt \
      > bacEnds.temp
    sorttbl chrom chromStart < bacEnds.temp > bacEnds.rdb
    rm bacEnds.initial.acc bacEnds.sort bacEnds.temp

    createBACpairs bacEnds.rdb bacEndPairs.txt > temp.rdb
    sorttbl chrom1 -r ord1 chromStart1 < temp.rdb > bacEnds.pairs.rdb
    rm temp.rdb
    createBACpairs -bed bacEnds.rdb bacEndPairs.txt > bacEndPairs.rdb
    sorttbl chrom chromStart < bacEndPairs.rdb \
    | headchg -del > bacEndPairs.bed    
    rm bacEndPairs.rdb
    createBacPairsBad -bed bacEnds.rdb bacEndPairs.txt > bacEndPairsBad.rdb
    sorttbl chrom chromStart < bacEndPairsBad.rdb \
    | headchg -del > bacEndPairsBad.bed    
    rm bacEndPairsBad.rdb
    sorttbl chrom chromStart < bacEndPairsLong.rdb \
    | headchg -del > bacEndPairsLong.bed
    rm bacEndPairsLong.rdb
    findMissingEnd -max 500000 singleBac.txt bacEnds.psl.filter.2.dup.psl \
      bacEnds.psl.filter.1.dup.psl bacEnds.psl.filter.dup.psl > bacEndsMiss.psl
    mv bacEnds.psl.filter.lifted bacEnds.psl.filter.lifted.orig
    cat bacEnds.psl.filter.lifted.orig bacEndsMiss.psl \
      > bacEnds.psl.filter.lifted
    rm bacEnds.psl.filter.2.dup.psl bacEnds.psl.filter.1.dup.psl \
       bacEnds.psl.filter.dup.psl
    extractPslLoad bacEnds.psl.filter.lifted bacEndPairs.bed \
      bacEndPairsBad.bed bacEndPairsLong.bed > bacEnds.psl.rdb
    sorttbl tname tstart < bacEnds.psl.rdb | headchg -del > bacEnds.load.psl
    rm bacEnds.psl.rdb

    # Load seq's and alignments
    ssh hgwdev
    cd /cluster/data/galGal2/bed/bacends
    mkdir /gbdb/galGal2/bacends
    ln -s /cluster/data/galGal2/bed/bacends/bacends.fa /gbdb/galGal2/bacends
    hgLoadSeq galGal2 /gbdb/galGal2/bacends/bacends.fa
    hgLoadPsl -table=all_bacends -fastLoad \
      galGal2 /cluster/data/galGal2/bed/bacends/bacEnds.load.psl
    # Don't know what caused the warning... but all seem to have loaded.
#load of all_bacends did not go as planned: 76421 record(s), 0 row(s) skipped, 1 warning(s) loading psl.tab
    hgLoadBed -sqlTable=$HOME/kent/src/hg/lib/bacEndPairs.sql \
      -hasBin galGal2 bacEndPairs bacEndPairs.bed

    sed -e 's/bacEndPairs/bacEndPairsBad/g' \
      $HOME/kent/src/hg/lib/bacEndPairs.sql > bacEndPairsBad.sql
    ~/bin/i386/hgLoadBed -sqlTable=bacEndPairsBad.sql \
      -hasBin galGal2 bacEndPairsBad bacEndPairsBad.bed
    # Doh!  6 lines of that have negative starts.  Well, trim those 
    # for now and load the rest, then go back and find the neg-start 
    # cause...
    egrep -v '	-[0-9]+' bacEndPairsBad.bed > bacEndPairsBadFudge.bed
    ~/bin/i386/hgLoadBed -sqlTable=bacEndPairsBad.sql \
      -hasBin galGal2 bacEndPairsBad bacEndPairsBadFudge.bed

    sed -e 's/bacEndPairs/bacEndPairsLong/g' \
      $HOME/kent/src/hg/lib/bacEndPairs.sql > bacEndPairsLong.sql
    ~/bin/i386/hgLoadBed -sqlTable=bacEndPairsLong.sql \
      -hasBin galGal2 bacEndPairsLong bacEndPairsLong.bed


# SIMPLE REPEATS (TRF) (DONE 2/24/04 angie)
    # TRF runs pretty quickly now... it takes a few hours total runtime, 
    # so instead of binrsyncing and para-running, just do this on the
    # local fileserver
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/simpleRepeat
    cd /cluster/data/galGal2/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach d (/cluster/data/galGal2/*/chr*_?{,?})
      set ctg = $d:t
      foreach f ($d/${ctg}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
      end
    end
    csh -ef jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    endsInLf trf/*
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/galGal2/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load into the database:
    ssh hgwdev
    hgLoadBed galGal2 simpleRepeat \
      /cluster/data/galGal2/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
    featureBits galGal2 simpleRepeat
    # 8434365 bases of 1054197620 (0.800%) in intersection
    # Wow, identical to galGal1!  Which would really freak me out except that 
    # the underlying WGS contig sequences have not changed at all, only their 
    # relative ordering+orientation along chroms.  


# PROCESS SIMPLE REPEATS INTO MASK (DONE 2/24/04/ angie)
    # After the simpleRepeats track has been built, make a filtered version 
    # of the trf output: keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/galGal2/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/galGal2
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (`cat chrom.lst`)
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # Here's the coverage for the filtered TRF:
    ssh hgwdev
    cat /cluster/data/galGal2/bed/simpleRepeat/trfMaskChrom/*.bed \
      > /tmp/filtTrf.bed
    featureBits galGal2 /tmp/filtTrf.bed
    # 4510381 bases of 1054197620 (0.428%) in intersection
    # OK, not *identical* to galGal1 (4512560) but very close.  Maybe 
    # there's a difference in the period chosen for some range of bases??  


# MASK SEQUENCE WITH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE 2/25/04 angie)
    # Note: just to keep things consistent, redid chr1 and chr2 2/26 with 
    # the ProcessRepeats-only rerun results (only masking changes were 
    # 5bp in chr1 and 3bp in chr2)
    ssh kksilo
    cd /cluster/data/galGal2
    # Soft-mask (lower-case) the contig and chr .fa's, 
    # then make hard-masked versions from the soft-masked.  
    set trfCtg=bed/simpleRepeat/trfMask
    set trfChr=bed/simpleRepeat/trfMaskChrom
    foreach f (*/chr*.fa)
      echo "repeat- and trf-masking $f"
      maskOutFa -soft $f $f.out $f
      set chr = $f:t:r
      maskOutFa -softAdd $f $trfChr/$chr.bed $f
      echo "hard-masking $f"
      maskOutFa $f hard $f.masked
    end
# This warning is extremely rare -- if it indicates a problem, it's only 
# with the repeat annotation and doesn't affect our masking.
#WARNING: negative rEnd: -25 chr2:94907561-94907817 GGLTR3B1
# sent test case to Arian.  (line 101 of chr2_19_19.fa.out)
    foreach c (`cat chrom.lst`)
      echo "repeat- and trf-masking contigs of chr$c, chr${c}_random"
      foreach d ($c/chr*_?{,?})
        set ctg=$d:t
        set f=$d/$ctg.fa
        maskOutFa -soft $f $f.out $f
        maskOutFa -softAdd $f $trfCtg/$ctg.bed $f
        maskOutFa $f hard $f.masked
      end
    end
# same deal here:
#WARNING: negative rEnd: -25 chr2_19:4344750-4345006 GGLTR3B1
    #- Rebuild the nib files, using the soft masking in the fa:
    mkdir nib
    foreach f (*/chr*.fa)
      faToNib -softMask $f nib/$f:t:r.nib
    end
    # Make one big 2bit file as well, and make a link to it in 
    # /gbdb/galGal2/nib because hgBlat looks there:
    faToTwoBit */chr*.fa galGal2.2bit
    ln -s /cluster/data/galGal2/galGal2.2bit /gbdb/galGal2/nib/


# GOLD AND GAP TRACKS (DONE 2/24/04 angie)
    ssh hgwdev
    cd /cluster/data/galGal2
    hgGoldGapGl -noGl -chromLst=chrom.lst galGal2 /cluster/data/galGal2 .
    # featureBits fails if there's no chrM_gap, so make one:
    # echo "create table chrM_gap like chr1_gap" | hgsql galGal2
    # oops, that won't work until v4.1, so do this for the time being:
    echo "create table chrM_gap select * from chr1_gap where 0=1" \
    | hgsql galGal2


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR GALGAL1 (DONE 2/24/04 angie)
    ssh hgwdev
    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd $HOME/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add galGal2 in all the right places and do
    make update
    make alpha
    cvs commit makefile

    # Add dbDb and defaultDb entries:
    echo 'insert into dbDb (name, description, nibPath, organism,  \
          defaultPos, active, orderKey, genome, scientificName,  \
          htmlPath, hgNearOk)  \
          values("galGal2", "Feb. 2004", \
          "/gbdb/galGal2/nib", "Chicken", "chr13:13120186-13124117", 1, \
          35, "Chicken", "Gallus gallus", \
          "/gbdb/galGal2/html/description.html", 0);' \
    | hgsql -h genome-testdb hgcentraltest
    echo 'update defaultDb set name = "galGal2" where genome = "Chicken"' \
        | hgsql -h genome-testdb hgcentraltest


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR GALGAL1 (DONE 2/26/04 angie)
    ssh hgwdev
    echo 'insert into blatServers values("galGal2", "blat1", "17778", "1"); \
          insert into blatServers values("galGal2", "blat1", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


# MAKE DESCRIPTION/SAMPLE POSITION HTML PAGE (DONE 2/23/04 angie)
    ssh hgwdev
    mkdir /gbdb/galGal2/html
    # Write ~/kent/src/hg/makeDb/trackDb/chicken/galGal2/description.html 
    # with a description of the assembly and some sample position queries.  
    chmod a+r $HOME/kent/src/hg/makeDb/trackDb/chicken/galGal2/description.html
    # Check it in and copy (ideally using "make alpha" in trackDb) to 
    # /gbdb/galGal2/html


# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 2/25/04 angie)
    ssh kksilo
    cd /cluster/data/galGal2
    #- Build the .zip files
    cat << '_EOF_' > jkStuff/zipAll.csh
rm -rf zip
mkdir zip
zip -j zip/chromAgp.zip [0-9A-Z]*/chr*.agp
zip -j zip/chromOut.zip */chr*.fa.out
zip -j zip/chromFa.zip */chr*.fa
zip -j zip/chromFaMasked.zip */chr*.fa.masked
cd bed/simpleRepeat
zip ../../zip/chromTrf.zip trfMaskChrom/chr*.bed
cd ../..
cd /cluster/data/genbank
./bin/i386/gbGetSeqs -db=galGal2 -native GenBank mrna \
        /cluster/data/galGal2/zip/mrna.fa
cd /cluster/data/galGal2/zip
zip -j mrna.zip mrna.fa
'_EOF_'
    # << this line makes emacs coloring happy
    csh ./jkStuff/zipAll.csh |& tee zipAll.log
    cd zip
    #- Look at zipAll.log to make sure all file lists look reasonable.  
    #- Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end
    wc -l *.zip.test

    #- Copy the .zip files to hgwdev:/usr/local/apache/...
    ssh hgwdev
    cd /cluster/data/galGal2/zip
    set gp = /usr/local/apache/htdocs/goldenPath/galGal2
    mkdir -p $gp/bigZips
    cp -p *.zip $gp/bigZips
    mkdir -p $gp/chromosomes
    foreach f ( ../*/chr*.fa )
      zip -j $gp/chromosomes/$f:t.zip $f
    end

    cd $gp/bigZips
    md5sum *.zip > md5sum.txt
    cd $gp/chromosomes
    md5sum *.zip > md5sum.txt
    # Take a look at bigZips/* and chromosomes/*, update their README.txt's
    # Can't make refGene upstream sequence files - no refSeq for chicken.
    # Maybe ensGene when we get that.


# PUT MASKED SEQUENCE OUT FOR CLUSTER RUNS (DONE 2/26/04 angie)
    ssh kkr1u00
    # Chrom-level mixed nibs that have been repeat- and trf-masked:
    rm -rf /iscratch/i/galGal2/nib
    mkdir /iscratch/i/galGal2/nib
    cp -p /cluster/data/galGal2/nib/chr*.nib /iscratch/i/galGal2/nib
    # Pseudo-contig fa that have been repeat- and trf-masked:
    rm -rf /iscratch/i/galGal2/trfFa
    mkdir /iscratch/i/galGal2/trfFa
    foreach d (/cluster/data/galGal2/*/chr*_?{,?})
      cp $d/$d:t.fa /iscratch/i/galGal2/trfFa
    end
    cp -p /cluster/data/galGal2/galGal2.2bit /iscratch/i/galGal2/
    iSync


# MAKE CHICKEN LINEAGE-SPECIFIC REPEATS (DONE 2/25/04 angie)
    # In an email 2/13/04, Arian said we could treat all human repeats as 
    # lineage-specific, but could exclude these from chicken as ancestral:
    # L3, L3a, L3b, MIR, MIR3, MIRb, MIRm
    ssh kkr1u00
    cd /cluster/data/galGal2
    mkdir -p /iscratch/i/galGal2/linSpecRep
    foreach f (*/chr*.fa.out)
      awk '$10 !~/^(L3|L3a|L3b|MIR|MIR3|MIRb|MIRm)$/ {print;}' $f \
      > /iscratch/i/galGal2/linSpecRep/$f:t:r:r.out.spec
    end


# SWAP BLASTZ HUMAN-CHICKEN TO CHICKEN-HUMAN (HG16) (DONE 2/26/04 angie)
    ssh kolossus
    mkdir /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    set aliDir = /cluster/data/hg16/bed/blastz.galGal2.2004-02-25
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    mkdir unsorted axtChrom
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSplitByTarget stdin unsorted
    # Sort the shuffled .axt files.
    foreach f (unsorted/*.axt)
      echo sorting $f:t:r
      axtSort $f axtChrom/$f:t
    end
    du -sh $aliDir/axtChrom unsorted axtChrom
#1.4G    /cluster/data/hg16/bed/blastz.galGal2.2004-02-25/axtChrom
#1.4G    unsorted
#1.4G    axtChrom
    rm -r unsorted


# CHAIN HUMAN BLASTZ (DONE 2/26/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    # Make our own linear gap file with reduced gap penalties, 
    # in hopes of getting longer chains:
    cat << '_EOF_' > ../../chickenHumanTuned.gap
tablesize	11
smallSize	111
position	1	2	3	11	111	2111	12111	32111	72111	152111	252111
qGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
tGap	325	360	400	450	600	1100	3600	7600	15600	31600	56600
bothGap	625	660	700	750	900	1400	4000	8000	16000	32000	57000
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtFilter -notQ=chrUn_random $1 \
| axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
           -linearGap=../../chickenHumanTuned.gap \
           -minScore=5000 stdin \
  /iscratch/i/galGal2/nib \
  /iscratch/i/gs.17/build34/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 50 of 50 jobs
#Average job time:                  69s       1.15m     0.02h    0.00d
#Longest job:                      218s       3.63m     0.06h    0.00d
#Submission to last job:           232s       3.87m     0.06h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain galGal2 ${c}_chainHg16 $i
    end


# NET HUMAN BLASTZ (DONE 2/26/04 angie)
    ssh kksilo
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain
    netClass noClass.net galGal2 hg16 human.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn human.net > humanSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet galGal2 netHg16 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet galGal2 netSyntenyHg16 stdin
    # Add entries for chaing16, netHg16, syntenyHg16 to chicken/galGal2 trackDb


# RUN AXTBEST ON CHICKEN/HUMAN (DONE 2/26/04 angie)
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    mkdir axtBest pslBest
    foreach f (axtChrom/chr*.axt)
      set chr=$f:t:r
      echo axtBesting $chr
      axtBest $f $chr axtBest/$chr.axt -minScore=300
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/$chr.psl
    end
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    cat pslBest/chr*.psl | hgLoadPsl -table=blastzBestHg16 galGal2 stdin


# RESCORE HUMAN BLASTZ (DONE 3/1/04 angie)
    # Webb noticed low scores in latest runs with repeats abridged --
    # PSU's restore_rpts program rescored alignments with default matrix 
    # instead of BLASTZ_Q matrix.  Rescore them here so the chainer sees 
    # the higher scores:
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    mkdir axtChrom.rescore
    foreach f (axtChrom/chr*.axt)
      axtRescore -scoreScheme=/cluster/data/blastz/HoxD55.q \
        $f axtChrom.rescore/$f:t
    end
    mv axtChrom axtChrom.orig
    mv axtChrom.rescore axtChrom


# MAKE VSHG16 DOWNLOADABLES (DONE 3/1/04 angie)
    ssh kksilo
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25
    # Webb asked for axtChrom/chr22.axt... since axtChrom is rel. small 
    # this time, just put it all out there.
    zip /cluster/data/galGal2/zip/HGaxtChrom.zip axtChrom/chr*.axt
    cd /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain
    cp all.chain human.chain
    zip /cluster/data/galGal2/zip/human.chain.zip human.chain
    rm human.chain
    zip /cluster/data/galGal2/zip/human.net.zip human.net
    zip /cluster/data/galGal2/zip/humanSyn.net.zip humanSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/galGal2/vsHg16
    cd /usr/local/apache/htdocs/goldenPath/galGal2/vsHg16
    mv /cluster/data/galGal2/zip/HGaxtChrom.zip axtChrom.zip
    mv /cluster/data/galGal2/zip/human*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# BLASTZ SELF (DONE 3/3/04 angie)
    ssh kk
    mkdir -p /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    # OK, the 500k x whole chrom 03-02 run was taking FOREVER (18hrs, ~63%)
    # and multiple folks are asking me to dig up pileups for Arian.  So, 
    # just do a vanilla run as a baseline; return to the experiments later.
    cat << '_EOF_' > DEF
# chicken vs. chicken
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET
# Chicken
SEQ1_DIR=/iscratch/i/galGal2/nib
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Chicken
SEQ2_DIR=/iscratch/i/galGal2/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/data/galGal2/bed/blastz.galGal2.2004-03-03

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line makes emacs coloring happy

    # Save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.galGal2-galGal2

    # source the DEF file
    bash
    . ./DEF
    mkdir -p $BASE/run
    ~angie/hummus/make-joblist $DEF > $BASE/run/j
    sh $BASE/xdir.sh
    cd $BASE/run
    # now edit j to prefix path to executable name
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    # make sure the j2 edits are OK, then use it:
    mv j2 j
    para create j
    para try, check, push, check, ...
#Completed: 22801 of 22801 jobs
#Average job time:                 257s       4.29m     0.07h    0.00d
#Longest job:                     1238s      20.63m     0.34h    0.01d
#Submission to last job:          6939s     115.65m     1.93h    0.08d

    # --- normalize (PennSpeak for lift)
    ssh kki
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    # run bash shell if not running it already
    source DEF
    mkdir -p $BASE/run.1
    mkdir -p $BASE/lav
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE \
                        > run.1/jobList
    cd run.1
    wc -l jobList
    head jobList
    # make sure the job list is OK
    para create jobList
    para push
#Completed: 151 of 151 jobs
#Average job time:                  24s       0.41m     0.01h    0.00d
#Longest job:                      127s       2.12m     0.04h    0.00d
#Submission to last job:           246s       4.10m     0.07h    0.00d

    # convert lav files to axt
    ssh kki
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    mkdir axtChrom
    # a new run directory
    mkdir run.2
    cd run.2
# lavToAxt has a new -dropSelf option that *will* replace axtDropOverlap,
# once /cluster/bin/i386/lavToAxt is rebuilt...  Meanwhile it's built 
# for x86_64.
    cat << '_EOF_' > do.csh
#!/bin/csh
cd $1
cat `ls -1 *.lav | sort -g` \
| lavToAxt -dropSelf stdin /iscratch/i/galGal2/nib /iscratch/i/galGal2/nib \
    stdout \
| axtSort stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x do.csh
    cat << '_EOF_' > gsub
#LOOP
./do.csh {check in exists $(path1)} {check out line+ /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChrom/$(root1).axt}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    \ls -1Sd ../lav/chr* > chrom.list
    gensub2 chrom.list single gsub jobList
    wc -l jobList
    head jobList
    para create jobList
    para try, check, push, check,...
#Completed: 53 of 54 jobs
#Crashed: 1 jobs
#Average job time:                  30s       0.51m     0.01h    0.00d
#Longest job:                      541s       9.02m     0.15h    0.01d
#Submission to last job:           576s       9.60m     0.16h    0.01d
    # The crash was not a memory problem -- it was that chr8_random's lav 
    # contained only 1 alignment, to itself (dropped), so its .axt is empty.  


# CHAIN SELF BLASTZ (DONE 3/3/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtFilter -notQ=chrUn $1 \
| axtChain stdin /iscratch/i/galGal2/nib /iscratch/i/galGal2/nib $2 \
  > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
    # oops -- empty chr8_random strikes again:
#Completed: 53 of 54 jobs
#Crashed: 1 jobs
#Average job time:                  53s       0.89m     0.01h    0.00d
#Longest job:                      514s       8.57m     0.14h    0.01d
#Submission to last job:           514s       8.57m     0.14h    0.01d

    # now on the cluster server, sort chains
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # trim to minScore=20000 to cut some of the fluff
    mkdir chainFilt
    foreach f (chain/*.chain)
      chainFilter -minScore=20000 $f > chainFilt/$f:t
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain/chainFilt
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain galGal2 ${c}_chainSelf $i
    end


# NET SELF BLASTZ (DONE 3/3/04 angie)
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain
    netClass -noAr noClass.net galGal2 galGal2 self.net

    # Make a 'syntenic' subset:
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain
    rm noClass.net
    netFilter -syn self.net > selfSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain
    netFilter -minGap=10 self.net |  hgLoadNet galGal2 netSelf stdin
    netFilter -minGap=10 selfSyn.net | hgLoadNet galGal2 netSyntenySelf stdin
    # Add entries for chainSelf, netSelf, netSyntenySelf to 
    # chicken/galGal2 trackDb


# RUN AXTBEST ON SELF (TODO 3//04 angie)
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    mkdir axtBest pslBest
    foreach f (axtChrom/chr*.axt)
      set chr=$f:t:r
      echo axtBesting $chr
      axtBest $f $chr axtBest/$chr.axt -minScore=300
      axtToPsl axtBest/$chr.axt S1.len S2.len pslBest/$chr.psl
    end


# MAKE VSSELF DOWNLOADABLES (DONE 3/3/04 angie)
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    # Webb asked for axtChrom/chr22.axt... since axtChrom is rel. small 
    # this time, just put it all out there.
    zip /cluster/data/galGal2/zip/GGaxtChrom.zip axtChrom/chr*.axt
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03/axtChain
    cp all.chain self.chain
    zip /cluster/data/galGal2/zip/self.chain.zip self.chain
    rm self.chain
    zip /cluster/data/galGal2/zip/self.net.zip self.net
    zip /cluster/data/galGal2/zip/selfSyn.net.zip selfSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/galGal2/vsSelf
    cd /usr/local/apache/htdocs/goldenPath/galGal2/vsSelf
    mv /cluster/data/galGal2/zip/GGaxtChrom.zip axtChrom.zip
    mv /cluster/data/galGal2/zip/self*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# EXTRACT PILEUPS FROM SELF ALIGNMENTS (DONE 3/9/04 angie)
    ssh kolossus
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    mkdir pslChrom
    foreach f (axtChrom/chr*.axt)
      echo $f:t:r
      axtToPsl $f S1.len S2.len pslChrom/$f:t:r.psl
    end
    mkdir pileups
    foreach f (pslChrom/chr*.psl)
      echo extracting pileups from $f:t:r
      pslToPileup $f S1.len pileups/$f:t:r.bed
    end
    ssh hgwdev
    cd /cluster/data/galGal2/bed/blastz.galGal2.2004-03-03
    hgLoadBed -noBin -sqlTable=$HOME/kent/src/hg/lib/pileups.sql galGal2 \
      pileups pileups/chr*.bed
    # Used table browser to intersect pileups w/>=50% overlap with rmsk,
    # save BED to pileups50PctRmsk.bed .


# AUTO UPDATE GENBANK MRNA RUN  (DONE 2/26/04 angie)
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .
    # See if /cluster/data/genbank/etc/genbank.conf has had any un-checked-in
    # edits, check them in if necessary:
    diff /cluster/data/genbank/etc/genbank.conf etc/genbank.conf

    # Edit etc/genbank.conf and add these lines:
# galGal2 (chicken)
galGal2.genome = /iscratch/i/galGal2/nib/chr*.nib
galGal2.lift = /cluster/data/galGal2/jkStuff/liftAll.lft
galGal2.refseq.mrna.native.load = no
galGal2.genbank.mrna.xeno.load = yes
galGal2.genbank.est.xeno.load = no
galGal2.downloadDir = galGal2

    cvs ci etc/genbank.conf
    # Edit src/align/gbBlat to add /iscratch/i/galGal2/11.ooc
    cvs diff src/align/gbBlat
    make
    cvs ci src/align/gbBlat
    # Install to /cluster/data/genbank:
    make install-server

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -clusterRootDir=/cluster/bluearc/genbank \
      -iserver=kkr1u00 -iserver=kkr2u00 -iserver=kkr3u00 -iserver=kkr4u00 \
      -iserver=kkr5u00 -iserver=kkr6u00 -iserver=kkr7u00 -iserver=kkr8u00 \
      -srcDb=genbank -type=mrna -verbose=1 -initial galGal2
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad galGal2
    # Clean up:
    rm -r /cluster/bluearc/genbank/work/initial.galGal2

    ssh eieio
    # -initial for ESTs (now with /cluster/store7 and iservers):
    nice bin/gbAlignStep -clusterRootDir=/cluster/store7/genbank \
      -iserver=kkr1u00 -iserver=kkr2u00 -iserver=kkr3u00 -iserver=kkr4u00 \
      -iserver=kkr5u00 -iserver=kkr6u00 -iserver=kkr7u00 -iserver=kkr8u00 \
      -srcDb=genbank -type=est -verbose=1 -initial galGal2
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 galGal2
    # Clean up:
    rm -r /cluster/store7/genbank/work/initial.galGal2


# PRODUCING GENSCAN PREDICTIONS (DONE 2/25/04 angie)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/genscan
    cd /cluster/data/galGal2/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Run on small cluster (more mem than big cluster).
    ssh kki
    cd /cluster/data/galGal2/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/data/galGal2/*/chr*_*/chr*_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end
    wc -l genome.list
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 254 of 259 jobs
#Crashed: 5 jobs
#Average job time:                 438s       7.29m     0.12h    0.01d
#Longest job:                    21229s     353.82m     5.90h    0.25d
#Submission to last job:         21229s     353.82m     5.90h    0.25d
    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    /cluster/bin/i386/gsBig /cluster/data/galGal2/1/chr1_4/chr1_4.fa.masked gtf/chr1_4.fa.gtf -trans=pep/chr1_4.fa.pep -subopt=subopt/chr1_4.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/i386/gsBig /cluster/data/galGal2/7/chr7_5/chr7_5.fa.masked gtf/chr7_5.fa.gtf -trans=pep/chr7_5.fa.pep -subopt=subopt/chr7_5.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/i386/gsBig /cluster/data/galGal2/11/chr11_2/chr11_2.fa.masked gtf/chr11_2.fa.gtf -trans=pep/chr11_2.fa.pep -subopt=subopt/chr11_2.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/i386/gsBig /cluster/data/galGal2/1/chr1_36/chr1_36.fa.masked gtf/chr1_36.fa.gtf -trans=pep/chr1_36.fa.pep -subopt=subopt/chr1_36.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000
    /cluster/bin/i386/gsBig /cluster/data/galGal2/Z/chrZ_6/chrZ_6.fa.masked gtf/chrZ_6.fa.gtf -trans=pep/chrZ_6.fa.pep -subopt=subopt/chrZ_6.fa.bed -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=1200000

    # Convert these to chromosome level files as so:
    ssh kksilo
    cd /cluster/data/galGal2/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/galGal2/bed/genscan
    ldHgGene galGal2 genscan genscan.gtf
    hgPepPred galGal2 generic genscanPep genscan.pep
    hgLoadBed galGal2 genscanSubopt genscanSubopt.bed


# PRODUCING FUGU BLAT ALIGNMENTS (DONE 2/27/04)
    ssh kk
    mkdir /cluster/data/galGal2/bed/blatFr1
    cd /cluster/data/galGal2/bed/blatFr1
    ls -1S /iscratch/i/fugu/trfFa/*.fa > fugu.lst
    ls -1S /iscratch/i/galGal2/nib/*.nib > chicken.lst
    cat << '_EOF_' > gsub
#LOOP
blat -mask=lower -q=dnax -t=dnax {check in exists $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    mkdir psl
    gensub2 chicken.lst fugu.lst gsub spec
    para create spec
    para try, check, push, check, ...
    # for future reference, the trfFa on bluearc seem better partitioned...
#Completed: 31212 of 31212 jobs
#Average job time:                 187s       3.11m     0.05h    0.00d
#Longest job:                    31706s     528.43m     8.81h    0.37d
#Submission to last job:         31706s     528.43m     8.81h    0.37d

    # Sort alignments:
    ssh kksilo
    cd /cluster/data/galGal2/bed/blatFr1
    pslCat -dir psl | pslSortAcc nohead chrom /cluster/store2/temp stdin

    # load seq & psl into database:
    ssh hgwdev
    mkdir /gbdb/galGal2/fuguSeq
    ln -s /cluster/data/fr1/fugu_v3.masked.fa /gbdb/galGal2/fuguSeq/
    cd /cluster/data/galGal2/bed/blatFr1
    hgLoadSeq galGal2 /gbdb/galGal2/fuguSeq/fugu_v3.masked.fa
    cd /cluster/data/galGal2/bed/blatFr1/chrom
    cat *.psl | hgLoadPsl -fastLoad -table=blatFr1 galGal2 stdin


# LOAD CPGISSLANDS (DONE 3/23/04 angie)
    ssh hgwdev
    mkdir -p /cluster/data/galGal2/bed/cpgIsland
    cd /cluster/data/galGal2/bed/cpgIsland
    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    mv cpglh.exe /cluster/data/galGal2/bed/cpgIsland/
    
    ssh kksilo
    cd /cluster/data/galGal2/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpglh.exe $f > $fout
    end
    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
/* Input columns: */
/* chrom, start, end, len, CpG: cpgNum, perGc, cpg:gpc, observed:expected */
/* chr1\t 41776\t 42129\t 259\t CpG: 34\t 65.8\t 0.92\t 0.94 */
/* Output columns: */
/* chrom, start, end, name, length, cpgNum, gcNum, perCpg, perGc, obsExp */
/* chr1\t41775\t42129\tCpG: 34\t354\t34\t233\t19.2\t65.8\to0.94 */
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load into database:
    ssh hgwdev
    cd /cluster/data/galGal2/bed/cpgIsland
    hgLoadBed galGal2 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed


# LOAD GENEID GENES (DONE 3/4/04 angie)
    # reloaded 3/16/04 with -gtf instead of -exon=CDS (nec. now! for stop_codon)
    mkdir -p /cluster/data/galGal2/bed/geneid/download
    cd /cluster/data/galGal2/bed/geneid/download
    foreach f (/cluster/data/galGal2/*/chr*.fa)
      set chr = $f:t:r
      wget \
http://genome.imim.es/genepredictions/G.gallus/golden_path_200402/geneid_v1.1/$chr.gtf
      wget \
http://genome.imim.es/genepredictions/G.gallus/golden_path_200402/geneid_v1.1/$chr.prot
    end
    # Add missing .1 to protein id's
    foreach f (*.prot)
      perl -wpe 's/^(>chr\w+)$/$1.1/' $f > $f:r-fixed.prot
    end
    cd ..
    ldHgGene -gtf galGal2 geneid download/*.gtf
    hgPepPred galGal2 generic geneidPep download/*-fixed.prot

# LOAD SOFTBERRY GENES (TODO)
     cd /cluster/data/galGal2/bed
     mkdir softberry
     cd softberry
     wget \
        ftp://www.softberry.com/pub/SC_CHICKEN_JUN03/Softb_fgenesh_chicken_jun03.tar.gz
     tar xvzf Softb_fgenesh_chicken_jun03.tar.gz
     ldHgGene galGal2 softberryGene chr*.gff
     hgPepPred galGal2 softberry *.protein
     hgSoftberryHom galGal2 *.protein


# BUILD BLAST DATABASES
    cd /cluster/data/galGal2
    mkdir blastDb
     for i in `cat chrom.lst`; do for j in `echo $i/chr$i_*/chr*_*_*.fa`; do ln -s `pwd`/$j blastDb/`basename $j .fa`;
      done; done 
      cd blastDb
      for i in *; do formatdb -p F -i $i; done
# END BLAST


# TIGR GENE INDEX (TODO)
    mkdir -p /cluster/data/galGal2/bed/tigr
    cd /cluster/data/galGal2/bed/tigr
    wget ftp://ftp.tigr.org//pub/data/tgi/TGI_track_ChickenGenome_Jun2003.tgz
    tar xvfz TGI_track_ChickenGenome_Jun2003.tgz
    foreach f (*cattle*)
      set f1 = `echo $f | sed -e 's/cattle/cow/g'`
      mv $f $f1
    end
    foreach o (rat cow human pig chicken)
      setenv O $o
      foreach f (chr*_$o*s)
        tail +2 $f | perl -wpe 's /THC/TC/; s/(TH?C\d+)/$ENV{O}_$1/;' > $f.gff
      end
    end
    ldHgGene -exon=TC galGal2 tigrGeneIndex *.gff
       # 139456 gene predictions
    gzip *TCs *.gff


# GC 5 BASE WIGGLE TRACK (DONE 2/24/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/gc5Base
    cd /cluster/data/galGal2/bed/gc5Base
    mkdir wigData5 dataLimits5
    foreach n (../../nib/*.nib)
      set c=`basename ${n} | sed -e "s/.nib//"`
      set C=`echo $c | sed -e "s/chr//"`
      echo "working on ${c} - ${C} ... "
      hgGcPercent -chr=${c} -doGaps -file=stdout -win=5 galGal2 ../../nib \
      | grep -w GC \
      | awk '{ \
               bases = $3 - $2 \
               perCent = $5/10.0 \
               printf "%d\t%.1f\n", $2+1, perCent \
             }' \
      | wigAsciiToBinary \
        -dataSpan=5 -chrom=${c} -wibFile=wigData5/gc5Base_${C} \
        -name=${C} stdin > dataLimits5/${c}
    end
    # data is complete, load track on hgwdev
    ssh hgwdev
    cd /cluster/data/galGal2/bed/gc5Base
    # create symlinks for .wib files, then load track
    mkdir /gbdb/galGal2/wib
    ln -s `pwd`/wigData5/*.wib /gbdb/galGal2/wib
    hgLoadWiggle galGal2 gc5Base wigData5/*.wig


# SUPERCONTIG LOCATIONS TRACK (DONE 2/26/04 angie)
    # Supercontig N is a collection of contained "ContigN.*".  
    # Extract Supercontig starts and ends from AGP into bed.  
    mkdir /cluster/data/galGal2/bed/supercontig
    cd /cluster/data/galGal2/bed/supercontig
    cat ../../agp_040224/chr*.agp \
    | perl -we 'while (<>) { \
                  chop; @words = split("\t"); \
                  next if ($words[4] eq "N"); \
                  if ($words[5] =~ /^(Contig\d+)\.(\d+)$/) { \
                    $sup = $1;  $newNum = $2; \
                    $firstNum = $newNum if (! defined $firstNum); \
                    if (defined $lastSup && $lastSup ne $sup) { \
                      $start--; \
                      print "$chr\t$start\t$end\t$lastSup ($firstNum-$lastNum)\t1000\t$strand\n"; \
                      undef $start;  undef $end;  $firstNum = $newNum; \
                    } \
                    $chr = $words[0]; $cStart = $words[1]; $cEnd = $words[2]; \
                    $strand = $words[8]; \
                    $start = $cStart if (\!defined $start || $start > $cStart); \
                    $end = $cEnd if (\!defined $end || $end < $cEnd); \
                    $lastSup = $sup;  $lastNum = $newNum; \
                  } else { die "bad 6th word $words[5]\n"; } \
                } \
                print "$chr\t$start\t$end\t$lastSup ($firstNum-$lastNum)\t1000\t$strand\n";' \
    > supercontig.bed
    ssh hgwdev
    cd /cluster/data/galGal2/bed/supercontig
    hgLoadBed -tab galGal2 supercontig supercontig.bed


# CREATING QUALITY SCORE TRACK (DONE 2/24/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/qual
    cd /cluster/data/galGal2/bed/qual
    cat ../../agp_040224/chr*.agp > assembly.agp
    tar xvzf ../../chicken_040105.contigs.qual.tar.gz
    cat chicken*.qual | qaToQac stdin stdout \
    | chimpChromQuals assembly.agp stdin chrom.qac
    rm chicken*.qual
    mkdir wigData dataLimits
    foreach c (`cat ../../chrom.lst`)
      foreach agp (../../$c/chr$c.agp ../../$c/chr${c}_random.agp)
        if (-e $agp) then
          set chr = $agp:t:r
          set abbrev = `echo $chr | sed -e 's/^chr//;  s/_random/r/;'`
          echo $chr to $abbrev wiggle
          qacToWig chrom.qac -name=$chr stdout \
          | wigAsciiToBinary -dataSpan=1 -chrom=$chr \
              -wibFile=wigData/qual_$abbrev -name=$abbrev stdin \
              > dataLimits/$chr
        endif
      end
    end
    # Verify size of .wib file = chrom length
    foreach f (wigData/*.wib)
      set abbrev = $f:t:r
      set chr = `echo $abbrev | sed -e 's/^qual_/chr/;  s/r$/_random/;'`
      set wibLen = `ls -l $f | awk '{print $5;}'`
      set chromLen = `grep -w $chr ../../chrom.sizes | awk '{print $2;}'`
      if ($wibLen != $chromLen) then
        echo "ERROR: $chr size is $chromLen but wib size is $wibLen"
      else
        echo $chr OK.
      endif
    end
#ERROR: chr12 size is 19821895 but wib size is 19811895
#ERROR: chr23 size is 5666127 but wib size is 5166127
#ERROR: chr28 size is 4731479 but wib size is 4231479
    # That's OK -- they end in gaps of the right sizes (not incl'd in wib)

    # /gbdb & load:
    ssh hgwdev
    cd /cluster/data/galGal2/bed/qual
    mkdir -p /gbdb/galGal2/wib
    ln -s `pwd`/wigData/*.wib /gbdb/galGal2/wib
    hgLoadWiggle galGal2 quality wigData/*.wig

    # To speed up display for whole chrom views, need to make zoomed
    # data views.  Zoom to 1K points per pixel.
    ssh kksilo
    cd /cluster/data/galGal2/bed/qual/wigData1K
    mkdir -p wigData1K
    mkdir -p dataLimits1K
    foreach c (`cat ../../chrom.lst`)
      if (-f ../../${c}/chr${c}.agp) then
        echo "chr${c} quality 1K zoom"
        qacToWig chrom.qac -name=chr${c} stdout \
        | wigZoom stdin \
        | wigAsciiToBinary -dataSpan=1024 \
                -chrom=chr${c} -wibFile=wigData1K/qc1K_${c} \
                -name=${c} stdin > dataLimits1K/chr${c}
      endif
      if (-f ../../${c}/chr${c}_random.agp) then
        echo "chr${c}_random quality 1K zoom"
        qacToWig chrom.qac -name=chr${c}_random stdout \
        | wigZoom stdin \
        | wigAsciiToBinary -dataSpan=1024 \
                -chrom=chr${c}_random -wibFile=wigData1K/qc1K_${c}r \
                -name=${c}_random stdin > dataLimits1K/chr${c}r
      endif
    end

    ssh hgwdev
    cd /cluster/data/galGal2/bed/qual/wigData1K
    # create symlinks for .wib files
    ln -s `pwd`/*.wib /gbdb/galGal2/wib
    # load in addition to existing data
    hgLoadWiggle -oldTable galGal2 quality *.wig


# MAKE UNIGENE ALIGNMENTS (DONE 2/29/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/unigene
    cd /cluster/data/galGal2/bed/unigene
    # Download chicken Unigene and run Chuck's preproc scripts:
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Gga.info
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Gga.seq.uniq.gz
    wget ftp://ftp.ncbi.nih.gov/repository/UniGene/Gga.data.gz
    gunzip *.gz
    # Chuck's script expects human (Hs) -- use Gga for chicken:
    sed -e 's/Hs/Gga/g' /projects/cc/hg/sugnet/uniGene/countSeqsInCluster.pl \
    > ./countSeqsInCluster.pl
    chmod a+x ./countSeqsInCluster.pl
    ./countSeqsInCluster.pl Gga.data counts.tab
    /projects/cc/hg/sugnet/uniGene/parseUnigene.pl Gga.seq.uniq \
      Gga.seq.uniq.simpleHeader.fa leftoverData.tab
    # Put on iscratch for cluster run
    ssh kkr1u00
    mkdir /iscratch/i/galGal2/unigene
    cp -p /cluster/data/galGal2/bed/unigene/Gga.seq.uniq.simpleHeader.fa \
      /iscratch/i/galGal2/unigene/
    iSync
    # align on big cluster
    ssh kk
    cd /cluster/data/galGal2/bed/unigene
    ls -1S /iscratch/i/galGal2/trfFa/*.fa > allctg.lst
    ls -1S /iscratch/i/galGal2/unigene/*.fa > uniGene.lst
# seems to be a bug in latest blat: -mask=lower => 0 alignments!  
# for now, use Jim's next-to-latest blat.27:
    cat << '_EOF_' > template.sub
#LOOP
/cluster/home/kent/bin/i386/blat.27 -mask=lower -minIdentity=95 -ooc=/iscratch/i/galGal2/11.ooc {check in line+ $(path1)} {check in line+ $(path2)}  {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 allctg.lst uniGene.lst template.sub jobList
    para create jobList
    mkdir psl
    para try, check, push, check
#Completed: 259 of 259 jobs
#Average job time:                  13s       0.22m     0.00h    0.00d
#Longest job:                       21s       0.35m     0.01h    0.00d
#Submission to last job:            22s       0.37m     0.01h    0.00d
    # postprocess
    ssh kksilo
    pslSort dirs raw.psl tmp psl >& pslSort.log
    liftUp -type=.psl stdout ../../jkStuff/liftAll.lft warn raw.psl \
    | pslReps -minCover=0.2 -minAli=0.965 -nearTop=0.002 \
      stdin uniGene.lifted.pslReps.psl /dev/null
    rm raw.psl
    gzip Gga.seq.uniq Gga.data 
    # load into db
    ssh hgwdev
    cd /cluster/data/galGal2/bed/unigene
    mkdir /gbdb/galGal2/unigene
    ln -s /cluster/data/galGal2/bed/unigene/Gga.seq.uniq.simpleHeader.fa \
      /gbdb/galGal2/unigene/
    hgLoadSeq galGal2 /gbdb/galGal2/unigene/Gga.seq.uniq.simpleHeader.fa
    hgLoadPsl -fastLoad -table=uniGene_gg galGal2 uniGene.lifted.pslReps.psl


# LIFTOVER ENCODE REGIONS FOR JOHN WALLIS (DONE 3/2/04 angie)
    # It's too early to show these in the browser, but try to liftOver:
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/encodeLiftOver
    cd /cluster/data/galGal2/bed/encodeLiftOver
    echo 'select * from hg16.encodeRegions' | hgsql hg16 -N > hg16.eR.bed
    # Of 44 regions:
    # -minMatch=.95 (default) -> nothing mapped
    # -minMatch=.1 -> 2 mapped
    # -minMatch=.01 -> 33 mapped
    # -minMatch=.001 -> 14 mapped -- huh??? -> "Duplicated in new."
    # -minMatch=.011 -> 34 mapped -- best I could get.
    liftOver -minMatch=.011 hg16.eR.bed \
      /cluster/data/hg16/bed/bedOver/hg16TogalGal2.chain \
      galGal2.encodeRegions.bed galGal2.encodeRegions.unmapped
    # emailed the files to John Wallis w/warning they're prelim, automated.


# SNP & GENES FROM BEIJING GENOME INST. (DONE 3/18/04 angie)
    ssh kolossus
    mkdir /cluster/data/galGal2/bed/bgi
    cd /cluster/data/galGal2/bed/bgi
    # Their files are very fragmented into a deep dir structure.  
    # Pull the whole thing (except chromatograms) over intact.  
    # Use --active-ftp because passive mode was timing out.  
    # Replace XXXX, YYYY and HHHH with username, password & host emailed from 
    # Yong Zhang <zhangy@genomics.org.cn>.
    wget -r --exclude-directories=\*/chromatograms --active-ftp \
      --timestamping ftp://XXXX:YYYY@HHHH/BGI/
    # Takes hours... ~30kB/s from China, & lots o' data...

    # Coverage track: bed 4 showing where SNP reads were performed.
    # Looks like we can get strain info from filename... 
    find . -name \*ContigCov-\*.txt\* -print \
    | xargs $HOME/kent/src/hg/snp/bgi/bgiCovToBed.pl \
      > bgiCov.bed

    # Gene annotations:
    find . -name \*exon_intron.txt -print \
    | sed -e 's/ /\\ /g' \
    | xargs $HOME/kent/src/hg/snp/bgi/bgiExonIntronToGenePred.pl \
      > bgiGene.tab

    # Gene annotation peptide seqs:
    find 6* -name \*.pep\* -print \
    | sed -e 's/ /\\ /g' \
    | xargs $HOME/kent/src/hg/snp/bgi/bgiPep.pl \
      > bgiGenePep.fa

    # Gene info and SNPs: slurp in all of the GeneSNPcon* files and 
    # SNPlist-* files, cross-reference, and dump out bgiGeneInfo.sql 
    # and bgiSnp.bed.  (bgiGeneInfo.sql with INSERT statements because of 
    # the longblobs which can't be loaded in from .tab unfortunately)
    find . -name SNPlist-\*.txt\* -print \
      > SNPlists.list
    find 6*/BGI/SNPs_by_cDNA/2004-03-15 -name \*GeneSNPcon\*.txt\* -print \
      > GeneSNPcons.list
    find 6*/BGI/SNPs_by_locus -name \*GeneSNPcon\*.txt\* -print \
    | grep -v MHC_Region \
      >> GeneSNPcons.list
    $HOME/kent/src/hg/snp/bgi/bgiXref.pl SNPlists.list GeneSNPcons.list

    # Load 'em up...
    ssh hgwdev
    cd /cluster/data/galGal2/bed/bgi
    hgLoadBed galGal2 bgiCov bgiCov.bed
    hgsql galGal2 < $HOME/kent/src/hg/lib/bgiGeneInfo.sql
    hgsql galGal2 < ./bgiGeneInfo.sql
    hgsql galGal2 < $HOME/kent/src/hg/lib/bgiGeneSnp.sql
    echo "load data local infile './bgiGeneSnp.tab' into table bgiGeneSnp" \
    | hgsql galGal2
    hgPepPred galGal2 generic bgiGenePep bgiGenePep.fa
    ldHgGene galGal2 bgiGene -predTab bgiGene.tab
    hgLoadBed galGal2 bgiSnp -tab -sqlTable=$HOME/kent/src/hg/lib/bgiSnp.sql \
      bgiSnp.bed


# ENSEMBL GENE BUILD (DONE 4/27/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/ensembl
    cd /cluster/data/galGal2/bed/ensembl
    wget ftp://ftp.sanger.ac.uk/pub/searle/chicken/chicken_build.pep.gz
    wget ftp://ftp.sanger.ac.uk/pub/searle/chicken/chicken_build.gtf.gz
    gunzip *.gz
    sed -e 's/^/chr/' chicken_build.gtf \
      > chicken_build.fixed.gtf
    perl -wpe 's/^>.*trans_id=(\w+).*/>$1/' \
      chicken_build.pep > chicken_build.fixed.pep
    ssh hgwdev
    cd /cluster/data/galGal2/bed/ensembl
    hgPepPred galGal2 generic ensPep chicken_build.fixed.pep
    ldHgGene -gtf -frame -id -geneName galGal2 ensGene chicken_build.fixed.gtf


# MAKE KNOWN REGULATORY REGIONS (DONE 3/29/04 angie)
    # Adam got several text files from Webb (and/or Laura Elnitski?), 
    # translated them to bed 3, and loaded.  I tweaked -> bed 4.  
    # (this does both hg16 and galGal2)
    ssh hgwdev
    cd /cluster/home/acs/webb-launcher
    make -f Makefile.angie munge
    make -f Makefile.angie track


# RUN GENE-CHECK ON MRNA W/CDS, ENSEMBL (DONE 3/29/04 markd)
    # Note: /cluster/bin/scripts/runGeneCheck should make this easier 
    # in the future, but this also shows how MarkD ran gene-check on 
    # mRNAs with annotated CDS:

    # get mrna data from hgwbeta, which is most current:
    ssh hgwbeta
    mkdir /cluster/store7/markd/galGal2
    cd /cluster/store7/markd/galGal2
    mkdir data
    hgsql -N -e 'select * from all_mrna' galGal2 |cut -f 2-30 \
      > data/all_mrna.psl
    hgsql -N -e 'select mrna.acc,cds.name from mrna,cds,all_mrna where all_mrna.qName=mrna.acc and mrna.cds = cds.id' galGal2 \
      > data/cds.tab
    nice mrnaToGene -cdsFile=data/cds.tab data/all_mrna.psl data/all_mrna.gp \
      >& data/all_mrna.log

    # get ensGene data from hgwdev:
    ssh hgwdev
    cd /cluster/store7/markd/galGal2
    hgsql -N -e 'select * from ensGene ' galGal2 >data/ensGene.gp

    # run gene-check and gene-extract
    ssh kksilo
    cd /cluster/store7/markd/galGal2
    mkdir results
    ~markd/bin/gene-check -incl-ok -nib-dir /cluster/data/galGal2/nib \
      -details-out results/all_mrna.details data/all_mrna.gp \
      results/all_mrna.chk >& all_mrna.log
    ~markd/bin/gene-check -incl-ok -nib-dir /cluster/data/galGal2/nib \
      -details-out results/ensGene.details data/ensGene.gp \
      results/ensGene.chk >& ensGene.log
    ~markd/bin/gene-extract -nib-dir  /cluster/data/galGal2/nib \
      -all-cds-fa results/all_mrna.cds.fa  data/all_mrna.gp >& all_mrna.log
    ~markd/bin/gene-extract -nib-dir  /cluster/data/galGal2/nib \
      -all-cds-fa results/ensGene.cds.fa  data/ensGene.gp >&ensGene.log
    # Files in results/
    #     *.chk - output of the gene-check program, rdb format
    #     *.details - details of problems detected 
    #     *.cds.fa - fasta of CDS taken from genome
    # Columns in *.chk file are
    #     acc - name field from genePred
    #     chr  - genome location from genePred
    #     chrStart
    #     chrEnd
    #     strand
    #     stat - overall status based on other data: ok or err
    #     frame - is the frame annotation sane (mult of 3): ok, bad, or noCDS
    #             if noCDS, other CDS checks are not done.
    #     start - Is there a valid start codon: ok or no
    #     stop - Is there a valid stop codon: ok or no
    #     orfStop - Number of in-frame stop codons
    #     smallGap - Number of small gaps, too small to be introns
    #     unknownSplice - Number of introns with unknown splicing patterns 
    #          (considers the three most common splicing patterns as valid)
    #     causes - list of symbolic names summarizing the failures 


# WEBB'S PUTATIVE NON-EXONIC CONSERVED REGIONS (DONE 4/5/04 angie)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/webbNonExonic
    cd /cluster/data/galGal2/bed/webbNonExonic
    wget http://bio.cse.psu.edu/~webb/nonexonic.tar.gz
    tar xvzf nonexonic.tar.gz 
    # Score should really be scaled from 5k..276k --> 200-1000
    cat chr* \
    | awk '{printf "%s\t%d\t%d\t%s:%d-%d\t%d\t%c\n", $5, $6 - 1, $7, $2, $3, $4, $9, $8;}' \
    > webbNonExonic.bed
    hgLoadBed galGal2 webbNonExonic webbNonExonic.bed


# UN-ANNOTATED (EXCEPT FOR CROSS-SPECIES) REGIONS (DONE 4/27/04 angie)
    # Anton Nekrutenko asked the chickenanalysis list for this... sounds 
    # like a job for featureBits.  :)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/unAnnotated
    cd /cluster/data/galGal2/bed/unAnnotated
    nice featureBits galGal2 -minSize=12 \
      \!gap \!bgiGene \!ensGene \!geneid \!genscan \!twinscan \
      \!mrna \!intronEst \!est \!xenoMrna \
      \!uniGene_gg \!cpgIslandExt \!rmsk \!simpleRepeat \
      -bed=unAnnotated.bed
#826274476 bases of 1054197620 (78.379%) in intersection
    hgLoadBed galGal2 unAnnotated unAnnotated.bed
    # not much of a drop in coverage with the -minSize:
    nice featureBits galGal2 unAnnotated
#825770129 bases of 1054197620 (78.332%) in intersection


# SYNTENY BY HOMOLOGY FROM EVGENY ZDOBNOV (DONE 4/15/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/zdobnov
    cd /cluster/data/galGal2/bed/zdobnov
    wget --timestamping \
      http://azra.embl-heidelberg.de/~zdobnov/Chicken/homo_chicken_synteny.txt
    wget --timestamping \
      http://azra.embl-heidelberg.de/~zdobnov/Chicken/mouse_chicken_synteny.txt
    wget --timestamping \
      http://azra.embl-heidelberg.de/~zdobnov/Chicken/rat_chicken_synteny.txt
    # This is a one-shot, so I'm writing a perl script...
    transZdobnov.pl hg16 homo_chicken_synteny.txt  > zdobnovHg16.bed
    transZdobnov.pl mm3  mouse_chicken_synteny.txt > zdobnovMm3.bed
    transZdobnov.pl rn3  rat_chicken_synteny.txt   > zdobnovRn3.bed
    ssh hgwdev
    cd /cluster/data/galGal2/bed/zdobnov
    sed -e 's/zdobnovSynt/zdobnovHg16/' $HOME/kent/src/hg/lib/zdobnovSynt.sql \
      > zd.sql
    hgLoadBed -sqlTable=zd.sql galGal2 zdobnovHg16 zdobnovHg16.bed
    sed -e 's/zdobnovSynt/zdobnovMm3/' $HOME/kent/src/hg/lib/zdobnovSynt.sql \
      > zd.sql
    hgLoadBed -sqlTable=zd.sql galGal2 zdobnovMm3 zdobnovMm3.bed
    sed -e 's/zdobnovSynt/zdobnovRn3/' $HOME/kent/src/hg/lib/zdobnovSynt.sql \
      > zd.sql
    hgLoadBed -sqlTable=zd.sql galGal2 zdobnovRn3 zdobnovRn3.bed


# FILTER MRNAS FOR CHECKING ENSEMBL GENES (DONE 4/12/04 angie)
    # Use the TB to generate BED for mRNA alignments with no overlap w/ensGene.
    # saved as galGal2.mrnaNotEnsGene.bed (Sent to Ewan 4/6/04 -- needed filt)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/tightMrna
    cd /cluster/data/galGal2/bed/tightMrna
    # Get list of mRNA accs from the chEST project, which may be a little 
    # more shaky than others (?).
    echo 'select mrna.acc from mrna,description \
          where mrna.description = description.id and \
          description.name like "Gallus gallus finished cDNA, clone ChEST%.";' \
    | use galGal2 -N > chESTaccs.txt
    ssh kksilo
    cd /cluster/data/galGal2/bed/tightMrna
    # Make a uniq'd list of accs that didn't overlap ensGene:
    awk '{print $4;}' galGal2.mrnaNotEnsGene.bed | sort | uniq > mNotE.txt
    # Separate those into chEST and non-chEST:
    cp /dev/null mNotEChEST.txt
    cp /dev/null mNotEOther.txt
    foreach a (`cat mNotE.txt`)
      if (`grep $a chESTaccs.txt` != "") then
        echo $a >> mNotEChEST.txt
      else
        echo $a >> mNotEOther.txt
      endif
    end
    wc -l mNot*.txt
#   2987 mNotE.txt
#   2484 mNotEChEST.txt
#    503 mNotEOther.txt
    # Get psl for those alignments using the TB (paste in those files as 
    # keyword lists).  (All fields but bin.)  Save as mNotEChEST.psl, 
    # mNotEOther.psl.  Edit the #chrom ... comments out of them.
    # Dang, extra tab at end causes trouble for pslReps, edit out:
    perl -wpe 's/\t$//' mNotEChEST.psl > tmp; mv tmp mNotEChEST.psl
    perl -wpe 's/\t$//' mNotEOther.psl > tmp; mv tmp mNotEOther.psl
    # Run pslReps with more stringent parameters than used for genbank:
    pslReps -minCover=0.50 -minAli=0.97 -nearTop=0.001 \
      mNotEChEST.psl mNotEChEST.filt.psl /dev/null
    pslReps -minCover=0.50 -minAli=0.97 -nearTop=0.001 \
      mNotEOther.psl mNotEOther.filt.psl /dev/null

    # Get overlap with human net
    netToBed -maxGap=1000 -minFill=12 \
      /cluster/data/galGal2/bed/blastz.hg16.swap.2004-02-25/axtChain/human.net \
      netHg16Cov.bed

    ssh hgwdev
    cd /cluster/data/galGal2/bed/tightMrna
    # Load these tables temporarily for TB usage...
    hgLoadBed galGal2 netHg16Cov netHg16Cov.bed
    hgLoadPsl galGal2 -table=mNotEChEST mNotEChEST.filt.psl
    hgLoadPsl galGal2 -table=mNotEOther mNotEOther.filt.psl
    featureBits galGal2 -or genscan geneid -bed=lotsaExons.bed
    hgLoadBed galGal2 lotsaExons lotsaExons.bed 

    # Use TB to keep mrna's with overlap w/netHg16Cov but no overlap w/ensGene.
    # Saved as mNotE{ChEST,Other}_pslReps_netHg16Cov_noEnsGene.bed
    # Use TB to overlap above w/lotsaExons (genscan | geneid).
    # Saved as mNotE{ChEST,Other}_pslReps_netHg16Cov_noEnsGene_abinit.bed
    # Made /usr/local/apache/htdocs/angie/ensPrelim/ w/index.html linking 
    # to custom track files and to browser w/custom tracks.

    # clean up.
    hgsql galGal2 -e 'drop table netHg16Cov; drop table lotsaExons'
    hgsql galGal2 -e 'drop table mNotEChEST; drop table mNotEOther'


# 5-SPECIES ORTHOLOGY FROM DEWEY/PACHTER (DONE 4/20/04 angie)
    ssh kksilo
    mkdir /cluster/data/galGal2/bed/deweySynt
    cd /cluster/data/galGal2/bed/deweySynt
    # Saved email attachment from Colin Dewey <cdewey@eecs.berkeley.edu>
    # as gg-hs-mm-pt-rn.map.gz
    gunzip gg-hs-mm-pt-rn.map.gz 
# format of the map file is:
# segment# chrom start end strand chrom start end strand ...
# where the columns chrom, start, end, strand are repeated for each 
# genome in the map (in this case we have 5*4 + 1 = 21 columns).  If a 
# segment is not found in one of the genomes, the columns for that genome 
# are set to "NA" for that segment.  The order of the genomes in the file is:
#   galGal2 hg16 mm3 panTro1 rn3
# and all intervals are 0-based, half-open.
    # Make a bed6 track for each xenoDb.
    ./deweyMap2Bed6.pl 1 5  gg-hs-mm-pt-rn.map > deweySyntHg16.bed
    ./deweyMap2Bed6.pl 1 9  gg-hs-mm-pt-rn.map > deweySyntMm3.bed
    ./deweyMap2Bed6.pl 1 13 gg-hs-mm-pt-rn.map > deweySyntPanTro1.bed
    ./deweyMap2Bed6.pl 1 17 gg-hs-mm-pt-rn.map > deweySyntRn3.bed
    ssh hgwdev
    cd /cluster/data/galGal2/bed/deweySynt
    hgLoadBed galGal2 deweySyntHg16 deweySyntHg16.bed
    hgLoadBed galGal2 deweySyntMm3 deweySyntMm3.bed
    hgLoadBed galGal2 deweySyntPanTro1 deweySyntPanTro1.bed
    hgLoadBed galGal2 deweySyntRn3 deweySyntRn3.bed


# CHICKEN NCRNA FROM SAM GRIFFITHS-JONES (DONE 4/20/04 angie)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/ncRNA
    cd /cluster/data/galGal2/bed/ncRNA
    # saved email attachment from Sam Griffiths-Jones <sgj@sanger.ac.uk>
    # as gallus_gallus_ncrna_sgj_v1.gff
    # That's not GTF with exons/CDS/codons the way that ldHgGene expects,
    # so translate it into the rnaGene.as format:
    perl -wpe 'if (/^#/) { $_ = ""; next } chomp; \
               ($chr,$source,$type,$start,$end,undef,$strand,undef,$other) = split(/\t/); \
               $start--; \
               $fullScore = 0; \
               if ($other =~ /SCORE=([^;]+);/) { $fullScore = $1; } \
               $score = int($fullScore); \
               $source = "miRNA_Registry" if ($source eq "SGJ"); \
               if ($other =~ /ACC=([^;]+); ID=([^;]+);/) { $name = "$1:$2";} \
               elsif ($other =~ /ID=([^;]+);/) { $name = $1; } \
               elsif ($other =~ /TYPE=([^;]+);/) { $name = $1; } \
               else { $name = $type; } \
               $_ = "$chr\t$start\t$end\t$name\t$score\t$strand\t$source\t$type\t$fullScore\t0\n";' \
      gallus_gallus_ncrna_sgj_v1.gff > rnaGene.bed
    hgLoadBed galGal2 rnaGene -sqlTable=$HOME/kent/src/hg/lib/rnaGene.sql \
      -noBin rnaGene.bed


# TWINSCAN FROM BRENT LAB (DONE 5/1/04 angie)
    # contact: Paul Flicek <paul.flicek@wustl.edu>
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/twinscan
    cd /cluster/data/galGal2/bed/twinscan
    wget http://www.cs.wustl.edu/~pflicek/chicken/chicken.043004.ts.tar.gz
    tar xvzf chicken.043004.ts.tar.gz
    # No .ptx, just gtf.
    ldHgGene -gtf -frame -id -geneName galGal2 twinscan chr*.gtf
    runGeneCheck .
#   1173 frameMismatch
#    775 badFrame
#    477 noStop
#    237 gap
#    223 noStart
#     22 frameDiscontig
#      6 inFrameStop


# ISOCHORES FROM NEKRUTENKO LAB (DONE 5/3/04 angie)
    # contact: Jianbin HE <jbhe@psu.edu>
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/isochore
    cd /cluster/data/galGal2/bed/isochore
    wget http://www.bx.psu.edu/~jbhe/isochore/chi-iso.tar.gz
    tar xvzf chi-iso.tar.gz
    # Remove the custom track "browser" and "track" lines:
    cat chr*.bed | egrep -v '^(browser|track)' > isochore.bed
    hgLoadBed galGal2 isochore isochore.bed


# SGP GENE PREDICTIONS (DONE 4/28/04 angie)
    # contact: "EYRAS, EDUARDO" <eeyras@imim.es> (Roderic Guigo's group)
    ssh hgwdev
    mkdir /cluster/data/galGal2/bed/sgp
    cd /cluster/data/galGal2/bed/sgp
    wget http://genome.imim.es/genepredictions/G.gallus/golden_path_200402xhs/chicken.sgp2.prot.tar.gz
    wget http://genome.imim.es/genepredictions/G.gallus/golden_path_200402xhs/chicken.sgp2.gtf.tar.gz
    tar xvzf chicken.sgp2.gtf.tar.gz
    tar xvzf chicken.sgp2.prot.tar.gz
    cat chr*.prot.fa | perl -wpe 's/^>(\w+)/>$1.1/' > sgpPep.fa
    hgPepPred galGal2 generic sgpPep sgpPep.fa
    cat chr*.gtf \
    | perl -wpe 's/gene_id\s+(\S+);\s+transcript_id\s+(\S+)/gene_id "$1"; transcript_id "$2";/' \
    > sgpGene.gtf
    ldHgGene -gtf -frame -id -geneName galGal2 sgpGene sgpGene.gtf


