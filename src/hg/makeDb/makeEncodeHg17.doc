#!/bin/csh -f
exit

# This is the make doc for the hg17 ENCODE data.
# NOTE: many of these tracks were lifted from hg16 with
# semi-automated processing. The liftOver leftovers were moved
# to the subdirectories "mapped" and "unmapped" of the main\
# work area, /cluster/data/encode/convertHg17

    # create work area
    mkdir /cluster/data/encode/convertHg17
    cd  /cluster/data/encode/convertHg17
    ln -s /cluster/data/hg16/bed/liftOver/hg16ToHg17.over.chain hg16ToHg17.chain

    # Inventory ENCODE tables on hg16 (hgwbeta)

    ssh hgwbeta "echo select tableName from trackDb where tableName like \'encode%\' and settings not like \'%composite%\' order by tableName | hgsql hg16" > tables.txt
    wc -l tables.txt
        #     350 tables.txt

    set encodeBin = /cluster/data/encode/bin/scripts
    csh $encodeBin/listEncodeTables.csh hg16 > tableTypes.txt
    grep bed tableTypes.txt > tables.bed.txt

##########################################################################
# DOWNLOADS

    ssh hgwdev
    cd /usr/local/apache/htdocs/hg17
    mkdir -p encode
    cd encode
    # release terms
    cp ../../hg16/encode/README.txt .
    # annotation database
    # request admin set up automated database dump
    mkdir database
    # auxiliary data files
    mkdir datafiles 
    # sequences
    mkdir regions
    cp ../../hg16/encode/regions/README.txt regions
    # edit README
    cd /cluster/data/encode/convertHg17
    hgsql hg17 -N -e \
      "SELECT name, chrom, chromStart, chromEnd FROM encodeRegions ORDER BY name">regions.txt 

    ssh kolossus
    cd /cluster/data/encode/convertHg17
    /cluster/data/encode/bin/scripts/encodeSequences.pl -upper \
        regions.txt /iscratch/i/hg17/nib  > hg17.fa
    /cluster/data/encode/bin/scripts/encodeSequences.pl -masked \
        regions.txt /iscratch/i/hg17/nib  > hg17.msk.fa
    faSize detailed=on hg17.fa > hg17_count.txt
    gzip *.fa
    md5sum *.fa.gz > md5sum.txt

    ssh hgwdev
    cd /cluster/data/encode/convertHg17
    cp hg17_count.txt md5sum.txt hg17.fa.gz hg17.msk.fa.gz /usr/local/apache/htdocs/goldenPath/hg17/encode/regions


!##########################################################################
###########################################################################
# Tracks lifted from hg16

##########################################################################
# GIS PET (2005-08-23 kate)

    cd  /cluster/data/encode/convertHg17

    # use mysqldump to generate .sql w/ schema, and .txt with data
    set t = encodeGisRnaPetHCT116
    $encodeBin/dumpTable.csh hg16 $t
    wc -l $t.txt
        # 112782 encodeGisRnaPetHCT116.txt

    # create table
    hgsql hg17 < $t.sql

    # convert data coordinates
    ~/bin/i386/liftOver $t.txt -hasBin -bedPlus=12 \
            hg16ToHg17.chain $t.tab $t.unmapped
    wc -l $t.tab $t.unmapped
         # 112701 encodeGisRnaPetHCT116.tab
         #    162 encodeGisRnaPetHCT116.unmapped

    # load into database
    echo "LOAD DATA local INFILE '$t.tab' INTO TABLE $t" | hgsql hg17
    hgsql hg17 -N -s -e "SELECT COUNT(*) FROM $t"
        # 112701
    checkTableCoords hg17 $t

    # Now try scripted version
    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeGisRnaPetMCF7 12
        # encodeGisRnaPetMCF7     hg16 104304   hg17 104187
    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeGisChipPet 12
        # encodeGisChipPet        hg16 65513   hg17 65510

##########################################################################
# KNOWN+PRED RNA (2005-08-29 kate)

    cd  /cluster/data/encode/convertHg17
    grep encodeRna tables.bed.txt
        # encodeRna       encodeGenes     bed 6 +

    $encodeBin/convertBedTable.csh hg16 hg17 encodeRna 6

##########################################################################
# TBA23 Evofold (2005-08-23 kate)

    cd  /cluster/data/encode/convertHg17
    csh $encodeBin/convertBedTable.csh hg16 hg17 encode_tba23EvoFold 6
            # 739 encode_tba23EvoFold.txt
        # Reading liftover chains
        # Mapping coordinates
            # 739 encode_tba23EvoFold.tab
              # 0 encode_tba23EvoFold.unmapped
            # 739 total
        # encode_tba23EvoFold     hg16 739   hg17 739



##########################################################################
# Transcription Levels Group
# BU FIRST EXON
    grep encodeBu tables.bed.txt
        # encodeBuFirstExonCerebrum       encodeTxLevels  bed 12 +
        # encodeBuFirstExonColon  encodeTxLevels  bed 12 +
        # encodeBuFirstExonHeart  encodeTxLevels  bed 12 +
        # encodeBuFirstExonKidney encodeTxLevels  bed 12 +
        # encodeBuFirstExonLiver  encodeTxLevels  bed 12 +
        # encodeBuFirstExonLung   encodeTxLevels  bed 12 +
        # encodeBuFirstExonSkMuscle       encodeTxLevels  bed 12 +
        # encodeBuFirstExonSpleen encodeTxLevels  bed 12 +
        # encodeBuFirstExonStomach        encodeTxLevels  bed 12 +
        # encodeBuFirstExonTestis encodeTxLevels  bed 12 +
    
    set buTables = `echo "SHOW TABLES LIKE 'encodeBuFirstExon%'" | hgsql -N -s hg16`
    foreach t ($buTables)
        csh $encodeBin/convertBedTable.csh hg16 hg17 $t 12
        checkTableCoords hg17 $t
    end


# RIKEN CAGE
    grep encodeRikenCage tables.bed.txt
        # encodeRikenCageMinus    encodeTxLevels  bedGraph 4
        # encodeRikenCagePlus     encodeTxLevels  bedGraph 4

    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeRikenCageMinus 4
        # Creating hg16 encodeRikenCageMinus.sql and encodeRikenCageMinus.txt
           # 6156 encodeRikenCageMinus.txt
        # Reading liftover chains
        # Mapping coordinates
           # 6153 encodeRikenCageMinus.tab
              # 6 encodeRikenCageMinus.unmapped
           # 6159 total
        # encodeRikenCageMinus    hg16 6156   hg17 6153

    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeRikenCagePlus 4
            # csh $encodeBin/convertBedTable.csh hg16 hg17 encodeRikenCagePlus 4
        # Creating hg16 encodeRikenCagePlus.sql and encodeRikenCagePlus.txt
           # 5688 encodeRikenCagePlus.txt
        # Reading liftover chains
        # Mapping coordinates
           # 5639 encodeRikenCagePlus.tab
             # 98 encodeRikenCagePlus.unmapped
           # 5737 total
        # encodeRikenCagePlus     hg16 5688   hg17 5639


##########################################################################
# CHIP/CHIP GROUP
# 
# STANFORD CHIP
# encodeStanfordChip* bedGraph 4 tracks

cat > doStan.csh << 'EOF'
    set stanTables = \
        `echo "SHOW TABLES LIKE 'encodeStanfordChip%'" | hgsql -N -s hg16`
    foreach t ($stanTables)
        csh /cluster/data/encode/bin/scripts/convertBedTable.csh \
                hg16 hg17 $t 4
    end
'EOF'
    csh doStan.csh >&! doStan.log
    grep hg17 doStan.log | wc -l
        # 12 tracks (6 smoothed)
        # encodeStanfordChipHCT116Sp1     hg16 369633   hg17 369465
        # encodeStanfordChipSmoothedHCT116Sp1     hg16 137439   hg17 137361

# UCD Ng
        csh $encodeBin/convertBedTable.csh hg16 hg17 encodeUCDavisE2F1Median 4
        # encodeUCDavisE2F1Median hg16 382884   hg17 382713

# UCSD/LI CHIP
# encodeUcsdChip* bedGraph 4 tracks (total 36)

cat > doUcsd.csh << 'EOF'
    set ucsdTables = \
        `echo "SHOW TABLES LIKE 'encodeUcsdChip%'" | hgsql -N -s hg16`
    foreach t ($ucsdTables)
        csh /cluster/data/encode/bin/scripts/convertBedTable.csh \
                hg16 hg17 $t 4
    end
'EOF'
    csh doUcsd.csh >&! doUcsd.log
    grep hg17 doUcsd.log | wc -l
    # 36 tracks
    # encodeUcsdChipAch3Imr90 hg16 24348   hg17 24339
    # encodeUcsdChipHeLaH3H4tmH3K4_p30        hg16 24537   hg17 24528


##########################################################################
# TRANSCRIPTION LEVELS TRACKS (2005-08-24 kate)

    # grep encodeTxLevels in tables.bed.txt and edit out already
    # completed tracks.  Prefix each table with a call to convertBedTable
    # and suffix with bed field count
    # Tracks are: Stanford RTPCR, Yale TARS

    csh doTx.csh >&! doTx.log
    grep hg17 doTx.log | wc -l
        # 9 tracks

##########################################################################
# CHROMATIN & CHROMOSOMES TRACKS (2005-08-24 kate)

    # Regulome, NHGRI DNase, Stanford Meth, UVA
    csh doChrom.csh >&! doChrom.log
    # 37 tables
    # do Stanford Meth Smoothed tables that weren't converted because
        # hg16 tables had incorrect capitalization wrt trackDb
        # and so weren't being displayed
    csh doChrom2.csh >&! doChrom2.log

##########################################################################
# CHIP/CHIP TRACKS (2005-08-24 kate)
# Sanger, UCSD Nimblegen

    doChip.csh >&! doChip.log

##########################################################################
# VARIATION TRACKS (2005-08-24 kate)
#  HapMap, Reseq, Sanger Gene Expr

    csh doVar.csh >&! doVar.log
    grep hg17 doVar.log
        # encodeReseqRegions      hg16 10   hg17 10
        # encodeSangerGenoExprAssociation hg16 13674   hg17 13674
    csh doHap.csh >&! doHap.log
    grep hg17 doHap.log
        # encodeHapMapAlleleFreqCEU       hg16 20772   hg17 20772
        # encodeHapMapAlleleFreqCHB       hg16 19629   hg17 19629
        # encodeHapMapAlleleFreqJPT       hg16 19629   hg17 19629
        # encodeHapMapAlleleFreqYRI       hg16 19520   hg17 19520
    csh /cluster/data/encode/bin/scripts/convertBedTable.csh \
                hg16 hg17 encodeRecomb         4


##########################################################################
# AFFY CHIP/CHIP TRACKS (2005-08-24 kate)
    csh doAffy.csh >&! doAffy.log
        # 41 doAffy.csh
    grep hg17 doAffy.log | wc -l
        # 41 

    # do tracks missing from RR!
    csh doAffy2.csh >&! doAffy2.log
    wc -l doAffy2.csh
        # 6 doAffy2.csh
    grep hg17 doAffy2.log | wc -l
        # 6

##########################################################################
# WIG TRACKS (2005-08-24 kate)
        doWig.csh > doWig.log
        # 75 tables

##########################################################################
# YALE TRACKS (2005-08-31 kate)
        doYale.csh > doYale.log
        wc -l doYale.csh
            # 54 doYale.csh
        grep hg17 doYale.log | wc -l
            # 50 
            # redo the 4 that failed
        doYale2.csh > doYale2.log
        grep hg17 doYale2.log | wc -l
            # 4 tracks

!##########################################################################
##########################################################################
# Tracks submitted in hg17 coords

##########################################################################
# GENCODE Sanger Havana annotations  (2005-08-18 kate)
    # Used latest (6/7/05) data submission, which was submitted
    #   in hg17 coords and lifted to hg16.  This was described in makeEncodeHg16.doc
    ssh hgwdev
    cd /cluster/data/encode/Gencode
    cd 2005-06-07

    ldHgGene -gtf -genePredExt hg17 encodeGencodeGene gencode.vega.gtf
        # 2888 gene predictions
    checkTableCoords hg17 encodeGencodeGene

    grep intron gencode.gtf | wc -l
        # 15814
    grep -v not_tested gencode.gtf | sed -e 's/-intron/-/g' | \
        ldGencodeIntron hg17 encodeGencodeIntron stdin
            # 469 introns

    # load gene class table 
    hgsql hg17 < ~/kent/src/hg/lib/gencodeGeneClass.sql
    echo "LOAD DATA LOCAL INFILE 'gencodeGeneClass.tab' into table gencodeGeneClass" | hgsql hg17
    wc -l gencodeGeneClass.tab
        #    2888 gencodeGeneClass.tab


##########################################################################
# EGASP Partial (2005-08-18 kate)
# Gene tracks submitted for the EGASP competition were hg17-based
#       by the Gencode group (Roderic Guigo, Julien Legarde, IMIM) 
# These were lifted to hg17, as described in makeEncodeHg16.doc
    cd /cluster/data/encode
    cd EGASP/Partial
    wc -l lab/*.gtf
       # 1778 lab/ASPic.gtf
       # 4215 lab/AceSCAN.gtf
       # 2692 lab/Augustus_EST-Protein.gtf
       # 2347 lab/Augustus_abinitio.gtf
       # 2736 lab/Augustus_any.gtf
       # 2567 lab/Augustus_dualgenome.gtf
       # 3458 lab/GeneZilla.gtf
       # 2194 lab/SAGA.gtf
    # NOTE: exclude ASPic, which contains only intron records
    # Filenames above, with _CHR_COORDS_hg17.gff appended, are chrom coordinate versions

    # GeneZilla
    ldHgGene hg17 encodeEgaspPartGenezilla lab/GeneZilla.*.gff
        # 656 gene predictions
    genePredCheck -db=hg17 encodeEgaspPartGenezilla

    # SAGA
    # Strip out trailing ## on lines where manual changes were made
    #   (see notes in .gtf file)
    sed -e 's/ ##.*//' lab/SAGA.*.gff | \
        ldHgGene hg17 encodeEgaspPartSaga stdin
        # 378 gene predictions
    genePredCheck -db=hg17 encodeEgaspPartSaga

    # Augustus
   ln -s lab/Augustus_EST-Protein.gtf_CHR_COORDS_hg17.gff augustus.est.gff
   ln -s lab/Augustus_abinitio.gtf_CHR_COORDS_hg17.gff augustus.abinitio.gff
   ln -s lab/Augustus_any.gtf_CHR_COORDS_hg17.gff augustus.any.gff
   ln -s lab/Augustus_dualgenome.gtf_CHR_COORDS_hg17.gff augustus.dual.gff

    foreach f (augustus.*.gff)
        set t = `echo $f | sed -e 's/augustus.\(.*\).gff/encodeEgaspPartAugustus\u\1/'`
        ldHgGene -genePredExt hg17 $t $f
        checkTableCoords hg17 $t
    end
        # augustus.abinitio.gff 418 gene predictions
        # augustus.any.gff      399 gene predictions
        # augustus.dual.gff     413 gene predictions
        # augustus.est.gff      381 gene predictions

    # AceSCAN
    # Split into two tracks -- conserved, and other, based on feature
    ldHgGene -predTab hg17 encodeEgaspPartAceCons aceCons.gp
        # 117 gene predictions
    ldHgGene -predTab hg17 encodeEgaspPartAceOther aceOther.gp
        # 727 gene predictions
    genePredCheck -db=hg17 encodeEgaspPartAceCons encodeEgaspPartAceOther

##########################################################################
# EGASP Full (2005-06-27 kate)
# Gene tracks submitted for the EGASP competition were hg17-based
#       by the Gencode group (Roderic Guigo, Julien Legarde, IMIM) 
    cd /cluster/data/encode
    cd EGASP/Full

    # Process "standard" gff files
    # NOTE: must dummy out scores -- float values
cat > doGene.hg17.csh << 'EOF'
ls *.gp | grep -v hg16 > gpList
foreach f (`cat gpList`)
    wc -l $f 
    set b = $f:r
    set t = encodeEgaspFull$b
    ldHgGene -predTab hg17 $t $f
    genePredCheck -db=hg17 $t
end
'EOF'
csh doGene.hg17.csh >&! doGene.hg17.log

    # process special files
    cd custom
cat > doGene.hg17.csh << 'EOF'
foreach f (Jigsaw.gp Ensembl.gp EnsemblPseudo.gp Exonhunter.gp GeneId.gp Sgp2.gp Twinscan.gp)
    set b = $f:r
    set t = encodeEgaspFull$b
    ldHgGene -genePredExt -predTab hg17 $t $b.gp
    genePredCheck -db=hg17 $t
end
'EOF'
# << for emacs
csh doGene.hg17.csh >&! doGene.hg17.log
    # NOTE: OK to have missing exonFrames
# Reading Ensembl.gp
# 735 gene predictions
# Reading EnsemblPseudo.gp
# 34 gene predictions
# Reading Exonhunter.gp
# 1435 gene predictions
# Reading GeneId.gp
# 476 gene predictions
# Reading Sgp2.gp
# 930 gene predictions
# Reading Twinscan.gp
# 954 gene predictions

end
'EOF'
# << for emacs
csh doGene.hg17.csh >&! doGene.hg17.log

    # process others
    set t = "encodeEgaspFullGenemark"
    ldHgGene -predTab hg17 $t Genemark.gp
        # 890 gene predictions
    genePredCheck -db=hg17 $t

    # create genepreds containing just exons flanking U12 introns
    set t = encodeEgaspFullGeneIdU12
    ldHgGene -predTab -genePredExt hg17 $t geneId.introns.gp
        # 24 gene predictions
    genePredCheck -db=hg17 $t
    set t = encodeEgaspFullSgp2U12
    ldHgGene -predTab -genePredExt hg17 $t sgp2.introns.gp
        # 20 gene predictions
    genePredCheck -db=hg17 $t


##########################################################################
# EGASP Update
# Submitted in hg17 coords

    # Jigsaw
    cd /cluster/data/encode
    cd EGASP/Jigsaw/2005-06-01
    ldHgGene -predTab -genePredExt hg17 encodeEgaspUpdJigsaw jigsaw.gp
        # 454 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdJigsaw

    # Augustus
    cd /cluster/data/encode
    cd EGASP/Augustus/2005-06-22
    foreach f (abinitio.gp any.gp dual.gp est.gp)
        genePredCheck $f
        set t = `echo $f | sed -e 's/\(.*\).gp/encodeEgaspUpdAugustus\u\1/'`
        ldHgGene -predTab -genePredExt hg17 $t $f
        checkTableCoords hg17 $t
    end
        # Reading abinitio.gp
        # 622 gene predictions
        # Reading any.gp
        # 571 gene predictions
        # Reading dual.gp
        # 617 gene predictions
        # Reading est.gp
        # 543 gene predictions

    # Exogean
    cd /cluster/data/encode
    cd EGASP/Exogean/2005-06-23
    ldHgGene -predTab hg17 encodeEgaspUpdExogean exogean.gp
        # 850 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdExogean

    # GeneIDU12 and SgpU12
    cd /cluster/data/encode
    cd EGASP/GeneIdU12/2005-06-10/
    # create GTF files from submitted GFF's
    awk -F\\t '/^chr/ {printf "%s\t%s\tCDS\t%s\t%s\t.\t%s\t%s\tgene_id \"%s\"; transcript_id \"%s\"; exon_type \"%s\";\n", $1, $2, $4, $5, $7, $8, $9, $9, $3}' < lab/UCSC-hg17-GeneID-U12-track.gff | grep -v intron > geneId.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdGeneId geneId.hg17.gtf
        # 476 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdGeneId

    awk -F\\t '/^chr/ {printf "%s\t%s\tCDS\t%s\t%s\t.\t%s\t%s\tgene_id \"%s\"; transcript_id \"%s\"; exon_type \"%s\";\n", $1, $2, $4, $5, $7, $8, $9, $9, $3}' < lab/UCSC-hg17-SGP2-U12-track.gff | grep -v intron > sgp2.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdSgp2 sgp2.hg17.gtf
        # 930 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdSgp2

    # create genepreds containing just exons flanking U12 introns
    # use U12 annotation as gene name, so it appears on details page
    grep U12 geneId.hg17.gtf | perl -wpe \
 's/(^.*gene_id) (\S+) (.*exon_type) (.*)(U12[^-]+)(.*)/$1 "$5"; $3 $4$5$6/' \
        > geneId.introns.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdGeneIdU12 geneId.introns.hg17.gtf
        # 24 gene predictions

    grep U12 sgp2.hg17.gtf | perl -wpe \
 's/(^.*gene_id) (\S+) (.*exon_type) (.*)(U12[^-]+)(.*)/$1 "$5"; $3 $4$5$6/' \
        > sgp2.introns.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdSgp2U12 sgp2.introns.hg17.gtf
        # 20 gene predictions


    # EGASP Yale Pseudogenes
    # Update submitted by Deyou Zheng 8/18/05
    cd /cluster/data/encode
    cd EGASP/yale/latest
    wc -l lab/*.submitted
        #  184 lab/YalePgene-NCBI35.gtf.submitted
        # NOTE: this is fewer than the previous submission -- I confirmed
        # with Deyou that this is correct.

    # munge to create CDS entries to display, and assign pseudogene
    # name as transcript_id, and pseudogene type as gene_id so
    # it displays on details page
    sed -e 's/pseudogene\t/CDS\t/' -e 's/pgene_type/gene_id/'  \
        -e 's/alt_name ENCODE_Yale/transcript_id /' \
                lab/YalePgene-NCBI35.gtf.submitted > yale.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdYalePseudo yale.hg17.gtf
        # 184 gene predictions 
    genePredCheck -db=hg17 encodeEgaspUpdYalePseudo

    # Fgenesh++
    # Update submitted 9/30/05 by Victor Solovyev to Julien Legarde at
    # IMIM, to fix 4 regions (predictions originally on hg16, redone
    # for hg17)
    cd /cluster/data/encode/EGASP
    mkdir -p Fgenesh/2005-09-30/lab
    cd Fgenesh/2005-09-30/lab
    wget ftp://genome.imim.es/pub/projects/gencode/data/egasp05/submitted_predictions/EGASP_Update/FGenesh++_corrected_update.gtf_CHR_COORDS_hg17.gff
    wget ftp://genome.imim.es/pub/projects/gencode/data/egasp05/submitted_predictions/EGASP_partial/FGenesh++_corrected_partial.gtf_CHR_COORDS_hg17.gff
    cd ..
    cat *.gff | ldHgGene hg17 encodeEgaspUpdFgenesh stdin
    genePredCheck -db=hg17 encodeEgaspUpdFgenesh
        # 820 gene predictions
    
##########################################################################
# UCSD/LI Nimblegen Hela

    cd /cluster/data/encode/UCSD/nimblegen/2005-06-01
    foreach f (lab/Nim*/*.wig)
        set t =  `echo $f:t:r | sed -e \
         's/rnap/encodeUcsdNgHeLaRnap/; s/tmh3k4/encodeUcsdNgHeLaH3K4me3/;'`
        echo $t
        grep "^chr" $f | hgLoadBed -onServer -bedGraph=4 hg17 $t stdin
        checkTableCoords hg17 $t
    end
        # Produces 4 tables, encodeUcsdNgHeLa{Rnap,H3K4me3}_p{0,30}
        # Loaded 385149 elements of size 4 

##########################################################################
# STANFORD PROMOTERS
    cd /cluster/data/encode/StanfordPromoters
    rm previous
    mv latest previous
    mkdir 2005-08-23
    ln -s 2005-08-23 latest
    mkdir latest/lab
    # copy updated files from Sara Hartman's email.
    # Both hg16 and hg17 versions were included:
    # hg16: StanfordPromoters_<cell>_08.23.txt
    # hg17: StanfordPromoters_hg17_<cell>_08.24.txt
    # Use Angie's processing from hg16, slightly modified
    cd latest
cat > doProm.csh << 'EOF'
    foreach f (lab/StanfordPromoters_hg17*.txt)
      set cellType = `echo $f | perl -wpe 's^lab/StanfordPromoters_hg17_(.*)_.*^$1^'`
      echo $cellType
      if ($cellType == "Average") then
        tail +2 $f \
        | perl -wpe 'chomp; @w = split("\t"); $w[7] =~ s/^\"(.*)\"$/$1/; \
                     $w[3] =~ tr/01/-+/; \
                     $_ = join("\t", \
  $w[2], $w[4], $w[5], $w[0], $w[9], $w[3], $w[4], $w[5], 0, $w[1], $w[7], \
  $w[8]) . "\n";' \
        | makeColoredBed > encodeStanfordPromoters$cellType.hg17.bed
      else
        tail +2 $f \
        | grep -v "Bad Txfn" \
        | perl -wpe 'chomp; @w = split("\t"); $w[7] =~ s/^\"(.*)\"$/$1/; \
                     $w[3] =~ tr/01/-+/; \
                     $_ = join("\t", \
  $w[2], $w[4], $w[5], $w[0], $w[15], $w[3], $w[4], $w[5], 0, $w[1], $w[7], \
  $w[8], $w[9], $w[10], $w[11], $w[12], $w[13], $w[14]) . "\n";' \
        | makeColoredBed > encodeStanfordPromoters$cellType.hg17.bed
      endif
    end
'EOF'
    csh doProm.csh >&! doProm.log

cat > doLoad.csh << 'EOF'
    foreach f (encode*.bed)
      set track = $f:r:r
      if ($track == "encodeStanfordPromotersAverage") then
        hgLoadBed -tab -noBin -sqlTable=$HOME/kent/src/hg/lib/$track.sql \
          hg17 $track $f
      else
        sed -e "s/encodeStanfordPromoters/$track/" \
          $HOME/kent/src/hg/lib/encodeStanfordPromoters.sql > /tmp/esp.sql
        hgLoadBed -tab -noBin -sqlTable=/tmp/esp.sql hg17 $track $f
      endif
    end
'EOF'
    csh doLoad.csh >&! doLoad.log 

    # Put the negative control data spreadsheet out for download.
    ssh kkstore03
    cd /cluster/data/encode/StanfordPromoters/latest/lab
    nice gzip hg17_NegControlDataStanfordPromoters.txt
    ssh hgwdev
    cd /usr/local/apache/htdocs/goldenPath/hg17/encode/datafiles
    mkdir -p stanfordPromoters
    cd stanfordPromoters
    cp -p \
        /cluster/data/encode/StanfordPromoters/latest/lab/hg17_NegControlDataStanfordPromoters.txt.gz \
                NegativeControlDataStanfordPromoters.txt.gz
    # Added a README.txt (edited form Angie's hg16 version)

##########################################################################
# UV Replication -- Segregation, Origins, and Origin Confidence tracks
#       New data for Oct. freeze (but submitted in hg16 coords)
#       All data are bed3
# Contact: Chris Taylor (cmt5n@cs.virginia.edu)

    cd /cluster/data/encode/UVa
    mv latest previous
    mkdir -p 2005-08-30
    ln -s 2005-08-30 latest

    # Segregation data - 4 subtracks (Early, Mid, Late, Pan-S)
    # 4 custom tracks in a single file -- use Hiram's script to split
    /cluster/data/encode/BU/2005-06-09/splitTracks.pl \
                lab/segchunks.hg16.qced.bed
    # creates t0, t1, t2, t3
    awk < lab/segchunks.hg16.qced.bed '/track/ {print $2}'
#name=early
#name=mid
#name=late
#name=pans
    grep -v "^track" t0 > encodeUvaDnaRepEarly.hg16.bed
    grep -v "^track" t1 > encodeUvaDnaRepMid.hg16.bed
    grep -v "^track" t2 > encodeUvaDnaRepLate.hg16.bed
    grep -v "^track" t3 > encodeUvaDnaRepPanS.hg16.bed
    rm t0 t1 t2 t3
    foreach f (encodeUvaDnaRep*.hg16.bed)
        set d = $f:r:r
        echo $d
        liftOver $f /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $d.hg17.bed $d.unmapped
        hgLoadBed -noBin -strict hg17 $d $d.hg17.bed
    end

    # Origin predictions -- fixed at 200bp
    set t = encodeUvaDnaRepOriginsPred
    ln -s lab/originspred.hg16.qced.bed $t.hg16.bed
    liftOver $t.hg16.bed \
        /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $t.hg17.bed $t.unmapped
    hgLoadBed -noBin -strict hg17 $t $t.hg17.bed
        # Loaded 289 elements of size 3

    # Origin confidence intervals -- varying length for averaged origins
    set t = encodeUvaDnaRepOriginsConf
    ln -s  lab/originsconf.hg16.qced.bed $t.hg16.bed
    liftOver $t.hg16.bed \
        /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $t.hg17.bed $t.unmapped
    hgLoadBed -noBin -strict hg17 $t $t.hg17.bed
        # Loaded 270 elements of size 3


##########################################################################
# Indels from Jim Mullikin
# Heather, Sept. 2005

    ssh hgwdev
    cd /cluster/data/encode/NHGRI/mullikin/hg17
    hgsql hg17 < encodeIndels.sql
    split4.pl < hg17.ENCODE.DIPtrack.Q23.bed4+ > split4.out
    # use a modified makeColoredBed
    ./makeColoredBed < split4.out > encodeIndels.bed  
    # don't use -strict because we have lots of simple insertions (where chromStart = chromEnd)
    hgLoadBed hg17 encodeIndels -tab -sqlTable=encodeIndels.sql encodeIndels.bed
    # check reference length
    mysql> select chrom, chromStart, chromEnd, (chromEnd-chromStart) as size, traceName, reference, length(reference) as refsize from encodeIndels where (chromEnd-chromStart) != length(reference) and length(reference) > 1;
    # Empty set (0.07 sec)

##########################################################################
# Boston University ORChID track - (2005-09-18 kate)
#	data developer contact:  Jay Greenbaum jj@bu.edu
    ssh hgwdev
    cd /cluster/data/encode/BU
    mkdir -p orchid/2005-09-08/lab
    cd -p orchid/2005-09-08/lab
    wget --timestamping "http://dna.bu.edu/%7Ejj/cleavage_data_hg17/oh_cleavage_hg17.wig.gz"
    cd ..
    mkdir wib
    # NOTE: continue reluctantly with non-standard table name
    # as in hg16
    wigEncode lab/oh_cleavage_hg17.wig.gz \
        encodeBu_ORChID1.wig wib/encodeBu_ORChID1.wib
                # upper limit 1.58, lower limit -0.56
    # load
    set dir = /gbdb/hg17/encode/Bu/2005-09-08
    mkdir -p $dir
    hgLoadWiggle -pathPrefix=$dir hg17 encodeBu_ORChID1 encodeBu_ORChID1.wig
    mkdir -p $dir/wib
    ln -s `pwd`/wib/encodeBu_ORChID1.wib $dir/wib

##########################################################################
# Genome Institute of Singapore -ChIP/PET of STAT1 TFBS (2005-09-29 kate)
# Submitted 9/19 by Atif Shahab
    cd /cluster/data/encode/GIS
    mkdir chip
    mkdir -p 2005-09-19/lab
    ln -s 2005-09-19 latest
    cd latest
    # copy files from FTP dir to lab subdi4
    # files: 2 bed files (stim and nonstim) and 1 doc file
    # use antiword to convert doc file to txt
    ln -s lab/STAT1+stimulation.bed Gif.bed
    ln -s lab/STAT1+w:o_stimulation.bed NoGif.bed

    # Use cluster-count info, now embedded into the name, to make scored BED:
    # (Angie's methods)
    foreach f (Gif.bed NoGif.bed)
        set d = $f:r
        echo $d
        set table = encodeGisChipPetStat1$d
        perl -wpe 'chomp; @w = split; \
                 if ($w[3] =~ /^\d+-(\d+)$/) { \
                   $w[4] = ($1 >= 4 ? 1000 : ($1 >= 3 ? 800 : 333)); \
                 } else { die "parse"; } \
                 $_ = join("\t", @w) . "\n";' \
               $f > ${table}.tab
       hgLoadBed hg17 $table ${table}.tab
       checkTableCoords hg17 $table
    end
    # Reading encodeGisChipPetStat1Gif.tab
    # Loaded 4007 elements of size 12
    # Reading encodeGisChipPetStat1NoGif.tab
    # Loaded 3180 elements of size 12
    # NOTE: These counts correspond with the doc file they provided
    # Better to have genome-wide.. I'll request this

    # Create composite track, encodeGisChipPetStat, with 2 subtracks

##########################################################################
# UCSD/Ludwig Institute (Bing Ren lab)

    cd /cluster/data/encode/UCSD/nimblegen
    mkdir 2005-09-29
    cd 2005-09-29
    mkdir lab
    # copy file from FTP dir, unzip and untar, into lab dir
    # 12 data files and README

    
