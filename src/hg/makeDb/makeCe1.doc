#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how to make the browser database for the
# worm C. elegans
# Currently 2003-05-28 this file is in a state of flux as it is being
# worked out.

DOWNLOAD SEQUENCE (DONE 2003-05-12 - Hiram)

    # next machine
    ssh eieio
    mkdir -p /cluster/store4/worm/ce1/sanger
    cd /cluster/store4/worm/ce1/sanger
    wget -o ce1.fetch.log -r -l1 --no-directories \
	ftp://ftp.sanger.ac.uk/pub/wormbase/current_release/CHROMOSOMES/
#   Takes about five minutes
#   This current_release is updated every two weeks.  Although the
#	sequence is quite stable at this time and rarely changes.
#   Check that you have some valid files. Should be chroms I II III IV V X
#	in dna, gff and agp formats
    ls -ogrt
#   get out of this download data directory, and create your home symlink
#	shortcut
    cd ..
    ln -s /cluster/store4/worm/ce1 ~/ce1
    cd ~/ce1
#   There is a Mitochondria sequence.  It can be found at NCBI
#	This search sequence at NCBI in 'nucleotide' selects one
#	entry: X54252:
#	Caenorhabditis Elegans[Organism] AND mitochondria AND MTCE
#	I'd like to figure out a wget command to fetch this, but doing
#	that manually via the WEB browser is not such a big deal.  And
#	besides, once it is fetched, it is pretty much stable so you can
#	merely copy from a previous Ce build.  A copy has been manually
#	placed in ~/ce1/ncbi/x54252.fa
#	
    sed -e "s/^>.*/>chrM/" ./ncbi/x54252.fa > ./chrM.fa
    mkdir nib
#   translate to unzipped .fa, all upper case, and to nib and
#	rename the agp files
#	These nib files are going to be remade below after RepeatMasker
#	and simpleRepeat have been run.
    foreach f (I II III IV V X)
	echo -n "${f} "
	zcat sanger/CHROMOSOME_${f}.dna.gz | tr '[a-z]' '[A-Z]' | \
		sed -e "s/CHROMOSOME_/chr/" > chr${f}.fa
        ln -s sanger/CHROMOSOME_${f}.agp ./chr${f}.agp
	faToNib chr${f}.fa nib/chr${f}.nib
    end
#   Typical output:
#	I Writing 15080473 bases in 7540245 bytes
#	II Writing 15279303 bases in 7639660 bytes
#	III Writing 13783268 bases in 6891642 bytes
#	IV Writing 17493790 bases in 8746903 bytes
#	V Writing 20922238 bases in 10461127 bytes
#	X Writing 17705013 bases in 8852515 bytes
#	M Writing 13794 bases in 6905 bytes

CREATING DATABASE (DONE 2003-05-12 - Hiram)

    # Create the database.
    # next machine
    ssh hgwdev
    echo 'create database ce1' | hgsql ''
    # if you need to delete that database:  !!! WILL DELETE EVERYTHING !!!
	echo 'drop database ce1' | hgsql ce1
    # make a semi-permanent read-only alias:
    alias ce1 "mysql -u hguser -phguserstuff -A ce1"
    # Use df to ake sure there is at least 5 gig free on 
    df -h /var/lib/mysql
# Before loading data:
# Filesystem            Size  Used Avail Use% Mounted on
# /dev/sda1             472G  389G   58G  87% /var/lib/mysql


CREATING GRP TABLE FOR TRACK GROUPING (DONE 2003-05-12 - Hiram)
    # next machine
    ssh hgwdev
    #  the following command copies all the data from the table
    #	grp in the database rn1 to our new database ce1
    echo "create table grp (PRIMARY KEY(NAME)) select * from rn1.grp" \
      | hgsql ce1
    # if you need to delete that table:   !!! WILL DELETE ALL grp data !!!
	echo 'drop table grp;' | hgsql ce1

STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE 2003-05-12 - Hiram)

    # Make symbolic links from /gbdb/ce1/nib to the real nibs.
    # next machine
    ssh hgwdev
    mkdir -p /gbdb/ce1/nib
    foreach f (/cluster/store4/worm/ce1/nib/*.nib)
      ln -s $f /gbdb/ce1/nib
    end
    # Load /gbdb/ce1/nib paths into database and save size info.
    hgsql ce1  < ~/kent/src/hg/lib/chromInfo.sql
    # if you need to delete that table:   !!! DELETES ALL DATA IN TABLE !!!
	echo 'drop table chromInfo;' | hgsql ce1
    cd ~/ce1/softMask
    hgNibSeq -preMadeNib ce1 /gbdb/ce1/nib chr*.fa
# Typical output:
# Processing chrI.fa to /gbdb/ce1/nib/chrI.nib
# Processing chrII.fa to /gbdb/ce1/nib/chrII.nib
# Processing chrIII.fa to /gbdb/ce1/nib/chrIII.nib
# Processing chrIV.fa to /gbdb/ce1/nib/chrIV.nib
# Processing chrM.fa to /gbdb/ce1/nib/chrM.nib
# Processing chrV.fa to /gbdb/ce1/nib/chrV.nib
# Processing chrX.fa to /gbdb/ce1/nib/chrX.nib
# 100277879 total bases

#   Verify the hgNibSeq load functioned OK:
    echo "select chrom,size from chromInfo" | hgsql -N ce1 > chrom.sizes
    cat chrom.sizes
#   Typical contents of chrom.sizes:
chrI    15080473
chrII   15279303
chrIII  13783268
chrIV   17493790
chrM    13794
chrV    20922238
chrX    17705013

    # Set up relational mrna tables.
    hgLoadRna new ce1
    # that created a bunch of tables.  If you need to delete them:
	echo 'drop table author; \
drop table cds; drop table cell; drop table description; \
drop table development; drop table extFile; drop table geneName; \
drop table history; drop table keyword; drop table library; drop table mrna; \
drop table mrnaClone; drop table organism; drop table productName; \
drop table seq; drop table sex; drop table source; drop table tissue;' \
	| hgsql ce1


MAKE GCPERCENT (DONE 2003-05-12 - Hiram)
    # next machine
     ssh hgwdev
     mkdir -p /cluster/store4/worm/ce1/bed/gcPercent
     cd /cluster/store4/worm/ce1/bed/gcPercent
     hgsql ce1  < ~/kent/src/hg/lib/gcPercent.sql
    #  If you need to delete that table created
	echo 'drop table gcPercent;' | hgsql ce1;
     hgGcPercent ce1 ../../nib

MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR CE1 (DONE 2002-05-12 - Hiram)
    # next machine
     ssh hgwdev
    echo 'insert into defaultDb values("C. elegans", "ce1");' \
      | hgsql -h genome-testdb hgcentraltest
    #  If you need to delete that entry:
	echo 'delete from defaultDb where name="ce1";' \
        | hgsql -h genome-testdb hgcentraltest
    echo 'insert into dbDb values("ce1", "May 2003", \
	"/gbdb/ce1/nib", "worm", "chrII:9423581-9478692", 1, 10, \
	"C. elegans");' \
	| hgsql -h genome-testdb hgcentraltest
    #  If you need to delete that entry:
	echo 'delete from dbDb where name="ce1";' \
	| hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add ce1 in all the right places and do
    make update
    make alpha
    cvs commit makefile

MAKE SANGER GENE TRACK (DONE - 2003-05-19 - Hiram)

    # next machine
    ssh eieio
    mkdir -p /cluster/store4/worm/ce1/bed/sangerGene
    cd /cluster/store4/worm/ce1/bed/sangerGene
    # the perl trims these files down to a reasonable size.  As they are
    #	they cause ldHgGene to hangup due to memory size.
    foreach f (I II III IV V X)
	echo -n "${f} "
	zcat ../../sanger/CHROMOSOME_${f}.gff.gz | \
	sed -e "s/CHROMOSOME_III/chrIII/g" -e "s/CHROMOSOME_II/chrII/g" \
	-e "s/CHROMOSOME_IV/chrIV/g" -e "s/CHROMOSOME_I/chrI/g" \
	-e "s/CHROMOSOME_X/chrX/g" -e "s/CHROMOSOME_V/chrV/g" \
	-e 's/Sequence "\(.*\)"$/\1/' -e 's/Transcript "\(.*\)"$/\1/' | \
	perl -ne '@a = split; \
        print if($a[1] =~ /curated|DNA|RNA/i && \
        $a[2] =~ /intron|exon|cds|sequence|transcri/i);' > chr${f}.gff
    end
    echo
    #  check file sizes, should be reasonable
    ls -ogrt
# [hiram@eieio sangerGene]$ ls -ogrt
# total 22656
# -rw-r--r--    1 hiram     3495873 May 19 11:52 chrI.gff
# -rw-r--r--    1 hiram     3670984 May 19 11:54 chrII.gff
# -rw-r--r--    1 hiram     3264917 May 19 11:56 chrIII.gff
# -rw-r--r--    1 hiram     3642256 May 19 11:59 chrIV.gff
# -rw-r--r--    1 hiram     4704564 May 19 12:02 chrV.gff
# -rw-rw-r--    1 hiram     3787721 May 19 12:03 chrX.gff

    # now load database with those transformed gff files
    # next machine
    ssh hgwdev
    cd /cluster/store4/worm/ce1/bed/sangerGene
    ldHgGene ce1 sangerGene *.gff
# Read 37330 transcripts in 411148 lines in 6 files
#  37330 groups 6 seqs 11 sources 6 feature types
#  22128 gene predictions

    # if you need to delete that table:
	echo 'drop table sangerGene' | hgsql ce1

PREPARE Split contigs into 100,000 bp chunks for cluster runs
    # next machine
    ssh eieio
    cd ~/ce1
    rm -fr ./split
    mkdir split
    foreach f (I II III IV V X M)
	mkdir split/$f
        faSplit size chr${f}.fa 100000 split/$f/c -lift=split/chr${f}.lft
    end
# 151 pieces of 151 written
# 153 pieces of 153 written
# 138 pieces of 138 written
# 175 pieces of 175 written
# 210 pieces of 210 written
# 178 pieces of 178 written
# 1 pieces of 1 written
    cat split/*.lft > liftAll.lft
    # copy them to /iscratch/i for cluster rsync
    # next machine
    ssh kkr1u00
    cd ~/ce1/split
    foreach c (I II III IV V X M)
	echo -n "${c} "
	mkdir -p /iscratch/i/worms/Celegans/${c}
        cp -p ${c}/c*.fa /iscratch/i/worms/Celegans/${c}
    end
    ~kent/bin/iSync

# Run RepeatMasker on the chromosomes (DONE 2003-05-27 - Hiram)
    # next machine
    ssh kk
    cd ~/ce1
    mkdir RMRun
    cd RMRun
    # create job list
    rm -f RMJobs
    foreach c (I II III IV V X M)
	mkdir ~/ce1/RMRun/${c}
        foreach t ( /iscratch/i/worms/Celegans/$c/c*.fa )
	    set d = $t:h
	    set f = $t:t
	    echo ~/ce1/scripts/RMLocalSens ${c} ${d} ${f} \
	    '{'check out line+ ~/ce1/RMRun/$c/${f}.out'}' \
	    >> RMJobs
	end
    end
    para create RMJobs
    para try
    para check
    # when they are finished, liftUp and load the .out files into the database:
    # next machine
    ssh eieio
    cd ~/ce1/RMRun
    foreach c (I II III IV V X M)
	liftUp chr${c}.fa.out ../split/chr${c}.lft warn ${c}/*.fa.out
    end
    
    # next machine
    ssh hgwdev
    cd ~/ce1/RMRun
    hgLoadOut ce1 chr*.fa.out

# SIMPLE REPEAT [TRF] TRACK (DONE 2003-05-27 - Hiram)
    # ensure chr*.fa files exist on /iscratch/i
    # next machine
    ssh kkr1u00
    cp -p /cluster/store4/worm/ce1/*.fa  /iscratch/i/worms/Celegans
    ~kent/bin/iSync

    # Create cluster parasol job:
    # next machine
    ssh kk
    mkdir -p ~/ce1/bed/simpleRepeat
    cd ~/ce1/bed/simpleRepeat
    mkdir trf
    ls -1S /iscratch/i/worms/Celegans/chr*.fa > genome.lst
    cp ~/hg15/bed/simpleRepeat/gsub .
    echo "" > dummy.lst
    gensub2 genome.lst dummy.lst gsub spec
    para create spec
    para try    # there are only 7, so this runs them all
    para check
# Longest job:                      983s      16.38m     0.27h    0.01d

    #  When cluster run is done, combine into one:
    cat trf/*.bed > simpleRepeat.bed
    
    # Load into the database:
    # next machine
    ssh hgwdev
    cd ~/ce1/bed/simpleRepeat
    /cluster/bin/i386/hgLoadBed ce1 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql

# PROCESS SIMPLE REPEATS INTO MASK (DONE 2003-05-27 - Hiram)
    # next machine
    ssh eieio
    cd ~/ce1/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
	awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

# Create Soft and Hard masks from RepeatMaster and TRF outputs:
#  and rebuild the nib files
    # next machine
    ssh eieio
    cd ~/ce1
    mkdir softMask
    foreach c (I II III IV V X M)
        echo -n "masking chr${c} "
	/cluster/bin/i386/maskOutFa chr${c}.fa RMRun/chr${c}.fa.out \
		softMask/chr${c}.fa -soft
	/cluster/bin/i386/maskOutFa softMask/chr${c}.fa \
		bed/simpleRepeat/trfMask/chr${c}.bed \
		softMask/chr${c}.fa -softAdd
		faToNib -softMask softMask/chr${c}.fa nib/chr${c}.nib
    end
    # unknown if hardMasks are actually needed for anything
    mkdir hardMask
    foreach c (I II III IV V X M)
        echo "masking chr${c}"
	/cluster/bin/i386/maskOutFa softMask/chr${c}.fa hard \
		hardMask/chr${c}.fa
    end

    #  With masked nib files ready, prepare cluster for blastz runs
    # next machine
    ssh kkr1u00
    cd ~/ce1/softMask
    mkdir -p /iscratch/i/worms/Celegans/trfFa
    cp -p *.fa /iscratch/i/worms/Celegans/trfFa


# MAKING AND STORING mRNA AND EST ALIGNMENTS (WORKING 2003-05-28 - Hiram)
    # next machine
    ssh kkr1u00
    cd /iscratch/i/worms/Celegans
    mkdir mRNA
    # there are 1644 sequences in mrna.fa, the 1000000 makes 1644 files
    faSplit sequence /iscratch/i/mrna.134/Caenorhabditis_elegans/mrna.fa \
		1000000 mRNA/m
    ~kent/bin/iSync

    # next machine
    ssh kk
    cd ~/ce1/bed
    mkdir mrna est
    cd mrna
    mkdir psl
    ls -1S /cluster/store4/worm/ce1/nib/chr*.nib > worm.lst
    ls -1S /iscratch/i/worms/Celegans/mRNA/m*.fa > mrna.lst
    echo '#LOOP
/cluster/bin/i386/blat -q=dna -t=dna -mask=lower {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP' > gsub
    gensub2 worm.lst mrna.lst gsub spec
    para create spec
    para try
    para check
    para push
    ... etc ...
# Longest job:                      328s       5.47m     0.09h    0.00d

    # cluster run done
    pslSort dirs raw.psl /tmp psl
    pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl all_mrna.psl \
      /dev/null
    pslSortAcc nohead chrom /tmp all_mrna.psl

    # load mrna tables
    # next machine
    ssh hgwdev
    cd ~/ce1/bed/mrna/chrom
    # names must be chr*_mrna.psl
    foreach d (I II III IV V X M)
	rm -f chr${d}_mrna.psl
	mv chr${d}.psl chr${d}_mrna.psl
    end
    # there is no chrM file, above will display error on that one
    hgLoadPsl ce1 *.psl
    mkdir /gbdb/ce1/mrna.134
    ln -s /cluster/store5/mrna.134/org/Caenorhabditis_elegans/mrna.fa \
	/gbdb/ce1/mrna.134
    hgLoadRna add -type=mRNA ce1 /gbdb/ce1/mrna.134/mrna.fa \
	/cluster/store5/mrna.134/org/Caenorhabditis_elegans/mrna.ra

    # setup /iscratch/i with the est.fa file for blat run
    # next machine
    ssh kkr1u00
    mkdir -p /iscratch/i/worms/Celegans/EST
    cd /iscratch/i/worms/Celegans/EST
    # create about a 1000 files to provide about 7000 jobs to the cluster
    #	(these jobs are too small)
    faSplit sequence \
	/cluster/store5/mrna.134/org/Caenorhabditis_elegans/est.fa 1000 e
    ~kent/bin/iSync

    # next machine
    ssh kk
    cd ~/ce1/bed/est
    mkdir psl
    ls -1S /cluster/store4/worm/ce1/nib/chr*.nib > worm.lst
    ls -1S /iscratch/i/worms/Celegans/EST/e*.fa > est.lst
    echo '#LOOP
/cluster/bin/i386/blat -q=dna -t=dna -mask=lower {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP' > gsub
    gensub2 worm.lst est.lst gsub spec
    para create spec
    para try
    para check
    para push
    # those 7000 jobs were too small:
# Longest job:                       35s       0.58m     0.01h    0.00d

    # cluster run done
    # next machine
    ssh hgwdev
    cd ~/ce1/bed/est
    pslSort dirs raw.psl /tmp psl
    pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl all_est.psl \
      /dev/null
    pslSortAcc nohead chrom /tmp all_est.psl
    cd chrom
    # names must be chr*_est.psl
    foreach d (I II III IV V X M)
	rm -f chr${d}_est.psl
	mv chr${d}.psl chr${d}_est.psl
    end
    hgLoadPsl ce1 *.psl


    ln -s /cluster/store5/mrna.134/org/Caenorhabditis_elegans/est.fa \
	/gbdb/ce1/mrna.134
    hgLoadRna add -type=EST ce1 /gbdb/ce1/mrna.134/est.fa \
	/cluster/store5/mrna.134/org/Caenorhabditis_elegans/est.ra
    hgLoadPsl ce1 all_est.psl -nobin

    
    # next machine
    ssh kk
    cd ~/ce1/bed/mrna
    mkdir psl
    ls -1S /scratch/hiram/Celegans/mrna.fa > mrna.lst
    cp -p ../../gsub .	# this will be from previous version when there is one
    gensub2 genome.lst mrna.lst gsub spec
    para create spec
    para try

MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR CE1 (TODO)
    # next machine
    ssh hgwdev
    echo 'insert into blatServers values("ce1", "blat10", "17778", "1"); \
          insert into blatServers values("ce1", "blat10", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest


SIMPLE REPEAT TRACK (DONE 2003-05-20 - 12:37 - Hiram)
    # This TRF run takes about an hour on eieio
    # so instead of binrsyncing and para-running, just do this on eieio:
    # next machine
    ssh eieio
    mkdir ~/ce1/bed/simpleRepeat
    cd ~/ce1/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    touch jobs.csh
    foreach f (/cluster/store4/worm/ce1/*.fa)
      set fout = $f:t:r.bed
      echo "/cluster/home/kent/bin/i386/trfBig -trf=/cluster/home/kent/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    tcsh jobs.csh |& tee jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l

    # When jobs are done,
    # To Load this into the database as so
    # next machine
    ssh hgwdev
    cd ~/ce1/bed/simpleRepeat
    cat trf/chr*.bed > simpleRepeat.bed
    hgLoadBed ce1 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql

PRODUCING FUGU FISH ALIGNMENTS  (DONE 2003-05-28 - Hiram)
    # Assumes masked NIBs have been prepared as above
    # and Fugu pieces are already on kluster /iscratch/i.
    # next machine
    ssh kk
    mkdir -p ~/ce1/bed/blatFugu
    cd ~/ce1/bed/blatFugu
    mkdir psl
    ls -1S /iscratch/i/fugu/*.fa > fugu.lst
    ls -1S /cluster/store4/worm/ce1/nib/chr*.nib > worm.lst
    echo '#LOOP
/cluster/bin/i386/blat -q=dnax -t=dnax -mask=lower {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP' > gsub

    gensub2 worm.lst fugu.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check
# Longest job:                     1290s      21.50m     0.36h    0.01d

    # want names chrI_blatFugu
    #  When cluster run is done, sort alignments
    # next machine
    ssh eieio
    cd ~/ce1/bed/blatFugu
    foreach d (I II III IV V X M)
        echo -n "${d} "
	pslCat psl/chr${d}_*.psl | \
	pslSortAcc nohead chrom temp stdin
	rm -f chrom/chr${d}_blatFugu.psl
	mv chrom/chr${d}.psl chrom/chr${d}_blatFugu.psl
    end

    # next machine
    ssh hgwdev
    cd ~/ce1/bed/blatFugu/chrom
    hgLoadPsl ce1 chr*_blatFugu.psl

    # Make fugu /gbdb/ symlink and load Fugu sequence data.
    mkdir /gbdb/ce1/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta /gbdb/ce1/fuguSeq
    hgLoadRna addSeq ce1 /gbdb/ce1/fuguSeq/fugu_v3_mask.fasta

RUN Waba alignment with briggsae
    # prepare contigs from C. briggsae
    #   Assumes C. briggsae data has been downloaded according to
    #   makeCb1.doc
    # next machine
    ssh kkr1u00
    mkdir -p /iscratch/i/worms/Cbriggsae/waba_contigs
    cd /iscratch/i/worms/Cbriggsae/waba_contigs
    faSplit sequence ../contigs.fa 2000 c
    ~kent/bin/iSync
    
    # next machine
    ssh kk
    mkdir ~/ce1/bed/waba/out
    cd ~/ce1/bed/waba
    ls /iscratch/i/worms/Cbriggsae/waba.contigs/c*.fa > briggsae.lst
    ls /iscratch/i/worms/Celegans/trfFa/chr*.fa > elegans.lst
    echo "" > dummy.lst
    # create scripts to be used here
    echo '#!/bin/csh -fe
#
#	$1 - full pathname to a waba.contig
#	$2 - file path to elegans.lst
#	$3 - result file full pathname
#
set f = $1:t
mkdir -p /tmp/$f
cp $1 /tmp/$f
pushd .
cd /tmp/$f
set t = $f:r
/cluster/bin/i386/waba 1 $f $2 $t.1
/cluster/bin/i386/waba 2 $t.1 $t.2
/cluster/bin/i386/waba 3 $t.2 $t.wab
cp $t.wab $3
popd
rm -f /tmp/$f/$t.*
rmdir --ignore-fail-on-non-empty /tmp/$f' > wabaRun
    chmod +x wabaRun

    echo '#LOOP
/cluster/store4/worm/ce1/bed/waba/wabaRun {check in exists+ $(path1)} /cluster/store4/worm/ce1/bed/waba/elegans.lst {check out line+ /cluster/store4/worm/ce1/bed/waba/out/$(root1).wab}
#ENDLOOP' > gsub

    gensub2 briggsae.lst dummy.lst gsub spec
    para create spec
    para try
    para check
    para push
    ... etc ...


RUN BLASTZ with C. briggsae
    #  Still trying to figure out how this works.  There is more to this
    #  than seems at first glance.
    # Created a new DEF file for this since this is the first time
    

MAKING VIRAL mRNA FILES (DONE 04/15/03)
    cd /cluster/store5/mrna.134
    gunzip -c \
      /cluster/store5/genbank.134/gbvrl* \
    | gbToFaRa anyRna.fil viralRna.{fa,ra,ta} stdin
    mkdir /gbdb/sc1/mrna.134
    ln -s  /cluster/store5/mrna.134/viralRna.fa /gbdb/sc1/mrna.134/
    hgLoadRna add -type=mrna sc1 /gbdb/sc1/mrna.134/viralRna.fa \
      /cluster/store5/mrna.134/viralRna.ra
    # distribute to /iscratch/i/
    # next machine
    ssh kkr1u00
    mkdir -p /iscratch/i/mrna.134
    cp -p /cluster/store5/mrna.134/viralRna.fa  /iscratch/i/mrna.134
    ~kent/bin/iSync
