#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on 
# NCBI build 36 (October 2005 freeze)

# HOW TO BUILD AN ASSEMBLY FROM NCBI FILES 
# ---------------------------------------
# 10/06/2005
# Make gs.19 directory, gs.19/build36 directory, and gs.19/ffa directory.
    ssh kkstore02
    mkdir /cluster/store11/gs.19
    mkdir /cluster/store11/gs.19/build36
    mkdir /cluster/store11/gs.19/agp
    mkdir /cluster/store11/gs.19/ffa

#    Make a symbolic link from /cluster/store1 to this location
#	(I assume there is some use for this later ?)
	
    cd /cluster/store1
    ln -s /cluster/store11/gs.19 ./gs.19
    ln -s /cluster/store11/gs.19/build36 /cluster/data/hg18

#    Make a symbolic link from your home directory to the build dir:
#	(Investigate what this is used for, may no longer be necessary)

    cd
    ln -s /cluster/store11/gs.19/build36 ~/oo

# NCBI download site, fetch everything into this one directory:

#	with the machine and password in your $HOME/.netrc file, this
#	wget command will require no login.  Your $HOME/.netrc file
#	is set to 'chmod 600 .netrc' to prevent anyone from finding
#	the data.  (There were some early files that later moved
#		into an OLD subdirectory.  They were broken.)

# 11/16/2005
# Received answer from Greg to go ahead with the new build.

    ssh kkstore02
    mkdir /cluster/store11/gs.19/ncbi
    cd /cluster/store11/gs.19/ncbi
    bash
    wget --timestamp ftp://ftp-private.ncbi.nih.gov/build_36/*

#	New to this build is the sequence: NC_001807 which is the
#	mitochondria sequence.  This prefix NC_ is new to the process
#	and will have to be accounted for below.  The other two special
#	prefixes are similar to what was seen before:
#	from DR52.agp NG_002392
#	Homo sapiens major histocompatibility complex, class II,
#		DR52 haplotype (DR52) on chromosome 6
#	and from DR53.agp NG_002433
#	Homo sapiens major histocompatibility complex, class II,
#		DR53 haplotype (DR53) on chromosome 6

#	Fixup seq_contig.md
#
#	It has a bunch of stuff belonging to the Celera
#	genome assembly.  Filter those out.  I don't know what the
#	NT_07959[0-7] items are, but there are no definitions for them
#	in the agp files and no sequence in any fa.gz file.
#	Fixup the names for the NG_ items, and change chrom MT to be M

# get the seq_contig.md file Craig just made for us on 11/28/05.
cd /cluster/store11/gs.19/ncbi
wget --timestamp ftp://ftp-private.ncbi.nih.gov/build_36/seq_contig.md

# remove Celera and Toronto entries
# and replace chrom number for those haplotypes

ssh hgwdev
cd /cluster/store11/gs.19/build36
egrep -v "Celera|NT_07959[0-7]" ../ncbi/seq_contig.md |grep -v CRA_TCA >seq_contig0.tab

hgsql hg18 -e 'drop table seq_contig0'
hgsql hg18 <~/src/hg/lib/seq_contig0.sql
hgsql hg18 -e 'load data local infile "seq_contig0.tab" into table seq_contig0'

#     fix seq_contig and
#	get the randoms sorted in proper order.  The createNcbiLifts
#	does not work correctly if the randoms are not grouped together
#	by chromosome
fixMd0 hg18 |sed -e "s/6_qbl_hap1/6_qbl_hap2/"| sed -e "s/MT/M/" | grep -v "|" >seq_contig1.tab

hgsql hg18 -e 'drop table seq_contig1'
hgsql hg18 <~/src/hg/lib/seq_contig1.sql
hgsql hg18 -e 'load data local infile "seq_contig1.tab" into table seq_contig1'
fixMd hg18 seq_contig1 >seq_contig.md

#	This pulls out all the randoms and groups them within the
#	same chrom but leaving them in the same order as they orginally
#	were  (warning this is BASH code ...)
bash
    grep "|" seq_contig0.tab | awk -F"|" '{print $1}' | \
        awk '{print $2}' | sort -n -u | while read CHR
do
        grep "[^0-9]${CHR}|" seq_contig0.tab
done >> seq_contig.md
exit

hgsql hg18 -e 'drop table seq_contig'
hgsql hg18 <~/src/hg/lib/seq_contig.sql
hgsql hg18 -e 'load data local infile "seq_contig.md" into table seq_contig'

# FYI: agp file format documented at:
#	http://www.ncbi.nlm.nih.gov/Genbank/WGS.agpformat.html# fixup a couple of names for our own purposes here
cd /cluster/store11/gs.19/agp
ln -s ../ncbi/chr*.agp ../ncbi/chr*.fa.gz .

sed -e "s#MT/NC_001807#NC_001807#" ../ncbi/chrMT.agp > chrM.agp

cat ../ncbi/c22_H2.agp > chr22_h2_hap1.agp
cat ../ncbi/c5_H2.agp  > chr5_h2_hap1.agp
cat ../ncbi/c6_COX.agp > chr6_cox_hap1.agp
cat ../ncbi/c6_QBL.agp > chr6_qbl_hap2.agp

cp -p ../ncbi/c22_H2.fa.gz chr22_h2_hap1.fa.gz
cp -p ../ncbi/c5_H2.fa.gz  chr5_h2_hap1.fa.gz
cp -p ../ncbi/c6_COX.fa.gz chr6_cox_hap1.fa.gz
cp -p ../ncbi/c6_QBL.fa.gz chr6_qbl_hap2.fa.gz

mkdir sav
cp -p *hap*.agp sav

# fix hap type agp files that have multiple contigs.
 
fixAgp hg18 sav/chr5_h2_hap1.agp chr5_h2_hap1.agp
fixAgp hg18 sav/chr6_qbl_hap2.agp chr6_qbl_hap2.agp

# PLEASE NOTE THAT THESE TWO CORRECTED .agp FILES ABOVE ARE USED LATER, 
# NOT BY THE NEXT STEP IMMEDIATELY.
    
#  Put all the agp files together into one.

#	The chrM sequence now has its own agp, remove it from
#	ref_placed.agp
# sed -e "/^NC_001807/d" ../ncbi/ref_placed.agp > ref_placed.agp

# PLEASE NOTE THAT THE ORIGINAL NCBI .agp FILES FOR THOSE
# SPECIAL HAP TYPE SEQUENCES ARE USED, NOT THE CORRECTED ONES.

cd /cluster/store11/gs.19/build36
cat ../ncbi/ref_placed.agp ../agp/chrM.agp ../ncbi/ref_unplaced.agp \
../ncbi/c22_H2.agp \
../ncbi/c5_H2.agp \
../ncbi/c6_COX.agp \
../ncbi/c6_QBL.agp \
../ncbi/PAR.agp > ncbi_build36.agp

# cat ../ncbi/ref_placed.agp ../agp/chrM.agp ../ncbi/ref_unplaced.agp \
# ../agp/chr22_h2_hap1.agp ../agp/chr5_h2_hap1.agp \
# ../agp/chr6_cox_hap1.agp ../agp/chr6_qbl_hap2.agp \
# ../ncbi/PAR.agp > ncbi_build36.agp

    zcat ../ncbi/chrMT.fa.gz | \
	sed -e "s/gi|17981852|ref|NC_001807.4/ref|NC_001807/" | \
	gzip > chrM.fa.gz

#	and into ffa
    cd /cluster/store11/gs.19/ffa
# NO LONGER TRUE FOR GS19!
# There is a single bogus line at the end of ref_placed.fa.gz
#	declaring the NC_001807 MT sequence, this was later replaced by
#	chrMT.fa.gz, so remove that one line:
    zcat ../ncbi/ref_placed.fa.gz | sed -e "/^>ref|NC_001807/d" | \
    gzip > ref_placed.fa.gz
#	(That's a 40 minute job)

#	sequence.inf is usually here, symlink it
#ln -s ../ncbi/sequence.inf
    ln -s ../ncbi/chromosome_extents.inf
#	put all the fa.gz files together in one big fa.gz
#   time zcat ref_placed.fa.gz ../agp/chrM.fa.gz ../ncbi/ref_unplaced.fa.gz \
time zcat ../ncbi/ref_placed.fa.gz ../ncbi/ref_unplaced.fa.gz \
../agp/*hap?.fa.gz ../ncbi/PAR.fa.gz | gzip \
> ncbi_build36.fa.gz

#	Make a listing of all the fasta record headers, just FYI:
    cd /cluster/store11/gs.19
    zcat ffa/ncbi_build36.fa.gz | grep "^>" > ncbi.fa.headers

# Sanity check, checkYbr was updated to handle the NC_ identifier
cd /cluster/store11/gs.19/build36
zcat ../ffa/ncbi_build36.fa.gz | $HOME/bin/i386/checkYbr ncbi_build36.agp stdin seq_contig.md >check.seq_contig
#	result should be clean:
cat check.seq_contig
# Read 378 contigs from ncbi_build36.agp
# Verifying sequence sizes in stdin
# 0 problems detected

# Convert fa files into UCSC style fa files and place in "contigs"
# directory inside the gs.19/build36 directory 
#	(a check that can be done here is make a list of the contigs
#	in this ./contigs directory before and compare it with the
#	list of distributed contigs created after they have been
#	disbursed.)
#	faNcbiToUcsc was fixed to handle the NC_ identifier

cd /cluster/store11/gs.19/build36

# We've been through this often

# mv contigs contigs.0
zcat ../ffa/ncbi_build36.fa.gz | $HOME/bin/i386/faNcbiToUcsc \
-split -ntLast stdin contigs

#	If you want to compare anything to previous work, check now, then:
#     rm -fr contigs.0

# Determine the chromosome sizes from agps
#	Watch carefully how chrY gets constructed.  I'm not sure
#	this chrom_sizes represents the whole length of chrY with
#	the PAR added.  We will see about that.
#	Script updated to handle new chrom names:
#	my @chroms = (1 .. 22, 'X', 'Y', 'M', '6_hla_hap1', '6_hla_hap2');

cd /cluster/store11/gs.19/build36
/cluster/bin/scripts/getChromSizes ../agp

#	Create chrom.lst list for use in foreach() loops
awk '{print $1}' chrom_sizes | sed -e "s/chr//" > chrom.lst

# Create lift files (this will create chromosome directory structure) and
#	inserts file
  
/cluster/bin/scripts/createNcbiLifts -s chrom_sizes seq_contig.md .

# Create contig agp files (will create contig directory structure)
	
/cluster/bin/scripts/createNcbiCtgAgp seq_contig.md ncbi_build36.agp .

# Create chromsome random agp files.

/cluster/bin/scripts/createNcbiChrAgp -randomonly .

# Copy the original chrN.agp files from the gs.19/agp directory 
#    into each of the chromosome directories since they contain better 
#    gap information. Delete the comments at top from these.
cd /cluster/store11/gs.19/build36
foreach c ( `cat chrom.lst` )
	sed -e "/^#.*/d" ../agp/chr${c}.agp > ./${c}/chr${c}.agp
end
#	chrM needs a name fixup
sed -e "s#NC_001807#chrM#" ../agp/chrM.agp > M/chrM.agp

# Distribute contig .fa to appropriate directory (assumes all files
# are in "contigs" directory).

# Create inserts file from agp and lift files (new - added by Terry, 2004-07-12)
/cluster/bin/scripts/createInserts /cluster/data/hg18 > /cluster/data/hg18/inserts

# create global data link for everyone.  No more home directory
# links required.
ln -s /cluster/store11/gs.19/build36 /cluster/data/hg18
cd /cluster/data/hg18
/cluster/bin/scripts/distNcbiCtgFa contigs .
#	Verify that everything was moved properly, the contigs directory
#	should be empty:
ls contigs
#	Nothing there, then remove it
rmdir  contigs

#	Make a list of the contigs for use later
    rm contig.lst
    touch contig.lst
    foreach chrom ( `cat chrom.lst` )
	foreach c ( $chrom/N{C,G,T}_?????? )
	    set contig = $c:t
	    echo "${chrom}/${contig}/${contig}.fa" >> contig.lst
	end
    end
#   For later comparisons, this is how many contigs we have:
    wc -l contig.lst
# 378 contig.lst 

#	Note 2004-06-30 - there are some clone numbers left in some of
#	the NCBI files that are incorrect.  Due to version number
#	changes, more than one version is listed.  Namely for accession
#	numbers: AC004491 AC004921 AC004983 AC005088 AC006014 AC099654
#	The AGP files are correct, the sequence.inf file lists these
#	twice: AC004491.1 AC004491.2
#	AC004921.1 AC004921.2 AC004983.2 AC004983.3
#	AC005088.2 AC005088.3 AC006014.2 AC006014.3
#	AC099654.4 AC099654.5

# for hg18, NCBI did not provide the seq.inf file.

# FILES ARE NOW READY FOR REPEAT MASKING - start that process as
#	other steps here can proceed in parallel.

#	Previous practice used to copy everything over for jkStuff from a
#	previous build.  Rather than do that, pick up whatever is needed
#	at the time it is needed and verify that it is going to do what
#	you expect.

    cd /cluster/data/hg18
    mkdir jkStuff

# Create the contig.gl files - XXX - NCBI doesn't deliver
# contig_overlaps.agp - 2004-06-18 - this is beginning to come
# together and there is now a contig_overlaps.agp file

#	This is properly done below with a combination of psLayout
#	alignments to create the contig_overlaps.agp file
# /cluster/bin/i386/agpToGl contig_overlaps.agp . -md=seq_contig.md
# Create chromosome gl files
# jkStuff/liftGl.csh contig.gl

# CREATING DATABASE  (DONE - 2005-11-30 - Fan)

    ssh hgwdev

# Make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
# Filesystem            Size  Used Avail Use% Mounted on
# /dev/sdc1             1.8T  1.3T  356G  79% /var/lib/mysql

# Create the database.
    hgsql -e 'create database hg18' mysql
# Copy over grp table (for track grouping) from another database:
    hgsql -e "create table grp (PRIMARY KEY(NAME)) select * from hg17.grp" hg18

# The DB updates to grp below are not needed since we copied from hg17.
# ENCODE groups
# Added 2005-08016 kate
    echo 'UPDATE grp SET priority=7 WHERE name="varRep"'| hgsql hg18
    echo 'UPDATE grp SET priority=8 WHERE name="encode"'| hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeGenes", "ENCODE Regions and Genes", 8.1)' | hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeTxLevels", "ENCODE Transcript Levels", 8.2)' | hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeChip", "ENCODE Chromatin Immunoprecipitation", 8.3)' | hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeChrom", "ENCODE Chromosome, Chromatin and DNA Structure", 8.4)' | hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeCompGeno", "ENCODE Comparative Genomics", 8.5)' | hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeVariation", "ENCODE Variation", 8.6)' | hgsql hg18
    echo 'INSERT INTO grp (name, label, priority) VALUES ("encodeAnalysis", "ENCODE Analysis", 8.9)' | hgsql hg18
    
# MAKE CHROMINFO TABLE WITH (TEMPORARILY UNMASKED) NIBS
#	(DONE - 2005-12-02 - Fan)

# Make nib/, unmasked until RepeatMasker and TRF steps are done.
# Do this now so that the chromInfo table will exist and thus the
#	trackDb tables can be built in the next step.
#	These unmasked nibs will be replaced by the masked nibs after
#	repeat mask and trf are done.
    ssh kkstore02
    cd /cluster/data/hg18
    cp /cluster/data/hg17/jkStuff/chrFa.csh jkStuff -p

# Make chr*.fa from contig .fa
#  Copied chrFa.sh from hg17/jkStuff, renamed it to chrFa.csh
bash
time ./jkStuff/chrFa.csh
# real    2m34.406s
# user    1m17.405s
# sys     0m16.730s
exit

    mkdir nib
    foreach c (`cat chrom.lst`)
      foreach f ($c/chr${c}{,_random}.fa)
        if (-e $f) then
          echo "nibbing $f"
          /cluster/bin/i386/faToNib $f nib/$f:t:r.nib
        endif
      end
    end

# Make symbolic links from /gbdb/hg18/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/hg18/nib
    ln -s /cluster/data/hg18/nib/chr*.nib /gbdb/hg18/nib
# Load /gbdb/hg18/nib paths into database and save size info.
    cd /cluster/data/hg18
    hgsql hg18  < $HOME/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib hg18 /gbdb/hg18/nib */chr*.fa
    hgsql -N -e "select chrom,size from chromInfo order by chrom" hg18 \
	> chrom.sizes
# You can compare this chrom.sizes with the previously created
# chrom_sizes.  Should be no difference
    sort chrom_sizes > s0
    sort chrom.sizes | grep -v random > s1
    diff s0 s1
    rm s0 s1

# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE - 2005-12-06 - Fan)
#	dbDb orderKey updated 2005-12-06 - Fan
    ssh hgwdev
#	reset dbDb orderKey - these have never been ordered properly
#	before, this will get them on the program.
    hgsql -e 'update dbDb set orderKey=11 where name = "hg17";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=12 where name = "hg16";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=13 where name = "hg15";' \
	-h genome-testdb hgcentraltest
    hgsql -e 'update dbDb set orderKey=14 where name = "hg13";' \
	-h genome-testdb hgcentraltest

# Enter hg18 into hgcentraltest.dbDb so test browser knows about it:
    hgsql -e 'INSERT INTO dbDb (name, description, nibPath, organism, \
	defaultPos, active, orderKey, genome, scientificName, \
	htmlPath, hgNearOk, hgPbOk, sourceName) \
	VALUES("hg18", "Dec 2005", "/gbdb/hg18/nib", "Human", \
	"chr4:56214201-56291736", 1, 10, "Human", "Homo sapiens", \
	"/gbdb/hg18/html/description.html", 0, 0, "NCBI Build 36");' \
	-h genome-testdb hgcentraltest
# Make trackDb table so browser knows what tracks to expect:
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P .
# Edit the makefile to add hg18 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE LIFTALL.LFT, NCBI.LFT (DONE - 2005-12-07 Fan)
    cd /cluster/data/hg18
    mkdir -p jkStuff
    cat */lift/{ordered,random}.lft > jkStuff/liftAll.lft
# Create jkStuff/ncbi.lft for lifting stuff built with the NCBI assembly.
# Note: this ncbi.lift will not lift floating contigs to chr_random coords,
# but it will show the strand orientation of the floating contigs 
# (grep for '|').
#   mdToNcbiLift seq_contig.md jkStuff/ncbi.lft 
#	XXXX - appears to be unused, not done - Hiram

# REPEAT MASKING (DONE - 2005-12-09 - Fan)

#	Record the RM version here:
ls -l /cluster/bluearc/RepeatMasker
# lrwxrwxrwx    1 angie    protein        18 Nov  3 10:40 /cluster/bluearc/RepeatMasker -> RepeatMasker051101

/cluster/bluearc/RepeatMasker/RepeatMasker | head -1
# RepeatMasker version development-$Id: makeHg18.doc,v 1.18 2006/01/18 00:42:41 hiram Exp $

#	RepBase Update 8.12, RM database version 20040130  ??? don't know where this came from. Fan???
#	as this changes over time and there is no record in the results

# Split contigs, run RepeatMasker, lift results
#	This split takes a few minutes
    ssh kkstore02
    cd /cluster/data/hg18
    foreach chrom ( `cat chrom.lst` )
	foreach c ( $chrom/N{C,G,T}_?????? )
	    set contig = $c:t
	    echo "splitting ${chrom}/${contig}/${contig}.fa"
	    faSplit size ${chrom}/${contig}/$contig.fa 500000 \
		${chrom}/${contig}/${contig}_ \
		-lift=${chrom}/${contig}/$contig.lft -maxN=500000
	end
    end

#- Make the run directory and job list:
    cd /cluster/data/hg18
    mkdir -p jkStuff
#  According to RepeatMasker help file, no arguments are required to
#	specify species because its default is set for primate (human)
#  This run script saves the .tbl file to be sent to Arian.  He uses
# those for his analysis.  Sometimes he needs the .cat and .align files for
# checking problems.  Krish needs the .align files, they are large.

    cat << '_EOF_' > jkStuff/RMHuman
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/hg18/$2
/bin/cp $2 /tmp/hg18/$2/
cd /tmp/hg18/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s $2
popd
/bin/cp /tmp/hg18/$2/$2.out ./
if (-e /tmp/hg18/$2/$2.align) /bin/cp /tmp/hg18/$2/$2.align ./
if (-e /tmp/hg18/$2/$2.tbl) /bin/cp /tmp/hg18/$2/$2.tbl ./
# if (-e /tmp/hg18/$2/$2.cat) /bin/cp /tmp/hg18/$2/$2.cat ./
/bin/rm -fr /tmp/hg18/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg18/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/hg18
'_EOF_'
# << this line makes emacs coloring happy
    chmod +x jkStuff/RMHuman

    ssh kkstore02
    cd /cluster/data/hg18
    mkdir RMRun
    rm -f RMRun/RMJobs
    touch RMRun/RMJobs
    foreach d ( `cat chrom.lst` )
     foreach c ( ${d}/N{C,G,T}_*/N{C,G,T}_*_*.fa )
        set f = $c:t
        set cc = $c:h
        set contig = $cc:t
        echo /cluster/store11/gs.19/build36/jkStuff/RMHuman \
   		/cluster/store11/gs.19/build36/${d}/${contig} $f \
   '{'check out line+ /cluster/store11/gs.19/build36/${d}/${contig}/$f.out'}' \
          >> RMRun/RMJobs
      end
    end

# We have 5990 jobs in RMJobs:
    wc RMRun/RMJobs
#	5990   41930 1127992 RMRun/RMJobs

#- Do the run
    ssh pk
    cd /cluster/data/hg18/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...

#- While that is running, you can run TRF (simpleRepeat) on the small
# cluster.  See SIMPLE REPEAT section below
# Completed: 5990 of 5990 jobs
# CPU time in finished jobs:   30661460s  511024.34m  8517.07h  354.88d  0.972 y
# IO & Wait Time:                 38038s     633.96m    10.57h    0.44d  0.001 y
# Average job time:                5125s      85.42m     1.42h    0.06d
# Longest running job:                0s       0.00m     0.00h    0.00d
# Longest finished job:            6693s     111.55m     1.86h    0.08d
# Submission to last job:         86532s    1442.20m    24.04h    1.00d

#	Lift up the split-contig .out's to contig-level .out's
#
#	If a mistake is made in the following it would be possible to
#	destroy all the RM output.  So, just to be paranoid, save all
#	the RM output in bluearc for the time being:
    ssh kkstore02

    cd /cluster/data/hg18
    mkdir /cluster/bluearc/hg18/RMOutput
    foreach c ( `cat chrom.lst` )
     foreach d ( ${c}/N{C,G,T}_* )
	set T = /cluster/bluearc/hg18/RMOutput/${d}
	mkdir -p ${T}
        cd ${d}
        set contig = $d:t
        cp -p ${contig}_?{,?,??}.fa.out ${T}
        cd ../..
	echo "${d} done"
     end
    end
#	Make sure we got them all:
#	(this doesn't work later since there are more *.fa.out files
#	after the lifting.  More explicitly to find just these:
#		find . -name "N?_*_*.fa.out" -print | wc -l
    find . -name "*.fa.out" -print | wc -l
#	5990
    find /cluster/bluearc/hg18/RMOutput -type f | wc -l
#	5990
#	same count

#	OK, now you can try this operation, do it in a script like this
#	and save the output of the script for a record of what happened.

    cat << '_EOF_' > jkStuff/liftRM.csh
#!/bin/csh -fe
foreach c ( `cat chrom.lst` )
 foreach d ( ${c}/N{C,G,T}_* )
    cd $d
    set contig = $d:t
    liftUp $contig.fa.out $contig.lft warn ${contig}_?{,?,??}.fa.out 
    cd ../..
 end
end
'_EOF_'
    chmod +x jkStuff/liftRM.csh
    mkdir scriptsOutput
    
    script lift.log
    bash
    time jkStuff/liftRM.csh > scriptsOutput/liftRM.1 2>&1
    exit
    exit

#	Check that they all were done:
    grep "fa.out" scriptsOutput/liftRM.1 | wc -l
#	5990
#	same count as above

#- Lift up RepeatMask .out files to chromosome coordinates via
# picked up jkStuff/liftOut2.sh from the hg17 build.  Renamed to
# liftOut2.csh, changed the line that does the chrom listing
    bash
    time ./jkStuff/liftOut2.csh > scriptsOutput/liftOut2 2>&1
# real    0m30.488s
# user    0m24.670s
# sys     0m2.797s
# seems much faster than hg17 ???
    
# hg17 numbers:
#	real    9m46.780s
#	user    1m18.900s
#	sys     7m33.990s

#- By this point, the database should have been created (above):
    ssh hgwdev
    cd /cluster/data/hg18
    bash
    time hgLoadOut hg18 ?/*.fa.out ??/*.fa.out *hap*/*.fa.out > \
	scriptsOutput/hgLoadOut 2>&1
# real    9m9.045s
# user    2m19.500s
# sys     0m24.440s

# errors during this load:  (there are always a couple of these)
# Strange perc. field -1.2 line 153851 of 2/chr2.fa.out
# Strange perc. field -10423.3 line 174747 of 3/chr3.fa.out
# Strange perc. field -5635.9 line 174747 of 3/chr3.fa.out
# Strange perc. field -259.3 line 174747 of 3/chr3.fa.out
# Strange perc. field -1.4 line 205545 of 4/chr4.fa.out
# Strange perc. field -0.1 line 167690 of 7/chr7.fa.out
# Strange perc. field -1331.2 line 198656 of 7/chr7.fa.out
# Strange perc. field -1460.4 line 198656 of 7/chr7.fa.out
# Strange perc. field -4.2 line 223183 of 7/chr7.fa.out
# Strange perc. field -3192.0 line 60424 of 8/chr8.fa.out
# Strange perc. field -423.4 line 60424 of 8/chr8.fa.out
# Strange perc. field -784.0 line 60424 of 8/chr8.fa.out
# Strange perc. field -0.1 line 52020 of X/chrX.fa.out
# Strange perc. field -4526.7 line 190254 of X/chrX.fa.out
# Strange perc. field -3757.2 line 190254 of X/chrX.fa.out
# Strange perc. field -597.2 line 190254 of X/chrX.fa.out
# Strange perc. field -13030.4 line 137624 of 16/chr16.fa.out
# Strange perc. field -1359.8 line 137624 of 16/chr16.fa.out
# Strange perc. field -2223.5 line 137624 of 16/chr16.fa.out
# Strange perc. field -1.3 line 11573 of 22/chr22.fa.out
# Strange perc. field -12.7 line 69873 of 22/chr22.fa.out


#	Verify we have similar results to previous assembly:
#	featureBits hg18 rmsk
# 	1406290513 bases of 3107677273 (45.252%) in intersection
#	featureBits -countGaps hg17 rmsk
#	1390952984 bases of 3095016460 (44.942%) in intersection
#	featureBits hg17 rmsk
#	1391378842 bases of 2867328468 (48.525%) in intersection
#	featureBits hg16 rmsk
#	1388770568 bases of 2865248791 (48.469%) in intersection
#	Now proceed to MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
#	following the SIMPLE REPEAT sections below

# let Rachel know that RepeatMask is done.

# SIMPLE REPEAT [TRF] TRACK (DONE - 2005-12-07 - Fan)
#	Copy the contigs, first to the bluearc, then to /iscratch/i
    ssh kkstore02
    mkdir /cluster/bluearc/hg18
    mkdir /cluster/bluearc/hg18/contigs

    cd /cluster/data/hg18
    foreach ctg ( `cat contig.lst` )
	set c = $ctg:t
 	echo "$ctg > /cluster/bluearc/hg18/contigs/$c"
	cp -p $ctg /cluster/bluearc/hg18/contigs/$c
    end
#	Check how much is there:
#	du -hsc /cluster/bluearc/hg18/contigs
#	2.8G    /cluster/bluearc/hg18/contigs
    exit

# Distribute contigs to /iscratch/i
    ssh pk
    mkdir -p /san/sanvol1/scratch/hg18/unmaskedContigs
    cd /san/sanvol1/scratch/hg18/unmaskedContigs
    cp -p /cluster/bluearc/hg18/contigs/* .
    ls .

# Verify same amount made it there:
#	du -hsc /san/sanvol1/scratch/hg18/unmaskedContigs
#	2.9G    /san/sanvol1/scratch/hg18/unmaskedContigs
#	Then send them to the other 7 Iservers
#    /cluster/bin/iSync

#	Go to the small cluster for this business:
    ssh pk

    mkdir -p /cluster/data/hg18/bed/simpleRepeat
    cd /cluster/data/hg18/bed/simpleRepeat
    mkdir trf
    cat << '_EOF_' > runTrf
#!/bin/csh -fe
#
set path1 = $1
set inputFN = $1:t
set outpath = $2
set outputFN = $2:t
mkdir -p /tmp/$outputFN
cp $path1 /tmp/$outputFN
pushd .
cd /tmp/$outputFN
/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $inputFN /dev/null -bedAt=$outputFN -tempDir=/tmp
popd
rm -f $outpath
cp -p /tmp/$outputFN/$outputFN $outpath
rm -fr /tmp/$outputFN/*
rmdir --ignore-fail-on-non-empty /tmp/$outputFN
'_EOF_'
# << this line makes emacs coloring happy
    chmod +x runTrf

    cat << '_EOF_' > gsub
#LOOP
./runTrf {check in line+ $(path1)}  {check out line trf/$(root1).bed}
#ENDLOOP
'_EOF_'
# << this line makes emacs coloring happy

    ls -1S /san/sanvol1/scratch/hg18/unmaskedContigs/*.fa > genome.lst
    gensub2 genome.lst single gsub jobList
    para create jobList
    para try
    para check
    para push
    para check
# Completed: 378 of 378 jobs
# CPU time in finished jobs:      18956s     315.93m     5.27h    0.22d  0.001 y
# IO & Wait Time:                  2519s      41.98m     0.70h    0.03d  0.000 y
# Average job time:                  57s       0.95m     0.02h    0.00d
# Longest running job:                0s       0.00m     0.00h    0.00d
# Longest finished job:            2345s      39.08m     0.65h    0.03d
# Submission to last job:          2427s      40.45m     0.67h    0.03d

bash
liftUp simpleRepeat.bed /cluster/data/hg18/jkStuff/liftAll.lft \
warn trf/*.bed  > lu.out 2>&1

# Load into the database:
    ssh hgwdev
    cd /cluster/data/hg18/bed/simpleRepeat
    /cluster/bin/i386/hgLoadBed hg18 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql
#	Loaded 629076 elements of size 16
#	Compare with previous assembly
    featureBits hg18 simpleRepeat
# 56164158 bases of 3107677273 (1.807%) in intersection
# 	featureBits hg17 simpleRepeat
#	54952425 bases of 2866216770 (1.917%) in intersection
#     featureBits hg16 simpleRepeat
#	54320136 bases of 2865248791 (1.896%) in intersection
#	GAPS weren't in hg18 yet at this point, after gaps added:
#	featureBits hg18 simpleRepeat
#	54964044 bases of 2867328468 (1.917%) in intersection
#	featureBits -countGaps hg18 simpleRepeat
#	54964044 bases of 3096628158 (1.775%) in intersection

# PROCESS SIMPLE REPEATS INTO MASK (DONE - 2005-12-09 - Fan)
# After the simpleRepeats track has been built, make a filtered version 
# of the trf output: keep trf's with period <= 12:
    ssh kkstore02
    mkdir -p cd /cluster/data/hg18/bed/simpleRepeat
    cd /cluster/data/hg18/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

#	The 4 lines below were left over from makeHg17.doc.
#	EXPERIMENT, at a filter of <= 12, we have coverage:
#	20904399 bases of 2867328468 (0.729%) in intersection
#	at a filter of <= 9, we have coverage:
#	19271270 bases of 2867328468 (0.672%) in intersection

# Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/hg18
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c ( `cat chrom.lst` )
      if (-e $c/lift/ordered.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
          $c/lift/ordered.lst > $c/lift/oTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end

# MASK SEQUENCE BOTH REPEATMASKER AND SIMPLE REPEAT/TRF (DONE - 2005-12-09, Fan)
# This used to be done right after RepeatMasking.  Now, we mask with 
# TRF as well, so do this after the "PROCESS SIMPLE REPEATS" step above,
#	and after Repeat Masker is complete.
    ssh kkstore02
    cd /cluster/data/hg18

# Make chr*.fa from contig .fa
#  chrFa.csh was already copied from hg17/jkStuff
    bash    
    time ./jkStuff/chrFa.csh > scriptsOutput/chrFa.out 2>&1 &
# real    2m35.734s
# user    1m18.351s
# sys     0m16.596s
# much faster than hg17 numbers as shown below.  ???

# old hg17 numbers:
#	real    13m18.512s
#	user    9m1.670s
#	sys     1m7.290s

#- Soft-mask (lower-case) the contig and chr .fa's
    time ./jkStuff/makeFaMasked.csh > scriptsOutput/maFaMasked.out 2>&1
# real    8m47.289s
# user    3m45.698s
# sys     1m44.416s

#	old hg17 numbers:	
#	real    29m31.623s
#	user    13m49.700s
#	sys     5m58.750s

#- Make hard-masked .fa.masked files as well:
    time ./jkStuff/makeHardMasked.csh > scriptsOutput/maHardMasked.out 2>&1
# real    5m48.833s
# user    1m41.926s
# sys     0m52.084s

#- Create the bothMasksNib/ directory
    time ./jkStuff/makeNib.csh > scriptsOutput/maNib.out 2>&1
# real    2m23.280s
# user    1m6.462s
# sys     0m19.795s

# old hg17 numbers:
#	real    14m41.694s
#	user    6m28.000s
#	sys     1m42.500s

# Make symbolic links from /gbdb/hg18/nib to the real nibs.
    ssh hgwdev
    cd /cluster/store11/gs.19/build36
    mv nib nib.raw
    mv bothMasksNib nib
    rm /gbdb/hg18/nib/*.nib
    ln -s `pwd`/nib/* /gbdb/hg18/nib

# Load /gbdb/hg18/nib paths into database and save size info.

    cd /cluster/data/hg18
    hgNibSeq -preMadeNib hg18 /gbdb/hg18/nib */chr*.fa
# 3107677273 total bases

#	Should be the same size as before
    hgsql -N -e "select chrom,size from chromInfo order by chrom" hg18 \
	> chrom.sizes.masked
    diff chrom.sizes chrom.sizes.masked
#	should be no output at all, thus:
    rm chrom.sizes.masked

# Copy the masked contig fa to /scratch and /iscratch
#	And everything else we will need for blastz runs, etc ...
#	Best to do this sequence first to /cluster/bluearc/scratch,
#	which is going to be the source for the /scratch copy.
#	And then from there to the /iscratch
#	Make sure you are on the fileserver for the original source:
    ssh kkstore02
    mkdir -p /cluster/bluearc/scratch/hg/gs.19/build36
    cd /cluster/bluearc/scratch/hg/gs.19/build36

#	these copies take less than 2 minutes each
    mkdir bothMaskedNibs
    cp -p /cluster/data/hg18/nib/*.nib ./bothMaskedNibs
    mkdir maskedContigs
    foreach chrom ( `cat /cluster/data/hg18/chrom.lst` )
	cp -p /cluster/data/hg18/${chrom}/N{C,G,T}_*/N{C,G,T}_??????.fa \
		./maskedContigs
	echo "done ${chrom}"
    end
#	make sure you have them all:
    ls maskedContigs | wc -l
#	378
    wc -l /cluster/data/hg18/contig.lst
#	378
    mkdir rmsk
    foreach chrom ( `cat /cluster/data/hg18/chrom.lst` )
	cp -p /cluster/data/hg18/${chrom}/*.out ./rmsk
	echo "done ${chrom}"
    end

#	Now, go to the destination for /iscratch and copy from the
#	bluearc
    ssh kkr1u00
    mkdir -p /iscratch/i/gs.19/build36
    cd /iscratch/i/gs.19/build36
#	This takes about 5 minutes
    rsync -arlv /cluster/bluearc/scratch/hg/gs.19/build36/ .
    
    bash
    time /cluster/bin/iSync
#	real    7m27.649s

# request rsync of /cluster/bluearc/scratch to the KiloKluster /scratch

# Ask sysadmin to bring up BLAT server.

# update central dbDb table to add the new blat server entry

    echo 'INSERT INTO blatServers (db, host, port, isTrans) \
                VALUES ("hg18", "blat19", "17778", "1"); \
          INSERT INTO blatServers (db, host, port, isTrans) \
                VALUES ("hg18", "blat19", "17779", "0");' \
    | hgsql -h genome-testdb hgcentraltest

# LOAD ctgPos table - Contig position track 
#	After fixing up hgCtgPos to accept the -chromLst argument, simply:
    cd /cluster/data/hg18
    hgCtgPos -chromLst=chrom.lst hg18 .

# PRODUCING GENSCAN PREDICTIONS (DONE - 2005-12-16 - Fan)
    
    ssh hgwdev
    mkdir /cluster/data/hg18/bed/genscan
    cd /cluster/data/hg18/bed/genscan
    cvs co hg3rdParty/genscanlinux

    ssh kkstore02
    cd /cluster/data/hg18/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequencable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    bash
    for f in `cat /cluster/data/hg18/contig.lst`
    do
      egrep '[ACGT]' /cluster/data/hg18/$f.masked > /dev/null
	if [ $? = 0 ]; then
	    echo /cluster/data/hg18/$f.masked >> genome.list
	fi
    done
    # exit your bash shell if you are [t]csh ...
    #	This egrep matched all the contigs in hg18.  I guess none of
    #	them are complete Ns* at this point.

    # Log into kki (not kk !).  kki is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kki
    cd /cluster/data/hg18/bed/genscan
    # Create template file, gsub, for gensub2.  For example (3-line file):
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/x86_64/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy
    gensub2 genome.list single gsub jobList
    para create jobList
    para try
    para check
    para push ... etc ...
# Completed: 377 of 378 jobs
# Crashed: 1 jobs
# CPU time in finished jobs:      78976s    1316.27m    21.94h    0.91d  0.003 y
# IO & Wait Time:                  4961s      82.68m     1.38h    0.06d  0.000 y
# Average job time:                 223s       3.71m     0.06h    0.00d
# Longest running job:                0s       0.00m     0.00h    0.00d
# Longest finished job:            3491s      58.18m     0.97h    0.04d
# Submission to last job:          7541s     125.68m     2.09h    0.09d

    #	Running the single failed job on kolossus with a smaller window:

ssh kkr7u00.kilokluster.ucsc.edu
/cluster/bin/x86_64/gsBig /cluster/data/hg18/5/NT_006576/NT_006576.fa.masked \
        gtf/NT_006576.fa.gtf -trans=pep/NT_006576.fa.pep \
        -subopt=subopt/NT_006576.fa.bed -exe=hg3rdParty/genscanlinux/genscan \
        -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2000000

    # If there were out-of-memory problems (run "para problems"), then 
    # re-run those jobs by hand but change the -window arg from 2400000
    # something lower.  In build33, this was 22/NT_011519
    #  In build34 there were NO failures !

    # Convert these to chromosome level files as so:     
    ssh kkstore02
    cd /cluster/data/hg18/bed/genscan
    $HOME/bin/i386/liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/N*.gtf
    $HOME/bin/i386/liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft \
	warn subopt/N*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/hg18/bed/genscan
    ldHgGene hg18 genscan genscan.gtf
# Reading genscan.gtf
# Read 43122 transcripts in 329799 lines in 1 files
# 43122 groups 49 seqs 1 sources 1 feature types
# 43122 gene predictions

    hgPepPred hg18 generic genscanPep genscan.pep
    #	Processing genscan.pep
    hgLoadBed hg18 genscanSubopt genscanSubopt.bed
    # Reading genscanSubopt.bed
    # Loaded 514065 elements of size 6
    #	Sorted
    #	Creating table definition for 
    #	Saving bed.tab
    #	Loading hg18

    # featureBits hg18 genscan
    # 56039161 bases of 2881515245 (1.945%) in intersection 
    #	featureBits hg17 genscan
    #	55323340 bases of 2866216770 (1.930%) in intersection
    #	featureBits hg16 genscan
    #	55333689 bases of 2865248791 (1.931%) in intersection

    #	featureBits hg18 genscanSubopt
    # 55685959 bases of 2881515245 (1.933%) in intersection 
    # featureBits hg17 genscanSubopt
    #	55986178 bases of 2866216770 (1.953%) in intersection
    #	featureBits hg16 genscanSubopt
    #	56082952 bases of 2865248791 (1.957%) in intersection

    #	Should be zero intersection with rmsk
    #	featureBits -chrom=chr1 hg18 genscan rmsk

# CREATE 2 BIT FILE (DONE 12/20/05, Fan)
   
   ssh kkstore02
   cd /cluster/data/hg18
   faToTwoBit */chr*.fa hg18.2bit
	  
# BLASTZ, CHAIN, NET, MAFNET, AXTNET AND ALIGNMENT DOWNLOADS FOR
# ZEBRAFISH (danRer3) (DONE, 2005-12-23, hartera)
    ssh pk
    # Blastz uses lineage-specific repeats. There are none for mouse
    # and fish so use all repeats for each species as lineage-specific.
    mkdir -p /san/sanvol1/scratch/hg18/linSpecRep.notInOthers
   foreach f (/cluster/bluearc/hg18/linSpecRep/notInOthers/chr*.out.spec)
     cp -p $f /san/sanvol1/scratch/hg18/linSpecRep.notInOthers/
   end

    # get only lineage specific repeats for chr1-25 and chrM
    mkdir -p /san/sanvol1/scratch/danRer3/linSpecRep.notInOthers
    foreach f (/cluster/data/danRer3/*/chr[0-9M]*.fa.out)
      cp -p $f \
          /san/sanvol1/scratch/danRer3/linSpecRep.notInOthers/$f:t:r:r.out.spec
    end
    # make a nib dir without random chroms
    mkdir -p /san/sanvol1/scratch/hg18/chromNib
    cp -p /cluster/data/hg18/nib/chr*.nib \
       /san/sanvol1/scratch/hg18/chromNib
    rm -r chr*_random.nib
    # make a nib dir that is also just chr1-25 and chrM
    mkdir -p /san/sanvol1/scratch/danRer3/chromNib
    cp /cluster/data/danRer3/nib/chr[0-9M]*.nib \
       /san/sanvol1/scratch/danRer3/chromNib
    
    ssh kkstore02
    mkdir /cluster/data/hg18/bed/blastz.danRer3.2005-12-17
    cd /cluster/data/hg18/bed
    ln -s blastz.danRer3.2005-12-17 blastz.danRer3
    # Three separate runs done to create chains. Runs 1 and 3 could be 
    # combined into one.
    # RUN 1: hg18 chroms (no randoms) vs danRer3 chr1-25 and chrM using 
    # lineage-specific repeats.
    ssh hgwdev
    cd /cluster/data/hg18/bed/blastz.danRer3
    # make run dir
    mkdir -p /san/sanvol1/scratch/hg18/blastzDanRer3/chromsRun
    ln -s /san/sanvol1/scratch/hg18/blastzDanRer3/chromsRun
    # make out dir
    mkdir -p /san/sanvol1/scratch/hg18/blastzDanRer3/chromsOut
    ln -s /san/sanvol1/scratch/hg18/blastzDanRer3/chromsOut
    cd chromsRun 
    # use parameters as for hg17 vs danRer2 - see makeHg17.doc
    cat << '_EOF_' > DEF
# human (hg18) vs zebrafish (danRer3)
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz.v7.x86_64

# Reuse parameters from hg16-fr1, danRer-hg17 and mm5-danRer
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human (hg18)
SEQ1_DIR=/san/sanvol1/scratch/hg18/chromNib
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/san/sanvol1/scratch/hg18/linSpecRep.notInOthers
SEQ1_LIMIT=30
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Zebrafish (danRer3)
# just chroms 1-25 and chrM
SEQ2_DIR=/san/sanvol1/scratch/danRer3/chromNib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/san/sanvol1/scratch/danRer3/linSpecRep.notInOthers
SEQ2_LIMIT=30
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/san/sanvol1/scratch/hg18/blastzDanRer3/chromsRun

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1chroms.len
SEQ2_LEN=$BASE/S2chroms.len
TMPDIR=/scratch/tmp
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod +x DEF

    grep -v random /cluster/data/hg18/chrom.sizes > S1chroms.len
    grep -v chrUn /cluster/data/danRer3/chrom.sizes \
            | grep -v chrNA > S2chroms.len
    # do blastz and create chains for danRer3 chr1-25 and chrM using 
    # all repeats as lineage-specific repeats. 
    # chickenHumanTuned.gap scoring matrix is now used by axtChain if the 
    # linearGap parameter is set to "loose".
    nohup nice /cluster/bin/scripts/doBlastzChainNet.pl \
       -bigClusterHub=pk \
       -smallClusterHub=pk \
       -workhorse=pk \
       -blastzOutRoot /san/sanvol1/scratch/hg18/blastzDanRer3/chromsOut \ 
       -chainMinScore=5000 \
       -chainLinearGap loose \
       -stop chainRun `pwd`/DEF >& doChains.log &
    # Took 2 hours 45 minutes to run.
    # Then run the human hg18 chroms and randoms vs danRer3 chrUn and chrNA
    ssh hgwdev
    # get file of scaffolds for hg18 randoms. Use the Table Browser to
    # select sequence from the whole genome for the ctgPos table of contigs
    # restricting to chrom like "%_random" in the Free-form query box of 
    # the filter. hg18RandomContigs.fa
    cd /cluster/data/hg18/bed/blastz.danRer3
    # get the position and contig name from the ctgPos table
    hgsql -N -e 'select chrom, chromStart, chromEnd, contig from ctgPos \
          where chromlike "%_random";' hg18 > contigPosAndNames.txt
    ssh kkstore02
    cd /cluster/data/hg18/bed/blastz.danRer3
    # change header to just the position
    perl -pi.bak -e 's/>.+range=(chr[0-9XY]+_random:[0-9]+\-[0-9]+).+/>$1/' \
         hg18RandomContigs.fa
awk '{print "perl -pi.bak -e s/"$1":"$2+1"-"$3"/"$4"/ hg18RandomContigs.fa"}' \ 
       contigPosAndNames.txt > addContigNames.csh
    chmod +x addContigNames.csh
    # run script
    addContigNames.csh 
    ssh hgwdev
    # make a 2 bit file of the chroms and random scaffolds
    cd /cluster/data/hg18
    set dir=/san/sanvol1/scratch/hg18
    faToTwoBit [1-9]/chr[1-9].fa [12][0-9]/chr[12][0-9].fa M/chrM.fa \
               X/chrX.fa Y/chrY.fa *hap[12]/chr*.fa \
               /cluster/data/hg18/bed/blastz.danRer3/hg18RandomContigs.fa \
               $dir/chromsAndRandoms.2bit    
    twoBitInfo $dir/chromsAndRandoms.2bit $dir/chromsAndRandoms.len
    # make a 2 bit file for just the random scaffolds
    faToTwoBit /cluster/data/hg18/bed/blastz.danRer3/hg18RandomContigs.fa \
               $dir/randoms.2bit    
    twoBitInfo $dir/randoms.2bit $dir/randoms.len
    # make sure all the random chroms contigs are included - should be 88.
    # make a 2 bit file for all the chroms and random chroms, make sure to 
    # get the haplotype chrom sequences.
    faToTwoBit [1-9MXY]/chr*.fa [12][0-9]/chr*.fa *hap[12]/chr*.fa \
               $dir/hg18.2bit
    twoBitInfo $dir/hg18.2bit $dir/hg18Chroms.len
    twoBitInfo /san/sanvol1/scratch/danRer3/danRer3.2bit \
               /san/sanvol1/danRer3/danRer3Chroms.len
    # make file of scaffolds lengths for NA and Un scaffolds
    twoBitInfo \
       /san/sanvol1/scratch/danRer3/scaffoldsNAandUn/danRer3NAandUnScaf.2bit \
       /san/sanvol1/scratch/danRer3/scaffoldsNAandUn/NAandUnScafs.len
    cd /cluster/data/hg18/bed/blastz.danRer3
    # make a lift file for the hg18 randoms contigs
    cat /cluster/data/hg18/*/lift/random.lft >> $dir/randomContigs.lft
    # RUN 2: hg18 chroms and random chroms contigs vs danRer3 chrNA and 
    # chrUn scaffolds with no lineage-specific repeats as there are too 
    # many scaffolds in chrNA and chrUn. Use the dynamic masking function 
    # of Blastz instead.
    # make run dir
    mkdir -p /san/sanvol1/scratch/hg18/blastzDanRer3/chromsAndRandomsRun
    ln -s /san/sanvol1/scratch/hg18/blastzDanRer3/chromsAndRandomsRun
    # make out dir
    mkdir -p /san/sanvol1/scratch/hg18/blastzDanRer3/chromsAndRandomsOut
    ln -s /san/sanvol1/scratch/hg18/blastzDanRer3/chromsAndRandomsOut
    cd chromsAndRandomsRun 
    # use parameters similar to hg17 vs danRer2 - see makeHg17.doc
    # As lineage-specific repeats can not be used with chrUn and chrNA
    # scaffolds, then use dynamic masking, M=50.
    cat << '_EOF_' > DEF
# human (hg18) vs zebrafish (danRer3)
# human chroms and random chrom contigs vs zebrafish chrNA and chrUn scaffolds
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz.v7.x86_64

# Reuse some parameters from hg16-fr1, danRer-hg17 and mm5-danRer
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_M=50
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=0

# TARGET: Human (hg18)
SEQ1_DIR=/san/sanvol1/scratch/hg18/hg18.2bit
SEQ1_CTGDIR=/san/sanvol1/scratch/hg18/chromsAndRandoms.2bit
SEQ1_LIFT=/san/sanvol1/scratch/hg18/randomContigs.lft
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=
SEQ1_LIMIT=30
SEQ1_IN_CONTIGS=0
# 500 kb target with 5 kb overlap
SEQ1_CHUNK=500000
SEQ1_LAP=5000

# QUERY: Zebrafish (danRer3)
# just scaffolds for chrUn and chrNA
SEQ2_DIR=/san/sanvol1/scratch/danRer3/danRer3.2bit
SEQ2_CTGDIR=/san/sanvol1/scratch/danRer3/scaffoldsNAandUn/danRer3NAandUnScaf.2bit
SEQ2_LIFT=/san/sanvol1/scratch/danRer3/liftNAandUnScaffoldsToChrom.lft
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=1000000000
SEQ2_LAP=0

BASE=/san/sanvol1/scratch/hg18/blastzDanRer3/chromsAndRandomsRun

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=/san/sanvol1/scratch/hg18/hg18Chroms.len
SEQ1_CTGLEN=/san/sanvol1/scratch/hg18/chromsAndRandoms.len
SEQ2_LEN=/san/sanvol1/scratch/danRer3/danRer3Chroms.len
SEQ2_CTGLEN=/san/sanvol1/scratch/danRer3/scaffoldsNAandUn/NAandUnScafs.len
TMPDIR=/scratch/tmp
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod +x DEF

    # do blastz and create chains for human chroms and random chroms in contigs
    # vs zebrafish danRer3 chrNA and chrUn in scaffolds without
    # lineage-specific repeats but using blastz's dynamic masking.
    # chickenHumanTuned.gap scoring matrix is now used by axtChain if the 
    # linearGap parameter is set to "loose".
  nohup nice /cluster/bin/scripts/doBlastzChainNet.pl \       
   -bigClusterHub=pk \
   -smallClusterHub=pk \
   -workhorse=pk \
   -blastzOutRoot /san/sanvol1/scratch/hg18/blastzDanRer3/chromsAndRandomsOut \ 
   -chainMinScore=5000 \
   -chainLinearGap loose \
   -stop chainRun `pwd`/DEF >& doChains.log &
    # Took about 15 hours to finish.
    ssh hgwdev
    # Try running hg18 random chroms in contigs vs danRer3 chroms 1-25 and chrM
    # with lineage-specific repeats.
    # make directory of human contigs repeats to serve as lineage-specific 
    # repeats for the random chroms contigs. 
    mkdir -p /san/sanvol1/scratch/hg18/linSpecRepRandoms.notInOthers
    cd /cluster/data/hg18/bed/blastz.danRer3
    awk '{print $4}' contigPosAndNames.txt > contigNames.txt
    foreach c (`cat contigNames.txt`)
      foreach f (/cluster/data/hg18/*/${c}/${c}.fa.out)
      cp -p $f \
      /san/sanvol1/scratch/hg18/linSpecRepRandoms.notInOthers/$f:t:r:r.out.spec
      end
    end
    # RUN 3: hg18 random chroms contigs vs danRer3 chr1-25 and chrM using
    # lineage-specific repeats.
    # make run dir
    mkdir -p /san/sanvol1/scratch/hg18/blastzDanRer3/randomsRun 
    ln -s /san/sanvol1/scratch/hg18/blastzDanRer3/randomsRun 
    # make out dir
    mkdir -p /san/sanvol1/scratch/hg18/blastzDanRer3/randomsOut 
    ln -s /san/sanvol1/scratch/hg18/blastzDanRer3/randomsOut 
    set dir=/san/sanvol1/scratch
    cp $dir/hg18/blastzDanRer3/chromsRun/S2chroms.len \
       $dir/danRer3/chr1to25andM.len
    # make nib dir for random contigs for hg18
    mkdir -p $dir/hg18/randomContigsNib
    foreach c (`cat contigNames.txt`)
      foreach f (/cluster/data/hg18/*/${c}/${c}.fa)
      faToNib -softMask $f $dir/hg18/randomContigsNib/$f:t:r.nib
      end
    end
    cd randomsRun
    cat << '_EOF_' > DEF
# human (hg18) vs zebrafish (danRer3)
# human random chrom contigs vs zebrafish chr1-15 and chrM
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz.v7.x86_64

# Reuse parameters from hg16-fr1, danRer-hg17 and mm5-danRer
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human (hg18)
SEQ1_DIR=/san/sanvol1/scratch/hg18/hg18.2bit
SEQ1_CTGDIR=/san/sanvol1/scratch/hg18/randomContigsNib
SEQ1_LIFT=/san/sanvol1/scratch/hg18/randomContigs.lft
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/san/sanvol1/scratch/hg18/linSpecRepRandoms.notInOthers
SEQ1_LIMIT=30
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Zebrafish (danRer3)
# just chr1-25 and chrM
SEQ2_DIR=/san/sanvol1/scratch/danRer3/chromNib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_LIMIT=30
SEQ2_SMSK=/san/sanvol1/scratch/danRer3/linSpecRep.notInOthers
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/san/sanvol1/scratch/hg18/blastzDanRer3/randomsRun

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=/san/sanvol1/scratch/hg18/hg18Chroms.len
SEQ1_CTGLEN=/san/sanvol1/scratch/hg18/randoms.len
SEQ2_LEN=/san/sanvol1/scratch/danRer3/chr1to25andM.len
TMPDIR=/scratch/tmp
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod +x DEF

    # do blastz and create chains for human random chroms in contigs
    # vs zebrafish danRer3 chroms 1 to 25 and chrM using all repeats
    # as lineage-specific repeats. 
    # chickenHumanTuned.gap scoring matrix is now used by axtChain if the 
    # linearGap parameter is set to "loose".
  nohup nice /cluster/bin/scripts/doBlastzChainNet.pl \       
   -bigClusterHub=pk \
   -smallClusterHub=pk \
   -workhorse=pk \
   -blastzOutRoot /san/sanvol1/scratch/hg18/blastzDanRer3/randomsOut \ 
   -chainMinScore=5000 \
   -chainLinearGap loose \
   -stop chainRun `pwd`/DEF >& doChains.log &
   # Took 15 minutes.
   # chains are sorted by score so move into one directory and use
   # chainMergeSort
   ssh kolossus
   set blastzDir=/cluster/data/hg18/bed/blastz.danRer3
   cd $blastzDir/chromsRun/axtChain
   mkdir -p chainsNotMerged
   foreach r (chromsRun chromsAndRandomsRun randomsRun)
     nice cp -p ${blastzDir}/${r}/axtChain/run/chain/*.chain \
          ${blastzDir}/chromsRun/axtChain/chainsNotMerged/
   end
   nice chainMergeSort ./chainsNotMerged/*.chain | nice gzip -c \
        > hg18.danRer3.all.chain.gz
   # split into chains by chrom 
   nice zcat hg18.danRer3.all.chain.gz | chainSplit chain stdin
   # check chains, there are 48 should be 49. Chains for chr11_random
   # are missing. These sequences have a lot of repeats in the regions that
   # hits danRer3 with BLAT.
   # carry on with doBlastzChainNet.pl starting from net step
   ssh hgwdev
   cd /cluster/data/hg18/bed/blastz.danRer3/chromsRun
   mv DEF DEF.chroms
   # edit DEF to give hg18.2bit as the SEQ1_DIR and danRer3.2bit as SEQ2_DIR 
   # and remove lineage-specfic repeats.
   nohup nice /cluster/bin/scripts/doBlastzChainNet.pl \       
   -bigClusterHub=pk \
   -smallClusterHub=pk \
   -workhorse=pk \
   -blastzOutRoot /san/sanvol1/scratch/hg18/blastzDanRer3/chromsOut \
   -chainMinScore=5000 \
   -chainLinearGap loose \
   -continue net `pwd`/DEF >& doNetAndDownloads.log &
   # Took about 25 minutes.
   # crashed on ssh -X sanhead1 for cleanup so re-run script
   cleanUp.csh
   # copy chainDanRer3.html and netDanRer3.html to 
   # kent/src/hg/makeDb/trackDb/human/hg18/ and edit to describe method used.
   # Add tracks to trackDb.ra there. Edit README.txt in the downloads 
   # directory to describe method used for alignments.
# featureBits -chrom=chr1 hg18 refGene:cds chainDanRer3Link -enrichment
# refGene:cds 1.378%, chainDanRer3Link 2.601%, both 0.927%, cover 67.26%,
# enrich 25.86x 
# featureBits -chrom=chr1 hg17 refGene:cds chainDanRer2Link -enrichment
# refGene:cds 1.386%, chainDanRer3Link 2.742%, both 0.909%, cover 65.58%,
# enrich 23.91x 
# So similar coverage and enrichment to hg17 vs danRer2 chains.

#########################################################################
# BLASTZ MOUSE Mm7 second time (DONE - 2005-12-24 - 2005-12-25 Fan)
    #	After fixing a bug in the lineage specific repeat snip business
    #	in blastz-run-ucsc script
    ssh pk
    mkdir /cluster/data/hg18/bed/blastzMm7.2005-12-24
    cd /cluster/data/hg18/bed
    rm blastz.mm7
    ln -s blastzMm7.2005-12-24 blastz.mm7
    cd blastzMm7.2005-12-24

    cat << '_EOF_' > DEF
# human vs mouse
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_SMSK=/scratch/hg/hg18/linSpecRep/notInMouse
SEQ1_CHUNK=10000000
SEQ1_LAP=10000
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes

# QUERY: Mouse Mm7 - single chunk big enough to run entire genome
SEQ2_DIR=/scratch/hg/mm7/nib
SEQ2_SMSK=/scratch/hg/mm7/linSpecRep/notInHumanDogCow
SEQ2_LEN=/cluster/bluearc/mm7/chrom.sizes
SEQ2_CHUNK=3000000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzMm7.2005-12-24
TMPDIR=/scratch/tmp
'_EOF_'
    # << happy emacs

    #	establish a screen to control this job
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-stop=load \
	`pwd`/DEF > to-load.out 2>&1 &
    #	Started 2005-12-24 06:15

    mv to-load.out to-load.out.1

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
    -continue=chainMerge -stop=load \
    `pwd`/DEF > to-load.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-swap -stop=load \
	`pwd`/DEF > swap-load.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
    -continue=download \
    `pwd`/DEF > download.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
    -swap -continue=download \
    `pwd`/DEF > swap-download.out 2>&1 &

# PLEASE NOTE THAT SOME .OUT FILES MIGHT HAVE BEEN OVERWRITTEN
# DUE TO RETRIES AND/OR NEXT STEP COMMAND NOT FULLY EDITED CORRECTLY. 

    #	Measurements:

    ssh hgwdev

    featureBits mm7 chainHg18Link 
    # 990285408 bases of 2583394090 (38.333%) in intersection

    featureBits hg18 chainMm7Link 
    # 991769039 bases of 2881515245 (34.418%) in intersection

    # each of above took about half hour.

#########################################################################
# BLASTZ CHICKEN GalGal2 second time (DONE - 2005-12-28 Fan)

    ssh pk
    mkdir /cluster/data/hg18/bed/blastzGalGal2.2005-12-28
    cd /cluster/data/hg18/bed
    rm blastz.galGal2
    ln -s blastzGalGal2.2005-12-28 blastz.galGal2
    cd blastzGalGal2.2005-12-28

    cat << '_EOF_' > DEF
# human vs chicken
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64

# Specific settings for chicken (per Webb email to Brian Raney)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=10000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_SMSK=/cluster/bluearc/hg18/linSpecRep/notInOthers
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_IN_CONTIGS=0 
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Chicken GalGal2 - single chunk big enough to run entire genome
SEQ2_DIR=/scratch/hg/galGal2/nib
SEQ2_LEN=/cluster/bluearc/galGal2/chrom.sizes
SEQ2_SMSK=/scratch/hg/galGal2/linSpecRep
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=200000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzGalGal2.2005-12-28
TMPDIR=/scratch/tmp
'_EOF_'
    # << happy emacs

    #	establish a screen to control this job
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
	-stop=load \
	`pwd`/DEF > load.out 2>&1 &
    #	Started 2005-12-28 10:35

    # Two jobs stuck in the same node.  Did manual para stop and para push.  
    # Both finished within a few minutes.

    # Done! On Wed Dec 28 15:32:45 PST 2005.

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
	-swap -stop=load \
	`pwd`/DEF > swap-load.out 2>&1 &

    # Had an error at the net step

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
      -swap -continue=net -stop=load \
	`pwd`/DEF > swap-load.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
    -continue=download \
    `pwd`/DEF > download.out 2>&1 &

    # the gzip job on kolossus seems not moving at all.
    # killed it manually.  Try again.

    # Seemed not moving, kill it again.  Now use pk instead of kolossus.

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -workhorse=pk \
    -bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
    -continue=download \
    `pwd`/DEF > download.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -workhorse=pk \
    -bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
    -swap -continue=download \
    `pwd`/DEF > swap-download.out 2>&1 &

    # Done! Wed Dec 28 20:39:44 PST 2005

    #	Measurements:

    ssh hgwdev

    nice featureBits galGal2 chainHg18Link 
    # 91564024 bases of 1054197620 (8.686%) in intersection
    nice featureBits hg18 chainGalGal2Link 
    # 102417858 bases of 2881515245 (3.554%) in intersection

    nice featureBits galGal2 chainHg17Link 
    # 93277286 bases of 1054197620 (8.848%) in intersection
    nice featureBits hg17 chainGalGal2Link 
    # 103882699 bases of 2866216770 (3.624%) in intersection

#########################################################################
# BLASTZ DOG CanFam2 time (DONE - 2005-12-28 - 2005-12-29 Fan)

    ssh pk
    mkdir /cluster/data/hg18/bed/blastzCanFam2.2005-12-28
    cd /cluster/data/hg18/bed
    rm blastz.canFam2
    ln -s blastzCanFam2.2005-12-28 blastz.canFam2
    cd blastzCanFam2.2005-12-28

    cat << '_EOF_' > DEF
# human vs dog
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64

# Specific settings for dog (per Webb email to Brian Raney)
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Human Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_SMSK=/cluster/bluearc/hg18/linSpecRep/notInOthers
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_IN_CONTIGS=0 
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Dog CanFam2 - single chunk big enough to run entire genome
SEQ2_DIR=/scratch/hg/canFam2/nib
SEQ2_LEN=/cluster/bluearc/canFam2/chrom.sizes
SEQ2_SMSK=/san/sanvol1/scratch/canFam2/linSpecRep.notInHuman
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=200000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzCanFam2.2005-12-28
TMPDIR=/scratch/tmp
'_EOF_'
    # << happy emacs

    #	establish a screen to control this job
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-stop=load \
	`pwd`/DEF > load.out 2>&1 &
    #	Started 2005-12-28 21:33

    # Two jobs stuck in the same node.  Did manual para stop and para push.  
    # Both finished within a few minutes.

    # Done! On Thu Dec 29 05:27:31 PST 2005.

    # system seems hang on kolossus (3 processes of [tcsh -c nice chainMergeSort], not moving)
    # manually killed the jobs.
    # now use pk as the workhorse.

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
      -workhorse=pk \
      -continue=chainMerge \
	-stop=load \
	`pwd`/DEF > load2.out 2>&1 &

    # Done! Thu Dec 29 09:10:02 PST 2005.

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-workhorse=pk \
      -swap -stop=load \
	`pwd`/DEF > swap-load.out 2>&1 &

    # Had an error at the load step,
    # mySQL error 2013: Lost connection to MySQL server during query,
    # probably due to sys admin working on network connections,
    # continue at the load step

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
      -workhorse=pk \
      -swap -continue=load -stop=load \
	`pwd`/DEF > swap-load2.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
    -workhorse=pk \
    -continue=download \
    `pwd`/DEF > download.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
    -workhorse=pk \
    -bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
    -swap -continue=download \
    `pwd`/DEF > swap-download.out 2>&1 &

    # Done! Dec 29 13:21

    #	Measurements:

    ssh hgwdev
nice featureBits canFam2 chainHg18Link 
# 1477551526 bases of 2384996543 (61.952%) in intersection
nice featureBits hg18 chainCanFam2Link 
# 1524764349 bases of 2881515245 (52.915%) in intersection
nice featureBits canFam2 chainHg17Link 
# 1487483112 bases of 2384996543 (62.368%) in intersection
nice featureBits hg17 chainCanFam2Link 
# 1530197469 bases of 2866216770 (53.387%) in intersection

# ENABLE GENBANK UPDATE (1/3/06 Fan)

# add hg18 to the following two files and check them in.

     src/hg/makeDb/genbank/etc/align.dbs
     src/hg/makeDb/genbank/etc/hgwdev.dbs

# then go to /cluster/data/genbank/etc and do cvs update on these two files.

#########################################################################
# BLASTZ RAT Rn3 (STARTED - 2005-12-22, DONE 2006-01-05 Fan)

    ssh pk
    mkdir /cluster/data/hg18/bed/blastzRn3.2005-12-22
    cd /cluster/data/hg18/bed
    rm blastz.rn3
    ln -s blastzRn3.2005-12-22 blastz.rn3
    cd blastzRn3.2005-12-22

    cat << '_EOF_' > DEF
# human vs rat
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64

BLASTZ_ABRIDGE_REPEATS=1
    
# TARGET: Muman Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_SMSK=/scratch/hg/hg18/linSpecRep/notInRat
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Rat Rn3 - chunk big enough to do all chroms in single whole
pieces
SEQ2_DIR=/scratch/rat/rn3/softNib
SEQ2_SMSK=/cluster/bluearc/rat/rn3/linSpecRep.notInHuman
SEQ2_LEN=/cluster/bluearc/rat/rn3/chrom.sizes
SEQ2_CHUNK=300000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzRn3.2005-12-22
TMPDIR=/scratch/tmp
'_EOF_'
    # happy emacs

    #	establish a screen to control this job
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-stop=load \
	`pwd`/DEF > to-load.out 2>&1 &

# start processing again on 12/31/05.

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-workhorse=pk \
      -swap \
      -stop=load \
	`pwd`/DEF > swap.out 2>&1 &

# Either UCSC RR and hgwdev systems or network went down around 11 AM 12/31/05.

# After holidays, start again on 1/3/06 and again on 1/5/06.

    ssh pk
    cd /cluster/data/hg18/bed
    cd blastzRn3.2005-12-22
    screen
    bash

      time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
	-workhorse=pk \
      -swap \
      -continue=net \
      -stop=load \
	`pwd`/DEF > swap6.out 2>&1 &

# DONE! Jan  5 13:39

# Measurements:
nice featureBits rn3 chainHg18Link 
# 962630574 bases of 2571104688 (37.440%) in intersection
nice featureBits hg18 chainRn3Link 
# 964251210 bases of 2881515245 (33.463%) in intersection

#########################################################################
# BLASTZ FUGU fr1 (STARTED - 2005-12-20, DONE 2006-01-05 Fan)
    ssh pk
    mkdir /cluster/data/hg18/bed/blastzFr1.2005-12-20
    cd /cluster/data/hg18/bed
    ln -s blastzFr1.2005-12-20 blastz.fr1
    cd blastzFr1.2005-12-20

    cat << '_EOF_' > DEF
# human vs. fugu
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64

# Reuse parameters from human-chicken, except L=6000 (more relaxed)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q

# TARGET: Human Hg18 - testing 100,000,000 sized chunk on pk kluster
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_CHUNK=100000000
SEQ1_LAP=10000

# QUERY: Fugu Fr1 - chunk big enough to run the whole chrom at once
SEQ2_DIR=/san/sanvol1/scratch/fr1/nib
SEQ2_LEN=/san/sanvol1/scratch/fr1/chrom.sizes
SEQ2_CHUNK=400000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzFr1.2005-12-20
'_EOF_'
    # << happy emacs

    #	establish a screen to control this job
    ssh pk
    cd /cluster/data/hg18/bed/blastzFr1.2005-12-20
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -stop=load \
	`pwd`/DEF > thruLoad.out 2>&1 &

    ssh pk
    cd /cluster/data/hg18/bed/blastzFr1.2005-12-20
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -continue=chainMerge -stop=load \
	`pwd`/DEF > thruLoad.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -continue=download \
	`pwd`/DEF > download.clean.out 2>&1 &

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -swap \
	`pwd`/DEF > swap.out 2>&1 &

# Finish the remaining step, 1/4/05.

    ssh pk
    cd /cluster/data/hg18/bed/blastzFr1.2005-12-20
    screen
    bash

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 \
	-swap -continue=download \
	`pwd`/DEF > DownloadSwap.out 2>&1 &

# First try found the DEF was some how altered for rn3.
# Re-generated DEF and try again.

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 \
	-swap -continue=download \
	`pwd`/DEF > DownloadSwap2.out 2>&1 &

# Done.  Jan  4 09:48.

# measurements

nice featureBits hg18 chainFr1Link
# 51795958 bases of 2881515245 (1.798%) in intersection
nice featureBits hg17 chainFr1Link
#50831650 bases of 2866216770 (1.773%) in intersection

nice featureBits hg18 netFr1
# 691148929 bases of 2881515245 (23.986%) in intersection
nice featureBits hg17 netFr1
# 714234935 bases of 2866216770 (24.919%) in intersection

nice featureBits fr1 chainHg18Link
# 43267869 bases of 315518167 (13.713%) in intersection
# nice featureBits fr1 chainHg17Link
0 bases of 315518167 (0.000%) in intersection
nice featureBits fr1 netHg18
# 140843080 bases of 315518167 (44.639%) in intersection
nice featureBits fr1 netHg17
# 0 bases of 315518167 (0.000%) in intersection

# BLASTZ TETRAODON TetNig1 second time (DONE - 2006-01-07 Fan)

ssh pk
mkdir /cluster/data/hg18/bed/blastzTetNig1.2006-01-07
cd /cluster/data/hg18/bed
rm blastz.tetNig1
ln -s blastzTetNig1.2006-01-07 blastz.tetNig1
cd blastzTetNig1.2006-01-07

    cat << '_EOF_' > DEF
# human vs tetraodon
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64

BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q

# TARGET: Human Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Tetraodon TetNig1 - single chunk big enough to run entire genome
SEQ2_DIR=/san/sanvol1/scratch/tetNig1/tetNig1.2bit
SEQ2_LEN=/san/sanvol1/scratch/tetNig1/chrom.sizes
SEQ2_CHUNK=410000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzTetNig1.2006-01-07
TMPDIR=/scratch/tmp
'_EOF_'
    # << happy emacs

# establish a screen to control this job
screen
bash
time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-stop=load \
`pwd`/DEF > load.out 2>&1 &
# Started Sat Jan  7 05:40:51 PST 2006

# Encountered an error:
startStep: 0, at step 5 net to stopStep 6
netChains: looks like previous stage was not successful (can't find [hg18.tetNig1.]all.chain[.gz]).

# Try it with pk as the workhorse.
time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-workhorse=pk \
-continue=net \
-stop=load \
`pwd`/DEF > load2.out 2>&1 &

# Load done.  Sat Jan  7 07:34:56 PST 2006

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-workhorse=pk \
-swap -stop=load \
`pwd`/DEF > swap-load.out 2>&1 &

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-workhorse=pk \
-continue=download \
 `pwd`/DEF > download.out 2>&1 &

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-workhorse=pk \
-swap -continue=download \
`pwd`/DEF > swap-download.out 2>&1 &

# Done! Sat Jan  7 08:02:14 PST 2006
# The download and swap-download took less than 10 seconds each.  ???

# Measurements:

ssh hgwdev
nice featureBits tetNig1 chainHg18Link 
# 50026847 bases of 342403326 (14.611%) in intersection
nice featureBits hg18 chainTetNig1Link 
# 57654754 bases of 2881515245 (2.001%) in intersection

nice featureBits tetNig1 chainHg17Link 
# 34379509 bases of 342403326 (10.041%) in intersection
nice featureBits hg17 chainTetNig1Link 
# 35910128 bases of 2866216770 (1.253%) in intersection

# BLASTZ FROG XenTro1 second time (STARTED - 2006-01-06 Fan)

    ssh pk
    mkdir /cluster/data/hg18/bed/blastzXenTro1.2006-01-06
    cd /cluster/data/hg18/bed
    rm blastz.xenTro1
    ln -s blastzXenTro1.2006-01-06 blastz.xenTro1
    cd blastzXenTro1.2006-01-06

    cat << '_EOF_' > DEF
# human vs frog
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64

BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=8000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q

# TARGET: Human Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_CHUNK=20000000
SEQ1_LAP=10000

# QUERY: Frog XenTro1 - single chunk big enough to run entire genome
SEQ2_DIR=/scratch/hg/xenTro1/xenTro1.2bit
SEQ2_LEN=/scratch/hg/xenTro1/chrom.sizes
SEQ2_LIMIT=400
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzXenTro1.2006-01-06
TMPDIR=/scratch/tmp
'_EOF_'
    # << happy emacs

    #	establish a screen to control this job
    screen
    bash
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
      -stop=load \
	`pwd`/DEF > load.out 2>&1 &
# Started Fri Jan  6 20:19:30 PST 2006
# Blastz run done.  Jan  7 02:07 load.out

    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
	-swap -stop=load \
	`pwd`/DEF > swap-load.out 2>&1 &

# got the following error:

startStep: 4, at step 5 net to stopStep 6
netChains: looks like previous stage was not successful (can't find [xenTro1.hg18.]all.chain[.gz]).

# Try it with pk instead of kolossus:

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-workhorse=pk \
-swap -stop=load \
`pwd`/DEF > swap-load2.out 2>&1 &

# It worked, swap-load done. Jan  7 06:05

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-workhorse=pk \
-continue=download \
`pwd`/DEF > download.out 2>&1 &

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-workhorse=pk \
-bigClusterHub=pk -chainMinScore=5000 -chainLinearGap=loose \
-swap -continue=download \
`pwd`/DEF > swap-download.out 2>&1 &

# Done! Jan  7 06:18

# Measurements:

ssh hgwdev
nice featureBits xenTro1 chainHg18Link 
# 61197900 bases of 1381238994 (4.431%) in intersection
nice featureBits hg18 chainXenTro1Link 
# 67810866 bases of 2881515245 (2.353%) in intersection

nice featureBits xenTro1 chainHg17Link 
# 81777842 bases of 1381238994 (5.921%) in intersection
nice featureBits hg17 chainXenTro1Link 
# 85701475 bases of 2866216770 (2.990%) in intersection

############################################################################
# BLASTZ COW BosTau2 second time (STARTED - 2006-01-07, DONE 2006-01-08 Fan)

    ssh pk
    mkdir /cluster/data/hg18/bed/blastzBosTau2.2006-01-07
    cd /cluster/data/hg18/bed
    rm blastz.bosTau2
    ln -s blastzBosTau2.2006-01-07 blastz.bosTau2
    cd blastzBosTau2.2006-01-07

    cat << '_EOF_' > DEF
# human vs cow
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64
BLASTZ_M=50

# TARGET: Human Hg18
SEQ1_DIR=/scratch/hg/hg18/nib
SEQ1_LEN=/scratch/hg/hg18/chrom.sizes
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Cow BosTau2 - single chunk big enough to run entire genome
SEQ2_DIR=/san/sanvol1/scratch/bosTau2/bosTau2.2bit
SEQ2_LEN=/san/sanvol1/scratch/bosTau2/chrom.sizes
SEQ2_CHUNK=3200000000
SEQ2_LAP=0

BASE=/cluster/data/hg18/bed/blastzBosTau2.2006-01-07
TMPDIR=/scratch/tmp
'_EOF_'
    # << happy emacs

# establish a screen to control this job
screen
bash
time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
-stop=load \
-workhorse=pk \
`pwd`/DEF > load.out 2>&1 &

# Started Sat Jan  7 07:57:22 PST 2006
# blastz run (and load) done Jan  8 00:13

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
-swap -stop=load \
`pwd`/DEF > swap-load.out 2>&1 &

# took a long time to finish.

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
-continue=download \
`pwd`/DEF > download.out 2>&1 &

time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
-bigClusterHub=pk -chainMinScore=3000 -chainLinearGap=medium \
-swap -continue=download \
`pwd`/DEF > swap-download.out 2>&1 &

# Done! Jan  8 21:10

# Measurements:

ssh hgwdev
nice featureBits bosTau2 chainHg18Link 
# 1357027317 bases of 2812203870 (48.255%) in intersection
nice featureBits hg18 chainBosTau2Link 
# 1357291762 bases of 2881515245 (47.103%) in intersection
nice featureBits bosTau2 chainHg17Link 
# 0 bases of 2812203870 (0.000%) in intersection
nice featureBits hg17 chainBosTau2Link 
# 1350076765 bases of 2866216770 (47.103%) in intersection

#######################################################################
# MAKE 11.OOC FILE FOR BLAT (DONE - 2006-01-11 - Fan)
    ssh kkstore02
    cd /cluster/data/hg18

    blat hg18.2bit \
	 /dev/null /dev/null -tileSize=11 -makeOoc=11.ooc -repMatch=1024
# Wrote 30378 overused 11-mers to 11.ooc

# Copy over to the bluearc
   cp -p 11.ooc /cluster/bluearc/hg18
   
#######################################################################
# PLACE ASSEMBLY CLONES ON CONTIGS AND SEQUENCE (WORKING - 2006-01-12 - Hiram)
    ssh kkstore02
    mkdir /cluster/data/hg18/bed/coverage
    cd /cluster/data/hg18/bed/coverage
    #	find all the clones that were used in the assembly
    sed -e "/^#.*/d" ../../ncbi_build36.agp | \
        awk '{if (!match($5,"N")) {print $6}}' | \
        sort -u > placed_in_assembly.list
    wc -l placed_in_assembly.list
    #	27093 placed_in_assembly.list

    #	And all possible clones considered for assembly.
    #	The AADB clones are the Celera assembly, don't want them.
    sed -e "/^#.*/d" /cluster/store11/gs.19/ncbi/sequence.inf | \
	grep for_assembly | grep -v AADB | awk '{print $1}' | sort -u \
	    > allButOneClonesConsidered.list
    (grep AADB01066164.1 \
	/cluster/store11/gs.19/ncbi/sequence.inf | awk '{print $1}'; \
	cat allButOneClonesConsidered.list) | sort -u \
	    > allClonesConsidered.list
    #	The grep for AADB eliminates a single clone: AADB01066164.1
    #	Which actually should be in the list since it is in the
    #	ncbi_build36.agp file.  Back in Hg17, this was the only AADB
    #	clone in the sequence.inf file, now there are 400,673 of them in
    #	this Hg18 sequence.inf file marked "for_assembly"
    comm -12 allClonesConsidered.list \
	/cluster/data/hg17/bed/contig_overlaps/sequence.list \
	    > allClones.InHg17AndHg18.list
    comm -23 allClonesConsidered.list \
	/cluster/data/hg17/bed/contig_overlaps/sequence.list \
	    > allClones.InHg18NotHg17.list
    comm -13 allClonesConsidered.list \
	/cluster/data/hg17/bed/contig_overlaps/sequence.list \
	    > allClones.InHg17NotHg18.list

    #	how many are the same as previous build:
    comm -12 /cluster/data/hg17/bed/contig_overlaps/placed_in_assembly.list \
	placed_in_assembly.list > sameAsHg17.list
    wc sameAsHg17.list
    #	26775  26775 300641 sameAsHg17.list
    #	There is one clone: AADB01066164.1
    #	Which is listed in allClones.InHg17NotHg18.list
    #	But it is on the Hg18 placed_in_assembly.list
    #	And it is on the Hg17 placed_in_assembly.list but it isn't
    #	actually found in Hg17 ?  Perhaps it didn't align good enough.
    comm -23 /cluster/data/hg17/bed/contig_overlaps/placed_in_assembly.list \
	placed_in_assembly.list > uniqueToHg17.list
    wc uniqueToHg17.list
    #	97   97 1080 uniqueToHg17.list
    #	and unique to hg18, not in hg17:
    comm -13 /cluster/data/hg17/bed/contig_overlaps/placed_in_assembly.list \
	placed_in_assembly.list > newToHg18.list
    wc newToHg18.list
    #	318  318 3547 newToHg18.list
    #	make a list of these new contigs:
    #	using the previous perl scripts:
    cp -p /cluster/data/hg17/bed/contig_overlaps/*.pl .

    #	Now, we need to distribute the clone sequence files in a
    #	directory hierarchy by chrom name.  Using the contigAcc.pl file
    #	from the previous release:
    cp /cluster/data/hg17/bed/contig_overlaps/contigAcc.pl .
    #	This newer version is generalized a bit better to take command
    #	line arguments for the two files it is to read instead of having
    #	them explicitly in the code, then:
    ./contigAcc.pl /cluster/data/hg18/ncbi_build36.agp \
	/cluster/data/hg18/seq_contig.md > cloneToChrom.list 2>&1
    #	And now, since most of the clone sequence already exists in the
    #	Hg17 work directory, we only need to make symlinks to the
    #	existing ones, and move only the new ones.  The following script
    #	will find an existing copy and symlink it correctly.

    cat << '_EOF_' > createPlacedHierarchy.sh
#!/bin/sh

mkdir -p placedClones

sed -e "/^#.*/d" cloneToChrom.list | while read L
do
    CHROM=`echo "${L}" | awk '{print $1}'`
    CLONE=`echo "${L}" | awk '{print $2}'`
    if [ ! -d "placedClones/${CHROM}" ]; then
	mkdir placedClones/${CHROM}
    fi
    HG17_version="/cluster/data/hg17/bed/contig_overlaps/${CHROM}/${CLONE}"
    HG18_version_0="/cluster/data/hg18/bed/coverage/newToHg18/${CLONE}"	    
  HG18_version_1="/cluster/data/hg18/bed/coverage/allClones.newToHg18/${CLONE}"	    
    if [ -f "${HG17_version}" ]; then
	if [ -f "${HG18_version_0}" -o -f "${HG18_version_1}" ]; then
	  echo "ERROR: Why is there both an Hg17 and Hg18 version for ${CLONE}"
	  exit 255
	fi
	ln -s "/cluster/data/hg17/bed/contig_overlaps/${CHROM}/${CLONE}" \
		"./placedClones/${CHROM}/${CLONE}"
    else
	if [ -f "${HG18_version_0}" -a -f "${HG18_version_1}" ]; then
	    echo "ERROR: Why are there two Hg18 copies for ${CLONE}"
	    exit 255
	fi
	if [ -f "${HG18_version_0}" ]; then
	    ln -s "${HG18_version_0}" "./placedClones/${CHROM}/${CLONE}"
	else
	    if [ -f "${HG18_version_1}" ]; then
		ln -s "${HG18_version_1}" "./placedClones/${CHROM}/${CLONE}"
	    else
		# must be on a different chrom in hg17
		HG17_chrom=`grep -v "^#" \
	/cluster/data/hg17/bed/contig_overlaps/disburseEm.list \
	| grep "^${L}$" | awk '{print $1}'`
    HG17_version="/cluster/data/hg17/bed/contig_overlaps/${HG17_chrom}/${CLONE}"
		if [ -f "${HG17_version}" ]; then
		    echo "ERROR: Why is there no version for ${CLONE}"
		    exit 255
		fi
		ln -s "${HG17_version}" "./placedClones/${CHROM}/${CLONE}"
	    fi
	fi
    fi
done
'_EOF_'
    #	happy emacs
    chmod +x createPlacedHierarchy.sh
    ./createPlacedHierarchy.sh
    #	There should be no errors

    #	We need masked contigs for the psLayout alignments
    ssh hgwdev
    mkdir /cluster/data/hg18/bed/coverage/maskedContigs
    cd /cluster/data/hg18/bed/coverage/maskedContigs
    hgsql -N \
	-e "select chrom,chromStart,chromEnd,contig,size from ctgPos;" hg18 \
	> ctgPos.txt

    ssh kkstore02
    cd /cluster/data/hg18/bed/coverage/maskedContigs
    #	verify each contig only listed once:
    awk '{print $4}' ctgPos.txt | sort | uniq -c | sort -n | less
    #	should all have a count of one
    #	verify all chrom sizes match the contig sizes:
    awk '{print $3-$2}' ctgPos.txt > chrSize.list
    awk '{print $5}' ctgPos.txt > ctgSize.list
    diff ctgSize.list chrSize.list
    #	should be no difference
    #	OK, now fetch the contigs from the twoBit file:
    
    cat << '_EOF_' > 2bitToFa.pl
#!/usr/bin/env perl
use warnings;
use strict;
while (my $line=<>) {
chomp $line;
my ($chrom, $start, $end, $contig, $size) = split('\s',$line);
$chrom =~ s/chr//;
printf "echo -n 'working $contig ...'; mkdir -p $chrom; twoBitToFa /cluster/data/hg18/hg18.2bit:chr$chrom:$start-$end stdout | sed -e 's/^>.*/>$contig/' > $chrom/$contig.fa; gzip $chrom/$contig.fa; echo 'done'\n";
}
'_EOF_'
    # happy emacs
    chmod +x 2bitToFa.pl
    cat ctgPos.txt | ./2bitToFa.pl > 2bitToFa.sh
    chmod +x 2bitToFa.sh
    time ./2bitToFa.sh

    #	and create a lift file for these contigs
    cat << '_EOF_' > mkCtgLift.pl
#!/usr/bin/env perl
use warnings;
use strict;
while (my $line=<>)
{
chomp $line;
my ($start, $chrCtg, $size, $chrom, $chrLen) = split('\s',$line);
$chrCtg =~ s#.*/##;
printf "%s\t%s\t%s\t%s\t%s\n", $start, $chrCtg, $size, $chrom, $chrLen;
}
'_EOF_'
    #	happy emacs
    chmod +x mkCtgLift.pl
    cat /cluster/data/hg18/jkStuff/liftAll.lft \
	| ./mkCtgLift.pl > liftContigs.lft

    #	Create individual ooc files for each contig
    mkdir ooc
    for C in `ls */*.fa.gz | sed -e "s/.fa.gz//"`
    do
	CONTIG=`basename ${C}`
	CHR=`dirname ${C}`
	mkdir -p ooc/${CHR}
	zcat ${C}.fa.gz | blat -repMatch=256 \
	    -makeOoc=ooc/${CHR}/${CONTIG}.10.ooc -tileSize=10 \
	    stdin /dev/null /dev/null
	echo "done: ${CONTIG}"
    done

    #	Copy everything to san filesystem for kluster run:
    ssh pk
    mkdir /san/sanvol1/scratch/hg18/coverage
    cd /san/sanvol1/scratch/hg18/coverage
    rsync -a --progress --copy-links \
	/cluster/data/hg18/bed/coverage/placedClones/ ./placedClones/
    rsync -a --progress --copy-links \
	/cluster/data/hg18/bed/coverage/maskedContigs/ ./maskedContigs/

    mkdir /san/sanvol1/scratch/hg18/coverage/runPlaced
    cd /san/sanvol1/scratch/hg18/coverage/runPlaced

    cat << '_EOF_' > runPsLayout.sh
#!/bin/sh
#   runPsLayout.sh <chrom> <clone> <contig>
#     where <chrom> is the chrom this contig is on
#      <clone> is one of the .fa.gz files in
#	  /san/sanvol1/scratch/hg18/coverage/placedClones/<chrom>/<clone>.fa.gz
#      <contig> is one of the contigs found in:
#	/san/sanvol1/scratch/hg18/coverage/maskedContigs/<chrom>/<contig>.fa.gz
#
HERE=`pwd`
CHROM=$1
CLONE=$2
CONTIG=$3
TARGET=/san/sanvol1/scratch/hg18/coverage/maskedContigs/$CHROM/$CONTIG.fa.gz
CLONESRC=/san/sanvol1/scratch/hg18/coverage/placedClones/$CHROM/$CLONE.fa.gz
OOC=/san/sanvol1/scratch/hg18/coverage/maskedContigs/ooc/$CHROM/$CONTIG.10.ooc
RESULT="${HERE}/psl/${CHROM}/${CONTIG}/${CLONE}.psl"
mkdir -p psl/${CHROM}/${CONTIG}
if [ ! -s ${CLONESRC} ]; then
        echo "Can not find: ${CLONESRC}" 1>/dev/stderr
        exit 255
fi
if [ ! -s ${TARGET} ]; then
        echo "Can not find: ${TARGET}" 1>/dev/stderr
        exit 255
fi
if [ ! -s ${OOC} ]; then
        echo "Can not find: ${OOC}" 1>/dev/stderr
        exit 255
fi
WRKDIR="/scratch/tmp/hg18_${CHROM}/${CONTIG}/${CLONE}"
mkdir -p "${WRKDIR}"
cd ${WRKDIR}
zcat ${CLONESRC} > ${CLONE}.fa
zcat ${TARGET} > ${CONTIG}.fa
cp -p ${OOC} ./10.ooc
/cluster/bin/x86_64/psLayout ${CONTIG}.fa ${CLONE}.fa genomic 10.ooc ${RESULT}
RET=$?
cd ${HERE}
rm -fr ${WRKDIR}
rmdir --ignore-fail-on-non-empty "/scratch/tmp/hg18_${CHROM}/${CONTIG}"
rmdir --ignore-fail-on-non-empty "/scratch/tmp/hg18_${CHROM}"
exit ${RET}
'_EOF_'
    #	happy emacs
    chmod +x runPsLayout.sh

    #	create jobList from cloneToChrom.list:
    grep -v "^#" /cluster/data/hg18/bed/coverage/cloneToChrom.list \
	| sed -e "s/.fa.gz//" \
	| awk '{
printf "./runPsLayout.sh %s %s %s {check out line+ psl/%s/%s/%s.psl}\n",
        $1, $2, $3, $1, $3, $2
}' > masterJobList

    #	To do a quick test, run just chrM:
    grep " M " masterJobList > jobList
s
    para create jobList
    para try ... check ... etc ...


    #	Then, the whole run:
    rm -fr psl err
    para create masterJobList
    para try ... check ... push ... etc ...
    #	running 2006-01-17  16:41

###########################################################################
# FISH CLONES (WORKING - 2006-01-13 - Hiram)
# The STS Marker, Coverage, and BAC End Pairs tracks must be completed prior to 
# creating this track  (and why is this ?)

    ssh kkstore01
    mkdir /cluster/data/ncbi/fishClones/fishClones.2006-01/
    cd /cluster/data/ncbi/fishClones/fishClones.2006-01/

# Download information from NCBI
        # point browser at:
#   http://www.ncbi.nlm.nih.gov/genome/cyto/cytobac.cgi?CHR=all&VERBOSE=ctg
        # change "Show details on sequence-tag" to "yes"
        # change "Download or Display" to "Download table for UNIX"
        # press Submit - save as
# /cluster/data/ncbi/fishClones/fishClones.2006-01/hbrc.txt
    chmod 664 /cluster/data/ncbi/fishClones/fishClones.2006-01/hbrc.txt

# Get current clone/accession information
    wget --timestamping http://www.ncbi.nlm.nih.gov/genome/clone/DATA/clac.out

###########################################################################
#  BLASTZ SELF

    ssh pk
    mkdir /cluster/data/hg18/bed/blastzSelf.2006-01-17
    cd /cluster/data/hg18/bed/blastzSelf.2006-01-17

    cat << '_EOF_' > DEF
# human vs human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/x86_64:/cluster/home/angie/schwartzbin:/parasol/bin

BLASTZ=blastz.v7.x86_64
BLASTZ_M=400

# TARGET: Human Hg18
SEQ1_DIR=/san/sanvol1/scratch/hg18/selfNib
SEQ1_LEN=/san/sanvol1/scratch/hg18/self.sizes
SEQ1_CHUNK=10000000
SEQ1_LAP=10000
SEQ1_IN_CONTIGS=0

# QUERY: Human Hg18
SEQ2_DIR=/san/sanvol1/scratch/hg18/selfNib
SEQ2_LEN=/san/sanvol1/scratch/hg18/self.sizes
SEQ2_CHUNK=10000000
SEQ2_LAP=0
SEQ2_IN_CONTIGS=0

BASE=/cluster/data/hg18/bed/blastzSelf.2006-01-17
TMPDIR=/scratch/tmp
'_EOF_'
    #	happy emacs

    cd /cluster/data/hg18/bed/blastzSelf.2006-01-17
    time /cluster/bin/scripts/doBlastzChainNet.pl -verbose=2 \
	-chainMinScore=10000 -chainLinearGap=medium -bigClusterHub=pk \
	`pwd`/DEF > blastz.out 2>&1 &

