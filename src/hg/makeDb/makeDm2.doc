#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# Drosophila Melanogaster -- 
# 
# euchromatin (2L, 2R, 3L, 3R, 4, X):
# Berkeley Drosophila Genome Project (fruitfly.org) release 4 (Apr. 2004)
# http://www.fruitfly.org/annot/release4.html
#
# heterochromatin (2h, 3h, 4h, Xh, Yh, U):
# Drosophila Heterochromatin Genome Project (dhgp.org) release 3.2 
# (submitted to GenBank June 2004) 
# http://www.dhgp.org/index_release_notes.html
#
# Gene annotations:
# FlyBase (http://flybase.bio.indiana.edu/) last updated ???
#

# DOWNLOAD SEQUENCE (DONE 9/8/04 angie)
    ssh kksilo
    mkdir /cluster/store8/dm2
    ln -s /cluster/store8/dm2 /cluster/data/dm2
    cd /cluster/data/dm2
    wget ftp://ftp.fruitfly.org/pub/download/compressed/na_euchromatin_genomic_dmel_RELEASE4.FASTA.gz
    zcat na_euchromatin_genomic_dmel_RELEASE4.FASTA.gz \
    | faSplit byname stdin dummyArg
    # Follow FlyBase's lead on the chromosome names, but still use our 
    # "chr" prefix:
    foreach c (2L 2R 3L 3R 4 X)
      mkdir $c
      sed -e 's/^>arm_/>chr/' arm_$c.fa > $c/chr$c.fa
      echo arm_$c.fa size:
      faSize arm_$c.fa
      echo $c/chr$c.fa size:
      faSize $c/chr$c.fa
      echo comparison:
      faCmp arm_$c.fa $c/chr$c.fa
      echo ""
    end
    # heterochromatin sold separately... ftp://ftp.dhgp.org/pub/DHGP still 
    # has release 3.2 as its latest.  But that's June 2004... wtf, grab it:
    wget ftp://ftp.dhgp.org/pub/DHGP/Release3.2/FASTA/super-scaffolds/heterochromatin_super-scaffolds-genomic_dmel_RELEASE3.2.FASTA.tar.gz
    tar xvzf heterochromatin_super-scaffolds-genomic_dmel_RELEASE3.2.FASTA.tar.gz
    foreach c (2h 3h 4h Xh Yh U)
      mkdir $c
      perl -wpe 's/^>(\w+).*/>chr$1/' $c.FASTA > $c/chr$c.fa
      echo $c.FASTA size:
      faSize $c.FASTA
      echo $c/chr$c.fa size:
      faSize $c/chr$c.fa
      echo comparison:
      faCmp $c.FASTA $c/chr$c.fa
      echo ""
    end
    # Carefully review output of those commands, then:
    rm *.fa *.FASTA

    # put away the big download files
    mkdir downloads
    mv *.gz downloads/


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 9/9/04 angie)
    mkdir /cluster/data/dm2/M
    cd /cluster/data/dm2/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "drosophila melanogaster mitochondrion genome".  That shows the gi number:
    # 5835233
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=5835233&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Drosophila melanogaster mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# SPLIT CHROM FA INTO SMALLER CHUNKS BY GAPS (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    foreach c (?{,?})
      faSplit -minGapSize=100 -lift=$c/chr$c.lft \
        gap $c/chr$c.fa 2000000 $c/chr${c}_
    end
    foreach ctgFa (?{,?}/chr*_*.fa)
      set ctg = $ctgFa:r
      mkdir $ctg
      mv $ctgFa $ctg
    end


# CREATING DATABASE (DONE 9/9/04 angie)
    ssh hgwdev
    # Make sure there is at least 5 gig free for the database
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  535G  1.1T  33% /var/lib/mysql
    # Create the database.
    hgsql '' -e 'create database dm2'


# EXTRACT GAP INFORMATION FROM FASTA, LOAD GAP TRACK (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    # Do as Jim suggested back when we got dm1 sequence:
    # I think that we can probably just show all gaps as bridged
    # in the non-h chromosomes, and as unbridged in the h chromosomes
    # and leave it at that.

    # Extract gaps using scaffoldFaToAgp.  It's really meant for a different 
    # purpose, so clean up its output: remove the .lft and .agp, and remove 
    # the last line of .gap (extra gap added at end).  Also substitute in 
    # the correct chrom name in .gap.  
    foreach c (?{,?})
      set chr = chr$c
      pushd $c
      mv $chr.lft $chr.lft.bak
      scaffoldFaToAgp -minGapSize=100 $chr.fa
      rm $chr.{lft,agp}
      mv $chr.lft.bak $chr.lft
      set chrSize = `faSize $chr.fa | awk '{print $1;}'`
      set origLines = `cat $chr.gap | wc -l`
      awk '($2 != '$chrSize'+1) {print;}' $chr.gap \
      | sed -e "s/chrUn/$chr/" > $chr.gap2
      set newLines = `cat $chr.gap2 | wc -l`
      if ($newLines == ($origLines - 1)) then
        mv $chr.gap2 $chr.gap
      else
        echo "Error: $chr/$chr.gap2 has wrong number of lines."
      endif
      popd
    end
    # Call the gaps unbridged in chrU and chr*h:
    foreach c (U ?h)
      set chr = chr$c
      sed -e 's/yes/no/' $c/$chr.gap > $c/$chr.gap2
      mv $c/$chr.gap2 $c/$chr.gap
    end
    ssh hgwdev
    hgLoadGap dm2 /cluster/data/dm2


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 9/9/04 angie)
    # This used to hold scripts -- better to keep them inline in the .doc 
    # so they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/dm2/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/dm2/bed


# MAKE LIFTALL.LFT (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    cat ?{,?}/chr*.lft > jkStuff/liftAll.lft


# RUN REPEAT MASKER (DONE 9/9/04 angie)
    # Note: drosophila library ("drosophila.lib") is dated May 27 '03.
    # Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
    # RepeatMasker runs manageable on the cluster ==> results need lifting.

    # Split contigs into 500kb chunks:
    ssh kksilo
    cd /cluster/data/dm2
    foreach d ( */chr*_?{,?} )
      cd $d
      set contig = $d:t
      faSplit -minGapSize=100 -lift=$contig.lft -maxN=500000 \
        gap $contig.fa 500000 ${contig}_
      cd ../..
    end

    #- Make the run directory and job list:
    cd /cluster/data/dm2
    cat << '_EOF_' > jkStuff/RMDrosophila
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/dm2/$2
/bin/cp $2 /tmp/dm2/$2/
cd /tmp/dm2/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -s -spec drosophila $2
popd
/bin/cp /tmp/dm2/$2/$2.out ./
if (-e /tmp/dm2/$2/$2.tbl) /bin/cp /tmp/dm2/$2/$2.tbl ./
if (-e /tmp/dm2/$2/$2.cat) /bin/cp /tmp/dm2/$2/$2.cat ./
/bin/rm -fr /tmp/dm2/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/dm2/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/dm2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMDrosophila
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach d ( ?{,?}/chr*_?{,?} )
      set ctg = $d:t
      foreach f ( $d/${ctg}_?{,?}.fa )
        set f = $f:t
        echo /cluster/data/dm2/jkStuff/RMDrosophila \
             /cluster/data/dm2/$d $f /cluster/data/dm2/$d \
           '{'check out line+ /cluster/data/dm2/$d/$f.out'}' \
        >> RMRun/RMJobs
      end
    end

    # do the run
    ssh kk9
    cd /cluster/data/dm2/RMRun
    para create RMJobs
    para try, check, push, check,...
#Completed: 288 of 288 jobs
#Average job time:                3169s      52.82m     0.88h    0.04d
#Longest job:                     4752s      79.20m     1.32h    0.06d
#Submission to last job:         13769s     229.48m     3.82h    0.16d

    # Lift up the split-contig .out's to contig-level .out's
    ssh kksilo
    cd /cluster/data/dm2
    foreach d ( ?{,?}/chr*_?{,?} )
      cd $d
      set contig = $d:t
      liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
      cd ../..
    end

    # Lift up the contig-level .out's to chr-level
    foreach c (?{,?})
      cd $c
      if (-e chr$c.lft && ! -z chr$c.lft) then
        echo lifting $c
        /cluster/bin/i386/liftUp chr$c.fa.out chr$c.lft warn \
          `awk '{print $2"/"$2".fa.out";}' chr$c.lft` > /dev/null
      else
        echo Can\'t find $c/chr$c.lft \!
      endif
      cd ..
    end

    # Load the .out files into the database with:
    ssh hgwdev
    hgLoadOut dm2 /cluster/data/dm2/?{,?}/*.fa.out


# SIMPLE REPEATS (TRF) (DONE 9/9/04 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/simpleRepeat
    cd /cluster/data/dm2/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach f (/cluster/data/dm2/?{,?}/chr*_*/chr?{,?}_?{,?}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    tcsh jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/dm2/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load this into the database as so
    ssh hgwdev
    hgLoadBed dm2 simpleRepeat \
      /cluster/data/dm2/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql


# FILTER SIMPLE REPEATS (TRF) INTO MASK (DONE 9/9/04 angie)
    # make a filtered version # of the trf output: 
    # keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/dm2/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
        echo "filtering $f"
        awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/dm2
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed $c/chr$c.lft warn \
        `awk '{print "bed/simpleRepeat/trfMask/"$2".bed";}' $c/chr$c.lft`
    end


# MASK FA USING REPEATMASKER AND FILTERED TRF FILES (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    foreach c (?{,?})
      echo repeat- and trf-masking chr$c.fa
      /cluster/home/kent/bin/i386/maskOutFa -soft \
        $c/chr$c.fa $c/chr$c.fa.out $c/chr$c.fa
      /cluster/home/kent/bin/i386/maskOutFa -softAdd \
        $c/chr$c.fa bed/simpleRepeat/trfMaskChrom/chr$c.bed $c/chr$c.fa
    end
    foreach c (?{,?})
      echo repeat- and trf-masking contigs of chr$c
      foreach ctgFa ($c/chr*/chr${c}_?{,?}.fa)
        set trfMask=bed/simpleRepeat/trfMask/$ctgFa:t:r.bed
        /cluster/home/kent/bin/i386/maskOutFa -soft $ctgFa $ctgFa.out $ctgFa
        /cluster/home/kent/bin/i386/maskOutFa -softAdd $ctgFa $trfMask $ctgFa
      end
    end


# STORE SEQUENCE AND ASSEMBLY INFORMATION (DONE 9/9/04 angie)
    # Translate to nib
    ssh kksilo
    cd /cluster/data/dm2
    mkdir nib
    foreach c (?{,?})
      faToNib -softMask $c/chr$c.fa nib/chr$c.nib
    end

    # Make symbolic links from /gbdb/dm2/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/dm2/nib
    foreach f (/cluster/data/dm2/nib/chr*.nib)
      ln -s $f /gbdb/dm2/nib
    end

    # Load /gbdb/dm2/nib paths into database and save size info.
    hgsql dm2  < ~/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib dm2 /gbdb/dm2/nib /cluster/data/dm2/?{,?}/chr?{,?}.fa
    echo "select chrom,size from chromInfo" | hgsql -N dm2 \
      > /cluster/data/dm2/chrom.sizes


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 9/9/04 angie)
    # Copy all the data from the table "grp" 
    # in the existing database dm1 to the new database
    ssh hgwdev
    hgsql dm2 -e "create table grp (PRIMARY KEY(NAME)) select * from dm1.grp"


# MAKE GCPERCENT (DONE 9/9/04 angie)
     ssh hgwdev
     mkdir /cluster/data/dm2/bed/gcPercent
     cd /cluster/data/dm2/bed/gcPercent
     # create and load gcPercent table
     hgsql dm2  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent dm2 ../../nib


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR DROSOPHILA (DONE 9/9/04 angie)
    # Warning: must genome and organism fields must correspond
    # with defaultDb values
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome, scientificName, \
                htmlPath, hgNearOk, hgPbOk, sourceName) values \
        ("dm2", "Apr. 2004", "/gbdb/dm2/nib", "D. melanogaster", \
               "chr2L:825964-851061", 1, 55, "D. melanogaster", \
                "Drosophila melanogaster", "/gbdb/dm2/html/description.html", \
                0, 0, "BDGP v. 4 / DHGP v. 3.2");' \
      | hgsql -h genome-testdb hgcentraltest
#TODO -- not enough tracks to throw this switch yet!
    echo 'update defaultDb set name = "dm2" where genome = "D. melanogaster"' \
      | hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P

    # Edit that makefile to add dm2 to DBS and do
    make update

    # go public on genome-test
    cvs commit makefile
    make alpha

    # Add trackDb directories and description.html
    mkdir drosophila/dm2
    cvs add drosophila/dm2
    # Write ~/kent/src/hg/makeDb/trackDb/drosophila/dm2/description.html 
    # with a description of the assembly and some sample position queries.  
    chmod a+r drosophila/dm2/description.html
    # Check it in and copy (via "make alpha" in trackDb/) to 
    # /cluster/data/dm2/html/.  
    cvs add drosophila/dm2/description.html
    cvs commit drosophila/dm2
    mkdir -p /gbdb/dm2/html
    make alpha


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR DROSOPHILA (TODO 9/?/04 angie)
    ssh hgwdev
    # Get appropriate hostname and port numbers from cluster admins:
    echo 'insert into blatServers values("dm2", "blat?", ?, 1, 0); \
          insert into blatServers values("dm2", "blat?", ?, 0, 1);' \
      | hgsql -h genome-testdb hgcentraltest


# PUT NIBS ON ISCRATCH (DONE 9/9/04 angie)
    ssh kkr1u00
    mkdir /iscratch/i/dm2
    cd /iscratch/i/dm2
    cp -pR /cluster/data/dm2/nib .
    iSync
    # Added "contigs" (chunks) 9/16/04
    mkdir maskedContigs
    cp -p /cluster/data/dm2/*/chr*_*/chr?{,?}_?{,?}.fa maskedContigs
    iSync


# AUTO UPDATE GENBANK MRNA RUN  (IN PROGRESS 9/10/04 angie)
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .
    # See if /cluster/data/genbank/etc/genbank.conf has had any un-checked-in
    # edits, check them in if necessary:
    diff /cluster/data/genbank/etc/genbank.conf etc/genbank.conf

    # Edit etc/genbank.conf and add these lines:
# dm2 (D. melanogaster)
dm2.genome = /iscratch/i/dm2/nib/chr*.nib
dm2.lift = /cluster/data/dm2/jkStuff/liftAll.lft
dm2.genbank.mrna.xeno.load = yes
dm2.genbank.est.xeno.load = no
dm2.downloadDir = dm2

    cvs ci etc/genbank.conf

    # Install to /cluster/data/genbank:
    make install-server

    ssh kksilo
#TODO -- for some reason it found no refseqs on the first try... ???
    cd /cluster/data/genbank
    # This is an -initial run, refseq only:
    nice bin/gbAlignStep -srcDb=refseq -type=mrna -initial dm2 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -drop -initialLoad dm2
    featureBits dm2 refGene
    # Clean up:
    rm -rf work/initial.dm2

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -srcDb=genbank -type=mrna -initial dm2 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -drop -initialLoad dm2
    featureBits dm2 mrna
#23438015 bases of 131698467 (17.797%) in intersection
    featureBits dm2 xenoMrna
#6147777 bases of 131698467 (4.668%) in intersection
    # Clean up:
    rm -rf work/initial.dm2

    ssh eieio
    # -initial for ESTs:
    nice bin/gbAlignStep -srcDb=genbank -type=est -initial dm2 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep dm2
    featureBits dm2 intronEst
#12644283 bases of 131698467 (9.601%) in intersection
    featureBits dm2 est
#30993609 bases of 131698467 (23.534%) in intersection
    # Clean up:
    rm -rf work/initial.dm2


# PRODUCING FUGU FISH ALIGNMENTS  (TODO 9/10/04 angie)
    # Assumes masked NIBs have been prepared as above
    # and Fugu pieces are already on kluster /iscratch/i.
    # next machine
    ssh kk
    mkdir -p /cluster/data/dm2/bed/blatFugu
    cd /cluster/data/dm2/bed/blatFugu
    mkdir psl
    ls -1S /iscratch/i/fugu/*.fa > fugu.lst
    ls -1S /iscratch/i/dm2/nib/chr*.nib > fly.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -q=dnax -t=dnax -mask=lower {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 fly.lst fugu.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check
#Completed: 1408 of 1408 jobs
#Average job time:                 217s       3.61m     0.06h    0.00d
#Longest job:                     1431s      23.85m     0.40h    0.02d
#Submission to last job:          1433s      23.88m     0.40h    0.02d

    # When cluster run is done, sort alignments
    # append _blatFugu to chrom for .psl file names.
    ssh kksilo
    cd /cluster/data/dm2/bed/blatFugu
    foreach c (2L 2R 2h 3L 3R 3h 4 X Xh Yh U)
      echo -n "chr${c} "
      pslCat psl/chr${c}_*.psl \
      | pslSortAcc nohead chrom temp stdin
      rm -f chrom/chr${c}_blatFugu.psl
      mv chrom/chr${c}.psl chrom/chr${c}_blatFugu.psl
    end

    # Load alignments
    ssh hgwdev
    cd /cluster/data/dm2/bed/blatFugu/chrom
    hgLoadPsl -noTNameIx dm2 chr*_blatFugu.psl

    # Make fugu /gbdb/ symlink and load Fugu sequence data.
    mkdir /gbdb/dm2/fuguSeq
    ln -s /cluster/store3/fuguSeq/fugu_v3_mask.fasta /gbdb/dm2/fuguSeq
    # ! ! !  DO NOT RUN hgLoadSeq in /gbdb - it leaves .tab files
    cd /cluster/data/dm2/bed/blatFugu
    hgLoadSeq dm2 /gbdb/dm2/fuguSeq/fugu_v3_mask.fasta


# PRODUCING GENSCAN PREDICTIONS (DONE 9/10/04 angie)
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    ssh hgwdev
    mkdir /cluster/data/dm2/bed/genscan
    cd /cluster/data/dm2/bed/genscan
    cvs co hg3rdParty/genscanlinux
    ssh kksilo
    cd /cluster/data/dm2/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Make hard-masked contigs
    foreach f (/cluster/data/dm2/?{,?}/chr*/chr?{,?}_?{,?}.fa)
      maskOutFa $f hard $f.masked
    end
    # Generate a list file, contigs.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f contigs.list
    touch contigs.list
    foreach f ( `ls -1S /cluster/data/dm2/?{,?}/chr*/chr?{,?}{,_random}_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> contigs.list
    end
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 contigs.list single gsub jobList
    # Run on small cluster -- genscan needs big mem.
    ssh kki
    cd /cluster/data/dm2/bed/genscan
    para create jobList
    para try, check, push, check, ...
#Completed: 81 of 81 jobs
#Average job time:                  48s       0.80m     0.01h    0.00d
#Longest job:                      212s       3.53m     0.06h    0.00d
#Submission to last job:           589s       9.82m     0.16h    0.01d

    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    
    # Convert these to chromosome level files as so:
    ssh kksilo
    cd /cluster/data/dm2/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/dm2/bed/genscan
    ldHgGene -gtf -genePredExt dm2 genscan genscan.gtf
    hgPepPred dm2 generic genscanPep genscan.pep
    hgLoadBed dm2 genscanSubopt genscanSubopt.bed
    featureBits dm2 genscan
#24711981 bases of 131698467 (18.764%) in intersection


# MAKE DOWNLOADABLE FILES (TODO 9/10/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    mkdir zips
    zip -j zips/chromOut.zip ?{,?}/chr?{,?}.fa.out
    zip -j zips/chromFa.zip ?{,?}/chr?{,?}.fa
    foreach f (?{,?}/chr?{,?}.fa)
      maskOutFa $f hard $f.masked
    end
    zip -j zips/chromFaMasked.zip ?{,?}/chr?{,?}.fa.masked
    cd bed/simpleRepeat
    zip ../../zips/chromTrf.zip trfMaskChrom/chr*.bed
    zip ../../zips/contigTrf.zip trfMask/N{T,G}*.bed
    cd ../..
    # Make a starter mrna.zip -- it will get updated regularly on the RR. 
    /cluster/data/genbank/bin/i386/gbGetSeqs -gbRoot=/cluster/data/genbank \
      -db=dm2 -native genbank mrna mrna.fa
    zip zips/mrna.zip mrna.fa
    rm mrna.fa
    foreach f (zips/*.zip)
      echo $f
      unzip -t $f | tail -1
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2
    cd /usr/local/apache/htdocs/goldenPath/dm2
    mkdir bigZips database
    # Create README.txt files in bigZips/ and database/ to explain the files.
    cp -p /cluster/data/dm2/zips/*.zip bigZips


# BLASTZ D.YAKUBA (DONE 9/10/04 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.droYak1.2004-09-10
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.yakuba
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. yakuba
SEQ2_DIR=/iscratch/i/droYak1/nib
SEQ2_SMSK=
SEQ2_FLAG=-drosophila
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.droYak1.2004-09-10

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy
    # run bash shell if you don't already:
    bash
    source DEF
    mkdir run
    /cluster/bin/scripts/blastz-make-joblist $DEF > $BASE/run/j
    sh ./xdir.sh
    cd run
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    mv j2 j
    # cluster run
    ssh kk
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/run
    para create j
    para try, check, push, check, ....
#Completed: 736 of 736 jobs
#Average job time:                 168s       2.80m     0.05h    0.00d
#Longest job:                     1591s      26.52m     0.44h    0.02d
#Submission to last job:          1609s      26.82m     0.45h    0.02d

    # back on kksilo...
    mkdir /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/run.1
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/run.1
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                  10s       0.16m     0.00h    0.00d
#Longest job:                       34s       0.57m     0.01h    0.00d
#Submission to last job:            46s       0.77m     0.01h    0.00d
    cd ..
    rm -r raw

    # third run: lav -> axt
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10
    mkdir axtChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| lavToAxt stdin \
    /iscratch/i/dm2/nib /iscratch/i/droYak1/nib stdout \
| axtSort stdin ../../axtChrom/$chr.axt 
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 13 of 13 jobs
#Average job time:                  22s       0.37m     0.01h    0.00d
#Longest job:                       46s       0.77m     0.01h    0.00d
#Submission to last job:            46s       0.77m     0.01h    0.00d


# CHAIN YAKUBA BLASTZ (DONE 9/10/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/droYak1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  14s       0.24m     0.00h    0.00d
#Longest job:                       27s       0.45m     0.01h    0.00d
#Submission to last job:            27s       0.45m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDroYak1 $i
    end


# NET YAKUBA BLASTZ (DONE 9/10/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    netClass -noAr noClass.net dm2 droYak1 yakuba.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    rm noClass.net
    netFilter -syn yakuba.net > yakubaSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    netFilter -minGap=10 yakuba.net |  hgLoadNet dm2 netDroYak1 stdin
    netFilter -minGap=10 yakubaSyn.net | hgLoadNet dm2 netSyntenyDroYak1 stdin


# MAKE VSDROYAK1 DOWNLOADABLES (TODO 9/10/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    cp all.chain yakuba.chain
    zip /cluster/data/dm2/zips/yakuba.chain.zip yakuba.chain
    rm yakuba.chain
    zip /cluster/data/dm2/zips/yakuba.net.zip yakuba.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDroYak1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDroYak1
    mv /cluster/data/dm2/zips/yakuba*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# GENERATE DROYAK1 MAF FOR MULTIZ FROM NET (DONE 9/10/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/axtChain
    netSplit yakuba.net net
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.droYak1.2004-09-10
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/dm2/nib \
        /cluster/data/droYak1/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/droYak1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=droYak1.
    end


# BLASTZ D.PSEUDOOBSCURA (DONE 9/10/04 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    ln -s blastz.dp2.2004-09-10 /cluster/data/dm2/bed/blastz.dp2
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.pseudoobscura
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. pseudoobscura
SEQ2_DIR=/iscratch/i/dp2/nib
SEQ2_SMSK=
SEQ2_FLAG=-drosophila
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.dp2.2004-09-10

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy
    # run bash shell if you don't already:
    bash
    source DEF
    mkdir run
    /cluster/bin/scripts/blastz-make-joblist $DEF > $BASE/run/j
    sh ./xdir.sh
    cd run
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    mv j2 j
    # cluster run
    ssh kk
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run
    para create j
    para try, check, push, check, ....
#Completed: 17457 of 17457 jobs
#Average job time:                  11s       0.18m     0.00h    0.00d
#Longest job:                      295s       4.92m     0.08h    0.00d
#Submission to last job:          3337s      55.62m     0.93h    0.04d

    # back in the bash shell on kksilo...
    mkdir /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run.1
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run.1
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                  19s       0.31m     0.01h    0.00d
#Longest job:                       25s       0.42m     0.01h    0.00d
#Submission to last job:            41s       0.68m     0.01h    0.00d
    cd ..
    rm -r raw

    # Translate .lav to axt, with dp2 in scaffold coords for collaborators:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    mkdir axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin /cluster/data/dm2/nib /cluster/data/dp2/nib stdout \
        | axtSort stdin ../../$out
      popd
    end


# CHAIN PSEUDOOBSCURA BLASTZ (DONE 9/10/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/dp2/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                   7s       0.12m     0.00h    0.00d
#Longest job:                       16s       0.27m     0.00h    0.00d
#Submission to last job:            16s       0.27m     0.00h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDp2 $i
    end


# NET PSEUDOOBSCURA BLASTZ (DONE 9/11/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    netClass -noAr noClass.net dm2 dp2 pseudoobscura.net \
    |& g -v "table gap doesn't exist"

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    rm noClass.net
    netFilter -syn pseudoobscura.net > pseudoobscuraSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    netFilter -minGap=10 pseudoobscura.net |  hgLoadNet dm2 netDp2 stdin
    netFilter -minGap=10 pseudoobscuraSyn.net \
    | hgLoadNet dm2 netSyntenyDp2 stdin


# MAKE VSDP2 DOWNLOADABLES (TODO 9/10/04 angie)
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDp2
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDp2
    gzip -c \
      /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain/all.chain \
      > pseudoobscura.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain/pseudoobscura.net \
      > pseudoobscura.net.gz
    mkdir axtNet
    foreach f (/cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtNet/chr*axt)
      gzip -c $f > axtNet/$f:t.gz
    end
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# GENERATE DP2 MAF FOR MULTIZ FROM NET (DONE 9/11/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    netSplit pseudoobscura.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/dp2/nib stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/dp2/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=dp2.
    end


# BLASTZ ANOPHELES (DONE 9/13/04 angie)
    # Will give human-fugu params a try... but without abridging repeats 
    # since I don't know which are lin-spec for fly vs. mosquito, and don't 
    # want to bother Arian or speculate.
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    cat << '_EOF_' > DEF
# D.melanogaster vs. A. gambiae
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - A. gambiae
SEQ2_DIR=/iscratch/i/anoGam1/nib
SEQ2_SMSK=
SEQ2_FLAG=-anopheles
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.anoGam1.2004-09-13

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy
    # run bash shell if you don't already:
    bash
    source DEF
    mkdir run
    /cluster/bin/scripts/blastz-make-joblist $DEF > $BASE/run/j
    sh ./xdir.sh
    cd run
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    mv j2 j
    # cluster run
    ssh kk
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run
    para create j
    para try, check, push, check, ....
#Completed: 759 of 759 jobs
#Average job time:                 350s       5.84m     0.10h    0.00d
#Longest job:                     1111s      18.52m     0.31h    0.01d
#Submission to last job:          1911s      31.85m     0.53h    0.02d

    # back on kksilo...
    mkdir /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run.1
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run.1
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                   5s       0.09m     0.00h    0.00d
#Longest job:                       10s       0.17m     0.00h    0.00d
#Submission to last job:            15s       0.25m     0.00h    0.00d
    cd ..
    rm -r raw

    # third run: lav -> axt
    # Don't need to rescore (even though non-default BLASTZ_Q matrix was used)
    # because repeats were not abridged.
    ssh kki
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    mkdir axtChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| lavToAxt stdin \
    /iscratch/i/dm2/nib /iscratch/i/anoGam1/nib stdout \
| axtSort stdin ../../axtChrom/$chr.axt 
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 13 of 13 jobs
#Average job time:                   6s       0.10m     0.00h    0.00d
#Longest job:                       12s       0.20m     0.00h    0.00d
#Submission to last job:            14s       0.23m     0.00h    0.00d


# CHAIN ANOPHELES BLASTZ (DONE 9/13/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/anoGam1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  12s       0.19m     0.00h    0.00d
#Longest job:                       17s       0.28m     0.00h    0.00d
#Submission to last job:            19s       0.32m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainAnoGam1 $i
    end


# NET ANOPHELES BLASTZ (DONE 9/13/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    netClass -noAr noClass.net dm2 anoGam1 anopheles.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    rm noClass.net
    netFilter -syn anopheles.net > anophelesSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    netFilter -minGap=10 anopheles.net |  hgLoadNet dm2 netAnoGam1 stdin
    netFilter -minGap=10 anophelesSyn.net | hgLoadNet dm2 netSyntenyAnoGam1 stdin


# MAKE VSANOGAM1 DOWNLOADABLES (TODO 9/11/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    cp all.chain anopheles.chain
    zip /cluster/data/dm2/zips/anopheles.chain.zip anopheles.chain
    rm anopheles.chain
    zip /cluster/data/dm2/zips/anopheles.net.zip anopheles.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsAnoGam1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsAnoGam1
    mv /cluster/data/dm2/zips/anopheles*.zip .
    md5sum *.zip > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# GENERATE ANOGAM1 MAF FOR MULTIZ FROM NET (DONE 9/13/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    netSplit anopheles.net net
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/dm2/nib \
        /cluster/data/anoGam1/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/anoGam1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=anoGam1.
    end


# MULTIZ MELANOGASTER/YAKUBA/PSEUDOOBSCURA/ANOPHELES (DONE 9/22/04 angie)
    # put the MAFs on bluearc
    ssh kksilo
    mkdir -p /cluster/bluearc/multiz.flymo/my
    cp /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/mafNet/*.maf \
      /cluster/bluearc/multiz.flymo/my
    mkdir -p /cluster/bluearc/multiz.flymo/mp
    cp /cluster/data/dm2/bed/blastz.dp2.2004-09-10/mafNet/*.maf \
      /cluster/bluearc/multiz.flymo/mp
    mkdir -p /cluster/bluearc/multiz.flymo/ma
    cp /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/mafNet/*.maf \
      /cluster/bluearc/multiz.flymo/ma

    ssh kki
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1
    mkdir mypa
    # Use PSU's new var_multiz:
    cat << '_EOF_' > doMultiz
#!/bin/csh -ef
set path = (/cluster/bin/penn/var_multiz.2004.08.12 $path)
set chr = $1:t:r
if (-s $1 && -s $2) then
  set tmp = /scratch/$chr.tmp.maf
  var_multiz $1 $2 0 0 > $tmp
  maf_project $tmp dm2.$chr > /scratch/$chr.myp.maf
  rm $tmp
else if (-s $1) then
  cp $1 /scratch/$chr.myp.maf
else if (-s $2) then
  cp $2 /scratch/$chr.myp.maf
endif
if (-s /scratch/$chr.myp.maf && -s $3) then
  set tmp = /scratch/$chr.tmp.maf
  var_multiz /scratch/$chr.myp.maf $3 1 0 > $tmp
  maf_project $tmp dm2.$chr > $4
  rm $tmp
else if (-s /scratch/$chr.myp.maf) then
  cp /scratch/$chr.myp.maf $4
else if (-s $3) then
  cp $3 $4
endif
rm /scratch/$chr.myp.maf
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doMultiz
    cp /dev/null jobList
    foreach chr (`awk '{print $1;}' /cluster/data/dm2/chrom.sizes`)
      set f1 = /cluster/bluearc/multiz.flymo/my/$chr.maf
      set f2 = /cluster/bluearc/multiz.flymo/mp/$chr.maf
      set f3 = /cluster/bluearc/multiz.flymo/ma/$chr.maf
      echo "doMultiz $f1 $f2 $f3 mypa/$chr.maf" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 13 of 13 jobs
#Average job time:                 246s       4.09m     0.07h    0.00d
#Longest job:                      811s      13.52m     0.23h    0.01d
#Submission to last job:           811s      13.52m     0.23h    0.01d
    du -sh mypa
#417M    mypa

    # clean up bluearc
    rm -r /cluster/bluearc/multiz.flymo

    # setup external files for database reference
    ssh hgwdev
    mkdir /gbdb/dm2/mzDy1Dp2Ag1_phast
    ln -s /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/mypa/chr*.maf \
      /gbdb/dm2/mzDy1Dp2Ag1_phast/
    # load into database
    cd /tmp
    hgLoadMaf -warn dm2 mzDy1Dp2Ag1_phast
    cd /gbdb/dm2
    mkdir d_pseudoobscura_mypa d_yakuba_mypa a_gambiae_mypa
    cd /tmp
    ln -s /cluster/data/dm2/bed/blastz.dp2.2004-09-10/mafNet/*.maf \
      /gbdb/dm2/d_pseudoobscura_mypa
    hgLoadMaf -WARN dm2 d_pseudoobscura_mypa
    ln -s /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/mafNet/*.maf \
      /gbdb/dm2/d_yakuba_mypa
    hgLoadMaf -WARN dm2 d_yakuba_mypa
    ln -s /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/mafNet/*.maf \
      /gbdb/dm2/a_gambiae_mypa
    hgLoadMaf -WARN dm2 a_gambiae_mypa


# PHASTCONS MELANOGASTER/YAKUBA/PSEUDOOBSCURA/ANOPHELES (DONE 9/22/04 angie)
    ssh kksilo
    # copy chrom fa to bluearc, break up the genome-wide MAFs into pieces
    mkdir -p /cluster/bluearc/dm2/chrom
    cp -p /cluster/data/dm2/?{,?}/chr*.fa /cluster/bluearc/dm2/chrom/
    ssh kki
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.split
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.split
    set WINDOWS = /cluster/bluearc/dm2/phastCons/WINDOWS
    rm -fr $WINDOWS
    mkdir -p $WINDOWS
    cat << 'EOF' > doSplit.sh
#!/bin/csh -ef

set PHAST=/cluster/bin/phast
set FA_SRC=/cluster/bluearc/dm2/chrom
set WINDOWS=/cluster/bluearc/dm2/phastCons/WINDOWS

set maf=$1
set c = $maf:t:r
set tmpDir = /scratch/msa_split/$c
rm -rf $tmpDir
mkdir -p $tmpDir
${PHAST}/msa_split $maf -i MAF -M ${FA_SRC}/$c.fa -O dm2,droYak1,dp2,anoGam1 \
   -w 1000000,0 -r $tmpDir/$c -o SS -I 1000 -B 5000
cd $tmpDir
foreach file ($c.*.ss)
  gzip -c $file > ${WINDOWS}/$file.gz
end
rm -f $tmpDir/$c.*.ss
rmdir $tmpDir
'EOF'
# << for emacs
    chmod a+x doSplit.sh
    rm -f jobList
    foreach file (/cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/mypa/*.maf) 
      if (-s $file) then
        echo "doSplit.sh {check in line+ $file}" >> jobList
      endif
    end
    para create jobList
    para try,  check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  23s       0.38m     0.01h    0.00d
#Longest job:                       53s       0.88m     0.01h    0.00d
#Submission to last job:            53s       0.88m     0.01h    0.00d
    cd ..

    # use the model previously estimated (see makeDm1.doc) as a starting model
    sed -e 's/dm1/dm2/g' /cluster/data/dm1/bed/phastCons4way/rev-dg.mod \
      > starting-tree.mod
    # -- Because of the very long branch length to anoGam1 being pretty 
    # much impossible to estimate from alignment data, edit that file to 
    # reduce the anoGam1 branch length from 2.66 to 0.5.  Otherwise 
    # estimation process blows up.  So our starting tree becomes
#TREE: (((dm2:0.058,droYak1:0.074):0.133,dp2:0.200):0,anoGam1:0.5);

    # Get genome-wide average GC content (for all species together,
    # not just the reference genome).  If you have a globally
    # estimated tree model, as above, you can get this from the
    # BACKGROUND line in the .mod file.  E.g.,
# ALPHABET: A C G T
# ...
# BACKGROUND: 0.276938 0.223190 0.223142 0.276730
    # add up the C and G:
    awk '$1 == "BACKGROUND:" {printf "%0.3f\n", $3 + $4;}' starting-tree.mod
#0.446
    # Great, use 0.446 as the --gc parameter in phastCons below:.

    # Now set up cluster job to estimate model parameters.  
    # Parameters will be estimated separately for each alignment fragment 
    # then will be combined across fragments.
    # Use --gc from above, and --target-coverage computed as follows:
    # 1. Jim would like phastConsElements coverage to be 25% for fly.
    # 2. 83% of dm2 is covered by chainDroYak1Link, so use .25 / .83 = .30 
    #    as an initial --target-coverage.
    # 3. If actual coverage is different from our target, come back to this 
    #    step, adjust --target-coverage and rerun up through phastConsElements.
    # -- Actually, Adam suggests starting with what proved to work for worm:
    #    --target-coverage 0.4 and --expected-lengths 25 (not 12 as for mammal)
    # -- OK, that led to too-high coverage:
    # 51511266 bases of 131698467 (39.113%) in intersection
    #    so next try 0.3, 30:
    # 49886398 bases of 131698467 (37.879%) in intersection
    #   how about 0.3, 20?
    # 42067218 bases of 131698467 (31.942%) in intersection
    #   0.25, 20?
    # 38397215 bases of 131698467 (29.155%) in intersection
    #   0.25, 15?
    # 35039841 bases of 131698467 (26.606%) in intersection
    # -- that's close enough to the target.  If the "bumpiness" of the 
    #    wiggle looks aesthetically pleasing then we're done.
    # -- OK, Adam would like to see more smoothing so that coding exons 
    #    stand out better, so try 0.20, 25:
    # 37574714 bases of 131698467 (28.531%) in intersection
    # More smooting would be nice for coding exons, so tried 0.20, 50, 
    # but Adam didn't like that as much overall so stick with 0.20, 25.  

    mkdir run.estimate
    cd run.estimate
    cat << '_EOF_' > doEstimate.sh
#!/bin/csh -ef
zcat $1 \
| /cluster/bin/phast/phastCons - ../starting-tree.mod --gc 0.446 --nrates 1,1 \
    --no-post-probs --ignore-missing --expected-lengths 25 \
    --target-coverage 0.20 --quiet --log $2 --estimate-trees $3
'_EOF_'
# << for emacs
    chmod a+x doEstimate.sh
    rm -fr LOG TREES
    mkdir -p LOG TREES
    rm -f jobList
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*.ss.gz)
      set root = $f:t:r:r
      echo doEstimate.sh $f LOG/$root.log TREES/$root >> jobList
    end
    # run cluster job
    ssh kk9
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.estimate
    para create jobList
    para try, check, push, check, ...
#Completed: 139 of 139 jobs
#Average job time:                 133s       2.22m     0.04h    0.00d
#Longest job:                      221s       3.68m     0.06h    0.00d
#Submission to last job:           328s       5.47m     0.09h    0.00d

    # Now combine parameter estimates.  We can average the .mod files
    # using phyloBoot.  This must be done separately for the conserved
    # and nonconserved models
    ssh kksilo
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.estimate
    ls -1 TREES/*.cons.mod > cons.txt
    /cluster/bin/phast/phyloBoot --read-mods '*cons.txt' \
      --output-average ave.cons.mod > cons_summary.txt
    ls -1 TREES/*.noncons.mod > noncons.txt
    /cluster/bin/phast/phyloBoot --read-mods '*noncons.txt' \
      --output-average ave.noncons.mod > noncons_summary.txt
    grep TREE ave*.mod
#ave.cons.mod:TREE: (((dm2:0.028707,droYak1:0.019740):0.039091,dp2:0.065825):0.086142,anoGam1:0.086142);
#ave.noncons.mod:TREE: (((dm2:0.118202,droYak1:0.079147):0.162923,dp2:0.275544):0.360361,anoGam1:0.360361);
    # look over the files cons_summary.txt and noncons_summary.txt.
    # The means and medians should be roughly equal and the stdevs
    # should be reasonably small compared to the means, particularly
    # for rate matrix parameters (at bottom) and for branches to the
    # leaves of the tree.  The stdevs may be fairly high for branches
    # near the root of the tree; that's okay.  Some min values may be
    # 0 for some parameters.  That's okay, but watch out for very large
    # values in the max column, which might skew the mean.  If you see
    # any signs of bad outliers, you may have to track down the
    # responsible .mod files and throw them out.  I've never had to do
    # this; the estimates generally seem pretty well behaved.

    # NOTE: Actually, a random sample of several hundred to a thousand
    # alignment fragments (say, a number equal to the number of
    # available cluster nodes) should be more than adequate for
    # parameter estimation.  If pressed for time, use this strategy.

    # Now we are ready to set up the cluster job for computing the
    # conservation scores and predicted elements.  It's all downhill
    # from here.
    ssh kk9
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.phast
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.phast
    cat << 'EOF' > doPhastCons.sh
#!/bin/csh -ef
set pref = $1:t:r:r
set chr = `echo $pref | awk -F\. '{print $1}'`
set tmpfile = /scratch/phastCons.$$
zcat $1 \
| /cluster/bin/phast/phastCons - \
    ../run.estimate/ave.cons.mod,../run.estimate/ave.noncons.mod \
    --expected-lengths 25 --target-coverage 0.20 --quiet --seqname $chr \
    --idpref $pref \
    --viterbi /cluster/bluearc/dm2/phastCons/ELEMENTS/$pref.bed --score \
    --require-informative 0 \
  > $tmpfile
gzip -c $tmpfile > /cluster/bluearc/dm2/phastCons/POSTPROBS/$pref.pp.gz
rm $tmpfile
'EOF'
# << for emacs
    chmod a+x doPhastCons.sh
    rm -fr /cluster/bluearc/dm2/phastCons/{POSTPROBS,ELEMENTS}
    mkdir -p /cluster/bluearc/dm2/phastCons/{POSTPROBS,ELEMENTS}
    rm -f jobList
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*.ss.gz)
      echo doPhastCons.sh $f >> jobList
    end
    para create jobList
    para try, check, push, check, ...
#Completed: 139 of 139 jobs
#Average job time:                  23s       0.38m     0.01h    0.00d
#Longest job:                       49s       0.82m     0.01h    0.00d
#Submission to last job:            52s       0.87m     0.01h    0.00d

    # back on kksilo:
    # combine predictions and transform scores to be in 0-1000 interval
    # do in a way that avoids limits on numbers of args
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    awk '{printf "%s\t%d\t%d\tlod=%d\t%s\n", $1, $2, $3, $5, $5;}' \
      /cluster/bluearc/dm2/phastCons/ELEMENTS/*.bed \
    | /cluster/bin/scripts/lodToBedScore > all.bed

    ssh hgwdev
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    featureBits dm2 all.bed
#37574714 bases of 131698467 (28.531%) in intersection
    # OK, close enough.
    hgLoadBed dm2 phastConsElements all.bed

    # Create wiggle on the small cluster
    ssk kki
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.wib
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.wib
    rm -rf /cluster/bluearc/dm2/phastCons/wib
    mkdir -p /cluster/bluearc/dm2/phastCons/wib
    cat << 'EOF' > doWigAsciiToBinary
#!/bin/csh -ef
set chr = $1
zcat `ls -1 /cluster/bluearc/dm2/phastCons/POSTPROBS/$chr.*.pp.gz \
      | sort -t\. -k2,2n` \
| wigAsciiToBinary -chrom=$chr \
    -wibFile=/cluster/bluearc/dm2/phastCons/wib/${chr}_phastCons stdin 
'EOF'
# << for emacs
    chmod a+x doWigAsciiToBinary
    rm -f jobList
    foreach chr (`ls -1 /cluster/bluearc/dm2/phastCons/POSTPROBS \
                  | awk -F\. '{print $1}' | sort -u`)
      echo doWigAsciiToBinary $chr >> jobList
    end
    para create jobList
    para try, check, push, check, ...
#Completed: 13 of 13 jobs
#Average job time:                  14s       0.24m     0.00h    0.00d
#Longest job:                       36s       0.60m     0.01h    0.00d
#Submission to last job:            36s       0.60m     0.01h    0.00d

    # back on kksilo, copy wibs, wigs and POSTPROBS (people sometimes want 
    # the raw scores) from bluearc
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    rm -rf wib POSTPROBS
    rsync -av /cluster/bluearc/dm2/phastCons/wib .
    rsync -av /cluster/bluearc/dm2/phastCons/POSTPROBS .

    # load wiggle component of Conservation track
    ssh hgwdev
    mkdir -p /gbdb/dm2/wib/mzDy1Dp2Ag1_phast
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    chmod 775 . wib
    chmod 664 wib/*.wib
    ln -s `pwd`/wib/*.wib /gbdb/dm2/wib/mzDy1Dp2Ag1_phast/
    hgLoadWiggle dm2 mzDy1Dp2Ag1_phast_wig \
      -pathPrefix=/gbdb/dm2/wib/mzDy1Dp2Ag1_phast wib/*.wig

#TODO
    # make top-5000 list and launcher on Adam's home page:
    sort -k5,5nr raw.bed | head -5000 > top5000.bed
    /cluster/home/acs/bin/make-launcher-with-scores.sh top5000.bed \
      /cse/grads/acs/public_html/dm-top5000-4way \
      "top 5000 conserved elements (4way)" dm2

    # and clean up bluearc.
    rm -r /cluster/bluearc/dm2/phastCons
    rm -r /cluster/bluearc/dm2/chrom


# LIFTOVER BDGP 3.2 ANNOTATIONS FROM DM1 (TEMPORARY) (DONE 9/15/04 angie)
    ssh hgwdev
    mkdir /cluster/data/dm2/bed/bdgp3.2.liftOver
    cd /cluster/data/dm2/bed/bdgp3.2.liftOver
    hgsql dm1 -N -e 'select * from bdgpGene' > dm1.bdgpGene.tab
    hgsql dm1 -N -e 'select * from bdgpNonCoding' > dm1.bdgpNonCoding.tab
    ssh kksilo
    cd /cluster/data/dm2/bed/bdgp3.2.liftOver
# lift files to try out:
# blastz:
#  /cluster/data/dm1/bed/blastz.dm2.2004-09-15/axtChain/dm1ToDm2.over.chain \
# blat on dm1 chroms vs. dm2 2Mb chunks:
#  /cluster/data/dm1/bed/blat.dm2.2004-09-16/dm1ToDm2.over.chain \
# blat on dm1 chroms vs. dm2 3kb chunks:
#  /cluster/data/dm1/bed/blat.dm2.2004-09-17/dm1ToDm2.over.chain \
    liftOver -genePred dm1.bdgpGene.tab \
      /cluster/data/dm1/bed/bedOver/dm1ToDm2.over.chain \
      bdgpLiftGene.tab bdgpLiftGene.unmapped.tab
    liftOver -genePred dm1.bdgpNonCoding.tab \
      /cluster/data/dm1/bed/bedOver/dm1ToDm2.over.chain \
      bdgpLiftNonCoding.tab bdgpLiftNonCoding.unmapped.tab
    # Not perfect but not bad:
    wc -l bdgp*.tab
#  18707 bdgpLiftGene.tab
#     78 bdgpLiftGene.unmapped.tab
#   2134 bdgpLiftNonCoding.tab
#     62 bdgpLiftNonCoding.unmapped.tab

    ssh hgwdev
    cd /cluster/data/dm2/bed/bdgp3.2.liftOver
    ldHgGene -predTab dm2 bdgpLiftGene bdgpLiftGene.tab
    ldHgGene -predTab dm2 bdgpLiftNonCoding bdgpLiftNonCoding.tab
    # Copy over the gene info tables
    hgsql dm2 -e 'create table bdgpLiftGeneInfo (PRIMARY KEY(bdgpName(7)), INDEX(flyBaseId(11))) select * from dm1.bdgpGeneInfo'
    hgsql dm2 -e 'create table bdgpLiftNonCodingInfo (INDEX(bdgpName(16)), INDEX(flyBaseId(11))) select * from dm1.bdgpNonCodingInfo'


