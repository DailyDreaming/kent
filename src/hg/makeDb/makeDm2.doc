#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# Drosophila Melanogaster -- 
# 
# euchromatin (2L, 2R, 3L, 3R, 4, X):
# Berkeley Drosophila Genome Project (fruitfly.org) release 4 (Apr. 2004)
# http://www.fruitfly.org/annot/release4.html
#
# heterochromatin (2h, 3h, 4h, Xh, Yh, U):
# Drosophila Heterochromatin Genome Project (dhgp.org) release 3.2 
# (submitted to GenBank June 2004) 
# http://www.dhgp.org/index_release_notes.html
#
# Gene annotations:
# FlyBase (http://flybase.bio.indiana.edu/) last updated ???
#

# DOWNLOAD SEQUENCE (DONE 9/8/04 angie)
    ssh kksilo
    mkdir /cluster/store8/dm2
    ln -s /cluster/store8/dm2 /cluster/data/dm2
    cd /cluster/data/dm2
    wget ftp://ftp.fruitfly.org/pub/download/compressed/na_euchromatin_genomic_dmel_RELEASE4.FASTA.gz
    zcat na_euchromatin_genomic_dmel_RELEASE4.FASTA.gz \
    | faSplit byname stdin dummyArg
    # Follow FlyBase's lead on the chromosome names, but still use our 
    # "chr" prefix:
    foreach c (2L 2R 3L 3R 4 X)
      mkdir $c
      sed -e 's/^>arm_/>chr/' arm_$c.fa > $c/chr$c.fa
      echo arm_$c.fa size:
      faSize arm_$c.fa
      echo $c/chr$c.fa size:
      faSize $c/chr$c.fa
      echo comparison:
      faCmp arm_$c.fa $c/chr$c.fa
      echo ""
    end
    # heterochromatin sold separately... ftp://ftp.dhgp.org/pub/DHGP still 
    # has release 3.2 as its latest.  But that's June 2004... wtf, grab it:
    wget ftp://ftp.dhgp.org/pub/DHGP/Release3.2/FASTA/super-scaffolds/heterochromatin_super-scaffolds-genomic_dmel_RELEASE3.2.FASTA.tar.gz
    tar xvzf heterochromatin_super-scaffolds-genomic_dmel_RELEASE3.2.FASTA.tar.gz
    foreach c (2h 3h 4h Xh Yh U)
      mkdir $c
      perl -wpe 's/^>(\w+).*/>chr$1/' $c.FASTA > $c/chr$c.fa
      echo $c.FASTA size:
      faSize $c.FASTA
      echo $c/chr$c.fa size:
      faSize $c/chr$c.fa
      echo comparison:
      faCmp $c.FASTA $c/chr$c.fa
      echo ""
    end
    # Carefully review output of those commands, then:
    rm *.fa *.FASTA

    # put away the big download files
    mkdir downloads
    mv *.gz downloads/


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (DONE 9/9/04 angie)
    mkdir /cluster/data/dm2/M
    cd /cluster/data/dm2/M
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "drosophila melanogaster mitochondrion genome".  That shows the gi number:
    # 5835233
    # Use that number in the entrez linking interface to get fasta:
    wget -O chrM.fa \
      'http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Text&db=Nucleotide&uid=5835233&dopt=FASTA'
    # Edit chrM.fa: make sure the long fancy header line says it's the 
    # Drosophila melanogaster mitochondrion complete genome, and then replace the 
    # header line with just ">chrM".


# SPLIT CHROM FA INTO SMALLER CHUNKS BY GAPS (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    foreach c (?{,?})
      faSplit -minGapSize=100 -lift=$c/chr$c.lft \
        gap $c/chr$c.fa 2000000 $c/chr${c}_
    end
    foreach ctgFa (?{,?}/chr*_*.fa)
      set ctg = $ctgFa:r
      mkdir $ctg
      mv $ctgFa $ctg
    end


# CREATING DATABASE (DONE 9/9/04 angie)
    ssh hgwdev
    # Make sure there is at least 5 gig free for the database
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  535G  1.1T  33% /var/lib/mysql
    # Create the database.
    hgsql '' -e 'create database dm2'


# EXTRACT GAP INFORMATION FROM FASTA, LOAD GAP TRACK (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    # Do as Jim suggested back when we got dm1 sequence:
    # I think that we can probably just show all gaps as bridged
    # in the non-h chromosomes, and as unbridged in the h chromosomes
    # and leave it at that.

    # Extract gaps using scaffoldFaToAgp.  It's really meant for a different 
    # purpose, so clean up its output: remove the .lft and .agp, and remove 
    # the last line of .gap (extra gap added at end).  Also substitute in 
    # the correct chrom name in .gap.  
    foreach c (?{,?})
      set chr = chr$c
      pushd $c
      mv $chr.lft $chr.lft.bak
      scaffoldFaToAgp -minGapSize=100 $chr.fa
      rm $chr.{lft,agp}
      mv $chr.lft.bak $chr.lft
      set chrSize = `faSize $chr.fa | awk '{print $1;}'`
      set origLines = `cat $chr.gap | wc -l`
      awk '($2 != '$chrSize'+1) {print;}' $chr.gap \
      | sed -e "s/chrUn/$chr/" > $chr.gap2
      set newLines = `cat $chr.gap2 | wc -l`
      if ($newLines == ($origLines - 1)) then
        mv $chr.gap2 $chr.gap
      else
        echo "Error: $chr/$chr.gap2 has wrong number of lines."
      endif
      popd
    end
    # Call the gaps unbridged in chrU and chr*h:
    foreach c (U ?h)
      set chr = chr$c
      sed -e 's/yes/no/' $c/$chr.gap > $c/$chr.gap2
      mv $c/$chr.gap2 $c/$chr.gap
    end
    ssh hgwdev
    hgLoadGap dm2 /cluster/data/dm2


# MAKE JKSTUFF AND BED DIRECTORIES (DONE 9/9/04 angie)
    # This used to hold scripts -- better to keep them inline in the .doc 
    # so they're in CVS.  Now it should just hold lift file(s) and 
    # temporary scripts made by copy-paste from this file.  
    mkdir /cluster/data/dm2/jkStuff
    # This is where most tracks will be built:
    mkdir /cluster/data/dm2/bed


# MAKE LIFTALL.LFT (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    cat ?{,?}/chr*.lft > jkStuff/liftAll.lft


# RUN REPEAT MASKER (DONE 9/9/04 angie)
    # Note: drosophila library ("drosophila.lib") is dated May 27 '03.
    # Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make 
    # RepeatMasker runs manageable on the cluster ==> results need lifting.

    # Split contigs into 500kb chunks:
    ssh kksilo
    cd /cluster/data/dm2
    foreach d ( */chr*_?{,?} )
      cd $d
      set contig = $d:t
      faSplit -minGapSize=100 -lift=$contig.lft -maxN=500000 \
        gap $contig.fa 500000 ${contig}_
      cd ../..
    end

    #- Make the run directory and job list:
    cd /cluster/data/dm2
    cat << '_EOF_' > jkStuff/RMDrosophila
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/dm2/$2
/bin/cp $2 /tmp/dm2/$2/
cd /tmp/dm2/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -s -spec drosophila $2
popd
/bin/cp /tmp/dm2/$2/$2.out ./
if (-e /tmp/dm2/$2/$2.tbl) /bin/cp /tmp/dm2/$2/$2.tbl ./
if (-e /tmp/dm2/$2/$2.cat) /bin/cp /tmp/dm2/$2/$2.cat ./
/bin/rm -fr /tmp/dm2/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/dm2/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/dm2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMDrosophila
    mkdir RMRun
    cp /dev/null RMRun/RMJobs
    foreach d ( ?{,?}/chr*_?{,?} )
      set ctg = $d:t
      foreach f ( $d/${ctg}_?{,?}.fa )
        set f = $f:t
        echo /cluster/data/dm2/jkStuff/RMDrosophila \
             /cluster/data/dm2/$d $f /cluster/data/dm2/$d \
           '{'check out line+ /cluster/data/dm2/$d/$f.out'}' \
        >> RMRun/RMJobs
      end
    end

    # do the run
    ssh kk9
    cd /cluster/data/dm2/RMRun
    para create RMJobs
    para try, check, push, check,...
#Completed: 288 of 288 jobs
#Average job time:                3169s      52.82m     0.88h    0.04d
#Longest job:                     4752s      79.20m     1.32h    0.06d
#Submission to last job:         13769s     229.48m     3.82h    0.16d

    # Lift up the split-contig .out's to contig-level .out's
    ssh kksilo
    cd /cluster/data/dm2
    foreach d ( ?{,?}/chr*_?{,?} )
      cd $d
      set contig = $d:t
      liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
      cd ../..
    end

    # Lift up the contig-level .out's to chr-level
    foreach c (?{,?})
      cd $c
      if (-e chr$c.lft && ! -z chr$c.lft) then
        echo lifting $c
        /cluster/bin/i386/liftUp chr$c.fa.out chr$c.lft warn \
          `awk '{print $2"/"$2".fa.out";}' chr$c.lft` > /dev/null
      else
        echo Can\'t find $c/chr$c.lft \!
      endif
      cd ..
    end

    # Load the .out files into the database with:
    ssh hgwdev
    hgLoadOut dm2 /cluster/data/dm2/?{,?}/*.fa.out


# SIMPLE REPEATS (TRF) (DONE 9/9/04 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/simpleRepeat
    cd /cluster/data/dm2/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    foreach f (/cluster/data/dm2/?{,?}/chr*_*/chr?{,?}_?{,?}.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    tcsh jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l
    # When job is done do:
    liftUp simpleRepeat.bed /cluster/data/dm2/jkStuff/liftAll.lft warn \
      trf/*.bed

    # Load this into the database as so
    ssh hgwdev
    hgLoadBed dm2 simpleRepeat \
      /cluster/data/dm2/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql


# FILTER SIMPLE REPEATS (TRF) INTO MASK (DONE 9/9/04 angie)
    # make a filtered version # of the trf output: 
    # keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/dm2/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
        echo "filtering $f"
        awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end
    # Lift up filtered trf output to chrom coords as well:
    cd /cluster/data/dm2
    mkdir bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed $c/chr$c.lft warn \
        `awk '{print "bed/simpleRepeat/trfMask/"$2".bed";}' $c/chr$c.lft`
    end


# MASK FA USING REPEATMASKER AND FILTERED TRF FILES (DONE 9/9/04 angie)
    ssh kksilo
    cd /cluster/data/dm2
    foreach c (?{,?})
      echo repeat- and trf-masking chr$c.fa
      /cluster/home/kent/bin/i386/maskOutFa -soft \
        $c/chr$c.fa $c/chr$c.fa.out $c/chr$c.fa
      /cluster/home/kent/bin/i386/maskOutFa -softAdd \
        $c/chr$c.fa bed/simpleRepeat/trfMaskChrom/chr$c.bed $c/chr$c.fa
    end
    foreach c (?{,?})
      echo repeat- and trf-masking contigs of chr$c
      foreach ctgFa ($c/chr*/chr${c}_?{,?}.fa)
        set trfMask=bed/simpleRepeat/trfMask/$ctgFa:t:r.bed
        /cluster/home/kent/bin/i386/maskOutFa -soft $ctgFa $ctgFa.out $ctgFa
        /cluster/home/kent/bin/i386/maskOutFa -softAdd $ctgFa $trfMask $ctgFa
      end
    end


# STORE SEQUENCE AND ASSEMBLY INFORMATION (DONE 9/9/04 angie)
    # Translate to nib
    ssh kksilo
    cd /cluster/data/dm2
    mkdir nib
    foreach c (?{,?})
      faToNib -softMask $c/chr$c.fa nib/chr$c.nib
    end

    # Make symbolic links from /gbdb/dm2/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/dm2/nib
    foreach f (/cluster/data/dm2/nib/chr*.nib)
      ln -s $f /gbdb/dm2/nib
    end

    # Load /gbdb/dm2/nib paths into database and save size info.
    hgsql dm2  < ~/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib dm2 /gbdb/dm2/nib /cluster/data/dm2/?{,?}/chr?{,?}.fa
    echo "select chrom,size from chromInfo" | hgsql -N dm2 \
      > /cluster/data/dm2/chrom.sizes


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 9/9/04 angie)
    # Copy all the data from the table "grp" 
    # in the existing database dm1 to the new database
    ssh hgwdev
    hgsql dm2 -e "create table grp (PRIMARY KEY(NAME)) select * from dm1.grp"


# MAKE GCPERCENT (DONE 2/2/04 angie)
     ssh hgwdev
     mkdir /cluster/data/dm2/bed/gcPercent
     cd /cluster/data/dm2/bed/gcPercent
     # create and load gcPercent table
     hgsql dm2  < ~/src/hg/lib/gcPercent.sql
     hgGcPercent dm2 ../../nib


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR DROSOPHILA (DONE 9/9/04 angie)
    # Warning: must genome and organism fields must correspond
    # with defaultDb values
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome, scientificName, \
                htmlPath, hgNearOk, hgPbOk, sourceName) values \
        ("dm2", "Apr. 2004", "/gbdb/dm2/nib", "D. melanogaster", \
               "chr2L:825964-851061", 1, 55, "D. melanogaster", \
                "Drosophila melanogaster", "/gbdb/dm2/html/description.html", \
                0, 0, "BDGP v. 4 / DHGP v. 3.2");' \
      | hgsql -h genome-testdb hgcentraltest
    echo 'update defaultDb set name = "dm2" where genome = "D. melanogaster"' \
      | hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P

    # Edit that makefile to add dm2 to DBS and do
    make update

    # go public on genome-test
    cvs commit makefile
    make alpha

    # Add trackDb directories and description.html
    mkdir drosophila/dm2
    cvs add drosophila/dm2
    # Write ~/kent/src/hg/makeDb/trackDb/drosophila/dm2/description.html 
    # with a description of the assembly and some sample position queries.  
    chmod a+r drosophila/dm2/description.html
    # Check it in and copy (via "make alpha" in trackDb/) to 
    # /cluster/data/dm2/html/.  
    cvs add drosophila/dm2/description.html
    cvs commit drosophila/dm2
    mkdir -p /gbdb/dm2/html
    make alpha


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR DROSOPHILA (DONE 2/?/05 galt/angie)
    ssh hgwdev
    # Get appropriate hostname and port numbers from cluster admins:
    echo 'insert into blatServers values("dm2", "blat14", 17794, 1, 0); \
          insert into blatServers values("dm2", "blat14", 17795, 0, 1);' \
      | hgsql -h genome-testdb hgcentraltest


# PUT NIBS ON ISCRATCH (DONE 9/9/04 angie)
    ssh kkr1u00
    mkdir /iscratch/i/dm2
    cd /iscratch/i/dm2
    cp -pR /cluster/data/dm2/nib .
    iSync
    # Added "contigs" (chunks) 9/16/04
    mkdir maskedContigs
    cp -p /cluster/data/dm2/*/chr*_*/chr?{,?}_?{,?}.fa maskedContigs
    iSync


# AUTO UPDATE GENBANK MRNA RUN  (DONE 2/1/05 angie)
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .
    # See if /cluster/data/genbank/etc/genbank.conf has had any un-checked-in
    # edits, check them in if necessary:
    diff /cluster/data/genbank/etc/genbank.conf etc/genbank.conf

    # Edit etc/genbank.conf and add these lines:
# dm2 (D. melanogaster)
dm2.genome = /iscratch/i/dm2/nib/chr*.nib
dm2.lift = /cluster/data/dm2/jkStuff/liftAll.lft
dm2.genbank.mrna.xeno.load = yes
dm2.genbank.est.xeno.load = no
dm2.downloadDir = dm2

    cvs ci etc/genbank.conf

    # Install to /cluster/data/genbank:
    make install-server

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, refseq only:
    nice bin/gbAlignStep -srcDb=refseq -type=mrna -initial dm2 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -drop -initialLoad dm2
    featureBits dm2 refGene
#28230571 bases of 131698467 (21.436%) in intersection
    # Clean up:
    rm -rf work/initial.dm2

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -srcDb=genbank -type=mrna -initial dm2 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -drop -initialLoad dm2
    featureBits dm2 mrna
#23752517 bases of 131698467 (18.036%) in intersection
    featureBits dm2 xenoMrna
#5943805 bases of 131698467 (4.513%) in intersection
    # Clean up:
    rm -rf work/initial.dm2

    ssh eieio
    # -initial for ESTs:
    nice bin/gbAlignStep -srcDb=genbank -type=est -initial dm2 &
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep dm2
    featureBits dm2 intronEst
#12644283 bases of 131698467 (9.601%) in intersection
    featureBits dm2 est
#30993609 bases of 131698467 (23.534%) in intersection
    # Clean up:
    rm -rf work/initial.dm2


# PRODUCING GENSCAN PREDICTIONS (DONE 9/10/04 angie)
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    ssh hgwdev
    mkdir /cluster/data/dm2/bed/genscan
    cd /cluster/data/dm2/bed/genscan
    cvs co hg3rdParty/genscanlinux
    ssh kksilo
    cd /cluster/data/dm2/bed/genscan
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    # Make hard-masked contigs
    foreach f (/cluster/data/dm2/?{,?}/chr*/chr?{,?}_?{,?}.fa)
      maskOutFa $f hard $f.masked
    end
    # Generate a list file, contigs.list, of all the hard-masked contigs that 
    # *do not* consist of all-N's (which would cause genscan to blow up)
    rm -f contigs.list
    touch contigs.list
    foreach f ( `ls -1S /cluster/data/dm2/?{,?}/chr*/chr?{,?}{,_random}_?{,?}.fa.masked` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> contigs.list
    end
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 contigs.list single gsub jobList
    # Run on small cluster -- genscan needs big mem.
    ssh kki
    cd /cluster/data/dm2/bed/genscan
    para create jobList
    para try, check, push, check, ...
#Completed: 81 of 81 jobs
#Average job time:                  48s       0.80m     0.01h    0.00d
#Longest job:                      212s       3.53m     0.06h    0.00d
#Submission to last job:           589s       9.82m     0.16h    0.01d

    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    
    # Convert these to chromosome level files as so:
    ssh kksilo
    cd /cluster/data/dm2/bed/genscan
    liftUp genscan.gtf ../../jkStuff/liftAll.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ../../jkStuff/liftAll.lft warn subopt/*.bed
    cat pep/*.pep > genscan.pep

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/dm2/bed/genscan
    ldHgGene -gtf dm2 genscan genscan.gtf
    hgPepPred dm2 generic genscanPep genscan.pep
    hgLoadBed dm2 genscanSubopt genscanSubopt.bed
    featureBits dm2 genscan
#24711981 bases of 131698467 (18.764%) in intersection


# MAKE DOWNLOADABLE FILES (DONE 1/26/05 angie)
    ssh kksilo
    cd /cluster/data/dm2
    mkdir zips
    zip -j zips/chromOut.zip ?{,?}/chr?{,?}.fa.out
    zip -j zips/chromFa.zip ?{,?}/chr?{,?}.fa
    foreach f (?{,?}/chr?{,?}.fa)
      maskOutFa $f hard $f.masked
    end
    zip -j zips/chromFaMasked.zip ?{,?}/chr?{,?}.fa.masked
    cd bed/simpleRepeat
    zip ../../zips/chromTrf.zip trfMaskChrom/chr*.bed
    cd ../..
    # Make a starter mrna.zip -- it will get updated regularly on the RR. 
    /cluster/data/genbank/bin/i386/gbGetSeqs -gbRoot=/cluster/data/genbank \
      -db=dm2 -native genbank mrna zips/mrna.fa
    gzip zips/mrna.fa
    foreach f (zips/*.zip)
      echo $f
      unzip -t $f | tail -1
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2
    cd /usr/local/apache/htdocs/goldenPath/dm2
    mkdir bigZips database
    # Create README.txt files in bigZips/ and database/ to explain the files.
    cp -p /cluster/data/dm2/zips/*.{zip,gz} bigZips
    cd bigZips
    md5sum *.{zip,gz} > md5sum.txt


# BLASTZ D.PSEUDOOBSCURA (DONE 9/10/04 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    ln -s blastz.dp2.2004-09-10 /cluster/data/dm2/bed/blastz.dp2
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.pseudoobscura
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. pseudoobscura
SEQ2_DIR=/iscratch/i/dp2/nib
SEQ2_SMSK=
SEQ2_FLAG=-drosophila
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.dp2.2004-09-10

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy
    # run bash shell if you don't already:
    bash
    source DEF
    mkdir run
    /cluster/bin/scripts/blastz-make-joblist $DEF > $BASE/run/j
    sh ./xdir.sh
    cd run
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    mv j2 j
    # cluster run
    ssh kk
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run
    para create j
    para try, check, push, check, ....
#Completed: 17457 of 17457 jobs
#Average job time:                  11s       0.18m     0.00h    0.00d
#Longest job:                      295s       4.92m     0.08h    0.00d
#Submission to last job:          3337s      55.62m     0.93h    0.04d

    # back in the bash shell on kksilo...
    mkdir /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run.1
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run.1
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                  19s       0.31m     0.01h    0.00d
#Longest job:                       25s       0.42m     0.01h    0.00d
#Submission to last job:            41s       0.68m     0.01h    0.00d
    cd ..
    rm -r raw

    # Translate .lav to axt, with dp2 in scaffold coords for collaborators:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    mkdir axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin /cluster/data/dm2/nib /cluster/data/dp2/nib stdout \
        | axtSort stdin ../../$out
      popd
    end


# CHAIN PSEUDOOBSCURA BLASTZ (DONE 9/10/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/dp2/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                   7s       0.12m     0.00h    0.00d
#Longest job:                       16s       0.27m     0.00h    0.00d
#Submission to last job:            16s       0.27m     0.00h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDp2 $i
    end


# NET PSEUDOOBSCURA BLASTZ (DONE 9/11/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    netClass -noAr noClass.net dm2 dp2 pseudoobscura.net \
    |& g -v "table gap doesn't exist"

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    rm noClass.net
    netFilter -syn pseudoobscura.net > pseudoobscuraSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    netFilter -minGap=10 pseudoobscura.net |  hgLoadNet dm2 netDp2 stdin
    netFilter -minGap=10 pseudoobscuraSyn.net \
    | hgLoadNet dm2 netSyntenyDp2 stdin


# GENERATE DP2 MAF FOR MULTIZ FROM NET (DONE 9/11/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp2.2004-09-10/axtChain
    netSplit pseudoobscura.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/dp2/nib stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/dp2/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=dp2.
    end


# MAKE VSDP2 DOWNLOADABLES (DONE 2/15/05 angie)
    ssh kksilo
    mkdir -p /cluster/data/dm2/zips/axtNet
    gzip -c \
      /cluster/data/dm2/bed/blastz.dp2/axtChain/all.chain \
      > /cluster/data/dm2/zips/pseudoobscura.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.dp2/axtChain/pseudoobscura.net \
      > /cluster/data/dm2/zips/pseudoobscura.net.gz
    foreach f (/cluster/data/dm2/bed/blastz.dp2/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDp2
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDp2
    mv /cluster/data/dm2/zips/pseu*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# BLASTZ ANOPHELES (DONE 9/13/04 angie)
    # Will give human-fugu params a try... but without abridging repeats 
    # since I don't know which are lin-spec for fly vs. mosquito, and don't 
    # want to bother Arian or speculate.
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    cat << '_EOF_' > DEF
# D.melanogaster vs. A. gambiae
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - A. gambiae
SEQ2_DIR=/iscratch/i/anoGam1/nib
SEQ2_SMSK=
SEQ2_FLAG=-anopheles
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.anoGam1.2004-09-13

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy
    # run bash shell if you don't already:
    bash
    source DEF
    mkdir run
    /cluster/bin/scripts/blastz-make-joblist $DEF > $BASE/run/j
    sh ./xdir.sh
    cd run
    sed -e 's#^#/cluster/bin/penn/#' j > j2
    wc -l j*
    head j2
    mv j2 j
    # cluster run
    ssh kk
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run
    para create j
    para try, check, push, check, ....
#Completed: 759 of 759 jobs
#Average job time:                 350s       5.84m     0.10h    0.00d
#Longest job:                     1111s      18.52m     0.31h    0.01d
#Submission to last job:          1911s      31.85m     0.53h    0.02d

    # back on kksilo...
    mkdir /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run.1
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run.1
    # create a new job list to convert out files to lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                   5s       0.09m     0.00h    0.00d
#Longest job:                       10s       0.17m     0.00h    0.00d
#Submission to last job:            15s       0.25m     0.00h    0.00d
    cd ..
    rm -r raw

    # third run: lav -> axt
    # Don't need to rescore (even though non-default BLASTZ_Q matrix was used)
    # because repeats were not abridged.
    ssh kki
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    mkdir axtChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| lavToAxt stdin \
    /iscratch/i/dm2/nib /iscratch/i/anoGam1/nib stdout \
| axtSort stdin ../../axtChrom/$chr.axt 
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 13 of 13 jobs
#Average job time:                   6s       0.10m     0.00h    0.00d
#Longest job:                       12s       0.20m     0.00h    0.00d
#Submission to last job:            14s       0.23m     0.00h    0.00d


# CHAIN ANOPHELES BLASTZ (DONE 9/13/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/anoGam1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  12s       0.19m     0.00h    0.00d
#Longest job:                       17s       0.28m     0.00h    0.00d
#Submission to last job:            19s       0.32m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainAnoGam1 $i
    end


# NET ANOPHELES BLASTZ (DONE 9/13/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    netClass -noAr noClass.net dm2 anoGam1 anopheles.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    rm noClass.net
    netFilter -syn anopheles.net > anophelesSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    netFilter -minGap=10 anopheles.net |  hgLoadNet dm2 netAnoGam1 stdin
    netFilter -minGap=10 anophelesSyn.net | hgLoadNet dm2 netSyntenyAnoGam1 stdin


# MAKE VSANOGAM1 DOWNLOADABLES (DONE 1/28/05 angie)
    ssh kksilo
    gzip -c \
      /cluster/data/dm2/bed/blastz.anoGam1/axtChain/all.chain \
      > /cluster/data/dm2/zips/anopheles.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.anoGam1/axtChain/anopheles.net \
      > /cluster/data/dm2/zips/anopheles.net.gz
    mkdir -p /cluster/data/dm2/zips/axtNet
    foreach f (/cluster/data/dm2/bed/blastz.anoGam1/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsAnoGam1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsAnoGam1
    mv /cluster/data/dm2/zips/ano*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# GENERATE ANOGAM1 MAF FOR MULTIZ FROM NET (DONE 9/13/04 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/axtChain
    netSplit anopheles.net net
    cd /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/dm2/nib \
        /cluster/data/anoGam1/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/anoGam1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=anoGam1.
    end


# MULTIZ MELANOGASTER/YAKUBA/PSEUDOOBSCURA/ANOPHELES (DONE 9/22/04 angie)
    # put the MAFs on bluearc
    ssh kksilo
    mkdir -p /cluster/bluearc/multiz.flymo/my
    cp /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/mafNet/*.maf \
      /cluster/bluearc/multiz.flymo/my
    mkdir -p /cluster/bluearc/multiz.flymo/mp
    cp /cluster/data/dm2/bed/blastz.dp2.2004-09-10/mafNet/*.maf \
      /cluster/bluearc/multiz.flymo/mp
    mkdir -p /cluster/bluearc/multiz.flymo/ma
    cp /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/mafNet/*.maf \
      /cluster/bluearc/multiz.flymo/ma

    ssh kki
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1
    mkdir mypa
    # Use PSU's new var_multiz:
    cat << '_EOF_' > doMultiz
#!/bin/csh -ef
set path = (/cluster/bin/penn/var_multiz.2004.08.12 $path)
set chr = $1:t:r
if (-s $1 && -s $2) then
  set tmp = /scratch/$chr.tmp.maf
  var_multiz $1 $2 0 0 > $tmp
  maf_project $tmp dm2.$chr > /scratch/$chr.myp.maf
  rm $tmp
else if (-s $1) then
  cp $1 /scratch/$chr.myp.maf
else if (-s $2) then
  cp $2 /scratch/$chr.myp.maf
endif
if (-s /scratch/$chr.myp.maf && -s $3) then
  set tmp = /scratch/$chr.tmp.maf
  var_multiz /scratch/$chr.myp.maf $3 1 0 > $tmp
  maf_project $tmp dm2.$chr > $4
  rm $tmp
else if (-s /scratch/$chr.myp.maf) then
  cp /scratch/$chr.myp.maf $4
else if (-s $3) then
  cp $3 $4
endif
rm /scratch/$chr.myp.maf
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doMultiz
    cp /dev/null jobList
    foreach chr (`awk '{print $1;}' /cluster/data/dm2/chrom.sizes`)
      set f1 = /cluster/bluearc/multiz.flymo/my/$chr.maf
      set f2 = /cluster/bluearc/multiz.flymo/mp/$chr.maf
      set f3 = /cluster/bluearc/multiz.flymo/ma/$chr.maf
      echo "doMultiz $f1 $f2 $f3 mypa/$chr.maf" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 13 of 13 jobs
#Average job time:                 246s       4.09m     0.07h    0.00d
#Longest job:                      811s      13.52m     0.23h    0.01d
#Submission to last job:           811s      13.52m     0.23h    0.01d
    du -sh mypa
#417M    mypa

    # clean up bluearc
    rm -r /cluster/bluearc/multiz.flymo

    # setup external files for database reference
    ssh hgwdev
    mkdir /gbdb/dm2/mzDy1Dp2Ag1_phast
    ln -s /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/mypa/chr*.maf \
      /gbdb/dm2/mzDy1Dp2Ag1_phast/
    # load into database
    cd /tmp
    hgLoadMaf -warn dm2 mzDy1Dp2Ag1_phast
    cd /gbdb/dm2
    mkdir d_pseudoobscura_mypa d_yakuba_mypa a_gambiae_mypa
    cd /tmp
    ln -s /cluster/data/dm2/bed/blastz.dp2.2004-09-10/mafNet/*.maf \
      /gbdb/dm2/d_pseudoobscura_mypa
    hgLoadMaf -WARN dm2 d_pseudoobscura_mypa
    ln -s /cluster/data/dm2/bed/blastz.droYak1.2004-09-10/mafNet/*.maf \
      /gbdb/dm2/d_yakuba_mypa
    hgLoadMaf -WARN dm2 d_yakuba_mypa
    ln -s /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/mafNet/*.maf \
      /gbdb/dm2/a_gambiae_mypa
    hgLoadMaf -WARN dm2 a_gambiae_mypa


# PHASTCONS MELANOGASTER/YAKUBA/PSEUDOOBSCURA/ANOPHELES (DONE 9/22/04 angie)
    ssh kksilo
    # copy chrom fa to bluearc, break up the genome-wide MAFs into pieces
    mkdir -p /cluster/bluearc/dm2/chrom
    cp -p /cluster/data/dm2/?{,?}/chr*.fa /cluster/bluearc/dm2/chrom/
    ssh kki
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.split
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.split
    set WINDOWS = /cluster/bluearc/dm2/phastCons/WINDOWS
    rm -fr $WINDOWS
    mkdir -p $WINDOWS
    cat << 'EOF' > doSplit.sh
#!/bin/csh -ef

set PHAST=/cluster/bin/phast
set FA_SRC=/cluster/bluearc/dm2/chrom
set WINDOWS=/cluster/bluearc/dm2/phastCons/WINDOWS

set maf=$1
set c = $maf:t:r
set tmpDir = /scratch/msa_split/$c
rm -rf $tmpDir
mkdir -p $tmpDir
${PHAST}/msa_split $maf -i MAF -M ${FA_SRC}/$c.fa -O dm2,droYak1,dp2,anoGam1 \
   -w 1000000,0 -r $tmpDir/$c -o SS -I 1000 -B 5000
cd $tmpDir
foreach file ($c.*.ss)
  gzip -c $file > ${WINDOWS}/$file.gz
end
rm -f $tmpDir/$c.*.ss
rmdir $tmpDir
'EOF'
# << for emacs
    chmod a+x doSplit.sh
    rm -f jobList
    foreach file (/cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/mypa/*.maf) 
      if (-s $file) then
        echo "doSplit.sh {check in line+ $file}" >> jobList
      endif
    end
    para create jobList
    para try,  check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  23s       0.38m     0.01h    0.00d
#Longest job:                       53s       0.88m     0.01h    0.00d
#Submission to last job:            53s       0.88m     0.01h    0.00d
    cd ..

    # use the model previously estimated (see makeDm1.doc) as a starting model
    sed -e 's/dm1/dm2/g' /cluster/data/dm1/bed/phastCons4way/rev-dg.mod \
      > starting-tree.mod
    # -- Because of the very long branch length to anoGam1 being pretty 
    # much impossible to estimate from alignment data, edit that file to 
    # reduce the anoGam1 branch length from 2.66 to 0.5.  Otherwise 
    # estimation process blows up.  So our starting tree becomes
#TREE: (((dm2:0.058,droYak1:0.074):0.133,dp2:0.200):0,anoGam1:0.5);

    # Get genome-wide average GC content (for all species together,
    # not just the reference genome).  If you have a globally
    # estimated tree model, as above, you can get this from the
    # BACKGROUND line in the .mod file.  E.g.,
# ALPHABET: A C G T
# ...
# BACKGROUND: 0.276938 0.223190 0.223142 0.276730
    # add up the C and G:
    awk '$1 == "BACKGROUND:" {printf "%0.3f\n", $3 + $4;}' starting-tree.mod
#0.446
    # Great, use 0.446 as the --gc parameter in phastCons below:.

    # Now set up cluster job to estimate model parameters.  
    # Parameters will be estimated separately for each alignment fragment 
    # then will be combined across fragments.
    # Use --gc from above, and --target-coverage computed as follows:
    # 1. Jim would like phastConsElements coverage to be 25% for fly.
    # 2. 83% of dm2 is covered by chainDroYak1Link, so use .25 / .83 = .30 
    #    as an initial --target-coverage.
    # 3. If actual coverage is different from our target, come back to this 
    #    step, adjust --target-coverage and rerun up through phastConsElements.
    # -- Actually, Adam suggests starting with what proved to work for worm:
    #    --target-coverage 0.4 and --expected-lengths 25 (not 12 as for mammal)
    # -- OK, that led to too-high coverage:
    # 51511266 bases of 131698467 (39.113%) in intersection
    #    so next try 0.3, 30:
    # 49886398 bases of 131698467 (37.879%) in intersection
    #   how about 0.3, 20?
    # 42067218 bases of 131698467 (31.942%) in intersection
    #   0.25, 20?
    # 38397215 bases of 131698467 (29.155%) in intersection
    #   0.25, 15?
    # 35039841 bases of 131698467 (26.606%) in intersection
    # -- that's close enough to the target.  If the "bumpiness" of the 
    #    wiggle looks aesthetically pleasing then we're done.
    # -- OK, Adam would like to see more smoothing so that coding exons 
    #    stand out better, so try 0.20, 25:
    # 37574714 bases of 131698467 (28.531%) in intersection
    # More smooting would be nice for coding exons, so tried 0.20, 50, 
    # but Adam didn't like that as much overall so stick with 0.20, 25.  

    mkdir run.estimate
    cd run.estimate
    cat << '_EOF_' > doEstimate.sh
#!/bin/csh -ef
zcat $1 \
| /cluster/bin/phast/phastCons - ../starting-tree.mod --gc 0.435 --nrates 1,1 \
    --no-post-probs --ignore-missing --expected-lengths 25 \
    --target-coverage 0.20 --quiet --log $2 --estimate-trees $3
'_EOF_'
# << for emacs
    chmod a+x doEstimate.sh
    rm -fr LOG TREES
    mkdir -p LOG TREES
    rm -f jobList
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*.ss.gz)
      set root = $f:t:r:r
      echo doEstimate.sh $f LOG/$root.log TREES/$root >> jobList
    end
    # run cluster job
    ssh kk9
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.estimate
    para create jobList
    para try, check, push, check, ...
#Completed: 139 of 139 jobs
#Average job time:                 133s       2.22m     0.04h    0.00d
#Longest job:                      221s       3.68m     0.06h    0.00d
#Submission to last job:           328s       5.47m     0.09h    0.00d

    # Now combine parameter estimates.  We can average the .mod files
    # using phyloBoot.  This must be done separately for the conserved
    # and nonconserved models
    ssh kksilo
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.estimate
    ls -1 TREES/*.cons.mod > cons.txt
    /cluster/bin/phast/phyloBoot --read-mods '*cons.txt' \
      --output-average ave.cons.mod > cons_summary.txt
    ls -1 TREES/*.noncons.mod > noncons.txt
    /cluster/bin/phast/phyloBoot --read-mods '*noncons.txt' \
      --output-average ave.noncons.mod > noncons_summary.txt
    grep TREE ave*.mod
#ave.cons.mod:TREE: (((dm2:0.028707,droYak1:0.019740):0.039091,dp2:0.065825):0.086142,anoGam1:0.086142);
#ave.noncons.mod:TREE: (((dm2:0.118202,droYak1:0.079147):0.162923,dp2:0.275544):0.360361,anoGam1:0.360361);
    # look over the files cons_summary.txt and noncons_summary.txt.
    # The means and medians should be roughly equal and the stdevs
    # should be reasonably small compared to the means, particularly
    # for rate matrix parameters (at bottom) and for branches to the
    # leaves of the tree.  The stdevs may be fairly high for branches
    # near the root of the tree; that's okay.  Some min values may be
    # 0 for some parameters.  That's okay, but watch out for very large
    # values in the max column, which might skew the mean.  If you see
    # any signs of bad outliers, you may have to track down the
    # responsible .mod files and throw them out.  I've never had to do
    # this; the estimates generally seem pretty well behaved.

    # NOTE: Actually, a random sample of several hundred to a thousand
    # alignment fragments (say, a number equal to the number of
    # available cluster nodes) should be more than adequate for
    # parameter estimation.  If pressed for time, use this strategy.

    # Now we are ready to set up the cluster job for computing the
    # conservation scores and predicted elements.  It's all downhill
    # from here.
    ssh kk9
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.phast
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.phast
    cat << 'EOF' > doPhastCons.sh
#!/bin/csh -ef
set pref = $1:t:r:r
set chr = `echo $pref | awk -F\. '{print $1}'`
set tmpfile = /scratch/phastCons.$$
zcat $1 \
| /cluster/bin/phast/phastCons - \
    ../run.estimate/ave.cons.mod,../run.estimate/ave.noncons.mod \
    --expected-lengths 25 --target-coverage 0.20 --quiet --seqname $chr \
    --idpref $pref \
    --viterbi /cluster/bluearc/dm2/phastCons/ELEMENTS/$pref.bed --score \
    --require-informative 0 \
  > $tmpfile
gzip -c $tmpfile > /cluster/bluearc/dm2/phastCons/POSTPROBS/$pref.pp.gz
rm $tmpfile
'EOF'
# << for emacs
    chmod a+x doPhastCons.sh
    rm -fr /cluster/bluearc/dm2/phastCons/{POSTPROBS,ELEMENTS}
    mkdir -p /cluster/bluearc/dm2/phastCons/{POSTPROBS,ELEMENTS}
    rm -f jobList
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*.ss.gz)
      echo doPhastCons.sh $f >> jobList
    end
    para create jobList
    para try, check, push, check, ...
#Completed: 139 of 139 jobs
#Average job time:                  23s       0.38m     0.01h    0.00d
#Longest job:                       49s       0.82m     0.01h    0.00d
#Submission to last job:            52s       0.87m     0.01h    0.00d

    # back on kksilo:
    # combine predictions and transform scores to be in 0-1000 interval
    # do in a way that avoids limits on numbers of args
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    awk '{printf "%s\t%d\t%d\tlod=%d\t%s\n", $1, $2, $3, $5, $5;}' \
      /cluster/bluearc/dm2/phastCons/ELEMENTS/*.bed \
    | /cluster/bin/scripts/lodToBedScore > all.bed

    ssh hgwdev
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    featureBits dm2 all.bed
#37574714 bases of 131698467 (28.531%) in intersection
    # OK, close enough.
    hgLoadBed dm2 phastConsElements all.bed

    # Create wiggle on the small cluster
    ssh kki
    mkdir /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.wib
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons/run.wib
    rm -rf /cluster/bluearc/dm2/phastCons/wib
    mkdir -p /cluster/bluearc/dm2/phastCons/wib
    cat << 'EOF' > doWigAsciiToBinary
#!/bin/csh -ef
set chr = $1
zcat `ls -1 /cluster/bluearc/dm2/phastCons/POSTPROBS/$chr.*.pp.gz \
      | sort -t\. -k2,2n` \
| wigAsciiToBinary -chrom=$chr \
    -wibFile=/cluster/bluearc/dm2/phastCons/wib/${chr}_phastCons stdin 
'EOF'
# << for emacs
    chmod a+x doWigAsciiToBinary
    rm -f jobList
    foreach chr (`ls -1 /cluster/bluearc/dm2/phastCons/POSTPROBS \
                  | awk -F\. '{print $1}' | sort -u`)
      echo doWigAsciiToBinary $chr >> jobList
    end
    para create jobList
    para try, check, push, check, ...
#Completed: 13 of 13 jobs
#Average job time:                  14s       0.24m     0.00h    0.00d
#Longest job:                       36s       0.60m     0.01h    0.00d
#Submission to last job:            36s       0.60m     0.01h    0.00d

    # back on kksilo, copy wibs, wigs and POSTPROBS (people sometimes want 
    # the raw scores) from bluearc
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    rm -rf wib POSTPROBS
    rsync -av /cluster/bluearc/dm2/phastCons/wib .
    rsync -av /cluster/bluearc/dm2/phastCons/POSTPROBS .

    # load wiggle component of Conservation track
    ssh hgwdev
    mkdir -p /gbdb/dm2/wib/mzDy1Dp2Ag1_phast
    cd /cluster/data/dm2/bed/multiz.droYak1dp2anoGam1/phastCons
    chmod 775 . wib
    chmod 664 wib/*.wib
    ln -s `pwd`/wib/*.wib /gbdb/dm2/wib/mzDy1Dp2Ag1_phast/
    hgLoadWiggle dm2 mzDy1Dp2Ag1_phast_wig \
      -pathPrefix=/gbdb/dm2/wib/mzDy1Dp2Ag1_phast wib/*.wig

#NOT DONE -- still using dm1 for this:
    # make top-5000 list and launcher on Adam's home page:
    sort -k5,5nr raw.bed | head -5000 > top5000.bed
    /cluster/home/acs/bin/make-launcher-with-scores.sh top5000.bed \
      /cse/grads/acs/public_html/dm-top5000-4way \
      "top 5000 conserved elements (4way)" dm2

    # and clean up bluearc.
    rm -r /cluster/bluearc/dm2/phastCons
    rm -r /cluster/bluearc/dm2/chrom


# LIFTOVER BDGP 3.2 ANNOTATIONS FROM DM1 (TEMPORARY) (DONE 9/15/04 angie)
    ssh hgwdev
    mkdir /cluster/data/dm2/bed/bdgp3.2.liftOver
    cd /cluster/data/dm2/bed/bdgp3.2.liftOver
    hgsql dm1 -N -e 'select * from bdgpGene' > dm1.bdgpGene.tab
    hgsql dm1 -N -e 'select * from bdgpNonCoding' > dm1.bdgpNonCoding.tab
    ssh kksilo
    cd /cluster/data/dm2/bed/bdgp3.2.liftOver
# lift files to try out:
# blastz:
#  /cluster/data/dm1/bed/blastz.dm2.2004-09-15/axtChain/dm1ToDm2.over.chain \
# blat on dm1 chroms vs. dm2 2Mb chunks:
#  /cluster/data/dm1/bed/blat.dm2.2004-09-16/dm1ToDm2.over.chain \
# blat on dm1 chroms vs. dm2 3kb chunks:
#  /cluster/data/dm1/bed/blat.dm2.2004-09-17/dm1ToDm2.over.chain \
    liftOver -genePred dm1.bdgpGene.tab \
      /cluster/data/dm1/bed/bedOver/dm1ToDm2.over.chain \
      bdgpLiftGene.tab bdgpLiftGene.unmapped.tab
    liftOver -genePred dm1.bdgpNonCoding.tab \
      /cluster/data/dm1/bed/bedOver/dm1ToDm2.over.chain \
      bdgpLiftNonCoding.tab bdgpLiftNonCoding.unmapped.tab
    # Not perfect but not bad:
    wc -l bdgp*.tab
#  18707 bdgpLiftGene.tab
#     78 bdgpLiftGene.unmapped.tab
#   2134 bdgpLiftNonCoding.tab
#     62 bdgpLiftNonCoding.unmapped.tab

    ssh hgwdev
    cd /cluster/data/dm2/bed/bdgp3.2.liftOver
    ldHgGene -predTab dm2 bdgpLiftGene bdgpLiftGene.tab
    ldHgGene -predTab dm2 bdgpLiftNonCoding bdgpLiftNonCoding.tab
    # Copy over the gene info tables
    hgsql dm2 -e 'create table bdgpLiftGeneInfo (PRIMARY KEY(bdgpName(7)), INDEX(flyBaseId(11))) select * from dm1.bdgpGeneInfo'
    hgsql dm2 -e 'create table bdgpLiftNonCodingInfo (INDEX(bdgpName(16)), INDEX(flyBaseId(11))) select * from dm1.bdgpNonCodingInfo'


# FLYBASE ANNOTATIONS (DONE 1/12/05 angie)
# REPLACED 2/23/05 -- SEE "FLYBASE 4.1" BELOW
    ssh kksilo
    mkdir /cluster/data/dm2/bed/flybase
    cd /cluster/data/dm2/bed/flybase
    foreach c (2L 2R 3L 3R 4 X)
      wget ftp://flybase.net/genomes/Drosophila_melanogaster/dmel_r4.0_20041119/gff/dmel-$c-r4.0.gff.gz
    end
    zcat *.gff.gz > flybase.gff3
    # What data sources are represented in this file?
    grep -v '^#' flybase.gff3 | awk '{print $2 "\t" $3;}' | sort | uniq -c
    # excerpt (many other sources, including blastx:... , sim4:... and 
    # tblastx:...; also various other types for source "."):
  18747 .       CDS
  62629 .       exon
  13472 .       gene
  19301 .       mRNA
     70 .       ncRNA
     40 .       pseudogene
     96 .       rRNA
     28 .       snRNA
     28 .       snoRNA
    288 .       tRNA
  36921 .       transcription_start_site
   1571 .       transposable_element
   4680 .       transposable_element_insertion_site

    # What keywords are defined in the 9th field?
    grep -v '^#' flybase.gff3 \
    | awk '{print $9;}' | perl -wpe 's/=[^;]+;/\n/g; s/=.*$//;' \
    | sort | uniq -c
    # This incarnation of gff3 looks similar to the one encountered in 
    # dp3, but still uses slightly different keywords and there are different 
    # data sources of interest.  So one-shot perl-script again:
    extractGenes.pl flybase.gff3

    # Get predicted proteins (for main annotations only)
    wget ftp://flybase.net/genomes/Drosophila_melanogaster/dmel_r4.0_20041119/fasta/dmel-all-translation-r4.0.fasta.gz
    zcat dmel-all-translation-r4.0.fasta.gz \
    | perl -wpe 's/^(>\w+)-P(\w)/$1-R$2/' > flybasePep.fa

    ssh hgwdev
    cd /cluster/data/dm2/bed/flybase
    # Protein-coding genes:
    ldHgGene -gtf dm2 flyBaseGene flybase.gtf
    hgPepPred dm2 generic flyBasePep flybasePep.fa
    # Noncoding genes:
    hgLoadBed dm2 flyBaseNoncoding flyBaseNoncoding.bed
    # Cross-referencing info for both coding and noncoding:
    hgsql dm2 < $HOME/kent/src/hg/lib/flyBase2004Xref.sql
    hgsql dm2 -e 'load data local infile "flyBase2004Xref.tab" \
      into table flyBase2004Xref'

    # add upstream* downloadable files (added 2/10/05)
    cd /usr/local/apache/htdocs/goldenPath/dm2/bigZips
    foreach size (1000 2000 5000)
      echo upstream$size
      featureBits dm2 flyBaseGene:upstream:$size -fa=stdout \
      | gzip -c > upstream$size.fa.gz
    end
    md5sum upstream*.fa.gz >> md5sum.txt


# BLASTZ D. PSEUDOOBSCURA (DP3) (DONE 1/18/05 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.dp3.2005-01-17
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17
    ln -s blastz.dp3.2005-01-17 /cluster/data/dm2/bed/blastz.dp3
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.pseudoobscura
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
# unused: SEQ1_RMSK=
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. pseudoobscura
SEQ2_DIR=/iscratch/i/dp3/nib
# unused: SEQ2_RMSK=
SEQ2_SMSK=
SEQ2_FLAG=-drosophila
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.dp3.2005-01-17

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Create run dir, job list, and raw/ dir structure:
    mkdir run
    ~/kent/src/utils/blastz-make-joblist DEF \
      /cluster/data/dm2/chrom.sizes /cluster/data/dp3/chrom.sizes \
    > run/j
    csh -ef ./xdir.sh
    cd run
    # cluster run
    ssh kk
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/run
    para create j
    para try, check, push, check, ....
#Completed: 552 of 552 jobs
#Average job time:                 226s       3.76m     0.06h    0.00d
#Longest job:                     3617s      60.28m     1.00h    0.04d
#Submission to last job:          3625s      60.42m     1.01h    0.04d

    # back on kksilo...
    mkdir /cluster/data/dm2/bed/blastz.dp3.2005-01-17/run.1
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/run.1
    /cluster/bin/scripts/blastz-make-out2lav ../DEF .. > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                   8s       0.13m     0.00h    0.00d
#Longest job:                       14s       0.23m     0.00h    0.00d
#Submission to last job:            21s       0.35m     0.01h    0.00d

    # Translate .lav to axt:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17
    rm -r raw
    mkdir axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin /cluster/data/dm2/nib /cluster/data/dp3/nib stdout \
        | axtSort stdin ../../$out
      popd
    end


# CHAIN PSEUDOOBSCURA BLASTZ (DONE 1/18/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/dp3/nib stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/dp3/nib \
    stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  13s       0.21m     0.00h    0.00d
#Longest job:                       23s       0.38m     0.01h    0.00d
#Submission to last job:            23s       0.38m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDp3 $i
    end


# NET PSEUDOOBSCURA BLASTZ (DONE 1/18/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChain
    netClass -noAr noClass.net dm2 dp3 pseudoobscura.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 pseudoobscura.net |  hgLoadNet dm2 netDp3 stdin


# GENERATE DP3 AXTNET AND MAF FOR MULTIZ (DONE 1/18/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.dp3/axtChain
    netSplit pseudoobscura.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/dp3/dp3.2bit stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/dp3/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=dp3.
    end


# MAKE VSDP3 DOWNLOADABLES (DONE 1/18/05 angie)
    ssh kksilo
    mkdir -p /cluster/data/dm2/zips/axtNet
    gzip -c \
      /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChain/all.chain \
      > /cluster/data/dm2/zips/pseudoobscura.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtChain/pseudoobscura.net \
      > /cluster/data/dm2/zips/pseudoobscura.net.gz
    foreach f (/cluster/data/dm2/bed/blastz.dp3.2005-01-17/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDp3
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDp3
    mv /cluster/data/dm2/zips/pseu*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# BLASTZ.V7 EVAL: BLASTZ D. PSEUDOOBSCURA (DP3) (DONE 1/18/05 angie)
    ssh kk9
    mkdir /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18
    ln -s blastzv7.dp3.2005-01-18 /cluster/data/dm2/bed/blastzv7.dp3
    # Note the full path for BLASTZ so we get blastz.v7 (which is not in 
    # PSU's CVS, argh!):
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.pseudoobscura
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=/cluster/bin/penn/blastz.2004-12-27/blastz-source/blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
# unused: SEQ1_RMSK=
SEQ1_SMSK=
SEQ1_FLAG=-drosophila
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. pseudoobscura
SEQ2_DIR=/iscratch/i/dp3/nib
# unused: SEQ2_RMSK=
SEQ2_SMSK=
SEQ2_FLAG=-drosophila
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastzv7.dp3.2005-01-18

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Create run dir, job list, and raw/ dir structure:
    mkdir run
    ~/kent/src/utils/blastz-make-joblist DEF \
      /cluster/data/dm2/chrom.sizes /cluster/data/dp3/chrom.sizes \
    > run/j
    csh -ef ./xdir.sh
    cd run
    # cluster run
    para create j
    para try, check, push, check, ....
#Completed: 552 of 552 jobs
#Average job time:                 100s       1.66m     0.03h    0.00d
#Longest job:                      480s       8.00m     0.13h    0.01d
#Submission to last job:           733s      12.22m     0.20h    0.01d

    # back on kksilo...
    mkdir /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18/run.1
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18/run.1
    /cluster/bin/scripts/blastz-make-out2lav ../DEF .. > j
    # small cluster run
    ssh kki
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18/run.1
    para create j
    para try, check, push, check, ....
#Completed: 23 of 23 jobs
#Average job time:                   8s       0.14m     0.00h    0.00d
#Longest job:                       29s       0.48m     0.01h    0.00d
#Submission to last job:            60s       1.00m     0.02h    0.00d

    # Translate .lav to axt:
    ssh kksilo
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18
    rm -r raw
    mkdir axtChrom
    foreach c (lav/*)
      pushd $c
      set chr=$c:t
      set out=axtChrom/$chr.axt
      echo "Translating $chr lav to $out"
      cat `ls -1 *.lav | sort -g` \
        | lavToAxt stdin /cluster/data/dm2/nib /cluster/data/dp3/nib stdout \
        | axtSort stdin ../../$out
      popd
    end


# BLASTZ.V7 EVAL: CHAIN PSEUDOOBSCURA BLASTZ (DONE 1/18/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/dp3/nib stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/dp3/nib \
    stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  10s       0.17m     0.00h    0.00d
#Longest job:                       22s       0.37m     0.01h    0.00d
#Submission to last job:            22s       0.37m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastzv7.dp3.2005-01-18/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainBz7Dp3 $i
    end
    # Compare to regular (blastz.v6) chains:
    featureBits dm2 chainDp3Link
#76557614 bases of 131698467 (58.131%) in intersection
    featureBits dm2 chainBz7Dp3Link
#76340831 bases of 131698467 (57.966%) in intersection
    # Looks like v6 found more than v7 in general, but not too different.
    # Look at some cases where blastz.v7 found something but v6 didn't:
    featureBits dm2 chainBz7Dp3Link \!chainDp3Link -minSize=20 -bed=stdout
#chrYh   212776  212811  chrYh.1
...
#chr3R   18027130        18027160        chr3R.59
...
#chr2h   300968  301032  chr2h.1
...
#34843 bases of 131698467 (0.026%) in intersection


    # BLATZ EVAL: D. PSEUDOOBSCURA (DP3) (IN PROGRESS 1/24/05 angie)
    ssh kk9
    mkdir /cluster/data/dm2/bed/blatz.dp3.2004-01-19
    cd /cluster/data/dm2/bed/blatz.dp3.2004-01-19
    mkdir chainRaw
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib \
      /cluster/data/dm2/chrom.sizes > dm2.lst
    partitionSequence.pl 10000000 10000 /iscratch/i/dp3/nib \
      /cluster/data/dp3/chrom.sizes > dp3.lst
    cat << '_EOF_' > gsub
#LOOP
blatz $(path1) $(path2) {check out line chainRaw/$(file1)_$(file2).chain}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst dp3.lst gsub spec
    para create spec
    para try, check, push, check, ...
#Completed: 549 of 552 jobs
#Crashed: 3 jobs
#Average job time:                 289s       4.82m     0.08h    0.00d
#Longest job:                     1664s      27.73m     0.46h    0.02d
#Submission to last job:          6206s     103.43m     1.72h    0.07d
    # With default blatz params, 3 jobs crashed due to out-of-mem, 
    # all others succeeded.  Try again with thresholds more like 
    # blastz human-mouse, i.e. -minGapless=3000?  No, Jim says forget 
    # the crashers for now (narrow down later) and just forge ahead 
    # with the comparison to blastz (v6).
    ssh kksilo
    cd /cluster/data/dm2/bed/blatz.dp3.2004-01-19
    sed -e 's@/iscratch/i/d../nib/@@g; s/.nib//g;' chainRaw/* \
    | chainMergeSort stdin > all.chain
    chainSplit chain all.chain

    # take a look at score distr's -- LOTS of low-scoring chains
    foreach f (chain/*.chain)
      grep ^chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Jim recommends -minScore=5000 for cross-species.  Filter for now:
    mv all.chain all.chain.unfiltered
    chainFilter -minScore=5000 all.chain.unfiltered > all.chain
    chainSplit chain all.chain
    gzip all.chain.unfiltered

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blatz.dp3.2004-01-19/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainBz1Dp3 $i
    end
    # Compare to regular (blastz.v6) chains:
    featureBits dm2 -enrichment flyBaseGene:CDS chainDp3Link
#flyBaseGene:CDS 16.551%, chainDp3Link 58.131%, both 15.303%, cover 92.46%, enrich 1.59x
    featureBits dm2 -enrichment flyBaseGene:CDS chainBz1Dp3Link
#flyBaseGene:CDS 16.551%, chainBz1Dp3Link 79.858%, both 16.179%, cover 97.76%, enrich 1.22x
    # Look at some examples where blatz covers some CDS that blastz doesn't:
    featureBits -chrom=chr3R dm2 flyBaseGene:CDS chainBz1Dp3Link \
      \!chainDp3Link -minSize=30 -bed=/tmp/bz1Cds.bed


# BLASTZ D.YAKUBA (DONE 1/26/05 angie)
    ssh kk
    mkdir /cluster/data/dm2/bed/blastz.droYak1.2005-01-26
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26
    ln -s blastz.droYak1.2005-01-26 /cluster/data/dm2/bed/blastz.droYak1
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.yakuba
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. yakuba
SEQ2_DIR=/iscratch/i/droYak1/nib
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/dm2/bed/blastz.droYak1.2005-01-26

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Partition chroms into 10MB (+10k overlap) chunks and generate parasol 
    # job list.
    cp /cluster/data/dm2/chrom.sizes S1.len
    cp /cluster/data/droYak1/chrom.sizes S2.len
    mkdir lav
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib S1.len \
      > dm2.lst
    partitionSequence.pl 10000000 10000 /iscratch/i/droYak1/nib S2.len \
      > droYak1.lst
    # The total number of jobs/output files is low for fly-fly, so no need 
    # to make multi-level directory structure:
    cat << '_EOF_' > gsub
#LOOP
blastz-run-ucsc $(path1) $(path2) DEF {check out line lav/$(file1)_$(file2).out}
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst droYak1.lst gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 736 of 736 jobs
#Average job time:                 179s       2.98m     0.05h    0.00d
#Longest job:                     2183s      36.38m     0.61h    0.03d
#Submission to last job:          2627s      43.78m     0.73h    0.03d

    # lav -> axt
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26
    mkdir axtChrom runLavToAxt
    cd runLavToAxt
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
set chr = $1
set out = $2
cat ../lav/$chr.*.out \
| lavToAxt stdin /iscratch/i/dm2/nib /iscratch/i/droYak1/nib stdout \
| axtSort stdin $2
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach chr (`awk '{print $1;}' ../S1.len`)
      echo "do.csh $chr {check out exists ../axtChrom/$chr.axt }" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 13 of 13 jobs
#Average job time:                  19s       0.31m     0.01h    0.00d
#Longest job:                       44s       0.73m     0.01h    0.00d
#Submission to last job:            44s       0.73m     0.01h    0.00d


# CHAIN YAKUBA BLASTZ (DONE 1/26/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -verbose=0 $1 /iscratch/i/dm2/nib /iscratch/i/droYak1/nib stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/droYak1/nib stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  23s       0.39m     0.01h    0.00d
#Longest job:                       97s       1.62m     0.03h    0.00d
#Submission to last job:            97s       1.62m     0.03h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDroYak1 $i
    end


# NET YAKUBA BLASTZ (DONE 1/26/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChain
    netClass -noAr noClass.net dm2 droYak1 yakuba.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 yakuba.net |  hgLoadNet dm2 netDroYak1 stdin


# GENERATE DROYAK1 MAF FOR MULTIZ FROM NET (DONE 1/26/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChain
    netSplit yakuba.net net
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/dm2/nib \
        /cluster/data/droYak1/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.my.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/droYak1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=droYak1.
    end
    gzip axtNet/*.axt


# MAKE VSDROYAK1 DOWNLOADABLES (DONE 1/26/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtChain
    gzip -c all.chain > ../../../zips/yakuba.chain.gz
    gzip -c yakuba.net > ../../../zips/yakuba.net.gz
    # axtNet/* already compressed...

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDroYak1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDroYak1
    mv /cluster/data/dm2/zips/yakuba*.gz .
    cp -pR /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# BLASTZ D.ANANASSAE (DONE 1/28/05 angie)
    ssh kk
    mkdir /cluster/data/dm2/bed/blastz.droAna1.2005-01-28
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28
    ln -s blastz.droAna1.2005-01-28 /cluster/data/dm2/bed/blastz.droAna1
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.ananassae
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. ananassae
SEQ2_DIR=/iscratch/i/droAna1
SEQ2_IN_CONTIGS=1
SEQ2_CHUNK=10000000
SEQ2_LAP=10000

BASE=/cluster/data/dm2/bed/blastz.droAna1.2005-01-28

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Partition chroms into 10MB (+10k overlap) chunks and generate parasol 
    # job list.
    cp /cluster/data/dm2/chrom.sizes S1.len
    cp /cluster/data/droAna1/chrom.sizes S2.len
    mkdir lav run
    cd run
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib ../S1.len \
      -xdir xdir.sh -rawDir ../lav \
      > dm2.lst
    sh xdir.sh
    mkdir parts
    partitionSequence.pl 10000000 10000 /iscratch/i/droAna1/droAna1.2bit \
      ../S2.len -lstDir parts \
      > droAna1.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-run-ucsc $(path1) $(path2) ../DEF {check out exists ../lav/$(file1)/$(file1)_$(file2).lav }
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst droAna1.lst gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 460 of 460 jobs
#Average job time:                 352s       5.87m     0.10h    0.00d
#Longest job:                     7540s     125.67m     2.09h    0.09d
#Submission to last job:          7560s     126.00m     2.10h    0.09d

    # Translate .lav to psl:
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28
    mkdir pslChrom
    foreach chr (`awk '{print $1;}' /cluster/data/dm2/chrom.sizes`)
      echo $chr
      cat lav/$chr.*/*.lav \
      | lavToPsl stdin stdout \
      | sort -k 14,14 -k 16n,17n \
      | gzip -c > pslChrom/$chr.psl.gz
    end


# CHAIN ANANASSAE BLASTZ (DONE 1/28/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastz.droAna1.2005-01-28/pslChrom/*.psl.gz \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -psl -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/droAna1/droAna1.2bit stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/droAna1/droAna1.2bit \
    stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  17s       0.28m     0.00h    0.00d
#Longest job:                       54s       0.90m     0.01h    0.00d
#Submission to last job:            54s       0.90m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDroAna1 $i
    end


# NET ANANASSAE BLASTZ (DONE 1/28/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droAna1.2005-01-28/axtChain
    netClass -noAr noClass.net dm2 droAna1 ananassae.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 ananassae.net |  hgLoadNet dm2 netDroAna1 stdin


# GENERATE DROANA1 AXTNET AND MAF FOR MULTIZ (DONE 1/28/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droAna1/axtChain
    netSplit ananassae.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/droAna1/droAna1.2bit stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/droAna1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=droAna1.
    end


# MAKE VSDROANA1 DOWNLOADABLES (DONE 1/28/05 angie)
    ssh kksilo
    gzip -c \
      /cluster/data/dm2/bed/blastz.droAna1/axtChain/all.chain \
      > /cluster/data/dm2/zips/ananassae.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.droAna1/axtChain/ananassae.net \
      > /cluster/data/dm2/zips/ananassae.net.gz
    mkdir -p /cluster/data/dm2/zips/axtNet
    foreach f (/cluster/data/dm2/bed/blastz.droAna1/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDroAna1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDroAna1
    mv /cluster/data/dm2/zips/ana*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# BLASTZ D.VIRILIS (DONE 1/28/05 angie)
    ssh kk
    mkdir /cluster/data/dm2/bed/blastz.droVir1.2005-01-28
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28
    ln -s blastz.droVir1.2005-01-28 /cluster/data/dm2/bed/blastz.droVir1
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.virilis
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. virilis
SEQ2_DIR=/iscratch/i/droVir1
SEQ2_IN_CONTIGS=1
SEQ2_CHUNK=5000000
SEQ2_LAP=10000

BASE=/cluster/data/dm2/bed/blastz.droVir1.2005-01-28

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Partition chroms into 10MB (+10k overlap) chunks and generate parasol 
    # job list.
    cp /cluster/data/dm2/chrom.sizes S1.len
    cp /cluster/data/droVir1/chrom.sizes S2.len
    mkdir run
    cd run
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib ../S1.len \
      -xdir xdir.sh -rawDir ../lav \
      > dm2.lst
    sh xdir.sh
    mkdir parts
    partitionSequence.pl 5000000 10000 /iscratch/i/droVir1/droVir1.2bit \
      ../S2.len -lstDir parts \
      > droVir1.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-run-ucsc $(path1) $(path2) ../DEF {check out exists ../lav/$(file1)/$(file1)_$(file2).lav }
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst droVir1.lst gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 1196 of 1196 jobs
#Average job time:                 208s       3.46m     0.06h    0.00d
#Longest job:                     2432s      40.53m     0.68h    0.03d
#Submission to last job:          2720s      45.33m     0.76h    0.03d

    # Translate .lav to psl:
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28
    mkdir pslChrom
    foreach chr (`awk '{print $1;}' /cluster/data/dm2/chrom.sizes`)
      echo $chr
      cat lav/$chr.*/*.lav \
      | lavToPsl stdin stdout \
      | sort -k 14,14 -k 16n,17n \
      | gzip -c > pslChrom/$chr.psl.gz
    end


# CHAIN VIRILIS BLASTZ (DONE 1/28/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastz.droVir1.2005-01-28/pslChrom/*.psl.gz \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -psl -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/droVir1/droVir1.2bit stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/droVir1/droVir1.2bit \
    stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  11s       0.18m     0.00h    0.00d
#Longest job:                       25s       0.42m     0.01h    0.00d
#Submission to last job:            25s       0.42m     0.01h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDroVir1 $i
    end


# NET VIRILIS BLASTZ (DONE 1/28/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droVir1.2005-01-28/axtChain
    netClass -noAr noClass.net dm2 droVir1 virilis.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 virilis.net |  hgLoadNet dm2 netDroVir1 stdin


# GENERATE DROVIR1 AXTNET AND MAF FOR MULTIZ (DONE 1/28/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droVir1/axtChain
    netSplit virilis.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/droVir1/droVir1.2bit stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/droVir1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=droVir1.
    end


# MAKE VSDROVIR1 DOWNLOADABLES (DONE 1/28/05 angie)
    ssh kksilo
    gzip -c \
      /cluster/data/dm2/bed/blastz.droVir1/axtChain/all.chain \
      > /cluster/data/dm2/zips/virilis.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.droVir1/axtChain/virilis.net \
      > /cluster/data/dm2/zips/virilis.net.gz
    mkdir -p /cluster/data/dm2/zips/axtNet
    foreach f (/cluster/data/dm2/bed/blastz.droVir1/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDroVir1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDroVir1
    mv /cluster/data/dm2/zips/vir*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# BLASTZ D.MOJAVENSIS (DONE 1/28/05 angie)
    ssh kk
    mkdir /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28
    ln -s blastz.droMoj1.2005-01-28 /cluster/data/dm2/bed/blastz.droMoj1
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.mojavensis
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - D. mojavensis
SEQ2_DIR=/iscratch/i/droMoj1
SEQ2_IN_CONTIGS=1
SEQ2_CHUNK=5000000
SEQ2_LAP=10000

BASE=/cluster/data/dm2/bed/blastz.droMoj1.2005-01-28

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Partition chroms into 10MB (+10k overlap) chunks and generate parasol 
    # job list.
    cp /cluster/data/dm2/chrom.sizes S1.len
    cp /cluster/data/droMoj1/chrom.sizes S2.len
    mkdir run
    cd run
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib ../S1.len \
      -xdir xdir.sh -rawDir ../lav \
      > dm2.lst
    sh xdir.sh
    mkdir parts
    partitionSequence.pl 5000000 10000 /iscratch/i/droMoj1/droMoj1.2bit \
      ../S2.len -lstDir parts \
      > droMoj1.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-run-ucsc $(path1) $(path2) ../DEF {check out exists ../lav/$(file1)/$(file1)_$(file2).lav }
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst droMoj1.lst gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 897 of 897 jobs
#Average job time:                 315s       5.25m     0.09h    0.00d
#Longest job:                     1599s      26.65m     0.44h    0.02d
#Submission to last job:          1714s      28.57m     0.48h    0.02d

    # Translate .lav to psl:
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28
    mkdir pslChrom
    foreach chr (`awk '{print $1;}' /cluster/data/dm2/chrom.sizes`)
      echo $chr
      cat lav/$chr.*/*.lav \
      | lavToPsl stdin stdout \
      | sort -k 14,14 -k 16n,17n \
      | gzip -c > pslChrom/$chr.psl.gz
    end


# CHAIN MOJAVENSIS BLASTZ (DONE 1/28/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28/pslChrom/*.psl.gz \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -psl -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/droMoj1/droMoj1.2bit stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/droMoj1/droMoj1.2bit \
    stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                   6s       0.09m     0.00h    0.00d
#Longest job:                       11s       0.18m     0.00h    0.00d
#Submission to last job:            11s       0.18m     0.00h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainDroMoj1 $i
    end


# NET MOJAVENSIS BLASTZ (DONE 1/28/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28/axtChain
    netClass -noAr noClass.net dm2 droMoj1 mojavensis.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 mojavensis.net |  hgLoadNet dm2 netDroMoj1 stdin


# GENERATE DROMOJ1 AXTNET AND MAF FOR MULTIZ (DONE 1/28/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.droMoj1/axtChain
    netSplit mojavensis.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/droMoj1/droMoj1.2bit stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/droMoj1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=droMoj1.
    end


# MAKE VSDROMOJ1 DOWNLOADABLES (DONE 1/28/05 angie)
    ssh kksilo
    gzip -c \
      /cluster/data/dm2/bed/blastz.droMoj1/axtChain/all.chain \
      > /cluster/data/dm2/zips/mojavensis.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.droMoj1/axtChain/mojavensis.net \
      > /cluster/data/dm2/zips/mojavensis.net.gz
    mkdir -p /cluster/data/dm2/zips/axtNet
    foreach f (/cluster/data/dm2/bed/blastz.droMoj1/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsDroMoj1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsDroMoj1
    mv /cluster/data/dm2/zips/moj*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# BLASTZ A.MELLIFERA (DONE 1/28/05 angie)
    # Use human-fugu sensitivity settings, as with mosquito.
    ssh kk
    mkdir /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28
    ln -s blastz.apiMel1.2005-01-28 /cluster/data/dm2/bed/blastz.apiMel1
    cat << '_EOF_' > DEF
# D.melanogaster vs. A.mellifera
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - A. mellifera
SEQ2_DIR=/iscratch/i/apiMel1
SEQ2_IN_CONTIGS=1
SEQ2_CHUNK=5000000
SEQ2_LAP=10000

BASE=/cluster/data/dm2/bed/blastz.apiMel1.2005-01-28

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

'_EOF_'
    # << this line keeps emacs coloring happy

    # Partition chroms into 10MB (+10k overlap) chunks and generate parasol 
    # job list.
    cp /cluster/data/dm2/chrom.sizes S1.len
    cp /cluster/data/apiMel1/chrom.sizes S2.len
    mkdir run
    cd run
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib ../S1.len \
      -xdir xdir.sh -rawDir ../lav \
      > dm2.lst
    sh xdir.sh
    mkdir parts
    partitionSequence.pl 5000000 10000 /iscratch/i/apiMel1/apiMel1.2bit \
      ../S2.len -lstDir parts \
      > apiMel1.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/scripts/blastz-run-ucsc $(path1) $(path2) ../DEF {check out exists ../lav/$(file1)/$(file1)_$(file2).lav }
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst apiMel1.lst gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 1035 of 1035 jobs
#Average job time:                 527s       8.79m     0.15h    0.01d
#Longest job:                    10912s     181.87m     3.03h    0.13d
#Submission to last job:         11190s     186.50m     3.11h    0.13d

    # Translate .lav to psl:
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28
    mkdir pslChrom
    foreach chr (`awk '{print $1;}' /cluster/data/dm2/chrom.sizes`)
      echo $chr
      cat lav/$chr.*/*.lav \
      | lavToPsl stdin stdout \
      | sort -k 14,14 -k 16n,17n \
      | gzip -c > pslChrom/$chr.psl.gz
    end


# CHAIN MELLIFERA BLASTZ (DONE 1/31/05 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/pslChrom/*.psl.gz \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh -ef
axtChain -psl -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/apiMel1/apiMel1.2bit stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/apiMel1/apiMel1.2bit \
    stdin $2
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                   7s       0.12m     0.00h    0.00d
#Longest job:                       16s       0.27m     0.00h    0.00d
#Submission to last job:            16s       0.27m     0.00h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=10000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain dm2 ${c}_chainApiMel1 $i
    end


# NET MELLIFERA BLASTZ (DONE 1/31/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/axtChain
    netClass -noAr noClass.net dm2 apiMel1 mellifera.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 mellifera.net |  hgLoadNet dm2 netApiMel1 stdin


# GENERATE APIMEL1 AXTNET AND MAF FOR MULTIZ (DONE 1/31/05 angie)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.apiMel1/axtChain
    netSplit mellifera.net net
    cd ..
    mkdir axtNet
    foreach f (axtChain/net/chr*.net)
      netToAxt $f axtChain/chain/$f:t:r.chain \
        /cluster/data/dm2/nib /cluster/data/apiMel1/apiMel1.2bit stdout \
      | axtSort stdin axtNet/$f:t:r.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.maf
      axtToMaf $f \
            /cluster/data/dm2/chrom.sizes /cluster/data/apiMel1/chrom.sizes \
            $maf -tPrefix=dm2. -qPrefix=apiMel1.
    end


# MAKE VSAPIMEL1 DOWNLOADABLES (DONE 1/31/05 angie)
    ssh kksilo
    gzip -c \
      /cluster/data/dm2/bed/blastz.apiMel1/axtChain/all.chain \
      > /cluster/data/dm2/zips/mellifera.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.apiMel1/axtChain/mellifera.net \
      > /cluster/data/dm2/zips/mellifera.net.gz
    mkdir -p /cluster/data/dm2/zips/axtNet
    foreach f (/cluster/data/dm2/bed/blastz.apiMel1/axtNet/chr*axt)
      gzip -c $f > /cluster/data/dm2/zips/axtNet/$f:t.gz
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsApiMel1
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsApiMel1
    mv /cluster/data/dm2/zips/mel*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# BLASTZ A.MELLIFERA 2.0 (DONE 2/8/05 Andy)
    # Use human-fugu sensitivity settings, as with mosquito.
    ssh kk
    mkdir /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08
    ln -s blastz.apiMel2.2005-01-28 /cluster/data/dm2/bed/blastz.apiMel2
    cat << "_EOF_" > DEF
# D.melanogaster vs. A.mellifera
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=6000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - A. mellifera
SEQ2_DIR=/iscratch/i/apiMel2/nib
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=5000000
SEQ2_LAP=10000

BASE=/cluster/data/dm2/bed/blastz.apiMel2.2005-02-08

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

_EOF_
    # << this line keeps emacs coloring happy

    # Partition chroms into 10MB (+10k overlap) chunks and generate parasol 
    # job list.
    cp /cluster/data/dm2/chrom.sizes S1.len
    cp /cluster/data/apiMel2/chrom.sizes S2.len
    mkdir run
    cd run
    partitionSequence.pl 10000000 10000 /iscratch/i/dm2/nib ../S1.len \
      -xdir xdir.sh -rawDir ../lav \
      > dm2.lst
    sh xdir.sh
    mkdir parts
    partitionSequence.pl 5000000 10000 /iscratch/i/apiMel2/nib \
      ../S2.len -xdir xdir.sh -rawDir parts \
      > apiMel2.lst
    cat << "_EOF_" > gsub
#LOOP
/cluster/bin/scripts/blastz-run-ucsc $(path1) $(path2) ../DEF {check out exists ../lav/$(file1)/$(file1)_$(file2).lav }
#ENDLOOP
_EOF_
    # << this line keeps emacs coloring happy
    gensub2 dm2.lst apiMel2.lst gsub jobList
    para create jobList
    para try, check, push, check, ...
#Completed: 2484 of 2484 jobs
#CPU time in finished jobs:     300981s    5016.34m    83.61h    3.48d  0.010 y
#IO & Wait Time:                 15859s     264.32m     4.41h    0.18d  0.001 y
#Average job time:                 128s       2.13m     0.04h    0.00d
#Longest job:                      839s      13.98m     0.23h    0.01d
#Submission to last job:         26649s     444.15m     7.40h    0.31d

    # Translate .lav to psl:
    ssh kolossus
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08
    mkdir pslChrom axtChrom
    for chr in `cut -f1 /cluster/data/dm2/chrom.sizes`; do
      echo $chr
      cat lav/${chr}.*/*.lav | lavToPsl stdin stdout \
        | sort -k 14,14 -k 16n,17n \
        | gzip -c > pslChrom/$chr.psl.gz
      cat lav/${chr}.*/*.lav | lavToAxt stdin \
          /cluster/data/dm2/nib /cluster/data/apiMel2/nib stdout \
        | axtSort stdin stdout \
        | gzip -c > axtChrom/$chr.axt.gz
    done

# CHAIN MELLIFERA 2.0 BLASTZ (DONE 2/9/05 Andy)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir chain
    ls -1S /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/pslChrom/*.psl.gz \
      > input.lst
    cat << "_EOF_" > gsub
#LOOP
/cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain/run1/doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain}
#ENDLOOP
_EOF_
    # << this line makes emacs coloring happy

    cat << "_EOF_" > doChain
#!/bin/bash
axtChain -psl -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -verbose=0 $1 \
  /iscratch/i/dm2/nib \
  /iscratch/i/apiMel2/nib stdout \
| chainAntiRepeat /iscratch/i/dm2/nib /iscratch/i/apiMel2/nib \
    stdin $2
_EOF_
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 13 of 13 jobs
#CPU time in finished jobs:        312s       5.21m     0.09h    0.00d  0.000 y
#IO & Wait Time:                    96s       1.59m     0.03h    0.00d  0.000 y
#Average job time:                  31s       0.52m     0.01h    0.00d
#Longest job:                       61s       1.02m     0.02h    0.00d
#Submission to last job:            61s       1.02m     0.02h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's (Need to do this later)
    #foreach f (chain/*.chain)
    #  grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
    #  echo $f:t:r
    #  textHistogram -binSize=10000 /tmp/score.$f:t:r
    #  echo ""
    #end
    
    # Load chains into database
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/axtChain/chain
    for chain in *.chain; do
        c=${chain%.chain}
        echo loading $c
        hgLoadChain dm2 ${c}_chainApiMel2 $chain
    done

# NET MELLIFERA 2.0 BLASTZ (DONE 2/9/05 Andy)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain
    netClass -noAr noClass.net dm2 apiMel2 mellifera.net
    rm noClass.net
    # Load the nets into database 
    netFilter -minGap=10 mellifera.net |  hgLoadNet dm2 netApiMel2 stdin

# GENERATE APIMEL2 AXTNET AND MAF FOR MULTIZ (DONE 2/9/05 Andy)
    ssh kksilo
    cd /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain
    netSplit mellifera.net net
    cd ..
    mkdir axtNet
    for net in axtChain/net/chr*.net; do
       chrom=${net##*\/}; chrom=${chrom%.net}
       netToAxt $net axtChain/chain/${chrom}.chain \
         /cluster/data/dm2/nib /cluster/data/apiMel2/nib stdout \
      | axtSort stdin axtNet/${chrom}.axt
    done
    mkdir mafNet
    for axt in axtNet/chr*.axt; do
      maf=${axt##*\/}; maf=mafNet/${maf%.axt}.maf
      axtToMaf $axt /cluster/data/dm2/chrom.sizes \
         /cluster/data/apiMel2/chrom.sizes $maf -tPrefix=dm2. -qPrefix=apiMel2.
    done

# MAKE VSAPIMEL2 DOWNLOADABLES (DONE 2/9/2005 Andy)
    ssh kksilo
    gzip -c \
      /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain/all.chain \
      > /cluster/data/dm2/zips/mellifera.chain.gz
    gzip -c \
      /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtChain/mellifera.net \
      > /cluster/data/dm2/zips/mellifera.net.gz
    mkdir -p /cluster/data/dm2/zips/axtNet
    for axt in /cluster/data/dm2/bed/blastz.apiMel2.2005-02-08/axtNet/chr*axt; do
      zip=${axt##*\/}.gz
      gzip -c $axt > /cluster/data/dm2/zips/axtNet/$zip
    done
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/vsApiMel2
    cd /usr/local/apache/htdocs/goldenPath/dm2/vsApiMel2
    mv /cluster/data/dm2/zips/mel*gz .
    mv /cluster/data/dm2/zips/axtNet .
    md5sum *.gz */*.gz > md5sum.txt
    # Make a README.txt which explains the files & formats.


# MULTIZ.V10 8WAY (6 FLIES, MOSQUITO, HONEYBEE) (REDONE 3/7/05 angie)
# originally done 2/1/05
# REDONE 3/7/05 angie -- User found that yakuba was missing (due to 
# pairwise maf files having different .suffixes, and the script tolerating 
# missing files... yikes!!!).  :(
    # Tree (8-way):
    # ((((((dm2 droYak1) droAna1) dp2) (droVir1 droMoj1)) anoGam1) apiMel1)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/multiz8way.2005-03-07
    ln -s /cluster/data/dm2/bed/multiz8way.2005-03-07 \
      /cluster/data/dm2/bed/multiz8way
    cd /cluster/data/dm2/bed/multiz8way
    # Setup: Copy pairwise MAF to /cluster/bluearc:
    mkdir /cluster/bluearc/flyMultiz8way
    foreach db (droYak1 droAna1 dp2 droVir1 droMoj1 anoGam1 apiMel1)
      cp -pR /cluster/data/dm2/bed/blastz.$db/mafNet \
        /cluster/bluearc/flyMultiz8way/$db
    end
    # Make output dir:
    mkdir maf
    # Create script to run multiz.v10 in the right order:
    cat << '_EOF_' > doMultiz.csh
#!/bin/csh -fe
set chr = $1
set tmp = /scratch/flyMultiz8way.$chr
mkdir $tmp

set REF = dm2.$chr
set YAK = /cluster/bluearc/flyMultiz8way/droYak1/$chr.maf
set ANA = /cluster/bluearc/flyMultiz8way/droAna1/$chr.maf
set PSE = /cluster/bluearc/flyMultiz8way/dp2/$chr.maf
set VIR = /cluster/bluearc/flyMultiz8way/droVir1/$chr.maf
set MOJ = /cluster/bluearc/flyMultiz8way/droMoj1/$chr.maf
set ANO = /cluster/bluearc/flyMultiz8way/anoGam1/$chr.maf
set API = /cluster/bluearc/flyMultiz8way/apiMel1/$chr.maf
set DEST = /cluster/data/dm2/bed/multiz8way/maf/$chr.maf

set MZ10 = /cluster/bin/penn/multiz.v10
set PROJECT = /cluster/bin/penn/maf_project

if ( -s $YAK && -s $ANA ) then 
    echo "Aligning $YAK $ANA..."
    $MZ10 $YAK $ANA 1 > $tmp/$chr.tmp.maf
    echo "Projecting on $REF..."
    $PROJECT $tmp/$chr.tmp.maf $REF > $tmp/$chr.YakAna.maf
else if ( -s $YAK ) then
    cp $YAK $tmp/$chr.YakAna.maf
else if ( -s $ANA ) then
    cp $ANA $tmp/$chr.YakAna.maf
endif

if ( -s $PSE && -s $tmp/$chr.YakAna.maf ) then
    echo "Adding $PSE..."
    $MZ10 $tmp/$chr.YakAna.maf $PSE 1 > $tmp/$chr.tmp.maf
    echo "Projecting on $REF..."
    $PROJECT $tmp/$chr.tmp.maf $REF > $tmp/$chr.YakAnaPse.maf
else if ( -s $PSE ) then
    cp $PSE $tmp/$chr.YakAnaPse.maf
else if ( -s $tmp/$chr.YakAna.maf ) then
    cp $tmp/$chr.YakAna.maf $tmp/$chr.YakAnaPse.maf
endif 

# droVir1 and droMoj1 are a subtree -- run on just them, then fold in:
if ( -s $VIR && -s $MOJ ) then 
    echo "Aligning $VIR $MOJ..."
    $MZ10 $VIR $MOJ 0 > $tmp/$chr.tmp.maf
    echo "Projecting on $REF..."
    $PROJECT $tmp/$chr.tmp.maf $REF > $tmp/$chr.VirMoj.maf
else if ( -s $VIR ) then
    cp $VIR $tmp/$chr.VirMoj.maf
else if ( -s $MOJ ) then
    cp $MOJ $tmp/$chr.VirMoj.maf
endif

if ( -s $tmp/$chr.VirMoj.maf && -s $tmp/$chr.YakAnaPse.maf ) then
    echo "Adding $tmp/$chr.VirMoj.maf..."
    $MZ10 $tmp/$chr.YakAnaPse.maf $tmp/$chr.VirMoj.maf 1 > $tmp/$chr.tmp.maf
    echo "Projecting on $REF..."
    $PROJECT $tmp/$chr.tmp.maf $REF > $tmp/$chr.YakAnaPseVirMoj.maf
else if ( -s $tmp/$chr.VirMoj.maf ) then
    cp $tmp/$chr.VirMoj.maf $tmp/$chr.YakAnaPseVirMoj.maf
else if ( -s $tmp/$chr.YakAnaPse.maf ) then
    cp $tmp/$chr.YakAnaPse.maf $tmp/$chr.YakAnaPseVirMoj.maf
endif 

if ( -s $ANO && -s $tmp/$chr.YakAnaPseVirMoj.maf ) then
    echo "Adding $ANO..."
    $MZ10 $tmp/$chr.YakAnaPseVirMoj.maf $ANO 1 > $tmp/$chr.tmp.maf
    echo "Projecting on $REF..."
    $PROJECT $tmp/$chr.tmp.maf $REF > $tmp/$chr.YakAnaPseVirMojAno.maf
else if ( -s $ANO ) then
    cp $ANO $tmp/$chr.YakAnaPseVirMojAno.maf
else if ( -s $tmp/$chr.YakAnaPseVirMoj.maf ) then
    cp $tmp/$chr.YakAnaPseVirMoj.maf $tmp/$chr.YakAnaPseVirMojAno.maf
endif 

if ( -s $API && -s $tmp/$chr.YakAnaPseVirMojAno.maf ) then
    echo "Adding $API..."
    $MZ10 $tmp/$chr.YakAnaPseVirMojAno.maf $API 1 > $tmp/$chr.tmp.maf
    echo "Projecting on $REF..."
    $PROJECT $tmp/$chr.tmp.maf $REF > $tmp/$chr.final.maf
    cp $tmp/$chr.final.maf $DEST
else if ( -s $API ) then
    cp $API $DEST
else if ( -s $tmp/$chr.YakAnaPseVirMojAno.maf ) then
    cp $tmp/$chr.YakAnaPseVirMojAno.maf $DEST
endif 

rm $tmp/$chr.*.maf
rmdir $tmp
'_EOF_'
    # << keep emacs coloring happy    
    chmod 755 doMultiz.csh
    awk '{print "./doMultiz.csh " $1;}' /cluster/data/dm2/chrom.sizes \
      > jobs.lst
    # Run on small cluster
    ssh kki
    cd /cluster/data/dm2/bed/multiz8way
    para create jobs.lst
    para try, check, push, check, ...
#Completed: 13 of 13 jobs
#Average job time:                 924s      15.40m     0.26h    0.01d
#Longest job:                     3148s      52.47m     0.87h    0.04d
#Submission to last job:          3148s      52.47m     0.87h    0.04d

    # make /gbdb/ links to 8way and pairwise maf files:
    ssh hgwdev
    mkdir -p /gbdb/dm2/multiz8way/maf/multiz8way
    ln -s /cluster/data/dm2/bed/multiz8way/maf/chr*.maf \
      /gbdb/dm2/multiz8way/maf/multiz8way/
    # pairwise setting from trackDb.ra entry:
    set pairwise = 050201
    foreach orgName (droYak1 droAna1 dp2 droVir1 droMoj1 anoGam1 apiMel1)
      mkdir /gbdb/dm2/multiz8way/maf/${orgName}_$pairwise
    end
    ln -s /cluster/data/dm2/bed/blastz.droYak1.2005-01-26/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/droYak1_$pairwise
    ln -s /cluster/data/dm2/bed/blastz.droAna1.2005-01-28/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/droAna1_$pairwise
    ln -s /cluster/data/dm2/bed/blastz.dp2.2004-09-10/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/dp2_$pairwise
    ln -s /cluster/data/dm2/bed/blastz.droVir1.2005-01-28/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/droVir1_$pairwise
    ln -s /cluster/data/dm2/bed/blastz.droMoj1.2005-01-28/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/droMoj1_$pairwise
    ln -s /cluster/data/dm2/bed/blastz.anoGam1.2004-09-13/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/anoGam1_$pairwise
    ln -s /cluster/data/dm2/bed/blastz.apiMel1.2005-01-28/mafNet/*.maf \
      /gbdb/dm2/multiz8way/maf/apiMel1_$pairwise
    # load into database
    cd /tmp
    hgLoadMaf -warn dm2 multiz8way \
      -pathPrefix=/gbdb/dm2/multiz8way/maf/multiz8way
    foreach orgName (droYak1 droAna1 dp2 droVir1 droMoj1 anoGam1 apiMel1)
      hgLoadMaf -WARN dm2 ${orgName}_$pairwise \
        -pathPrefix=/gbdb/dm2/multiz8way/maf/${orgName}_$pairwise
    end

    # put 8way MAF out for download
    ssh kksilo
    cd /cluster/data/dm2/bed/multiz8way
    mkdir mafDownload
    foreach f (maf/*.maf)
      nice gzip -c $f > mafDownload/$f:t.gz
    end
    cd mafDownload
    md5sum *.maf.gz > md5sum.txt
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/dm2/multiz8way
    ln -s /cluster/data/dm2/bed/multiz8way/mafDownload/{*.maf.gz,md5sum.txt} \
      /usr/local/apache/htdocs/goldenPath/dm2/multiz8way
    # make a README.txt

    # Cleanup
    rm -rf /cluster/bluearc/flyMultiz8way/


# PHASTCONS 8WAY WITH METHODS FROM PAPER (DONE 3/8/05 angie)
# originally done 2/2/05
# REDONE 3/8/05 angie -- after regenerating multiz alignments above.
    # Same procedure as for latest dm1 8way -- using the param estimation 
    # methods described in Adam's Genome Research paper.
    ssh kksilo
    mkdir -p /cluster/bluearc/dm2/chrom
    cp -p /cluster/data/dm2/?{,?}/chr*.fa /cluster/bluearc/dm2/chrom/
    # Split chrom fa into smaller windows for phastCons:
    ssh kki
    mkdir /cluster/data/dm2/bed/multiz8way/phastCons
    mkdir /cluster/data/dm2/bed/multiz8way/phastCons/run.split
    cd /cluster/data/dm2/bed/multiz8way/phastCons/run.split
    set WINDOWS = /cluster/bluearc/dm2/phastCons/WINDOWS
    rm -fr $WINDOWS
    mkdir -p $WINDOWS
    cat << 'EOF' > doSplit.sh
#!/bin/csh -ef

set PHAST=/cluster/bin/phast
set FA_SRC=/cluster/bluearc/dm2/chrom
set WINDOWS=/cluster/bluearc/dm2/phastCons/WINDOWS

set maf=$1
set c = $maf:t:r:r
set tmpDir = /scratch/msa_split/$c
rm -rf $tmpDir
mkdir -p $tmpDir
# apiMel1-specific tweak for msa_split:
zcat $1 | perl -wpe 's/(apiMel1\.Group\w+)\.(\d+)/$1_$2/' > $tmpDir/$c.maf
${PHAST}/msa_split $tmpDir/$c.maf -i MAF -M ${FA_SRC}/$c.fa \
   -O dm2,droYak1,droAna1,dp2,droVir1,droMoj1,anoGam1,apiMel1 \
   -w 1000000,0 -r $tmpDir/$c -o SS -I 1000 -B 5000
cd $tmpDir
foreach file ($c.*.ss)
  gzip -c $file > ${WINDOWS}/$file.gz
end
rm -f $tmpDir/$c.maf
rm -f $tmpDir/$c.*.ss
rmdir $tmpDir
'EOF'
# << for emacs
    chmod a+x doSplit.sh
    rm -f jobList
    foreach file (/cluster/data/dm2/bed/multiz8way/maf/*.maf.gz) 
      if (-s $file) then
        echo "doSplit.sh {check in exists+ $file}" >> jobList
      endif
    end
    para create jobList
    para try,  check, push, check...
#Completed: 13 of 13 jobs
#Average job time:                  34s       0.56m     0.01h    0.00d
#Longest job:                       89s       1.48m     0.02h    0.00d
#Submission to last job:            89s       1.48m     0.02h    0.00d

    ssh kolossus
    cd /cluster/data/dm2/bed/multiz8way/phastCons/
    # Use the dm1 8way run's ave.noncons.mod as starting model:
    cp /cluster/data/dm1/bed/multiz8way/phastCons/run.estimate/ave.noncons.mod starting-tree.mod
    # Get genome-wide all-species average GC content from starting-tree.mod
    # by running msa_view --aggregate --summary-only on the WINDOWS .SS files.
    # msa_view needs seekable single-ss file, so unpack each to /tmp and 
    # compute overall average:
    # Note: for larger organisms, this trick can be used to take a random
    # sample of windows:
    # foreach f (`ls -1 /cluster/bluearc/dm2/phastCons/WINDOWS/* \
    #             | randomLines stdin 50 stdout`)
    cp /dev/null gcs.txt
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*)
      zcat $f > /tmp/dm2.sample.ss
      /cluster/bin/phast/msa_view \
        --aggregate dm2,droYak1,droAna1,dp2,droVir1,droMoj1,anoGam1,apiMel1 \
        -i SS --summary-only /tmp/dm2.sample.ss \
      | awk '$1 == "[aggregate]" {printf "%0.4f\n", $3 + $4}' \
      >> gcs.txt
    end
    ave gcs.txt
#average 0.431152
    # OK, so use 0.431 as the --gc parameter below.
    rm /tmp/dm2.sample.ss

    ############### FIRST ITERATION OF PARAMETER ESTIMATION ONLY #############
    # Use consEntropy --NH to make it suggest a --expected-lengths param 
    # that we should try next.  Adam ran this on hg17 to find out the 
    # total entropy of the hg17 model:
    # consEntropy 0.265 12 ave.cons.mod ave.noncons.mod
#Transition parameters: gamma=0.265000, omega=12.000000, mu=0.083333, nu=0.030045
#Relative entropy: H=0.608216 bits/site
#Required length: N=16.085437 sites
#Total entropy: NH=9.783421 bits
    # Our target is that NH result: 9.7834 bits.  
    # Use the values of --target-coverage and --expected-lengths from the 
    # last iteration of the 8way run, 0.565 and 36.
    # Use the 8-way estimated models.  Should be a real headstart relative 
    # to starting from scratch (in which case we would use phyloFit).
    /cluster/bin/phast/consEntropy --NH 9.7834 0.565 36 \
      /cluster/data/dm1/bed/multiz8way/phastCons/run.estimate/ave.{cons,noncons}.mod
#( Solving for new omega: 36.000000 35.981000 )
#Transition parameters: gamma=0.565000, omega=36.000000, mu=0.027778, nu=0.036079
#Relative entropy: H=1.441934 bits/site
#Required length: N=6.786031 sites
#Total entropy: NH=9.785006 bits
#Recommended expected length: omega=35.981000 sites (for NH=9.783400)
    # Good, stick with --expected-lengths 36.

    ############## SUBSEQUENT ITERATIONS OF PARAM ESTIMATION ONLY ###########
    # We're here because the actual target coverage was not satisfactory,
    # so we're changing the --target-coverage param.  Given that we're 
    # changing that, take a guess at how we should change --expected-lengths
    # in order to also hit the total entropy target.
    cd /cluster/data/dm2/bed/multiz8way/phastCons/run.estimate
    # SECOND ITERATION:
    /cluster/bin/phast/consEntropy --NH 9.7834 0.57 36.1 ave.{cons,noncons}.mod
#Recommended expected length: omega=36.534136 sites (for NH=9.783400)
    # OK, --expected-lengths 36.5
    # THIRD ITERATION:
    /cluster/bin/phast/consEntropy --NH 9.7834 0.573 36.5 ave.{cons,noncons}.mod
#Recommended expected length: omega=36.812685 sites (for NH=9.783400)
    # ==> 36.8

    # Now set up cluster job to estimate model parameters given free params 
    # --target-coverage and --expected-lengths and the data.  
    ssh kk9
    mkdir /cluster/data/dm2/bed/multiz8way/phastCons/run.estimate
    cd /cluster/data/dm2/bed/multiz8way/phastCons/run.estimate
    # FIRST ITERATION: Use ../starting-tree.mod:
    cat << '_EOF_' > doEstimate.sh
#!/bin/csh -ef
zcat $1 \
| /cluster/bin/phast/phastCons - ../starting-tree.mod --gc 0.431 --nrates 1,1 \
    --no-post-probs --ignore-missing \
    --expected-lengths 36 --target-coverage 0.565 \
    --quiet --log $2 --estimate-trees $3
'_EOF_'
# << for emacs
    # SUBSEQUENT ITERATIONS: Use last iteration's estimated noncons model.
    cat << '_EOF_' > doEstimate.sh
#!/bin/csh -ef
zcat $1 \
| /cluster/bin/phast/phastCons - ave.noncons.mod --gc 0.431 --nrates 1,1 \
    --no-post-probs --ignore-missing \
    --expected-lengths 36.8 --target-coverage 0.573 \
    --quiet --log $2 --estimate-trees $3
'_EOF_'
# << for emacs
    chmod a+x doEstimate.sh
    rm -fr LOG TREES
    mkdir -p LOG TREES
    rm -f jobList
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*.ss.gz)
      set root = $f:t:r:r
      echo doEstimate.sh $f LOG/$root.log TREES/$root >> jobList
    end
    # run cluster job
    para create jobList
    para try, check, push, check, ...#
#Completed: 139 of 139 jobs
#Average job time:                 708s      11.80m     0.20h    0.01d
#Longest finished job:            1458s      24.30m     0.41h    0.02d
#Submission to last job:          1771s      29.52m     0.49h    0.02d

    # Now combine parameter estimates.  We can average the .mod files
    # using phyloBoot.  This must be done separately for the conserved
    # and nonconserved models
    ssh kksilo
    cd /cluster/data/dm2/bed/multiz8way/phastCons/run.estimate
    ls -1 TREES/*.cons.mod > cons.txt
    /cluster/bin/phast/phyloBoot --read-mods '*cons.txt' \
      --output-average ave.cons.mod > cons_summary.txt
    ls -1 TREES/*.noncons.mod > noncons.txt
    /cluster/bin/phast/phyloBoot --read-mods '*noncons.txt' \
      --output-average ave.noncons.mod > noncons_summary.txt
    grep TREE ave*.mod
    # FIRST ITERATION:
#ave.cons.mod:TREE: (((((droYak1:0.068799,droAna1:0.086121):0.025199,dp2:0.089389):0.025318,(droVir1:0.054838,droMoj1:0.061144):0.071262):0.086015,anoGam1:0.200622):0.155212,apiMel1:0.155212);
#ave.noncons.mod:TREE: (((((droYak1:0.237449,droAna1:0.302849):0.090002,dp2:0.313915):0.093683,(droVir1:0.189785,droMoj1:0.211406):0.262607):0.320424,anoGam1:0.710433):0.563275,apiMel1:0.563275);
    # SECOND ITERATION:
#ave.cons.mod:TREE: (((((droYak1:0.068940,droAna1:0.086293):0.025242,dp2:0.089550):0.025379,(droVir1:0.054937,droMoj1:0.061251):0.071378):0.086201,anoGam1:0.200916):0.155457,apiMel1:0.155457);
#ave.noncons.mod:TREE: (((((droYak1:0.237657,droAna1:0.303096):0.090034,dp2:0.314116):0.093804,(droVir1:0.189905,droMoj1:0.211526):0.262729):0.320771,anoGam1:0.710597):0.563469,apiMel1:0.563469);
    # THIRD ITERATION:
#ave.cons.mod:TREE: (((((droYak1:0.069060,droAna1:0.086433):0.025290,dp2:0.089694):0.025440,(droVir1:0.055027,droMoj1:0.061352):0.071482):0.086374,anoGam1:0.201201):0.155686,apiMel1:0.155686);
#ave.noncons.mod:TREE: (((((droYak1:0.237909,droAna1:0.303387):0.090149,dp2:0.314413):0.093960,(droVir1:0.190094,droMoj1:0.211733):0.262926):0.321185,anoGam1:0.711122):0.563897,apiMel1:0.563897);

    cat cons_summary.txt 
    # look over the files cons_summary.txt and noncons_summary.txt.
    # The means and medians should be roughly equal and the stdevs
    # should be reasonably small compared to the means, particularly
    # for rate matrix parameters (at bottom) and for branches to the
    # leaves of the tree.  The stdevs may be fairly high for branches
    # near the root of the tree; that's okay.  Some min values may be
    # 0 for some parameters.  That's okay, but watch out for very large
    # values in the max column, which might skew the mean.  If you see
    # any signs of bad outliers, you may have to track down the
    # responsible .mod files and throw them out.  I've never had to do
    # this; the estimates generally seem pretty well behaved.

    # NOTE: Actually, a random sample of several hundred to a thousand
    # alignment fragments (say, a number equal to the number of
    # available cluster nodes) should be more than adequate for
    # parameter estimation.  If pressed for time, use this strategy.

    # Check the total entropy figure to see if we're way off.
    # We probably don't need to do this, since it has always been very close 
    # if not the same as what we used above, but it only takes a second.
    # FIRST ITERATION:
    /cluster/bin/phast/consEntropy --NH 9.7834 0.565 35.6 ave.{cons,noncons}.mod
#Recommended expected length: omega=36.077755 sites (for NH=9.783400)
    # OK, tweak --expected-lengths to 36.1 below (and for next iteration).
    # SECOND ITERATION:
    /cluster/bin/phast/consEntropy --NH 9.7834 0.57 36.5 ave.{cons,noncons}.mod
#Recommended expected length: omega=36.535491 sites (for NH=9.783400)
    # ==> keep at 36.5.
    # THIRD ITERATION:
    /cluster/bin/phast/consEntropy --NH 9.7834 0.573 36.8 ave.{cons,noncons}.mod
#Recommended expected length: omega=36.813127 sites (for NH=9.783400)
    # ==> keep at 36.8.

    # Now we are ready to set up the cluster job for computing the
    # conservation scores and predicted elements.  The we measure the 
    # conserved elements coverage, and if that's not satisfactory then we 
    # adjust parameters and repeat.  
    ssh kk9
    mkdir /cluster/data/dm2/bed/multiz8way/phastCons/run.phast
    cd /cluster/data/dm2/bed/multiz8way/phastCons/run.phast
    cat << 'EOF' > doPhastCons.sh
#!/bin/csh -ef
set pref = $1:t:r:r
set chr = `echo $pref | awk -F\. '{print $1}'`
set tmpfile = /scratch/phastCons.$$
zcat $1 \
| /cluster/bin/phast/phastCons - \
    ../run.estimate/ave.cons.mod,../run.estimate/ave.noncons.mod \
    --expected-lengths 36.8 --target-coverage 0.573 \
    --quiet --seqname $chr --idpref $pref \
    --viterbi /cluster/bluearc/dm2/phastCons/ELEMENTS/$pref.bed --score \
    --require-informative 0 \
  > $tmpfile
gzip -c $tmpfile > /cluster/bluearc/dm2/phastCons/POSTPROBS/$pref.pp.gz
rm $tmpfile
'EOF'
# << for emacs
    chmod a+x doPhastCons.sh
    rm -fr /cluster/bluearc/dm2/phastCons/{POSTPROBS,ELEMENTS}
    mkdir -p /cluster/bluearc/dm2/phastCons/{POSTPROBS,ELEMENTS}
    rm -f jobList
    foreach f (/cluster/bluearc/dm2/phastCons/WINDOWS/*.ss.gz)
      echo doPhastCons.sh $f >> jobList
    end
    para create jobList
    para try, check, push, check, ...
#Completed: 139 of 139 jobs
#Average job time:                  17s       0.28m     0.00h    0.00d
#Longest finished job:              26s       0.43m     0.01h    0.00d
#Submission to last job:            37s       0.62m     0.01h    0.00d

    # back on kksilo:
    # combine predictions and transform scores to be in 0-1000 interval
    cd /cluster/data/dm2/bed/multiz8way/phastCons
    awk '{printf "%s\t%d\t%d\tlod=%d\t%s\n", $1, $2, $3, $5, $5;}' \
      /cluster/bluearc/dm2/phastCons/ELEMENTS/*.bed \
    | /cluster/bin/scripts/lodToBedScore > all.bed

    ssh hgwdev
    # Now measure coverage of CDS by conserved elements. 
    # We want the "cover" figure to be close to 68.9%.
    cd /cluster/data/dm2/bed/multiz8way/phastCons
    featureBits -enrichment dm2 flyBaseGene:cds all.bed
    # FIRST ITERATION: a bit too low; increase --target-coverage, re-estimate.
#flyBaseGene:cds 16.567%, all.bed 42.507%, both 11.375%, cover 68.66%, enrich 1.62x
#    # SECOND ITERATION: Close but no cigar... one more try for 68.9%:
#flyBaseGene:cds 16.567%, all.bed 42.794%, both 11.398%, cover 68.80%, enrich 1.61x
    # THIRD ITERATION: Sweet.
#flyBaseGene:cds 16.567%, all.bed 42.997%, both 11.417%, cover 68.92%, enrich 1.60x

    # Having met the CDS coverage target, load up the results.
    hgLoadBed dm2 phastConsElements8way all.bed

    # Create wiggle on the small cluster
    ssh kki
    mkdir /cluster/data/dm2/bed/multiz8way/phastCons/run.wib
    cd /cluster/data/dm2/bed/multiz8way/phastCons/run.wib
    rm -rf /cluster/bluearc/dm2/phastCons/wib
    mkdir -p /cluster/bluearc/dm2/phastCons/wib
    cat << 'EOF' > doWigEncode
#!/bin/csh -ef
set chr = $1
cd /cluster/bluearc/dm2/phastCons/wib
zcat `ls -1 /cluster/bluearc/dm2/phastCons/POSTPROBS/$chr.*.pp.gz \
      | sort -t\. -k2,2n` \
| wigEncode stdin ${chr}_phastCons.wi{g,b}
'EOF'
# << for emacs
    chmod a+x doWigEncode
    rm -f jobList
    foreach chr (`ls -1 /cluster/bluearc/dm2/phastCons/POSTPROBS \
                  | awk -F\. '{print $1}' | sort -u`)
      echo doWigEncode $chr >> jobList
    end
    para create jobList
    para try, check, push, check, ...
#Completed: 13 of 13 jobs
#Average job time:                   9s       0.15m     0.00h    0.00d
#Longest job:                       24s       0.40m     0.01h    0.00d
#Submission to last job:            24s       0.40m     0.01h    0.00d

    # back on kksilo, copy wibs, wigs and POSTPROBS (people sometimes want 
    # the raw scores) from bluearc
    cd /cluster/data/dm2/bed/multiz8way/phastCons
    rm -rf wib POSTPROBS
    rsync -av /cluster/bluearc/dm2/phastCons/wib .
    rsync -av /cluster/bluearc/dm2/phastCons/POSTPROBS .

    # load wiggle component of Conservation track
    ssh hgwdev
    mkdir /gbdb/dm2/multiz8way/wib
    cd /cluster/data/dm2/bed/multiz8way/phastCons
    chmod 775 . wib
    chmod 664 wib/*.wib
    ln -s `pwd`/wib/*.wib /gbdb/dm2/multiz8way/wib/
    hgLoadWiggle dm2 phastCons8way \
      -pathPrefix=/gbdb/dm2/multiz8way/wib wib/*.wig
    rm wiggle.tab

    # make top-5000 list and launcher on Adam's home page:
    sed -e 's/lod=//' all.bed | sort -k4,4nr | head -5000 \
    | awk '{printf "%s\t%d\t%d\tlod=%d\t%d\n", $1, $2, $3, $4, $4}' \
    > top5000.bed
    /cluster/home/acs/bin/make-launcher-with-scores.sh top5000.bed \
      /cse/grads/acs/public_html/dm-top5000-8way \
      "top 5000 conserved elements (8way)" dm2

    # and clean up bluearc.
    rm -r /cluster/bluearc/dm2/phastCons/{ELEMENTS,POSTPROBS,wib}
# NOT DONE (I see more phastCons in the future :)
    rm -r /cluster/bluearc/dm2/chrom


# MAP FEEP PROBES (DONE 2/3/05 angie)
    ssh kolossus
    mkdir /cluster/data/dm2/bed/flyFeep
    cd /cluster/data/dm2/bed/flyFeep
    set feepDir = /projects/compbio/data/microarray/flyFEEP
    # Make per-chrom probe FASTA files:
    foreach c (2L 2R 2h 3L 3R 3h 4 X Xh Yh)
      echo $c
      awk '$3 == "'$c'" {printf ">%s\n%s\n", $1, $7;}' \
        $feepDir/probes3.1-Exons.1_apr11_exon \
        $feepDir/probes3.1-Noncoding.1_apr11_tiling \
        > chr${c}_exonNonExonProbes.fa
      awk '$1 != "ID" && $5 == "'$c'+" {printf ">%s\n%s\n", $1, $8;}' \
        $feepDir/probes3.1-junctions.txt \
        > chr${c}_junctionProbes.fa
    end
    # For exon/non-exon probes (36 consecutive bases), require 36 matching 
    # bases (for some reason -minScore=36 doesn't filter anything out!).
    foreach c (2L 2R 2h 3L 3R 3h 4 X Xh Yh)
      blat -noHead \
        /cluster/data/dm2/nib/chr$c.nib chr${c}_exonNonExonProbes.fa stdout \
      | grep ^36 | uniq \
      > chr${c}_exonNonExonProbes.psl
    end
    # For splice junction probes (2 blocks of 18 consecutive bases), 
    # use a small tileSize and -fine, and still require 36 matching bases:
    # This was slow, do as small cluster job next time, will still take hours.
    foreach c (2L 2R 2h 3L 3R 3h 4 X Xh Yh)
      blat -noHead -tileSize=6 -fine \
        /cluster/data/dm2/nib/chr$c.nib chr${c}_junctionProbes.fa stdout \
      | grep ^36 | uniq \
      > chr${c}_junctionProbes.psl
    end
    # Check on how many probes were aligned:
    foreach f (chr*exon*.fa chr*junc*.fa)
      set probes = `cat $f | wc -l`
      set probes = `expr $probes / 2`
      set aligned = `cat $f:r.psl | wc -l`
      set reallyAligned = `awk '{print $10;}' $f:r.psl | sort -u | wc -l `
      set not = `expr $probes - $reallyAligned`
      echo $f:r"\t"$probes"\t"$aligned"\t"$reallyAligned"\t"\($not\)
    end
    # set			count	aligned	reallyA	not
#chr2h_exonNonExonProbes	644	611	611	(33)
#chr2L_exonNonExonProbes	26631	26749	26627	(4)
#chr2R_exonNonExonProbes	26100	26111	26098	(2)
#chr3h_exonNonExonProbes	833	833	833	(0)
#chr3L_exonNonExonProbes	28756	28773	28749	(7)
#chr3R_exonNonExonProbes	35060	35064	35055	(5)
#chr4_exonNonExonProbes	    	1798	1797	1797	(1)
#chrX_exonNonExonProbes	    	28912	28917	28912	(0)
#chrXh_exonNonExonProbes	354	354	354	(0)
#chrYh_exonNonExonProbes	97	97	97	(0)
#chr2h_junctionProbes    	3       3       3       (0)
#chr2L_junctionProbes    	5048    5015    5012    (36)
#chr2R_junctionProbes        	5697    5709    5652    (45)
#chr3h_junctionProbes        	1       1       1       (0)
#chr3L_junctionProbes        	6498    6437    6429    (69)
#chr3R_junctionProbes        	8747    8695    8684    (63)
#chr4_junctionProbes         	1056    1048    1048    (8)
#chrXh_junctionProbes        	50      50      50      (0)
#chrX_junctionProbes         	3688    3684    3680    (8)
#chrYh_junctionProbes        	0       0       0       (0)
    # Most probes successfully mapped, but a fair number of duplicates.  
    # Dug into one of those (159937) and found that its probe sequence 
    # halves were from a tandem repeat!  (And didn't map to where they 
    # were supposed to in dm1 either.)  I suspect the probe sequences 
    # might not be correct in the files I downloaded.  Sent Chris Mason 
    # an email about that.  
    # If the probe dm1 locations are correct (I sure hope so), just not 
    # some given probe sequences, I could extract dm1 sequence and map 
    # that to dm2 instead of mapping the given probes as above.  

    # Translate PSL to bed12 (this is too simple for PSL in general, but 
    # since we require the entire query to map perfectly, it works here):
    awk '{printf "%s\t%d\t%d\t%s\t0\t%s\t%d\t%d\t0\t%d\t%s\t%s\n", \
                 $14, $16, $17, $10, $9, $16, $17, $18, $19, $20;}' \
      chr*.psl \
      > flyFeepProbesBed12.bed

    # Load probes
    ssh hgwdev
    cd /cluster/data/dm2/bed/flyFeep
    # Add scores to bed:
    hgMapMicroarray -bedIn flyFeep.bed hgFixed.flyFeepMedianRatio \
      flyFeepProbesBed12.bed
    hgLoadBed dm2 flyFeep flyFeep.bed
    # (back on fileserver) Winnow probes by Bussemaker lab's lists:
    set dm1FeepDir = /cluster/data/dm1/bed/flyFeep
    $dm1FeepDir/winnowBed.pl $dm1FeepDir/probesExpressedAboveBackground.txt \
      flyFeep.bed \
      > flyFeepPEAB.bed
    $dm1FeepDir/winnowBed.pl $dm1FeepDir/probesAnovaDiffExpressed.txt \
      flyFeep.bed \
      > flyFeepAnova.bed
    # (back on hgwdev) Load winnowed sets:
    hgLoadBed dm2 flyFeepPEAB flyFeepPEAB.bed
    hgLoadBed dm2 flyFeepAnova flyFeepAnova.bed


# FLYBASE 4.1 ANNOTATIONS (DONE 2/28/05 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/flybase4.1
    cd /cluster/data/dm2/bed/flybase4.1
    foreach c (2L 2R 3L 3R 4 X)
      wget ftp://flybase.net/genomes/Drosophila_melanogaster/dmel_r4.1_20050207/gff/dmel-$c-r4.1.gff.gz
    end
    zcat *.gff.gz > flybase.gff3
    # What data sources are represented in this file?
    grep -v '^#' flybase.gff3 | awk '{print $2 "\t" $3;}' | sort | uniq -c
    # excerpt (many other sources, including blastx:... , sim4:... and 
    # tblastx:...; also various other types for source "."):
  18941 .       CDS
  63033 .       exon
  14066 .       gene
  18941 .       mRNA
    144 .       ncRNA
     39 .       pseudogene
     96 .       rRNA
     29 .       snRNA
     28 .       snoRNA
    295 .       tRNA
  36921 .       transcription_start_site
   1571 .       transposable_element
  16404 .       transposable_element_insertion_site
    # What keywords are defined in the 9th field?
    grep -v '^#' flybase.gff3 \
    | awk '{print $9;}' | perl -wpe 's/=[^;]+;/\n/g; s/=.*$//;' \
    | sort | uniq -c
    # Once again, the previous round's parsing needed some updates to 
    # handle the new data.
    extractGenes.pl flybase.gff3
#Oddball parentless ID=Sps2-exon-10336472..10336531 for exon

    # Get predicted proteins (for main annotations only)
    wget ftp://flybase.net/genomes/Drosophila_melanogaster/dmel_r4.1_20050207/fasta/dmel-all-translation-r4.1.fasta.gz
    zcat dmel-all-translation-r4.1.fasta.gz \
    | perl -wpe 's/^(>\w+)-P(\w)/$1-R$2/' > flybasePep.fa

    ssh hgwdev
    cd /cluster/data/dm2/bed/flybase4.1
    # Protein-coding genes:
    ldHgGene -gtf dm2 flyBaseGene flybase.gtf
    hgPepPred dm2 generic flyBasePep flybasePep.fa
    # Fix typo caught by Galt & all.joiner:
    hgsql dm2 -e 'update flyBasePep set name = "CG6207-RC" where name = "GLCAT-P-PC"'
    # Noncoding genes:
    hgLoadBed dm2 flyBaseNoncoding flyBaseNoncoding.bed
    # Cross-referencing info for both coding and noncoding:
    hgsql dm2 < $HOME/kent/src/hg/lib/flyBase2004Xref.sql
    hgsql dm2 -e 'load data local infile "flyBase2004Xref.tab" \
      into table flyBase2004Xref'
    # Some featureBits comparisons with refGene which is pretty much like 
    # version 4.0 but apparently includes some noncoding genes too:
    featureBits dm2 refGene \!flyBaseGene -minSize=1000 -bed=stdout
#chr3R   8221731 8222987 chr3R.1
#...
#87577 bases of 131698467 (0.066%) in intersection
    # This shows only the dropped isoforms/duplicates (ignores noncoding):
    featureBits dm2 refGene \!flyBaseGene \!flyBaseNoncoding -minSize=1000 \
       -bed=stdout
#chr3R   15620310        15621493        chr3R.1
#chr2L   4698094 4700940 chr2L.1
#chrX    3638700 3639895 chrX.1
#49911 bases of 131698467 (0.038%) in intersection

    # add upstream* downloadable files
    cd /usr/local/apache/htdocs/goldenPath/dm2/bigZips
    foreach size (1000 2000 5000)
      echo upstream$size
      nice featureBits dm2 flyBaseGene:upstream:$size -fa=stdout \
      | nice gzip -c > upstream$size.fa.gz
    end
    md5sum *.zip *.gz > md5sum.txt


# FLYREG (DONE 2/23/05 angie)
    ssh kksilo
    mkdir /cluster/data/dm2/bed/flyreg
    cd /cluster/data/dm2/bed/flyreg
    wget http://www.gen.cam.ac.uk/casey/data/Bergman2004/v2.0/Footprint.GFF
    # This is not GTF; it should really be bed +.  The contributor, 
    # Casey Bergman, says that coords are 0-based half-open, so 
    # translation will be even easier.
    grep -v '^#' Footprint.GFF \
    | perl -wpe 'if (! s/^(\S+)\tBergman_data\tbinding_site\t(\d+)\t(\d+)\t.\t.\t.\tFactor \"([^\"]+)\"; Target \"([^\"]+)\"; PMID \"(\d+)\"; FPID \"(\d+)\"$/chr$1\t$2\t$3\t$4\t$5\t$6\t$7/) { die "Cant parse line $.:\n$_\n"; }' \
      > flyreg2.bed
    ssh hgwdev
    hgLoadBed -sqlTable=$HOME/kent/src/hg/lib/flyreg2.sql \
      dm2 flyreg2 /cluster/data/dm2/bed/flyreg/flyreg2.bed
    # Add Dan Pollard's MEME motif data for the footprints:
    ssh kksilo
    cd /cluster/data/dm2/bed/flyreg
    wget http://rana.lbl.gov/~dan/matrices/bergman2004/footprint_matrices.txt
    /cluster/data/dm1/bed/flyreg/extractMatrices.pl \
      footprint_matrices.txt > flyregMotif.tab
    ssh hgwdev
    cd /cluster/data/dm2/bed/flyreg
    sed -e 's/dnaMotif/flyregMotif/' $HOME/kent/src/hg/lib/dnaMotif.sql \
    > flyregMotif.sql
    hgsql dm2 < flyregMotif.sql
    hgsql dm2 -e 'load data local infile "flyregMotif.tab" into table flyregMotif'


# LIFTOVER DM1 FLYREG, COMPARE TO DM2 FLYREG (DONE 2/25/05 angie)
    # Casey Bergman is very eager to see alternate confirmation of his 
    # dm1->dm2 mapping of flyreg, so run liftOver on it:
    ssh kksilo
    cd /cluster/data/dm2/bed/flyreg
    liftOver /cluster/data/dm1/bed/flyreg/flyreg.bed \
      /cluster/data/dm1/bed/bedOver/dm1ToDm2.over.chain \
      flyregLift.bed flyregLift.unmapped
    wc -l flyreg2.bed flyregLift.bed flyregLift.unmapped 
#  1362 flyreg2.bed
#  1363 flyregLift.bed
#     0 flyregLift.unmapped
    awk '{print $1 "\t" $2 "\t" $3 "\t" $4 "\t" $5;}' flyreg2.bed | sort \
      > /tmp/1
    awk '{print $1 "\t" $2 "\t" $3 "\t" $4 "\t" $5;}' flyregLift.bed | sort \
      > /tmp/2
    diff -c /tmp/[12] > newVsLift
    # Analyzed the differences: 2 duplicates in original (uniquified in v2),
    # 1 new item in v2, and 4 items incorrectly mapped by liftOver (fooled 
    # by what looks like a slightly diverged local duplication) but probably
    # correctly mapped by Casey.


# SELF ALIGNMENTS (DONE 2/24/05 angie)
    # Doing this largely as a test of doBlastzChainNet.pl...
    ssh kksilo
    mkdir /cluster/data/dm2/bed/blastz.dm2.2005-02-23
    cd /cluster/data/dm2/bed/blastz.dm2.2005-02-23
    cat << '_EOF_' > DEF
# D. melanogaster vs. self

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_CHUNK=10000000
SEQ1_LAP=10000
SEQ1_LEN=/cluster/data/dm2/chrom.sizes

# QUERY - D. melanogaster
SEQ2_DIR=/iscratch/i/dm2/nib
SEQ2_CHUNK=10000000
SEQ2_LAP=10000
SEQ2_LEN=/cluster/data/dm2/chrom.sizes

BASE=/cluster/data/dm2/bed/blastz.dm2.2005-02-23

'_EOF_'
    # << this line keeps emacs coloring happy
    doBlastzChainNet.pl DEF \
      -blastzOutRoot /panasas/store/dm2SelfOut >& do.log &
    tail -f do.log
    # The script died at the start of the cat step when kki couldn't see 
    # /panasas (doh!).  Asked cluster-admin to fix that.  
    # When fixed, restarted with -continue, appending to do.log:
    rm -r run.cat
    doBlastzChainNet.pl -continue cat DEF \
      -blastzOutRoot /panasas/store/dm2SelfOut >>& do.log &
    tail -f do.log
    rmdir /panasas/store/dm2SelfOut
    ln -s blastz.dm2.2005-02-23 /cluster/data/dm2/bed/blastz.dm2
    # chainSelf is already in top-level trackDb.ra, so no need to add.
    # Add /usr/local/apache/htdocs/goldenPath/dm2/vsSelf/README.txt


# BLASTZ/CHAIN/NET DROSIM1 (DONE 4/13/05 angie)
    mkdir /cluster/data/dm2/bed/blastz.droSim1.2005-04-13
    cd /cluster/data/dm2/bed/blastz.droSim1.2005-04-13
    # Since they're ~5MYA, I think the default blastz params should be OK:
    cat << '_EOF_' > DEF
# D.melanogaster vs. D.simulans

# TARGET - D. melanogaster
SEQ1_DIR=/iscratch/i/dm2/nib
SEQ1_CHUNK=5000000
SEQ1_LAP=10000
SEQ1_LEN=/cluster/data/dm2/chrom.sizes

# QUERY - D. simulans
SEQ2_DIR=/iscratch/i/droSim1/droSim1.2bit
SEQ2_CHUNK=5000000
SEQ2_LAP=10000
SEQ2_LEN=/cluster/data/droSim1/chrom.sizes

BASE=/cluster/data/dm2/bed/blastz.droSim1.2005-04-13
'_EOF_'
    # << this line keeps emacs coloring happy
    doBlastzChainNet.pl DEF -bigClusterHub kk9 -fileServer kolossus \
      -blastzOutRoot /cluster/bluearc/dm2droSim1 >& do.log &
    tail -f do.log
    # Pretty good coverage, but I wonder if it would be possible to do even 
    # better...?  
    featureBits dm2 chainDroSim1Link
#108586694 bases of 131698467 (82.451%) in intersection
    # Even with default params, yakuba (~13MYA) got slightly more cov!!
    featureBits dm2 chainDroYak1Link
#109036381 bases of 131698467 (82.792%) in intersection
    # Assembly size may explain some of that...? droYak1 has 169M non-gap bases
    # while droSim1 has only 127M.  
    rmdir /cluster/bluearc/dm2droSim1
    ln -s blastz.droSim1.2005-04-13 /cluster/data/dm2/bed/blastz.droSim1
    # Add {chain,net}DroSim1 to trackDb.ra if necessary.

# AUGUSTUS GENE PREDICTIONS (Done 6/1/2005 Andy)
    ssh hgwdev
    cd /cluster/data/dm2/bed
    mkdir augustus
    cd augustus/
    wget http://augustus.gobics.de/predictions/dm2/dm2.chr2L.augustus.gtf.gz
    ldHgGene -gtf dm2 augustus dm2.chr2L.augustus.gtf.gz
    for chr in chr{2R,2h,3L,3R,3h,4,U,X,Xh,Yh}; do 
      wget http://augustus.gobics.de/predictions/dm2/dm2.${chr}.augustus.gtf.gz
      ldHgGene -gtf -oldTable dm2 augustus dm2.${chr}.augustus.gtf.gz
    done
