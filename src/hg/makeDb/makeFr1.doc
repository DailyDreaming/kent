#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how we made the browser database on the 
# Fugu Rubripes (Japanese pufferfish), whole genome shotgun assembly dated 
# 26 August 2002, from the DOE Joint Genome Institute (v3.0).
# This release contains ~320Mbases, in 20,378 scaffolds.
# Size distribution is: 2 scaffolds ~1Mbase, 17 are 500-1000kbase.
# Kate Rosenbloom 4/03

# DOWNLOAD THE SEQUENCE FROM JGI (04/22/03 KRR)

    ssh eieio
    set fugudir = /cluster/store5/Fugu_Rubripes_V3
    mkdir $fugudir
    cd $fugudir

    # NOTE: there are two downloads available on the site -- one
    # is named indicating it is masked, and contains additional N's.
    # The other file (the one we are using) contains lower-case,
    # indicating it is soft-masked. (As an aside, the mask locations are not
    # consistent between the two files).
    # We use the soft-masked file, since it has more sequence; however
    # we will translate to upper case and repeat mask ourselves, 
    # so that we can generate a Repeats track.
    #
    # The file consists of fasta records, each named scaffold_#.
    # Unfortunately, the ordering of scaffolds is alphabetic, not numeric,
    # so scaffold_1 is followed by scaffold_10, not scaffold_2.
    # Also, the scaffold numbering has holes -- the highest numbered
    # scaffold is 32607. 

    wget ftp://ftp.jgi-psf.org/pub/JGI_data/Fugu/fugu_v3.fasta.Z
    ln -s $fugudir ~/fr1
    cd ~/fr1
    gunzip fugu_v3.fasta.Z

    # trim off garbage at end of file (list of scaffolds),
    # this appears to be an artifact of the release process

    mv fugu_v3.fasta fugu_v3.orig.fasta
    grep -v '^scaffold' fugu_v3.orig.fasta > fugu_v3.fasta

    # force to upper case (see above), but preserve lower case headers
    tr '[a-z]' '[A-Z]' < fugu_v3.fasta | \
        sed 's/>SCAFFOLD_/>scaffold_/' > fugu_v3.upper.fasta


# SPLIT THE FASTA FILE INTO SCAFFOLDS FOR FURTHER PROCESSING (DONE KRR)

    ssh eieio
    set fugudir = /cluster/store5/Fugu_Rubripes_V3
    cd $fugudir
    mkdir scaffolds

    # NOTE: must give a record count larger than the number of scaffolds
    # next time, use "faSplit byName" to do this
    faSplit sequence fugu_v3.upper.fasta 30000 scaffolds/

    # rename files to match scaffold (in fasta header)
    # and store in directories (00 .. 32) for convenience and readability
    # This produces directories with 200 - 1000 files per dir.
    # The directory is the leading two digits of the scaffold number,
    # (when represented as a zero-filled 5-digit number)
    cd scaffolds
    foreach d1 (0 1 2 3)
        foreach d2 (0 1 2 3 4 5 6 7 8 9)
            foreach file ($d1$d2*.fa)
                set num = `sed -n '1s/>scaffold_//p' $file`
                set dir = `printf "%05d" $num | sed 's/...$//'`
                mkdir -p $dir
                echo "moving $file to $dir/scaffold_$num"
                mv $file $dir/scaffold_${num}.fa
            end
        end
    end

    # remake a whole-genome fasta file, with the scaffold records
    # ordered more sensibly (numeric, not alphabetic)
    set ordered_file = fugu_v3.ordered.fa
    cp /dev/null $ordered_file
    cd scaffolds
    foreach d ([0-9][0-9])
        set filelist = `(cd $d; ls *.fa | sort -n -k 1.10)`
        foreach f ($filelist) 
            echo "concatenating $f"
            cat $d/$f >> ../$ordered_file
        end
    end
    cd ..

    # split into ~500KB "super-scaffolds"
    # each file has one or more scaffolds. Fasta records are preserved
    # This creates 577 files, size range ~51000 to ~1.2Mb
    rm -fr superscaffolds
    mkdir superscaffolds
    faSplit about $ordered_file 500000 superscaffolds/ss_
    

# RUN REPEAT MASKER ON THE SUPER-SCAFFOLDS (6/2/03 KRR)
    # note: fugu library ("puffer.lib") is dated 7/9/2002
    ssh eieio
    cd ~/fr1

    # make the run directory, output directory, and job list
    mkdir -p RMRun/Un
    cp /dev/null RMRun/RMJobs
    set fugudir = /cluster/store5/Fugu_Rubripes_V3
    cd superscaffolds
    foreach f (ss_*.fa)
        echo /cluster/bin/scripts/RMFugu \
                $fugudir/superscaffolds $f $fugudir/RMRun/Un \
               '{'check out line+ $fugudir/RMRun/Un/$f.out'}' \
              >> ../RMRun/RMJobs
    end

    # do the run
    ssh kk
    cd ~/fr1/RMRun
    para create RMJobs
    para try
    para check
    para push
    para check,...


# PROCESS SUPER-SCAFFOLDS FOR SIMPLE REPEATS (6/2/03 KRR)
    # TRF runs pretty quickly now... it takes a few hours total runtime, 
    # so instead of binrsyncing and para-running, just do this on the
    # local fileserver
    ssh eieio
    mkdir ~/fr1/bed/simpleRepeat
    cd ~/fr1/bed/simpleRepeat
    mkdir trf
    cp /dev/null jobs.csh
    set fugudir = /cluster/store5/Fugu_Rubripes_V3
    foreach f ($fugudir/superscaffolds/*.fa)
        set fout = $f:t:r.bed
        echo $fout
        echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    tcsh jobs.csh >&! jobs.log &
    # check on this with
    tail -f jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l


# FILTER SIMPLE REPEATS INTO MASK (6/3/03 KRR)
    # make a filtered version # of the trf output: 
    # keep trf's with period <= 12:
    ssh eieio
    cd ~/fr1/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/*.bed)
        echo "filtering $f"
        awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end


# MASK SUPER-SCAFFOLDS USING REPEATMASKER AND FILTERED TRF FILES (6/3/03 KRR)
    ssh eieio
    cd ~/fr1
    mkdir superscaffolds.masked
    foreach p (superscaffolds/ss_*.fa)
        set f = $p:t
        echo "masking $f"
        maskOutFa $p RMRun/Un/$f.out superscaffolds.masked/$f -soft
        maskOutFa superscaffolds.masked/$f bed/simpleRepeat/trfMask/${f:r}.bed superscaffolds.masked/$f -softAdd
    end


# CREATE FASTA FOR UNORDERED CHROM FROM MASKED SUPER-SCAFFOLDS (6/3/03 KRR)
# Note: scaffolds are separated by 1000 Bp gaps
    ssh eieio
    cd ~/fr1

    # remake a whole-genome fasta file from the masked supser-scaffolds
    set masked_file = fugu_v3.masked.fa
    cd superscaffolds.masked
    cat `ls ss_*.fa | sort -n -k 1.4` > ../$masked_file
    cd ..
    
    # generate AGP and lift files from the chromosome fasta 

    scaffoldFaToAgp $masked_file
    # gap size is 1000, total gaps: 20379
    # chrom size is 349519338

    mkdir Un
    mv fugu_v3.masked.agp Un/chrUn.agp
    mv fugu_v3.masked.lft Un/chrUn.lft

    # Create chromosome FA file from AGP and file of masked scaffolds
    cd Un
    agpToFa -simpleMultiMixed chrUn.agp chrUn chrUn.fa ../fugu_v3.masked.fa


# CREATING DATABASE (5/2/03 KRR)
    # Create the database.
    ssh hgwdev
    echo 'create database fr1' | hgsql ''
    # Make a semi-permanent read-only alias:
    alias fr1 "mysql -u hguser -phguserstuff -A fr1"
    # Make sure there is at least 5 gig free for the database
    df -h /var/lib/mysql


# STORE SEQUENCE AND ASSEMBLY INFORMATION (6/3/03 KRR)

    # Translate to nib
    ssh eieio
    cd ~/fr1
    mkdir nib
    faToNib -softMask Un/chrUn.fa nib/chrUn.nib

    # Make symbolic links from /gbdb/fr1/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/fr1/nib
    set fugudir = /cluster/store5/Fugu_Rubripes_V3
    ln -s $fugudir/nib/chrUn.nib  /gbdb/fr1/nib

    # Load /gbdb/fr1/nib paths into database and save size info.
     ssh hgwdev
     hgsql fr1  < ~/src/hg/lib/chromInfo.sql
     cd ~/fr1

    # NOTE: last arg here may be in error
     hgNibSeq -preMadeNib fr1 /gbdb/fr1/nib chrUn.nib
     echo "select chrom,size from chromInfo" | hgsql -N fr1 > chrom.sizes

    # create assembly and gap tracks
    ssh hgwdev
    hgGoldGapGl -noGl fr1 ~ fr1 


# CREATING GRP TABLE FOR TRACK GROUPING (5/2/03 KRR)
    # Copy all the data from the table "grp" 
    # in the existing database "rn1" to the new database
    ssh hgwdev
    echo "create table grp (PRIMARY KEY(NAME)) select * from rn1.grp" \
      | hgsql fr1


# CREATE REPEAT TRACKS (6/3/03 KRR)

    ssh eieio
    cd ~/fr1

    # merge and lift up the repeatmasker output files to chrom coordinates
    liftUp Un/chrUn.fa.out Un/chrUn.lft warn RMRun/Un/*.out

    # load into the database (chrUn_rmsk table)
    ssh hgwdev
    hgLoadOut fr1 Un/chrUn.fa.out

    # lift the simple repeat output to chrom coordinates
    ssh eieio
    cd ~/fr1
    cd bed/simpleRepeat
    liftUp simpleRepeat.bed ~/fr1/Un/chrUn.lft warn trf/*.bed

    # load into the database (simpleRepeat table)
    ssh hgwdev
    cd ~/fr1/bed/simpleRepeat
    hgLoadBed fr1 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql


# MAKE GCPERCENT (6/3/03 KRR)
     ssh hgwdev
    set fugudir = /cluster/store5/Fugu_Rubripes_V3
     mkdir -p $fugudir/bed/gcPercent
     cd $fugudir/bed/gcPercent
     hgsql fr1  < ~/src/hg/lib/gcPercent.sql

     # load gcPercent table
     hgGcPercent fr1 ../../nib


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR FUGU (5/6/03 KRR)
    echo 'INSERT INTO defaultDb VALUES ("Fugu", "fr1");' \
      | hgsql -h genome-testdb hgcentraltest

    # Warning: must genome and organism fields must correspond
    # with defaultDb values
    # Note: for next assembly, set scientificName column to "Fugu rubripes"
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
                defaultPos, active, orderKey, genome) values \
        ("fr1", "Aug. 2002", "/gbdb/fr1/nib", "Fugu", \
               "chrUn:827700-845800", 1, 10, "Fugu");' \
      | hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/src/hg/makeDb/trackDb
    cvs up -d -P

    # Edit that makefile to add fr1 in all the right places and do
    make update

    # go public on genome-test
    #make alpha
    cvs commit makefile

    # Add trackDb directories
    mkdir fugu
    mkdir fugu/fr1
    cvs add fugu
    cvs add fugu/fr1
    cvs commit fugu


# MAKE RELATIONAL RNA TABLES

    hgLoadRna new fr1


# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR FUGU (6/4/03 KRR)
    ssh hgwdev
    # Get appropriate hostname from cluster admins
    echo 'insert into blatServers values("fr1", "blat11", "17783", "1"); \
          insert into blatServers values("fr1", "blat11", "17782", "0");' \
      | hgsql -h genome-testdb hgcentraltest


# MAKE AND STORE mRNA ALIGNMENTS  (6/8/03 KRR)

    # Load up the local disks of the small cluster with  mrna.fa
    # and masked super-scaffolds
    # from /cluster/store5/mrna.134/org/Takifugu_rubripes
    # note: there are 76 mrna sequences, and 24398 EST's
    ssh kkr1u00
    cd /iscratch/i/fugu
    set mrnaDir = /cluster/store5/mrna.134/org/Takifugu_rubripes
    mkdir mrna 
    cp -p $mrnaDir/mrna.fa mrna
    mkdir trfFa 
    cp -p ~/fr1/superscaffolds.masked/*.fa trfFa
    # note: this isn't currently working for me 
    # (permission errors) -- Hiram did it
    ~kent/bin/iSync

    # generate alignment job 
    # TODO: try aligning whole mrna file against whole chrUn nib
    # on file server (eieio), instead of using cluster.
    # this would be simpler, and probably fast enough
    cd ~/fr1/bed
    mkdir mrna
    cd mrna
    mkdir psl
    ls -1S /iscratch/i/fugu/trfFa/*.fa > genome.lst
    ls -1S /iscratch/i/fugu/mrna/*.fa > mrna.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -mask=lower -ooc={check in exists /scratch/hg/h/11.ooc} {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP 
'_EOF_' 
    gensub2 genome.lst mrna.lst gsub spec
    para create spec
    para try
    para check
    para push
    # this just takes a few minutes

    ssh eieio
    cd ~/fr1/bed/mrna
    pslSort dirs raw.psl /tmp psl
        # psl with 578 files
        # 578 files in 1 dirs
        # Got 578 files 24 files per mid file
        # Writing /tmp/tmp0.psl
        # ...
        # Writing /tmp/tmp24.psl
        # writing raw.psl
        # Cleaning up temp files

    pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl scaffolds.psl \
      /dev/null
        # Processing raw.psl to scaffolds.psl and /dev/null
        # Processed 161 alignments

    # lift up PSL files to chrom coordinates
    liftUp -nohead all_mrna.psl ~/fr1/Un/chrUn.lft warn scaffolds.psl
        # Got 40758 lifts in /cluster/home/kate/fr1/Un/chrUn.lft
        # Lifting scaffolds.psl

    pslSortAcc nohead chrom /tmp all_mrna.psl
        # Processing all_mrna.psl
        # Processed 89 lines into 1 temp files

    # load mrna tables
    ssh hgwdev
    cd ~/fr1/bed/mrna/chrom

    # rename psl file to required format (must be chr*_mrna)
    mv chrUn.psl chrUn_mrna.psl

    # load alignments
    hgLoadPsl fr1 chrUn_mrna.psl
    cd ..
    hgLoadPsl fr1 all_mrna.psl -nobin

    # prepare for data load
    set mrnaDir = mrna.134
    mkdir /gbdb/fr1/mrna.134
    #ln -s /cluster/store5/$mrnaDir/org/Takifugu_rubripes /gbdb/fr1/$mrnaDir
    ln -s /cluster/store5/$mrnaDir/org/Takifugu_rubripes/mrna.fa /gbdb/fr1/$mrnaDir
    # load mRna into database
    # WARNING: had to use -ignore flag... check on this
    hgLoadRna add -type=mRNA fr1 /gbdb/fr1/$mrnaDir/mrna.fa \
        /cluster/store5/$mrnaDir/org/Takifugu_rubripes/mrna.ra
        # Adding data of type: mRNA ...


# MAKE AND STORE EST ALIGNMENTS  (6/8/03 KRR)

    # setup BlueArc with EST files
    ssh kk
    mkdir -p /cluster/bluearc/fugu/fr1/est
    cd /cluster/bluearc/fugu/fr1/est
    
    # split up est file into 100Kb chunks 
    # (makes ~120 query files * ~600 target superscaffolds = 70000 jobs)
    faSplit about  /cluster/store5/mrna.134/org/Takifugu_rubripes/est.fa \
                                100000 e

    # TODO: try aligning est files against whole chrUn nib
    # this would be easier on the filesystem, and probably fast enough
    cd ~/fr1/bed
    mkdir est
    cd est
    mkdir psl
    ls -1S /iscratch/i/fugu/trfFa/*.fa > genome.lst
    ls -1S /cluster/bluearc/fugu/fr1/est/*.fa > est.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -mask=lower -ooc={check in exists /scratch/hg/h/11.ooc} {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP 
'_EOF_' 
    gensub2 genome.lst est.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check...
    # just a few minutes to complete

    # process alignments
    ssh eieio
    cd ~/fr1/bed/est

    pslSort dirs raw.psl /tmp psl
    pslReps -minAli=0.98 -sizeMatters -nearTop=0.005 raw.psl scaffolds.psl \
      /dev/null

    # lift up PSL files to chrom coordinates
    liftUp -nohead all_est.psl ~/fr1/Un/chrUn.lft warn scaffolds.psl
        # Got 40758 lifts in /cluster/home/kate/fr1/Un/chrUn.lft
        # Lifting scaffolds.psl

    pslSortAcc nohead chrom /tmp all_est.psl
        # Processing all_est.psl
        # Processed 20501 lines into 1 temp files

    # load into database
    ssh hgwdev
    cd ~/fr1/bed/est/chrom

    # rename psl file to required format (must be chr*_est)
    mv chrUn.psl chrUn_est.psl

    # load alignments
    hgLoadPsl fr1 chrUn_est.psl
    cd ..
    hgLoadPsl fr1 all_est.psl -nobin

    set mrnaDir = mrna.134
    ln -s /cluster/store5/$mrnaDir/org/Takifugu_rubripes/est.fa /gbdb/fr1/$mrnaDir
    
    cd ~/fr1/bed/est
    rm *.tab
    hgLoadRna add -type=EST fr1 /gbdb/fr1/$mrnaDir/est.fa \
        /cluster/store5/$mrnaDir/org/Takifugu_rubripes/est.ra
    unset mrnaDir

    # note: there is no Genbank RefSeq directory for this organism

# PRODUCE CROSS_SPECIES MRNA ALIGNMENT (6/9/03 KRR)
    # Aligns non-Fugu mRNA's  against the masked genome
    # This uses Genbank mRNA files already downloaded 
    # to /cluster/store5/genbank.134
    # Files are unpacked to /cluster/store5/mrna.134

    # use fileserver where genbank.134 resides
    ssh eieio
    set genbankdir = /cluster/store5/genbank.134
    set mrnadir = /cluster/store5/mrna.134
    cd $mrnaDir

    # generate filter file for unpacking entries
    # note: skip this if fuguXenoRna.fil exists
    cat << '_EOF_' > fuguXenoRna.fil
restrict mol=mRNA & !(org="Takifugu rubripes")
hide mol
'_EOF_' 

    # unpack non-Fugu mRNAs
    gunzip -c $genbankdir/gb{pri,rod,v,mam,inv,bct,htc,pat,phg,pln}* \
        | gbToFaRa fuguXenoRna.fil \
                fuguXenoRna.fa fuguXenoRna.ra fuguXenoRna.ta stdin

    # copy masked chromosome nib to bluearc for cluster run
    # NOTE: probably want to do this earlier
    # so it is available for all alignments
    ssh kk
    cd /cluster/bluearc/fugu/fr1
    mkdir chromNib
    cp ~/fr1/nib/* chromNib

    # split masked scaffold file into 50Mb chunks
    # to produce 7 files
    mkdir trfFa
    faSplit about ~/fr1/fugu_v3.masked.fa 50000000 trfFa/s

    # split big xeno mrna file into 700Kb chunks on bluearc for cluster run
    # (makes ~1000 query files * 7 target files = ~7000 jobs)
    # This is not too many to handle in a single directory (psl)
    mkdir xenoRnaSplit
    faSplit about $mrnadir/fuguXenoRna.fa 700000 xenoRnaSplit/m

    cd ~/fr1/bed
    mkdir xenoMrna
    cd xenoMrna
    mkdir psl
    ls -1S /cluster/bluearc/fugu/fr1/trfFa/s*.fa > genome.lst
    ls -1S /cluster/bluearc/fugu/fr1/xenoRnaSplit/m*.fa > mrna.lst
    cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -q=rnax -t=dnax -mask=lower {check in exists+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP 
'_EOF_'
    gensub2 genome.lst mrna.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check...
        # Completed: 6629 of 6629 jobs
        # Avg. job: 2.7 min
        # Longest job: 4.7 min
        # Submission to last job: 49 min

    # process alignments
    ssh eieio
    cd ~/fr1/bed/xenoMrna

    # sort alignmnents
    pslSort dirs raw.psl /tmp psl
        # Got 6629 files 81 files per mid file

    # analyse repeats and generate genome-wide best alignment
    # note different parameters from previous alignments
    pslReps -minAli=0.25 raw.psl scaffolds.psl /dev/null
        # ...........Processed 1675350 alignments

    # lift up PSL files to chrom coordinates
    liftUp -nohead chrom.psl ~/fr1/Un/chrUn.lft warn scaffolds.psl
        # Got 40758 lifts in /cluster/home/kate/fr1/Un/chrUn.lft

    # extract psl file for each accession, into a dir
    pslSortAcc nohead chrom /tmp chrom.psl
    
    # merge psl files
    pslCat -dir chrom > xenoMrna.psl

    # load alignments into database
    ssh hgwdev
    cd ~/fr1/bed/xenoMrna
    rm *.tab
    hgLoadPsl fr1 xenoMrna.psl -tNameIx

    # load xeno rna into database
    set mrnadir = mrna.134
    set datadir = /cluster/store5
    ln -s $datadir/$mrnadir/fuguXenoRna.fa /gbdb/fr1/$mrnaDir
    hgLoadRna add -type=xenoRna fr1 /gbdb/fr1/$mrnadir/fuguXenoRna.fa \
         $datadir/$mrnadir/fuguXenoRna.ra


# PRODUCE HUMAN BLAT ALIGNMENT (6/19/03 KRR)
    ssh kk
    mkdir ~/hg15/bed/blatHg15.new
    cd ~/hg15/bed/blatHg15.new
    mkdir -p psl/chrUn
    ls -1S /cluster/bluearc/fugu/fr1/trfFa/*.fa > fugu.lst
    # 7 files of 50MB
    ls -1S /scratch/hg/gs.16/build33/trfFa/*.fa > human.lst
    cat << 'EOF' > gsub
#LOOP
/cluster/bin/i386/blat -mask=lower -q=dnax -t=dnax {check in line+ $(path1)} {check in line+ $(path2)} {check out line+ /cluster/store5/Fugu_Rubripes_V3/bed/blatHg15.new/psl/$(root1)_$(root2).psl}
#ENDLOOP
'EOF'

    gensub2 fugu.lst human.lst gsub spec
    para create spec
    para try
    para check
    para push
    para check

# PRODUCE HUMAN BLAT ALIGNMENT (6/11/03 KRR)
    # For this build, use the Fugu BLAT to human (hg15),
    # and reverse the alignment

    # use local fileserver
    ssh eieio

    mkdir ~/fr1/bed/blatHg15/psl
    set hg15dir = ~/hg15/bed/blatFugu
    set fr1dir = ~/fr1/bed/blatHg15
    mkdir -p $fr1dir/{psl,chrom}

    # swap alignments (for each human chrom)
    cd $hg15dir/chrom
    foreach f (chr?{,?}{,_random}_blatFugu.psl)
        pslSwap $f $fr1dir/psl/$f
    end

    # merge to single Fugu chrUn chrom
    cd $fr1dir/psl
    # pslCat -out=$fr1dir/chrom/chrUn_blatHg15.psl chr?{,?}{,_random}_blatFugu.psl
    pslCat chr?{,?}{,_random}_blatFugu.psl > \
                $fr1dir/chrom/scaffolds.psl 

    # lift target side (fugu) to chrom coordinates
    cd $fr1dir/chrom
    liftUp chrUn_blatHg15.psl ~/fr1/Un/chrUn.lft warn scaffolds.psl
    
    # load into database
    cd $fr1dir/chrom
    hgLoadPsl fr1 chrUn_blatHg15.psl

    # make hg15 symlink in /gbdb and load human sequence data
    set gbdbdir=/gbdb/fr1/hg15
    mkdir $gbdbdir
    cd $gbdbdir
    foreach f (/cluster/store5/gs.16/build33/?{,?})
        set c = $f:t
        if (-e $f/chr${c}.fa) then
            ln -s $f/chr${c}.fa
        endif
        if (-e $f/chr${c}_random.fa) then
            ln -s $f/chr${c}_random.fa
        endif
    end

    # load human sequences into database
    ssh hgwdev
    cd ~/fr1/bed/blatHg15
    hgLoadRna addSeq fr1 /gbdb/fr1/hg15/*.fa
    unset fr1dir hg15dir
        

# PRODUCE TETRAODON BLASTZ (6/13/03 IN PROGRESS KRR)
# NOTE: the tetra sequence wasn't repeatmasked -> must be redone

    cd eieio
    mkdir ~/fr1/bed/blastzTetra

    # translate the Genoscope fasta files to upper-case
    # so sequence doesn't look like it's masked out (all-lower)
    cd /iscratch/i/fish
    foreach f (*.fa)
        echo $f
        tr '[a-z]' '[A-Z]' < $f > /cluster/bluearc/tetra/$f
    end
    (cat README; echo "NOTE: Upper-cased files from /iscratch/i/fish") > \
                                        /cluster/bluearc/tetra/README

    # copy fugu files to cluster filesystem
    set clusterdir = /cluster/bluearc
    mkdir -p $clusterdir/fugu/fr1/rmsk
    cd $clusterdir/fugu/fr1/rmsk
    rm *.out
    cp ~/fr1/Un/chrUn.fa.out .

    # generate DEF file
    cd ~/fr1/bed/blastzTetra
    cat << '_EOF_' > DEF
# Tetraodon vs. Fugu
# TODO: angie's home dir out of this
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/home/angie/schwartzbin:/cluster/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
#BLASTZ_ABRIDGE_REPEATS=1 if SMSK is specified
BLASTZ_ABRIDGE_REPEATS=0

# TARGET - Fugu
# soft-masked chrom nib
SEQ1_DIR=/cluster/bluearc/fugu/fr1/chromNib
# repeat masker output file for chrom
SEQ1_RMSK=/cluster/bluearc/fugu/fr1/rmsk
# lineage-specific repeats -- (repeats in fugu, not in tetraodon)
# we don't have that information for these species
SEQ1_SMSK=/dev/null
# currently unused
SEQ1_FLAG=-fish
SEQ1_IN_CONTIGS=0
# 10 MB chunk for target
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY - Tetraodon
SEQ2_DIR=/cluster/bluearc/tetra
# no repeatmasker output for these sequences
SEQ2_RMSK=/dev/null
SEQ2_SMSK=/dev/null
# currently unused
SEQ2_FLAG=-fish
# set to 1 if multiple contigs are in 1 fasta file
SEQ2_IN_CONTIGS=1
# 10 Mbase for query
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/store5/Fugu_Rubripes_V3/bed/blastzTetra

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len

#DEBUG=1
'_EOF_' 

    # save the DEF file in the current standard place
    chmod +x DEF
    cp DEF ~angie/hummus/DEF.fr1-tetra.2003-06-17

    # setup cluster run
    ssh kk
    cd ~/fr1/bed/blastzTetra

    # source the DEF file
    bash
    . ./DEF

    # follow the next set of directions slavishly
    mkdir -p $BASE/run
    # give up on avoiding angie's directories
    # tcl script
    # creates xdir.sh and joblist run/j
    ~angie/hummus/make-joblist $DEF > $BASE/run/j
        # Computing genome sizes
        # Writing mkdir script: /cluster/store5/Fugu_Rubripes_V3/bed/blastzTetra/xdir.sh
        # Writing job list

    # xdir.sh makes a bunch of result directories in $BASE/raw/
    # based on chrom name and CHUNK size
    sh $BASE/xdir.sh
    cd $BASE/run

    # now edit j to prefix path to executable name
    # NOTE: we should have a controlled version of schwartz bin executables
    sed -e 's#^#/cluster/home/schwartz/bin/#' j > j2
    wc -l j*
    head j2

    # *** make sure the j2 edits are OK, then use it:
    mv j2 j

    # para create will create the file: 'batch' for the cluster run
    para create j
        # Checking input files
        # 1400 jobs written to batch
    para try
    para check
    para push
    # ... etc ...
    # about 3 hrs. per job

    # post-process blastz
    # normalize
    ssh kk
    cd ~/fr1/bed/blastzTetra
        #   source the DEF file again in case you are coming back to this
    bash
    . ./DEF

    # a new run directory
    mkdir -p $BASE/run.1

    # another obscure script creates a new job list:
    ~angie/hummus/do.out2lav $DEF >$BASE/run.1/j
    cd $BASE/run.1

    # add path to executable in the job list:
    sed -e 's/^/\/cluster\/home\/schwartz\/bin\//' j > j2
    wc -l j*
    head j2

    # make sure the edited j2 is OK, then use it:
    mv j2 j
    para create j
    para try
    para check
    para push
    # etc.
        # 15 minute jobs

    # Translate the .lav files
    # into axt files
    ssh kkstore
    set base="/cluster/store5/Fugu_Rubripes_V3/bed/blastzTetra"
    set tbl="blastzTetra"

    # generate single tetra fa file required for lavToAxt
    cd /cluster/bluearc
    cat tetra/* > tetra-all.fa

    # copy lav files to bluearc to speed up job
    ssh eieio
    mkdir -p /cluster/bluearc/fugu/fr1/blastzTetra/lav
    cp ~/fr1/bed/blastzTetra/lav/chrUn/* /cluster/bluearc/fugu/fr1/blastzTetra/lav
    
    # cluster job for converting lav files
    # these take a long time because query is in fa files
    # (with 880K sequences), not a chrom nib
    ssh kk
    cd ~/fr1/bed/blastzTetra
    mkdir -p axtLav
    mkdir run.lavToAxt
    cd run.lavToAxt
    
    # create file lists
    ls -1S /cluster/bluearc/fugu/fr1/blastzTetra/lav/*.lav > lav.lst
    echo "" > dummy.lst

    # Create template file, gsub, for gensub2. 
    cat << 'EOF' > gsub
#LOOP 
/cluster/bin/i386/lavToAxt {check in line+ $(path1)} /cluster/bluearc/fugu/fr1/chromNib -fa /cluster/bluearc/tetra-all.fa {check out line+ /cluster/store5/Fugu_Rubripes_V3/bed/blastzTetra/axtLav/$(root1).axt}
#ENDLOOP
'EOF'

    gensub2 lav.lst dummy.lst gsub jobList
    para create jobList
    para try 
    para check
    para push

    # 35 hours (too long -- need to split up better).

    cd $base
    mkdir -p axtChrom
    cat axtLav/*.axt | /cluster/bin/i386/axtSort stdin axtChrom/chrUn.axt
    
    #foreach c (lav/*)
      #pushd $c
      #set chr=$c:t
      #set out=$base/axtChrom/$chr.axt
      #echo "out=$out"
      #echo "Translating $chr lav to $out"
      #echo cat `ls -1 *.lav | sort -g` \
        #| /cluster/bin/i386/lavToAxt stdin $fugudir/nib \
                #-fa /cluster/bluearc/tetra-all.fa stdout \
        #| /cluster/bin/i386/axtSort stdin $out
      #popd
    #end

    # Translate the sorted axt files into psl:
    cd $base
    mkdir -p pslChrom
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end

    # load these blastz results
    ssh hgwdev
    cd ~/fr1/bed/blastzTetra/pslChrom
    /cluster/bin/i386/hgLoadPsl fr1 chr*_*.psl

    # STOPPED HERE -- due to empty output data


# PRODUCING GENSCAN PREDICTIONS (6/17/03 KRR)
#       Note: Genscan input files should be hard-masked
    
    ssh eieio

    # hard mask the super-scaffolds
    mkdir -p ~/fr1/superscaffolds.hardmasked
    cd ~/fr1/superscaffolds
    foreach f (ss_*.fa)
        echo $
        maskOutFa $f hard ../superscaffolds.hardmasked/$f
    end

    # setup the genscan directory
    mkdir -p ~/fr1/bed/genscan
    cd ~/fr1/bed/genscan

    # Make 3 subdirectories for genscan to put output files in
    mkdir -p gtf pep subopt

    # Generate a list file, genome.list, of all the contigs
    # *that do not have pure Ns* (due to heterochromatin, unsequenceable 
    # stuff) which would cause genscan to run forever.
    rm -f genome.list
    touch genome.list
    foreach f ( `ls -1S /cluster/store5/Fugu_Rubripes_V3/superscaffolds.hardmasked/ss_*.fa` )
      egrep '[ACGT]' $f > /dev/null
      if ($status == 0) echo $f >> genome.list
    end

    # Log into kkr1u00 (not kk!).  kkr1u00 is the driver node for the small
    # cluster (kkr2u00 -kkr8u00. Genscan has problem running on the
    # big cluster, due to limitation of memory and swap space on each
    # processing node).
    ssh kkr1u00
    cd ~/fr1/bed/genscan

    # Create template file, gsub, for gensub2. 
    # NOTE: According to the README for Genscan, 
    # the HumanIso.smat parameter files is used for all vertebrates
    cat << '_EOF_' > gsub
#LOOP 
/cluster/home/kent/bin/i386/gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/genscan -par=/cluster/home/fanhsu/projects/compbio/bin/genscan-linux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_' 
    echo "" > dummy.list
    gensub2 genome.list dummy.list gsub jobList
    para create jobList
    para try
    para check
    para push

    # Convert output to chrom coordinates
    ssh eieio
    cd ~/fr1/bed/genscan
    liftUp genscan.gtf ~/fr1/Un/chrUn.lft warn gtf/*.gtf
    liftUp genscanSubopt.bed ~/fr1/Un/chrUn.lft warn subopt/*.bed > /dev/null
    cat pep/*.pep > genscan.pep

    # Load into the database
    ssh hgwdev
    cd ~/fr1/bed/genscan
    ldHgGene fr1 genscan genscan.gtf
        # Reading genscan.gtf
        # Read 36106 transcripts in 243984 lines in 1 files
        # 36106 groups 1 seqs 1 sources 1 feature types
        # 36106 gene predictions
    hgPepPred fr1 generic genscanPep genscan.pep
    hgLoadBed fr1 genscanSubopt genscanSubopt.bed > /dev/null


# CPGISLANDS (6/17/03 KRR)
    ssh eieio
    mkdir -p ~/fr1/bed/cpgIsland
    cd ~/fr1/bed/cpgIsland

    # Build software emailed from Asif Chinwalla (achinwal@watson.wustl.edu)
    # NOTE: we should keep this centrally
    # tar xvf cpg_dist.tar 
    # cd cpg_dist
    # gcc readseq.c cpg_lh.c -o cpglh.exe
    cp ~kent/mm3/bed/cpgIsland/cpg_dist/cpglh.exe .

    # hard-mask the chrom fa 
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    cd ~/fr1/Un
    maskOutFa chrUn.fa hard chrUn.hardmasked.fa

    # run cpgislands on the hard-masked chrom fa
    cd ~/fr1/bed/cpgIsland
    ./cpglh.exe ~/fr1/Un/chrUn.hardmasked.fa > chrUn.cpg

    cp ~kent/mm3/bed/cpgIsland/filter.awk .
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    # load annotations into database
    ssh hgwdev
    cd ~/fr1/bed/cpgIsland
    # NOTE: this should go into a shared lib dir
    cp $HOME/kent/src/hg/lib/cpgIsland.sql .
    hgLoadBed fr1 cpgIsland -tab -noBin \
      -sqlTable=cpgIsland.sql cpgIsland.bed
        # Reading cpgIsland.bed
        # Loaded 41723 elements
        # Sorted
        # Saving bed.tab
        # Loading fr1


