#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# Drosophila mojavensis -- 
# 
# Agencourt's 11 Aug 2004 assembly
# 
#


# DOWNLOAD SEQUENCE (DONE 11/3/04 angie)
    ssh kksilo
    mkdir /cluster/store8/droMoj1
    cd /cluster/data
    ln -s /cluster/store8/droMoj1 droMoj1
    cd /cluster/data/droMoj1
    mkdir jkStuff bed
    mkdir downloads
    cd downloads
    wget http://rana.lbl.gov/drosophila/assemblies/dmoj_agencourt_arachne_11aug04.tar.gz
    tar xvzf dmoj_agencourt_arachne_11aug04.tar.gz
    gunzip mojavensis/assembly.bases.gz
    faSize mojavensis/assembly.bases
#189814987 bases (0 N's 189814987 real) in 38423 sequences in 1 files
#Total size: mean 4940.1 sd 12402.7 min 452 (contig_2604) max 332654 (contig_1100) median 1273
#N count: mean 0.0 sd 0.0


# PARTITION SCAFFOLDS FOR REPEATMASKER RUN (DONE 11/3/04 angie)
    # Max scaffold size is 332k, so no splitting/lifting req'd!
    # Agglomerate the small scaffolds up into ~500k collections.
    ssh kksilo
    cd /cluster/data/droMoj1
    mkdir chunks
    faSplit downloads/mojavensis/assembly.bases stdin 500000 chunks/chunk_


# CREATING DATABASE (DONE 11/3/04 angie)
    # Create the database.
    ssh hgwdev
    # Make sure there is at least 5 gig free for the database
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  638G 1022G  39% /var/lib/mysql
    hgsql '' -e 'create database droMoj1'


# RUN REPEAT MASKER (DONE 11/4/04 angie)
    # January ("March") '04 version of RepeatMasker and libs.
    # make the run directory, output directory, and job list
    ssh kksilo
    cd /cluster/data/droMoj1
    cat << '_EOF_' > jkStuff/RMDrosophila
#!/bin/csh -fe

cd $1
/bin/mkdir -p /tmp/droMoj1/$2
/bin/cp ../chunks/$2 /tmp/droMoj1/$2/
pushd /tmp/droMoj1/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -s -spec drosophila $2
popd
/bin/cp /tmp/droMoj1/$2/$2.out ./
/bin/rm -fr /tmp/droMoj1/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/droMoj1/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/droMoj1
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMDrosophila
    mkdir RMRun RMOut
    cp /dev/null RMRun/RMJobs
    foreach f ( chunks/*.fa )
      set chunk = $f:t
      echo ../jkStuff/RMDrosophila \
           /cluster/data/droMoj1/RMOut $chunk \
           '{'check in line+ /cluster/data/droMoj1/$f'}' \
         '{'check out line+ /cluster/data/droMoj1/RMOut/$chunk.out'}' \
      >> RMRun/RMJobs
    end

    # do the run
    ssh kk9
    cd /cluster/data/droMoj1/RMRun
    para create RMJobs
    para try, check, push, check,...
#Completed: 366 of 366 jobs
#Average job time:                2881s      48.01m     0.80h    0.03d
#Longest job:                     4316s      71.93m     1.20h    0.05d
#Submission to last job:         15955s     265.92m     4.43h    0.18d

    # Make a consolidated scaffold .out file too:
    head -3 RMOut/chunk_00.fa.out > RMOut/scaffolds.fa.out
    foreach f (RMOut/chunk*.fa.out)
      tail +4 $f >> RMOut/scaffolds.fa.out 
    end
    # Load the .out files into the database with:
    ssh hgwdev
    hgLoadOut droMoj1 /cluster/data/droMoj1/RMOut/scaffolds.fa.out
    # hgLoadOut made a "scaffolds_rmsk" table even with -table=rmsk, 
    # but we want a non-split with no prefix table:
    hgsql droMoj1 -e 'rename table scaffolds_rmsk to rmsk'
    # Fix up the indices too:
    hgsql droMoj1 -e 'drop index bin       on rmsk; \
                  drop index genoStart on rmsk; \
                  drop index genoEnd   on rmsk; \
                  create index bin       on rmsk (genoName(12), bin); \
                  create index genoStart on rmsk (genoName(12), genoStart); \
                  create index genoEnd   on rmsk (genoName(12), genoEnd);'


# EXTRACTING GAP INFO FROM BLOCKS OF NS (DONE 11/5/04 angie)
    ssh kksilo
    mkdir /cluster/data/droMoj1/bed/fakeAgp
    cd /cluster/data/droMoj1/bed/fakeAgp
    faGapSizes ../../downloads/mojavensis/assembly.bases \
        -niceSizes=5,10,20,25,30,40,50,100,250,500,1000,10000,100000
    # Oops, forgot that faSize told us there were no N's at all!
    # No need to run hgFakeAgp here -- just create an empty gap table.
    ssh hgwdev
    hgLoadGap -unsplit droMoj1 /dev/null


# SIMPLE REPEATS (TRF) (DONE 11/4/04 angie)
    ssh kksilo
    mkdir /cluster/data/droMoj1/bed/simpleRepeat
    cd /cluster/data/droMoj1/bed/simpleRepeat
    nice trfBig -trf=/cluster/bin/i386/trf \
      ../../downloads/mojavensis/assembly.bases \
      /dev/null -bedAt=simpleRepeat.bed -tempDir=/tmp \
    |& egrep -v '^(Removed|Tandem|Copyright|Loading|Allocating|Initializing|Computing|Scanning|Freeing)' \
    > trf.log &
    # check on this with
    tail -f trf.log

    # Load this into the database as so
    ssh hgwdev
    hgLoadBed droMoj1 simpleRepeat \
      /cluster/data/droMoj1/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql


# FILTER SIMPLE REPEATS (TRF) INTO MASK (DONE 11/4/04 angie)
    # make a filtered version of the trf output: 
    # keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/droMoj1/bed/simpleRepeat
    awk '{if ($5 <= 12) print;}' simpleRepeat.bed > trfMask.bed


# MASK FA USING REPEATMASKER AND FILTERED TRF FILES (DONE 11/4/04 angie)
    ssh kksilo
    cd /cluster/data/droMoj1
    maskOutFa -soft downloads/mojavensis/assembly.bases \
      bed/simpleRepeat/trfMask.bed scaffolds.fa
    maskOutFa -softAdd scaffolds.fa RMOut/scaffolds.fa.out scaffolds.fa
    # Now clean up the unmasked chunks to avoid confusion later.
    rm -r chunks


# STORE SEQUENCE AND ASSEMBLY INFORMATION (DONE 11/4/04 angie)
    # Translate to 2bit
    ssh kksilo
    cd /cluster/data/droMoj1
    faToTwoBit scaffolds.fa droMoj1.2bit
    # Make chromInfo.tab.
    mkdir bed/chromInfo
    twoBitInfo droMoj1.2bit stdout \
    | awk '{printf "%s\t%s\t/gbdb/droMoj1/nib/droMoj1.2bit\n", $1, $2;}' \
    > bed/chromInfo/chromInfo.tab

    # Make symbolic a link from /gbdb/droMoj1/nib to the 2bit.
    ssh hgwdev
    mkdir -p /gbdb/droMoj1/nib
    ln -s /cluster/data/droMoj1/droMoj1.2bit /gbdb/droMoj1/nib
    # Load chromInfo table.
    hgsql droMoj1 < $HOME/kent/src/hg/lib/chromInfo.sql
    hgsql droMoj1 -e 'load data local infile \
      "/cluster/data/droMoj1/bed/chromInfo/chromInfo.tab" into table chromInfo'
    # Make chrom.sizes from chromInfo contents and check scaffold count.
    hgsql droMoj1 -N -e 'select chrom,size from chromInfo' \
    > /cluster/data/droMoj1/chrom.sizes
    wc -l /cluster/data/droMoj1/chrom.sizes
#  38423 /cluster/data/droMoj1/chrom.sizes


# CREATING GRP TABLE FOR TRACK GROUPING (DONE 11/3/04 angie)
    # Copy all the data from the table "grp" 
    # in an existing database to the new database
    ssh hgwdev
    hgsql droMoj1 -e 'create table grp (PRIMARY KEY(NAME)) select * from hg17.grp'


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE 11/4/04 angie)
    # Warning: genome and organism fields must correspond
    # with defaultDb values
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
             defaultPos, active, orderKey, genome, scientificName, \
             htmlPath, hgNearOk, hgPbOk, sourceName) values \
        ("droMoj1", "Aug. 2004", "/gbdb/droMoj1/nib", "D. mojavensis", \
             "contig_1100:63975-78814", 1, 57, \
             "D. mojavensis", \
             "Drosophila mojavensis", "/gbdb/droMoj1/html/description.html", \
             0, 0, "Agencourt 11 Aug 2004");' \
      | hgsql -h genome-testdb hgcentraltest
    echo 'INSERT INTO defaultDb (genome, name) values ("D. mojavensis", "droMoj1");' \
      | hgsql -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P

    # Edit trackDb/makefile to add droMoj1 to the DBS variable.
    mkdir drosophila/droMoj1
    # Create a simple drosophila/droMoj1/description.html file.
    cvs add drosophila/droMoj1
    cvs add drosophila/droMoj1/description.html
    make update DBS=droMoj1 ZOO_DBS=

    # go public on genome-test
    cvs commit makefile
    cvs commit drosophila/droMoj1
    mkdir /gbdb/droMoj1/html
    # in a clean, updated tree's kent/src/hg/makeDb/trackDb:
    make alpha


# PUT SEQUENCE ON /ISCRATCH FOR BLASTZ (DONE 11/4/04 angie)
    # First, agglomerate small scaffolds into chunks of ~200k median 
    # (many scaffolds are larger than that) so we don't have too many 
    # files for one dir, but keep a reasonably low job run time:
    # I should have split these a little coarser -- avg job time too small.
    ssh kksilo
    cd /cluster/data/droMoj1
    mkdir chunks
    faSplit about scaffolds.fa 200000 chunks/chunk_
    ssh kkr1u00
    mkdir /iscratch/i/droMoj1
    cp -pR /cluster/data/droMoj1/chunks /iscratch/i/droMoj1/
    cp -p /cluster/data/droMoj1/droMoj1.2bit /iscratch/i/droMoj1/
    iSync


# PRODUCING GENSCAN PREDICTIONS (DONE 11/4/04 angie)
    ssh kksilo
    # Make hard-masked scaffolds and split up for processing:
    cd /cluster/data/droMoj1
    maskOutFa scaffolds.fa hard scaffolds.fa.masked
    mkdir chunksHardMasked
    faSplit about scaffolds.fa.masked 500000 chunksHardMasked/chunk_
    mkdir /cluster/data/droMoj1/bed/genscan
    cd /cluster/data/droMoj1/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    ls -1S ../../chunksHardMasked/chunk*.fa > chunks.list
    cat << '_EOF_' > gsub
#LOOP
gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    gensub2 chunks.list single gsub jobList
    ssh kki
    cd /cluster/data/droMoj1/bed/genscan
    para create jobList
    para try, check, push, check, ...
#Completed: 366 of 366 jobs
#Average job time:                  16s       0.26m     0.00h    0.00d
#Longest job:                       29s       0.48m     0.01h    0.00d
#Submission to last job:           462s       7.70m     0.13h    0.01d

    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    
    # Concatenate scaffold-level results:
    ssh kksilo
    cd /cluster/data/droMoj1/bed/genscan
    cat gtf/*.gtf > genscan.gtf
    cat subopt/*.bed > genscanSubopt.bed
    cat pep/*.pep > genscan.pep
    # Clean up:
    rm -r /cluster/data/droMoj1/chunksHardMasked

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/droMoj1/bed/genscan
    ldHgGene -gtf -genePredExt droMoj1 genscan genscan.gtf
    hgPepPred droMoj1 generic genscanPep genscan.pep
    hgLoadBed droMoj1 genscanSubopt genscanSubopt.bed


# MAKE DOWNLOADABLE FILES (DONE 11/4/04 angie)
    ssh kksilo
    mkdir /cluster/data/droMoj1/zips
    cd /cluster/data/droMoj1
    zip -j zips/scaffoldOut.zip RMOut/scaffolds.fa.out
    zip -j zips/scaffoldFa.zip scaffolds.fa
    zip -j zips/scaffoldFaMasked.zip scaffolds.fa.masked
    zip -j zips/scaffoldTrf.zip bed/simpleRepeat/trfMask.bed
    foreach f (zips/*.zip)
      echo $f
      unzip -t $f | tail -1
    end
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/droMoj1
    cd /usr/local/apache/htdocs/goldenPath/droMoj1
    mkdir bigZips database
    # Create README.txt files in bigZips/ and database/ to explain the files.
    cd bigZips
    cp -p /cluster/data/droMoj1/zips/*.zip .
    md5sum *.zip > md5sum.txt


# SWAP DM1-DROMOJ1 BLASTZ (DONE 11/4/04 angie)
    ssh kksilo
    mkdir -p /cluster/data/droMoj1/bed/blastz.dm1.swap.2004-11-04/axtScaffold
    ln -s blastz.dm1.swap.2004-11-04 /cluster/data/droMoj1/bed/blastz.dm1
    cd /cluster/data/droMoj1/bed/blastz.dm1
    set aliDir = /cluster/data/dm1/bed/blastz.droMoj1
    cp $aliDir/S1.len S2.len
    cp $aliDir/S2.len S1.len
    # With 38k scaffolds, we don't want a directory with one file per 
    # scaffold.  So just make one .axt with everything -- not too huge 
    # anyway, given these little insect genomes.
    cat $aliDir/axtChrom/chr*.axt \
    | axtSwap stdin $aliDir/S1.len $aliDir/S2.len stdout \
    | axtSort stdin dm1.axt
    du -sh $aliDir/axtChrom dm1.axt
#235M    /cluster/data/dm1/bed/blastz.droMoj1/axtChrom
#235M    dm1.axt


# CHAIN MELANOGASTER BLASTZ (DONE 11/4/04 angie)
    # Run axtChain on kolossus (one big dm1.axt input)
    ssh kolossus
    mkdir /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    axtChain -verbose=0 ../dm1.axt /cluster/data/droMoj1/droMoj1.2bit \
      /cluster/data/dm1/nib stdout \
    | chainAntiRepeat /cluster/data/droMoj1/droMoj1.2bit \
      /cluster/data/dm1/nib stdin stdout \
    | chainMergeSort stdin > all.chain
    # Load chains into database
    ssh hgwdev
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    hgLoadChain -tIndex droMoj1 chainDm1 all.chain


# NET MELANOGASTER BLASTZ (DONE 11/5/04 angie)
    ssh kksilo
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    # Note: this was painfully slow until I added an index on genoName to rmsk.
    # An index on genoName,bin is fine too -- but explain shows that the index 
    # on bin,genoName was ignored ==> 38k very slow hChromQuery calls.
    netClass -noAr noClass.net droMoj1 dm1 melanogaster.net \
    |& g -v "table gap doesn't exist"

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    rm noClass.net
    netFilter -syn melanogaster.net > melanogasterSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    netFilter -minGap=10 melanogaster.net |  hgLoadNet droMoj1 netDm1 stdin
    netFilter -minGap=10 melanogasterSyn.net \
    | hgLoadNet droMoj1 netSyntenyDm1 stdin


# MAKE AXTNET (DONE 11/4/04 angie)
    ssh kksilo
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    netToAxt melanogaster.net all.chain /cluster/data/droMoj1/droMoj1.2bit \
        /cluster/data/dm1/nib stdout \
      | axtSort stdin melanogasterNet.axt


# MAKE VSDM1 DOWNLOADABLES (DONE 11/5/04 angie)
    ssh kksilo
    cd /cluster/data/droMoj1/bed/blastz.dm1/axtChain
    nice gzip *.{chain,net,axt}
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/droMoj1/vsDm1
    cd /usr/local/apache/htdocs/goldenPath/droMoj1/vsDm1
    cp -p /cluster/data/droMoj1/bed/blastz.dm1/axtChain/all.chain.gz \
      melanogaster.chain.gz
    cp -p /cluster/data/droMoj1/bed/blastz.dm1/axtChain/melanogaster.net.gz .
    cp -p /cluster/data/droMoj1/bed/blastz.dm1/axtChain/melanogasterNet.axt.gz .
    # Make a README.txt which explains the files & formats.
    md5sum *.gz */*.gz > md5sum.txt


# MAKE 11.OOC FILE FOR BLAT (DONE 11/4/04 angie)
    # Use -repMatch=100 (based on size -- for human we use 1024, and 
    # fly size is ~4.4% of human judging by gapless dm1 genome size from 
    # featureBits -- we would use 45, but bump that up a bit to be more 
    # conservative).
    ssh kkr1u00
    mkdir /cluster/bluearc/droMoj1
    blat /cluster/data/droMoj1/droMoj1.2bit /dev/null /dev/null -tileSize=11 \
      -makeOoc=/cluster/bluearc/droMoj1/11.ooc -repMatch=100
#Wrote 18637 overused 11-mers to /cluster/bluearc/droMoj1/11.ooc
    cp -p /cluster/bluearc/droMoj1/*.ooc /iscratch/i/droMoj1/
    iSync


# AUTO UPDATE GENBANK MRNA RUN  (IN PROGRESS 11/10/04 angie)
    ssh hgwdev
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .

    # Edit etc/genbank.conf and add these lines (note scaffold-browser settings):
# droMoj1 (D. mojavensis)
droMoj1.genome = /iscratch/i/droMoj1/droMoj1.2bit
droMoj1.mondoTwoBitParts = 1000
droMoj1.lift = no
droMoj1.refseq.mrna.native.load = no
droMoj1.refseq.mrna.xeno.load = yes
droMoj1.refseq.mrna.xeno.pslReps = -minCover=0.15 -minAli=0.75 -nearTop=0.005
droMoj1.genbank.mrna.xeno.load = yes
# GenBank has no D. mojavensis ESTs at this point... that may change.
droMoj1.genbank.est.native.load = no
droMoj1.genbank.est.xeno.load = yes
droMoj1.genbank.est.xeno.pslReps = -minAli=0.5 -nearTop=0.01
droMoj1.downloadDir = droMoj1
droMoj1.perChromTables = no

    cvs ci etc/genbank.conf
    # Since D. mojavensis is a new species for us, edit src/lib/gbGenome.c.  
    # Pick some other browser species, & monkey-see monkey-do.  
    cvs diff src/lib/gbGenome.c
    make
    cvs ci src/lib/gbGenome.c
    # Edit src/align/gbBlat to add /iscratch/i/droMoj1/11.ooc
    cvs diff src/align/gbBlat
    make
    cvs ci src/align/gbBlat

    # Install to /cluster/data/genbank:
    make install-server

#TODO
    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, (xeno) RefSeq only:
    nice bin/gbAlignStep -srcDb=refseq -type=mrna -initial droMoj1 &
    tail -f [its logfile]
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad droMoj1
    featureBits droMoj1 xenoRefGene
#14616774 bases of 135845121 (10.760%) in intersection
    # Clean up:
    rm -rf work/initial.droMoj1

    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -srcDb=genbank -type=mrna -initial droMoj1 &
    tail -f [its logfile]
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad droMoj1
    featureBits droMoj1 all_mrna
    featureBits droMoj1 xenoMrna
    # Clean up:
    rm -rf work/initial.droMoj1

    # -initial for ESTs
    nice bin/gbAlignStep -srcDb=genbank -type=est -initial droMoj1 &
    tail -f [its logfile]
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 droMoj1 &
    # Clean up:
    rm -rf work/initial.droMoj1


# MAKE GCPERCENT (DONE 11/4/04 angie)
    ssh hgwdev
    mkdir /cluster/data/droMoj1/bed/gcPercent
    cd /cluster/data/droMoj1/bed/gcPercent
    # create and load gcPercent table
    hgGcPercent droMoj1 /cluster/data/droMoj1


# MAKE HGCENTRALTEST BLATSERVERS ENTRY (TODO 11/?/04 angie)
    ssh hgwdev
    echo 'insert into blatServers values("droMoj1", "blat?", "177??", 1, 0); \
          insert into blatServers values("droMoj1", "blat?", "177??", 0, 1);' \
      | hgsql -h genome-testdb hgcentraltest


