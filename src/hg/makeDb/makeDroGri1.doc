#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# Drosophila grimshawi -- 
# 
# Agencourt's 1 Aug 2005 assembly
#


# DOWNLOAD SEQUENCE (DONE 8/4/05 angie)
    ssh kkstore02
    mkdir /cluster/store11/droGri1
    cd /cluster/data
    ln -s /cluster/store11/droGri1 droGri1
    cd /cluster/data/droGri1
    mkdir jkStuff bed
    mkdir downloads
    cd downloads
    wget http://rana.lbl.gov/drosophila/assemblies/dgri_agencourt_arachne_01aug05.tar.gz
    tar xvzf dgri_agencourt_arachne_01aug05.tar.gz
    cd agencourt_arachne_01aug05
    faSize scaffolds.fa
#226113271 bases (11750600 N's 214362671 real 214362671 upper 0 lower) in 25052 sequences in 1 files
#Total size: mean 9025.8 sd 186055.6 min 196 (scaffold_22917) max 14170260 (scaffold_25013) median 2278
#N count: mean 469.0 sd 5266.4
#U count: mean 8556.7 sd 183411.7
#L count: mean 0.0 sd 0.0


# DOWNLOAD MITOCHONDRION GENOME SEQUENCE (OR NOT) (DONE 8/4/05 angie)
    # go to http://www.ncbi.nih.gov/ and search Nucleotide for 
    # "drosophila grimshawi mitochondrion" -- nada.


# PARTITION SCAFFOLDS FOR REPEATMASKER RUN (DONE 8/4/05 angie)
    # Max scaffold size is 26M! so chop up large scaffolds into ~500kb chunks 
    # and glom the tiny scaffolds up into ~500k collections (looks like 
    # some almost-500k pieces are glommed together --> a few almost-1M chunks,
    # but that's OK).
    ssh kkstore02
    cd /cluster/data/droGri1
    mv downloads/agencourt_arachne_01aug05/scaffolds.fa .
    mkdir scaffoldsSplit
    faSplit size scaffolds.fa \
      500000 -oneFile scaffoldsSplit -lift=jkStuff/scaffoldsSplit.lft
    mkdir chunks500k
    faSplit about scaffoldsSplit.fa 500000 chunks500k/chunk_


# CREATING DATABASE (DONE 8/4/05 angie)
    # Create the database.
    ssh hgwdev
    # Make sure there is at least 5 gig free for the database
    df -h /var/lib/mysql
#/dev/sdc1             1.8T  969G  691G  59% /var/lib/mysql
    hgsql '' -e 'create database droGri1'
    # Copy all the data from the table "grp" 
    # in an existing database to the new database
    hgsql droGri1 -e 'create table grp (PRIMARY KEY(NAME)) select * from dm2.grp'


# RUN REPEAT MASKER (DONE 8/4/05 angie)
    cat /cluster/bluearc/RepeatMasker/Libraries/version 
#RepBase Update 9.11, RM database version 20050112
    # make the run directory, output directory, and job list
    ssh kkstore02
    cd /cluster/data/droGri1
    cat << '_EOF_' > jkStuff/RMDrosophila
#!/bin/csh -fe

cd $1
/bin/mkdir -p /tmp/droGri1/$2
/bin/cp ../chunks500k/$2 /tmp/droGri1/$2/
pushd /tmp/droGri1/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -s -spec drosophila $2
popd
/bin/cp /tmp/droGri1/$2/$2.out ./
/bin/rm -fr /tmp/droGri1/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/droGri1/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/droGri1
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x jkStuff/RMDrosophila
    mkdir RMRun RMOut
    cp /dev/null RMRun/RMJobs
    foreach f ( chunks500k/*.fa )
      set chunk = $f:t
      echo ../jkStuff/RMDrosophila \
           /cluster/data/droGri1/RMOut $chunk \
           '{'check in line+ /cluster/data/droGri1/$f'}' \
         '{'check out line+ /cluster/data/droGri1/RMOut/$chunk.out'}' \
      >> RMRun/RMJobs
    end

    # In case this is the first time that the latest RepeatMasker version has 
    # been run on drosophila, do a little test run to make it unpack the 
    # drosophila lib files into the installation dir if necessary, before 
    # kicking off the cluster run.
    mkdir /tmp/RMtest
    cd /tmp/RMtest
    cp /cluster/data/droGri1/chunks500k/chunk_259.fa .
    /cluster/bluearc/RepeatMasker/RepeatMasker -qq -species drosophila \
      chunk_259.fa
    cd ..; rm -r RMtest

    # do the run
    ssh kk9
    cd /cluster/data/droGri1/RMRun
    para make RMJobs
    para time
#Completed: 426 of 426 jobs
#Average job time:                3423s      57.05m     0.95h    0.04d
#Longest finished job:            7504s     125.07m     2.08h    0.09d
#Submission to last job:         17509s     291.82m     4.86h    0.20d

    # Lift up the split-scaffold .out's to scaffold .out's
    ssh kkstore02
    cd /cluster/data/droGri1
    foreach f (RMOut/*.fa.out)
      liftUp $f:r:r.scaf.out jkStuff/scaffoldsSplit.lft warn $f > /dev/null
    end
    # Make a consolidated scaffold .out file too:
    head -3 RMOut/chunk_00.fa.out > RMOut/scaffolds.fa.out
    foreach f (RMOut/chunk*.scaf.out)
      tail +4 $f >> RMOut/scaffolds.fa.out 
    end
    # Load the .out files into the database with:
    ssh hgwdev
    hgLoadOut droGri1 /cluster/data/droGri1/RMOut/scaffolds.fa.out
    # hgLoadOut made a "scaffolds_rmsk" table even with -table=rmsk, 
    # but we want a non-split with no prefix table:
    hgsql droGri1 -e 'rename table scaffolds_rmsk to rmsk'
    # Fix up the indices too:
    hgsql droGri1 -e 'drop index bin       on rmsk; \
                  drop index genoStart on rmsk; \
                  drop index genoEnd   on rmsk; \
                  create index bin       on rmsk (genoName(12), bin); \
                  create index genoStart on rmsk (genoName(12), genoStart);'


# EXTRACTING GAP INFO FROM BLOCKS OF NS (DONE 8/4/05 angie)
    ssh kkstore02
    mkdir /cluster/data/droGri1/bed/fakeAgp
    cd /cluster/data/droGri1/bed/fakeAgp
    faGapSizes ../../scaffolds.fa \
        -niceSizes=5,10,20,25,30,40,50,100,250,500,1000,10000,100000
    # A disproportionately large number of gaps are exactly 25bp long, so
    # hgFakeAgp's default -minContigGap of 25 will be fine.  
    hgFakeAgp ../../scaffolds.fa fake.agp
    ssh hgwdev
    hgLoadGap -unsplit droGri1 /cluster/data/droGri1/bed/fakeAgp/fake.agp


# SIMPLE REPEATS (TRF) (DONE 8/4/05 angie)
    ssh kolossus
    mkdir /cluster/data/droGri1/bed/simpleRepeat
    cd /cluster/data/droGri1/bed/simpleRepeat
    nice trfBig -trf=/cluster/bin/i386/trf \
      ../../scaffolds.fa \
      /dev/null -bedAt=simpleRepeat.bed -tempDir=/tmp \
    |& egrep -v '^(Removed|Tandem|Copyright|Loading|Allocating|Initializing|Computing|Scanning|Freeing)' \
    > trf.log &
    # check on this with
    tail -f trf.log

    # Load this into the database as so
    ssh hgwdev
    hgLoadBed droGri1 simpleRepeat \
      /cluster/data/droGri1/bed/simpleRepeat/simpleRepeat.bed \
      -sqlTable=$HOME/kent/src/hg/lib/simpleRepeat.sql


# FILTER SIMPLE REPEATS (TRF) INTO MASK (DONE 8/4/05 angie)
    # make a filtered version of the trf output: 
    # keep trf's with period <= 12:
    ssh kkstore02
    cd /cluster/data/droGri1/bed/simpleRepeat
    awk '{if ($5 <= 12) print;}' simpleRepeat.bed > trfMask.bed


# MASK FA USING REPEATMASKER AND FILTERED TRF FILES (DONE 8/4/05 angie)
    ssh kkstore02
    cd /cluster/data/droGri1
    maskOutFa -soft scaffolds.fa \
      bed/simpleRepeat/trfMask.bed scaffolds.fa
    maskOutFa -softAdd scaffolds.fa RMOut/scaffolds.fa.out scaffolds.fa
    # Now clean up the unmasked chunks to avoid confusion later.
    rm -r chunks500k


# STORE SEQUENCE AND ASSEMBLY INFORMATION (DONE 8/4/05 angie)
    # Translate to 2bit
    ssh kkstore02
    cd /cluster/data/droGri1
    faToTwoBit scaffolds.fa droGri1.2bit
    # Make chromInfo.tab.
    mkdir bed/chromInfo
    twoBitInfo droGri1.2bit stdout \
    | awk '{printf "%s\t%s\t/gbdb/droGri1/droGri1.2bit\n", $1, $2;}' \
    > bed/chromInfo/chromInfo.tab

    # Make symbolic a link from /gbdb/droGri1/ to the 2bit.
    ssh hgwdev
    mkdir -p /gbdb/droGri1
    ln -s /cluster/data/droGri1/droGri1.2bit /gbdb/droGri1/
    # Load chromInfo table.
    hgsql droGri1 < $HOME/kent/src/hg/lib/chromInfo.sql
    hgsql droGri1 -e 'load data local infile \
      "/cluster/data/droGri1/bed/chromInfo/chromInfo.tab" into table chromInfo'
    # Make chrom.sizes from chromInfo contents and check scaffold count.
    hgsql droGri1 -N -e 'select chrom,size from chromInfo' \
    > /cluster/data/droGri1/chrom.sizes
    wc -l /cluster/data/droGri1/chrom.sizes
#  25052 /cluster/data/droGri1/chrom.sizes


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE (DONE 8/5/05 angie)
    # Warning: genome and organism fields must correspond
    # with defaultDb values
    echo 'INSERT INTO dbDb \
        (name, description, nibPath, organism, \
             defaultPos, active, orderKey, genome, scientificName, \
             htmlPath, hgNearOk, hgPbOk, sourceName) values \
        ("droGri1", "Aug. 2005", "/gbdb/droGri1", "D. grimshawi", \
             "scaffold_0", 1, 57, \
             "D. grimshawi", \
             "Drosophila grimshawi", "/gbdb/droGri1/html/description.html", \
             0, 0, "Agencourt 1 Aug 2005");' \
      | hgsql -h genome-testdb hgcentraltest
    echo 'INSERT INTO defaultDb (genome, name) values ("D. grimshawi", "droGri1");' \
      | hgsql -h genome-testdb hgcentraltest
    hgsql -h genome-testdb hgcentraltest \
      -e 'INSERT INTO genomeClade (genome, clade, priority) values \
            ("D. grimshawi", "insect", 77);'

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~/kent/src/hg/makeDb/trackDb
    cvsup

    # Edit trackDb/makefile to add droGri1 to the DBS variable.
    mkdir drosophila/droGri1
    # Create a simple drosophila/droGri1/description.html file.
    cvs add drosophila/droGri1
    cvs add drosophila/droGri1/description.html
    make update DBS=droGri1 ZOO_DBS=

    # go public on genome-test
    cvs ci makefile
    cvs ci drosophila/droGri1
    mkdir /gbdb/droGri1/html
    # in a clean, updated tree's kent/src/hg/makeDb/trackDb:
    make alpha

    # Also edit makeDb/schema/all.joiner, add new db.


# MAKE GCPERCENT (DONE 8/4/05 angie)
    ssh hgwdev
    mkdir /cluster/data/droGri1/bed/gc5Base
    cd /cluster/data/droGri1/bed/gc5Base
    hgGcPercent -wigOut -doGaps -file=stdout -win=5 -verbose=2 droGri1 \
       /cluster/data/droGri1 | wigEncode stdin gc5Base.wig gc5Base.wib
    mkdir /gbdb/droGri1/wib
    ln -s `pwd`/gc5Base.wib /gbdb/droGri1/wib
    hgLoadWiggle -pathPrefix=/gbdb/droGri1/wib droGri1 gc5Base gc5Base.wig


# PUT SEQUENCE ON /ISCRATCH FOR BLASTZ (DONE 8/4/05 angie)
    # First, agglomerate small scaffolds into chunks of ~500k median:
    ssh kkstore02
    cd /cluster/data/droGri1
    mkdir chunks
    faSplit about scaffolds.fa 500000 chunks/chunk_
    ssh kkr1u00
    mkdir /iscratch/i/droGri1
    rsync -av /cluster/data/droGri1/chunks /iscratch/i/droGri1/
    rsync -av /cluster/data/droGri1/droGri1.2bit /iscratch/i/droGri1/
    iSync


# PRODUCING GENSCAN PREDICTIONS (DONE 8/5/05 angie)
    ssh kkstore02
    # Make hard-masked scaffolds and split up for processing:
    cd /cluster/data/droGri1
    maskOutFa scaffolds.fa hard scaffolds.fa.masked
    mkdir chunksHardMasked
    faSplit about scaffolds.fa.masked 500000 chunksHardMasked/chunk_
    mkdir /cluster/data/droGri1/bed/genscan
    cd /cluster/data/droGri1/bed/genscan
    # Check out hg3rdParty/genscanlinux to get latest genscan:
    cvs co hg3rdParty/genscanlinux
    # Make 3 subdirectories for genscan to put their output files in
    mkdir gtf pep subopt
    ls -1S ../../chunksHardMasked/chunk*.fa > chunks.list
    cat << '_EOF_' > gsub
#LOOP
gsBig {check in line+ $(path1)} {check out line gtf/$(root1).gtf} -trans={check out line pep/$(root1).pep} -subopt={check out line subopt/$(root1).bed} -exe=hg3rdParty/genscanlinux/genscan -par=hg3rdParty/genscanlinux/HumanIso.smat -tmp=/tmp -window=2400000
#ENDLOOP
'_EOF_'
    # << this line keeps emacs coloring happy
    ssh kki
    cd /cluster/data/droGri1/bed/genscan
    gensub2 chunks.list single gsub jobList
    para make jobList
    para time
#Completed: 208 of 208 jobs
#Average job time:                  40s       0.67m     0.01h    0.00d
#Longest finished job:             446s       7.43m     0.12h    0.01d
#Submission to last job:           602s      10.03m     0.17h    0.01d

    # If there are crashes, diagnose with "para problems".  
    # If a job crashes due to genscan running out of memory, re-run it 
    # manually with "-window=1200000" instead of "-window=2400000".
    
    # Concatenate scaffold-level results:
    ssh kkstore02
    cd /cluster/data/droGri1/bed/genscan
    cat gtf/*.gtf > genscan.gtf
    cat subopt/*.bed > genscanSubopt.bed
    cat pep/*.pep > genscan.pep
    # Clean up:
    rm -r /cluster/data/droGri1/chunksHardMasked

    # Load into the database as so:
    ssh hgwdev
    cd /cluster/data/droGri1/bed/genscan
    ldHgGene -gtf droGri1 genscan genscan.gtf
    hgPepPred droGri1 generic genscanPep genscan.pep
    hgLoadBed droGri1 genscanSubopt genscanSubopt.bed


# MAKE DOWNLOADABLE FILES (DONE 8/5/05 angie)
    ssh kkstore02
    mkdir /cluster/data/droGri1/zips
    cd /cluster/data/droGri1
    gzip -c RMOut/scaffolds.fa.out > zips/scaffoldOut.gz
    gzip -c scaffolds.fa > zips/scaffoldFa.gz
    gzip -c scaffolds.fa.masked > zips/scaffoldFaMasked.gz
    gzip -c bed/simpleRepeat/trfMask.bed > zips/scaffoldTrf.gz
    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/droGri1
    cd /usr/local/apache/htdocs/goldenPath/droGri1
    mkdir bigZips database
    # Create README.txt files in bigZips/ and database/ to explain the files.
    cd bigZips
    ln -s /cluster/data/droGri1/zips/*.gz .
    nice md5sum *.gz > md5sum.txt


# MAKE 11.OOC FILE FOR BLAT (DONE 8/8/05 angie)
    # Use -repMatch=100 (based on size -- for human we use 1024, and 
    # fly size is ~4.4% of human judging by gapless dm1 genome size from 
    # featureBits -- we would use 45, but bump that up a bit to be more 
    # conservative).
    ssh kkr1u00
    mkdir /cluster/bluearc/droGri1
    blat /cluster/data/droGri1/droGri1.2bit /dev/null /dev/null -tileSize=11 \
      -makeOoc=/cluster/bluearc/droGri1/11.ooc -repMatch=100
#Wrote 19750 overused 11-mers to /cluster/bluearc/droGri1/11.ooc
    cp -p /cluster/bluearc/droGri1/*.ooc /iscratch/i/droGri1/
    iSync


# AUTO UPDATE GENBANK MRNA RUN (DONE 8/11/05 angie)
    ssh hgwdev
    # Update genbank config and source in CVS:
    cd ~/kent/src/hg/makeDb/genbank
    cvsup .

    # Edit etc/genbank.conf and add these lines (note scaffold-browser settings):
# droGri1 (D. grimshawi)
droGri1.genome = /iscratch/i/droGri1/droGri1.2bit
droGri1.mondoTwoBitParts = 100
droGri1.lift = no
droGri1.refseq.mrna.native.load = no
droGri1.refseq.mrna.xeno.load = yes
droGri1.refseq.mrna.xeno.pslReps = -minCover=0.15 -minAli=0.75 -nearTop=0.005
# GenBank has no D. grimshawi mRNAs nor ESTs at this point... that may change.
droGri1.genbank.mrna.native.load = no
droGri1.genbank.mrna.xeno.load = yes
droGri1.genbank.est.native.load = no
droGri1.genbank.est.xeno.load = no
droGri1.downloadDir = droGri1
droGri1.perChromTables = no

    cvs ci etc/genbank.conf
    # Since D. grimshawi is a new species for us, edit src/lib/gbGenome.c.  
    # Pick some other browser species, & monkey-see monkey-do.  
    cvs diff src/lib/gbGenome.c
    make
    cvs ci src/lib/gbGenome.c
    # Edit src/align/gbBlat to add /iscratch/i/droGri1/11.ooc
    cvs diff src/align/gbBlat
    make
    cvs ci src/align/gbBlat

    # Install to /cluster/data/genbank:
    make install-server

    ssh eieio
    cd /cluster/data/genbank
    # This is an -initial run, (xeno) RefSeq only:
    nice bin/gbAlignStep -srcDb=refseq -type=mrna -initial droGri1 &
    tail -f [its logfile]
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad droGri1
    featureBits droGri1 xenoRefGene
#11126253 bases of 214363807 (5.190%) in intersection
    # Clean up:
    rm -rf work/initial.droGri1

    # This is an -initial run, mRNA only:
    nice bin/gbAlignStep -srcDb=genbank -type=mrna -initial droGri1 &
    tail -f [its logfile]
    # Load results:
    ssh hgwdev
    cd /cluster/data/genbank
    nice bin/gbDbLoadStep -verbose=1 -drop -initialLoad droGri1
    featureBits droGri1 xenoMrna
#16072365 bases of 214363807 (7.498%) in intersection
    # Clean up:
    rm -rf work/initial.droGri1


# SWAP CHAINS FROM DM2, BUILD NETS ETC. (DONE 8/9/05 angie)
    mkdir /cluster/data/droGri1/bed/blastz.dm2.swap
    cd /cluster/data/droGri1/bed/blastz.dm2.swap
    doBlastzChainNet.pl -swap /cluster/data/dm2/bed/blastz.droGri1/DEF \
      >& do.log
    echo "check /cluster/data/droGri1/bed/blastz.dm2.swap/do.log" \
    | mail -s "check do.log" $USER
    # Add {chain,net}Dm2 to trackDb.ra if necessary.


