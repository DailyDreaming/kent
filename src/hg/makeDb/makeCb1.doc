#!/bin/csh -f # set emacs mode
exit; # don't actually run this like a script :)

# This file describes how to make the browser database for the
# worm C. briggsae
# Currently 2003-05-20 this file is in a HIGH state of flux as it is being
# worked out.

DOWNLOAD SEQUENCE (DONE 2003-05-20 - Hiram)

    ssh eieio
    mkdir -p /cluster/store4/worm/cb1/sanger
    cd /cluster/store4/worm/cb1/sanger
    wget -o cb1.fetch.log -r -l1 --no-directories \
	ftp://ftp.sanger.ac.uk/pub/wormbase/cbriggsae/cb25.agp8/
#   Takes about eight minutes
#   These files seem to have not been updated since July 2002
#   Check what you received:
    ls
# cb1.fetch.log                    cb25.agp8.gff.tar.gz
# cb25.agp8.agp.gz                 cb25.agp8.reads.placed.gz
# cb25.agp8.contigs.fasta.gz       cb25.agp8.supercontigs.fasta.gz
# cb25.agp8.contigs.fasta.qual.gz  cb25.agp8.supercontigs.fasta.qual.gz
# cb25.agp8.fasta.gz               README

#   get out of this download data directory, and create your home symlink
#	shortcut
    cd ..
    ln -s /cluster/store4/worm/cb1 ~/cb1
    cd ~/cb1
#   create chromosome subdirectory and populate it
    mkdir Un
    # unzip the ultra contig file
    zcat sanger/cb25.agp8.fasta.gz > cb25.agp8.ultra.fa
    # create an artifical chrUn agp file:  (does 1000 N gaps)
    rm -f cb25.agp8.ultra.agp Un
    scaffoldFaToAgp cb25.agp8.ultra.fa
    # and create the artifical chrUn.fa file:  (does 1000 N gaps)
    ~hiram/bin/fa2chrUn.pl cb25.agp8.ultra.fa > Un/chrUn.fa
    # create nib file:
    mkdir nib
    faToNib Un/chrUn.fa nib/chrUn.nib
# Writing 109024926 bases in 54512471 bytes

CREATING DATABASE (DONE 2003-05-20 - Hiram)

    # Create the database.
    ssh hgwdev
    echo 'create database cb1' | hgsql ''
    # if you need to delete that database:  !!! WILL DELETE EVERYTHING
    # !!!
        echo 'drop database cb1' | hgsql cb1
    # Use df to make sure there is at least 5 gig free on
    df -h /var/lib/mysql

CREATING GRP TABLE FOR TRACK GROUPING (DONE 2003-05-20 - Hiram)
    ssh hgwdev
    #  the following command copies all the data from the table
    #   grp in the database rn1 to our new database cb1
    echo "create table grp (PRIMARY KEY(NAME)) select * from rn1.grp" \
      | hgsql cb1
    # if you need to delete that table:   !!! WILL DELETE ALL grp data
    # !!!
        echo 'drop table grp;' | hgsql cb1

STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE 2003-05-20 - Hiram)

    # Make symbolic links from /gbdb/cb1/nib to the real nibs.
    ssh hgwdev
    mkdir -p /gbdb/cb1/nib
    foreach f (/cluster/store4/worm/cb1/nib/*.nib)
      ln -s $f /gbdb/cb1/nib
    end
    # Load /gbdb/cb1/nib paths into database and save size info.
    hgsql cb1  < ~/kent/src/hg/lib/chromInfo.sql
    # if you need to delete that table:   !!! DELETES ALL DATA IN TABLE
    # !!!
        echo 'drop table chromInfo;' | hgsql cb1
    cd ~/cb1
    hgNibSeq -preMadeNib cb1 /gbdb/cb1/nib Un/chrUn.fa
# Processing Un/chrUn.fa to /gbdb/cb1/nib/chrUn.nib
# 109024926 total bases
#   Verify the hgNibSeq load functioned OK: 
    echo "select chrom,size from chromInfo" | hgsql -N cb1 > chrom.sizes
    cat chrom.sizes
#   Typical contents of chrom.sizes:
# chrUn   109024926

# Set up relational mrna tables.
    hgLoadRna new cb1
    # that created a bunch of tables.  If you need to delete them:
        echo 'drop table author; \
drop table cds; drop table cell; drop table description; \
drop table development; drop table extFile; drop table geneName; \
drop table history; drop table keyword; drop table library; drop table
mrna; \
drop table mrnaClone; drop table organism; drop table productName; \
drop table seq; drop table sex; drop table source; drop table tissue;' \
        | hgsql cb1


MAKE GCPERCENT (DONE 2003-05-20 14:30 - Hiram)
     ssh hgwdev
     mkdir -p /cluster/store4/worm/cb1/bed/gcPercent
     cd /cluster/store4/worm/cb1/bed/gcPercent
     hgsql cb1  < ~/kent/src/hg/lib/gcPercent.sql
    #  If you need to delete that table created
        echo 'drop table gcPercent;' | hgsql cb1;
     hgGcPercent cb1 ../../nib


MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR CB1 (DONE 2002-05-20 - Hiram)
     ssh hgwdev
    echo 'insert into defaultDb values("Caenorhabditis briggsae",
"cb1");' \
      | hgsql -h genome-testdb hgcentraltest
    #  If you need to delete that entry:
        echo 'delete from defaultDb where name="cb1";' \
        | hgsql -h genome-testdb hgcentraltest
    echo 'insert into dbDb values("cb1", "July 2002", \
        "/gbdb/cb1/nib", "worm", "chrUn", 1, 10, \
        "C. briggsae");' \
        | hgsql -h genome-testdb hgcentraltest
    #  If you need to delete that entry:
        echo 'delete from dbDb where name="cb1";' \
        | hgsql -h genome-testdb hgcentraltest
    # Make trackDb table so browser knows what tracks to expect:
    cd ~/kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add cb1 in all the right places and do
    make update
    # before you make alpha you must commit your trackDb/makefile
    # and any other trackDb/worm files
    cvs commit makefile
    make alpha

SIMPLE REPEAT TRACK (DONE 2003-05-20 - 15:46 - Hiram)
    # This TRF run takes about an hour on eieio
    # so instead of binrsyncing and para-running, just do this on eieio:
    ssh eieio
    mkdir ~/cb1/bed/simpleRepeat
    cd ~/cb1/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    touch jobs.csh
    foreach f (/cluster/store4/worm/cb1/Un/chrUn.fa)
      set fout = $f:t:r.bed
      echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf ${f} /dev/null -bedAt=trf/${fout} -tempDir=/tmp" \
        >> jobs.csh
     echo ${f} ${fout}
    end
    tcsh jobs.csh |& tee jobs.log
    wc -l jobs.csh
    ls -1 trf | wc -l

    # When jobs are done,
    # To Load this into the database as so
    ssh hgwdev
    cd ~/cb1/bed/simpleRepeat
    cat trf/chr*.bed > simpleRepeat.bed
    hgLoadBed cb1 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql

Split into contigs for RepeatMasker, BLAT, and other cluster jobs
    ssh eieio
    cd ~cb1
    # it is a little over 100,000,000 bases, thus 100,000 sized chunks
    # produces about 1000 files  (1091 precisely)
    faSplit size Un/chrUn.fa 100000 split/c -lift=split.lft

    # copy those to scratch
    ssh kk
    mkdir -p /scratch/hiram/Cbriggsae
    cd /scratch/hiram/Cbriggsae
    cp -p ~/cb1/split/c*.fa .
    # request push
    
RepeatMasker run
    ssh kk
    cd ~/cb1
    mkdir RMRun
    cd RMRun
    rm -fr RMJobs
    touch RMJobs
    foreach d ( ../split/c*.fa )
      set bname = `basename $d`
      echo /cluster/bin/scripts/RMWorm $d \
	'{'check out line+ $bname.out'}' >> RMJobs
    end
    para create RMJobs
    para try
    para check
    para push

#   STOP HERE - 2003-05-20

MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR CB1 (TODO)
    ssh hgwdev
    echo 'insert into blatServers values("cb1", "blat10", "17778", "1"); \
          insert into blatServers values("cb1", "blat10", "17779", "0");' \
      | hgsql -h genome-testdb hgcentraltest
