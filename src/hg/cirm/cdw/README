Here lies code to implement the CIRM Data Warehouse (CDW).  The CDW is designed to track 
a moderate number (1,000,000's) of big (>1GB) files.  It consists of three parts:
1) A Linux file system with a fairly large block size.
2) A MySQL database with tables tracking
    a) Users (by their email name)
    b) Submits (by date/submitter/hub)
    c) Files (by hub file name and CDW license plate).
    d) Groups and file permissions
    e) Results of automatic quality assurance results on files.

The schema for the database is in lib/*.as, with most of the information in cdw.as. 
There is also a script lib/resetCdw that will delete the existing database and create 
a new one on the test site (hgwdev).  This should be viewed as documentation rather than
as a program to run at this point, since the test database has useful stuff. The programs
that interact with the database directly are in C, and all start with the "cdw" prefix.  
Arguably the most important program is cdwSubmit.  This program takes a tab separated manifest
file that contains a line for each file in the submission, and a tag-storm format metadata
file that describes the experiments the files came from, copies the files into the warehouse
directory, and puts the file into the cdwFile table.  It also adds jobs to a table
for the validation/QA script.

The validation is done asynchronously.  It is driven by the cdwRunDaemon program, which looks
for new rows in the cdwJob table,  and runs them, keeping a configurable number of jobs (currently
14) running in parallel.  The validation is done by a simple linear shell script, cdwQaAgent, 
which calls a number of C programs one after the other.  The first and perhaps most important
of these is cdwMakeValidFile,  which insures that a file is of the format it claims to be in
the manifest, gathers some preliminary statistics on the file, and adds the file to the cdwValidFile
table.  At this point the file will have a name that looks like a license plate, something like
CDW123ABC.

Once the asynchronous validation is complete, a wrangle will check for errors, deal with them
if necessary, and then run a few commands to index and otherwise prepare the data for web display.
The web display program is cdwWebBrowse.


PROCESS DESCRIPTION  (8/13 JK)
-------------------------------
1) cdwSubmit parses manifest.txt and meta.txt inputs and makes sure that the meta tags in the 
manifest exist in the meta.txt. It also checks meta.txt to make sure there are only legal tags
present. It then md5-sums each file. It creates a cdwSubmit table entry. Then it processes each 
file in the manifest sequentially, copying it to the warehouse,  and puts a row for 'cdwQaAgent' 
in the cdwJob table.  
2) cdwDaemon (another instance) notices cdwQaAgent job, and starts it, capturing start/end times and stderr output.  This means the server side validation/automatic QA process typically starts as cdwSubmit is working on copying the next file.
3) cdwQaAgent is just a very small shell script that invokes the next QA steps sequentially.
4) cdwMakeValidFile checks the file format really is what it is supposed to be, and for many file formats will gather statistics such as how many items covering how many bases are in the file.  This information goes into the cdwValidFile table, along with the CIRM license plate.  For fastq files additional information gets stored in the cdwFastqFile table,  and a sample fastq containing just 250,000 reads is made.   These reads get aligned against the target genome to compute the mapRatio.  For fastq files, and files such as BAM and bigBed, that include genomic coordinates,  a sample of 250,000 items is turned into a simple (non-blocked) bed file for later use.  If there is an error during the cdwMakeValidFile phase the cdwValidFile table entry will not be made, and there will be a message posted on the cdwFile errorMessage column.
5) cdwMakePairedEndQa checks for read concordance for faired end fastq files
6) cdwMakeEnrichments will take the sample bed files produced in step 10, and see where it lands relative to all the regions specified (as .bigBed files) in the cdwQaEnrichTarget table for the relevant assembly. It puts the results in the cdwQaEnrich table,  which will have one row for each file/target combination.
7) cdwMakeReplicateQa looks for any files that are in the database already with the same experiment and output type, but a different replicate.  For these it  uses the sample bed files from step 10 to make an entry in the cdwQaPairSampleOverlap table (aka cross-splatter or cross-enrichment analysis).  For bigWig files instead of the cross-enrichment, it does correlations, putting the results in the cdwQaPairCorrelation table.  These correlations are done genome wide, and also restricted to the regions specified as the target in the manifest.
8) cdwMakeContaminationQa runs only on fastq files.  It subsamples the 250,000 read sample down to 100,000 reads,  and aligns these against all organisms specified in the cdwQaContamTarget table.  The mapRatio is that results is stored in the cdwQaContam table, with one entry for each fastq file/target pair.
9) cdwMakeRepeatQa also runs only on fastq files.  (Potentially this could be extended to other files though.)  It aligns the 250,000 read sample against a RepeatMasker library for the organism,  and stores the results in the cdwQaRepeat table.  This will have one entry for each major repeat class (LINE, SINE, tRNA, rRNA, etc) that gets hit by the sample, and includes what proportion of reads align to that major repeat class.
10)cdwMakeTrackViz will prepare some file types for visualization in the genome browser, adding
them to the appropriate table, and if necessary creating indexes.

TROUBLE_SHOOTING TIPS (8/17 JK)
--------------------------------
when troubleshooting the CDW,  the first thing to do is use 'ps' to determine if cdwDaemons are running.  There should be at least 1:

        kent      5729     1  0 Aug14 ?        00:00:00 cdwRunDaemon cdw cdwJob 12 /data/www/userdata/cdwQaAgent.fifo -log=cdwQaAgent.

If not, go to:

        production: /data/cirm/cdw/startup
        test: /cluster/home/kent/kent/src/hg/cirm/cdw/lib

and run
        ./restartDaemons

At this point they'll be restarted.  If the daemons are working, the next thing to do is look at the recent entries in the cdwSubmit, cdwSubmitJob and cdwJob tables.   Look in the errorMessage and stderr fields.

SETTING UP THINGS FOR WEB BROWSER APP
---------------------------------------
There's some things that need to happen after the majority of the database is made by the validation
daemon and cdwSubmit.  

o - Run cdwMakeFileTags now to create cdwFileTags table
o - Run cdwTextForIndex to create full text for free index search
o - Run ixIxx to make the full text index in /gbdb
o - You *might* need to run cdwChangeAccess to update the accessibility to make things
    group readable, (or if the access all tag is intended but left off, world readable)

